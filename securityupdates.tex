\documentclass{llncs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[space]{grffile}
\graphicspath{figures/}
\usepackage{import}
\usepackage{url}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{siunitx}
\usepackage{todonotes}%[disable]
\let\OldTodo\todo
\renewcommand{\todo}{\OldTodo}%[inline]}
\newcommand{\todolater}[1]{\todo{#1}}%{}%
\RequirePackage[date=terse, isbn=true, doi=true, url=false, urldate=iso8601, maxbibnames=9, backref=false, backend=bibtex, style=ieee]{biblatex}
\addbibresource{securityupdates.bib}
\renewcommand{\bibfont}{\small}

\AtEveryBibitem{% Clean up the bibtex rather than editing it
 \clearname{editor} % remove editors
}

\input{dastats}
\newcommand{\da}{Device Analyzer}
\input{avostats}
\newcommand{\avo}{AVO}
% Evil hackery to provide an optional argument: https://tex.stackexchange.com/questions/308/different-command-definitions-with-and-without-optional-argument/314#314
\makeatletter
 \def\avovuln{\@ifnextchar[{\@avovulnsspecific}{\@avovulngeneral}}
 \def\@avovulnsspecific[#1]#2{\emph{\href{http://androidvulnerabilities.org/vulnerabilities/#1}{#2}}}
 \def\@avovulngeneral#1{\emph{\href{http://androidvulnerabilities.org/vulnerabilities/#1}{#1}}}
\makeatother
\newcommand{\percMarketShare}{83.6\%~\footnote{\url{http://www.theinquirer.net/inquirer/news/2379036/android-hits-836-percent-marketshare-while-ios-windows-and-blackberry-slide}}}
\newcommand{\daNumDevices}{\daNumOSDevices}
\newcommand{\daDeviceDays}{\daOSTotalDaysData}
% Num versions since \daStartDate
\input{countversions}
\newcommand{\otherProjNum}{\avoNumExternalProjects}%TODO check we are doing the right calculation here and not overcounting

% Blinding function
\newcommand{\identifying}[1]{#1}%{}%
\newcommand{\blindauthors}[1]{#1}%{Paper \#59}%

\begin{document}
\title{The thin blue line:\\what protects my Android device?}


\author{\blindauthors{Daniel~R.~Thomas \and Alastair~R.~Beresford \and Daniel~T.~Wagner \and Andrew~Rice}}
\institute{\blindauthors{Computer Laboratory,
University of Cambridge,
Cambridge, United Kingdom\\
\email{Firstname.Lastname@cl.cam.ac.uk}}}

% Terminology

% Android, Unix, adb
% update, release, patch: what do we actually mean and what relevance does that have to security?
% Device manufacturers
% Network operators
% Device model TODO check
% Device handset TODO check


\maketitle

% Hypothesis
% Attempts at fine grained restrictions on running arbitrary code are hampered by updates for security vulnerabilities not reaching users in a timely fashion.

\begin{abstract}
Modern smartphone operating systems protect users from malicious applications by providing a protected execution environment or sandbox.
This approach relies on the absence of exploits which allow apps to break out of the sandbox.
Many such exploits have been found, and therefore the security of a smartphone operating system relies on the prompt delivery of security updates.
In this paper we quantify the extent to which the security sandbox provided by Android protects devices from malicious apps.
We analysed \da\ data from over \daOSYearsOfData\ years and \daNumOSDevices\ devices and found that on average \daMeanInsecurityPercTwosfNominal\ of devices were exposed to known root privilege vulnerabilities and only \daUpdatednessPercTwosfNominal\ of devices run the most recent version of Android.
Devices apply \daUpdatesPerYearTwosfNominal\ updates each year, less than the rate of critical vulnerability discovery of between \avoVulnsPerYearAllAndroidTwosfNominal\ and \avoVulnsPerYearTwosfNominal\ per year.
\end{abstract}

\section{Introduction}
We show that the security of Android relies on the centralisation of app deployment with Google.
Computer systems which run untrusted code are considered secure if there are strong sandboxing mechanisms which prevent the untrusted code doing dangerous things.
However we show the Android ecosystem is secure even though on average \daMeanInsecurityPercTwosfNominal\ of devices are exposed to known critical vulnerabilities which break the sandboxing mechanisms.
The recurrent advice on keeping computers secure is to install the latest updates yet only \daUpdatednessPercTwosfNominal\ of Android devices run the latest version and the rate of critical vulnerability discovery of between \avoVulnsPerYearAllAndroidTwosfNominal\ and \avoVulnsPerYearTwosfNominal\ per year is higher than the rate of updates being delivered of \daUpdatesPerYearTwosfNominal.
Yet Android malware deployments are not widespread despite the many attempts of malware authors:
in 2012, between 36.7\%~\cite{Zhou2012b} and 40\%~\cite{Zhou2012a} of malware for Android contained exploits designed to enable a malicious app to break the sandbox and thousands of new malware samples are found each year.

Android is protected by many layers of security and while the sandbox is usually broken on most Android devices by known vulnerabilities, the outer layers of protection such as the Google Play store prevent the installation of malicious apps.
The Google Play store provides economic (app developers have to pay to register), technical (Google Bouncer which scans apps) and social (user reviews and reports of malicious software) measures to prevent malicious apps being distributed.
Even users who cannot use Google Play (e.g.\ because they are in China) may still get its `Verify apps' functionality which scans for malicious apps.

The claim of the open source software `bazzar' is that it is more secure because anyone can review the source code and provide fixes~\cite{Raymond1999}.
Yet Android is not a `bazzar' in the way that Debian is because while much of the code is open source and available for the many eyes review, end users cannot easily rebuild the binaries that run on their phones due to the binary blobs and closed source components within them.
Since only manufacturers can do that, rather than any one technically competent user, the availability of updates is controlled by the commercial interests of the manufacturers (and the operators).
Manufacturers do not even provide updates for the length of the contracts under which the users originally bought the phone, despite efforts by the ACLU to persuade the FTC to force them to do so~\cite{Soghoian2013}, and despite the FTC forcing HTC to do so~\cite{FTCHTC2013}.
Since only manufacturers can provide updates, malicious parties cannot do so, if manufacturers promptly provided updates this would improve security, but since they do not, it makes it worse.

However, despite the current low level of malicious software deployment on Android, the high level of vulnerability and the slow deployment of updates is still a cause for concern.
Some users may only be able to use third party app stores or have USB debugging enabled and connect their phone to a malicious machine.
There have also been two remote code execution vulnerabilities in Android, one in the Javascript-to-Java bridge and one in dhcpd which allow a network attacker to run malicious code in a user context, bypassing all the checks on apps and leaving only the sandbox which we show to be vulnerable.

Not all malicious apps need to break the sandbox in order to misbehave.
We focus on the issue of apps breaking out of the sandbox because malware which is able to take full control of a handset can do significantly more harm and is much harder to remove.
Ordinary malware can be uninstalled by the user, or remotely by Google through the Play Store, and returns the device to a secure state. 
Removing an app which has used an exploit to take control of the handset is unlikely to return the device to secure state.
We describe our threat model and three attack vectors in detail in \S\ref{sec:threatmodel}.


In order to determine whether an individual smartphone is exposed to a particular vulnerability, we need to combine vulnerability data with the operating system version string and build number from the handset.
For this we use handset data gathered from \daNumOSDevices\ devices in the \da~\cite{Wagner2013} project.
From this we have determined that since \daStartDate\ on five occasions all Android devices have been exposed to known critical vulnerabilities and that it takes a year for updates to reach most devices, by which time new vulnerabilities have been discovered.


In summary, the contributions of this paper are:
\begin{itemize}
 \item We show that the security of Android relies on the centralisation of app deployment with Google rather than the absence of vulnerabilities in its sandbox
 \item We quantify the Android update ecosystem showing how the OS version distribution changes and the frequency of updates.
 \item We quantify vulnerabilities by determining what proportion of devices they affected and how that changes over time.
 \item We created an open database to collate quantitative information on vulnerabilities which affect Android, and investigate their time-lines.
\end{itemize}

\section{Threat model}
\label{sec:threatmodel}

In this paper we measure whether an attacker can take control of a handset by breaking out of the app sandbox on Android using a known vulnerability.
We consider three attack vectors.
The first attack vector is through the installation of a malicious app on the device.
Android devices support the installation of apps through a number of app marketplaces, email attachments, URLs and via the Android Debug Bridge (ADB).
By default, many Android devices with Google Play installed will prevent the installation of apps from other sources.

Controlling potential sources of app installation is a good security feature because app marketplaces provide additional protection to prevent the listing of malicious apps.
For example, the Google Play marketplace uses Bouncer to automatically analyse apps as well as removing any apps which are reported as malicious.
Nevertheless, Google Play is not immune: 0.02\% of apps are malicious~\cite{Zhou2012a}.
Alternative markets are also popular, particularly in countries such as China where the Google Play is not available. 
In 2012 between 0.20\% and 0.47\% of apps on alternative markets were malicious~\cite{Zhou2012a}.

The second attack vector is to persuade an existing app to download and execute code at runtime.
The most direct method available to an attacker is to upload to a marketplace a seemingly innocent app which contains support for dynamic code loading from a remote server under control of the attacker.
Neither static nor dynamic analysis of this app by the marketplace will uncover any malicious code, since it does exist in the app binary.
Instead the attacker can choose to send a malicious payload directly to the app for execution at a later point in time.
Note that dynamic code loading is not actually needed for this to work -- it just makes the task easier -- since previous work has shown that even on a platform such as iOS, which does not permit dynamic code loading, a Return oriented Programming (ROP)-based attack is relatively easy if the attacker creates an app with carefully crafted flaws~\cite{Wang2013a}.

Support for dynamic code loading on Android also supports the third attack vector in which the attacker injects malicious code directly into existing apps already installed on the handset. 
For example, the addJavascriptInterface vulnerability (CVE-2012-6636) allows Javascript running in an Android WebView to execute arbitrary code in the same process address space as the vulnerable app.
This attack works when: (1) the WebView has the Javascript-to-Java bridge enabled; and (2) the attacker is able to inject a malicious Javascript payload into the network traffic between the phone and the web server. 
Many apps are vulnerable to this type of attack because ad-libraries typically embed adverts into apps by displaying HTML and Javascript inside a WebView with the Javascript-to-Java bridge enabled. 
The fix for the addJavascriptInterface vulnerability breaks backwards compatibility, and therefore apps are only immune to this attack if their target API level is greater than 16 and they are running on an Android device with an OS version of 4.2 or greater.
Our analysis shows that on \daGPAPISeventeenLaterDate, \daGPAPISeventeenEarlierProportion\ of handsets connecting to the Google Play store were still vulnerable to this attack.


\section{Data sources}
\label{sec:background}

We require two sources of data for this study: (1) information on the distribution of installed versions of Android over time and (2) information on the critical vulnerabilities found to affect specific versions of Android.
These two datasets can then be combined to determine the proportion of handsets at risk of attack from specific vulnerabilities for particular periods of time.

Where possible we indicate the uncertainty in our results by presenting them $\pm$ one standard deviation and give results to 3 significant figures, this occasionally results in `$\pm\, 0$' when the standard deviation is small.
This technique cannot account for systematic errors which we explore in \S\ref{sec:representative}.

\subsection{Versions of Android running on devices}

In our analysis we use historical data collected by the \da\ project~\cite{Wagner2013}.
\da\ collects data from study participants who install the Android app from the Google Play store.
Most study participants allow researchers around the world to access a subset of their device data, including the data presented in this paper.

The \da\ app collects a range of metadata from Android devices.\footnote{\url{https://deviceanalyzer.cl.cam.ac.uk/collected.html}}
For this paper, we extracted the build string and API version from the device log each day.
The build string is a user-readable version string.
The API version is a positive integer which increases when new features are added to the API.
Consequently security (bug) fixes do not result in a change in the API version.
Fortunately most (\daOSVersionPercValidLines) entries in the data have a build string of the form `x.y.z opaque\_marker' and so it is possible to extract the Android version number `x.y.z'.
On a large proportion of devices `opaque\_marker' is a well defined build number\footnote{\url{https://source.android.com/source/build-numbers.html}} however different device manufacturers use different schema.
Google provides API version distribution information but not the OS and build version information we need, we verify that the \da\ data is representative in~\S\ref{sec:representative}.

The \da\ project has collected data from \daNumDevices\ devices with a total of \daDeviceDays\footnote{Here we are only counting devices and days for which we have valid OS version data.} device days.
The majority of devices only contribute data for a short period of time, however \daMonthsDevices\ devices have contributed data for more than \daMonths~months.


\subsection{Critical vulnerabilities}
We compiled a list of critical vulnerabilities in Android, containing information on the discovery and publication dates, the versions affected and which versions fixed the problem.
We only looked for critical vulnerabilities such as root vulnerabilities which did not require USB debugging to exploit.
If malicious code exploits a critical vulnerability then it gains control of the device.
Some phones can be `rooted' by enabling USB debugging and using the special privileges of the ADB shell to root the device but only \daAdbEnabledPerc\ of devices have USB debugging enabled.
This is not something that applications running on the phone can exploit to break out of the app sandbox and so we do not include those vulnerabilities.
However there have been reports of Windows malware exploiting this vector.\footnote{\url{http://www.symantec.com/connect/blogs/windows-malware-attempts-infect-android-devices}}
Unfortunately, many published exploits use ADB for convenience and so determining whether the use of ADB is necessary to exploit the vulnerability can be difficult.

Some critical vulnerabilities are not traditional kernel vulnerabilities, for example the discovery of flaws in the verification of signatures on Android applications in February 2013~\cite{Forristal2013} meant that applications could pretend to be signed with system keys and hence gain root equivalent privileges.
On some versions of Android (below version 4.1) malware could use known system-to-root escalation mechanisms but on all versions they have a greatly increased attack area for further privilege escalation and also have the ability to control all user internet traffic (via VPNs), brick the phone, remove and install apps, steal user credentials, read the screen and make as well as receive calls.
The different categories which the vulnerabilities fall into are shown in Table~\ref{tab:andvulns}.
\avoTabAndVulns

We developed and maintain an open platform for filing critical vulnerabilities in a machine readable format, the \href{http://androidvulnerabilities.org/}{AndroidVulnerabilities.org}\footnote{\textbf{Note to reviewers:} we have removed our names and affiliation from the website for this review \textbf{with the exception of the contact page. Please do not visit the contact page until the review cycle has completed.}\vspace{-4em}} (\avo) website.
We seeded it with data from the CVE database, vendor lists, reports from the literature and forums.
In addition, we have received submissions or amendments from \avoNumSubmitters\ individuals.
We collected data between \avoStartDate\ and \avoEndDate\ and so it does not include any information lost before the start of that period.
\avo\ currently contains \avoNumVulnerabilities\ vulnerabilities of which \avoNumVulnAllAndroid\ affect all Android devices and \avoNumVulnSpecific\ are specific to particular devices or device manufacturers.

Unless otherwise stated, we use \daNumVulnsUsed\ vulnerabilities in our analysis as shown in Table~\ref{tab:andvulns}.
We have chosen these vulnerabilities to fit the attack vectors introduced in \S\ref{sec:threatmodel}.
These vulnerabilities affect all Android devices regardless of manufacturer, and as a result our selected vulnerabilities will dominate any security analysis of Android.
In many cases we could not match manufacturer- and model-specific vulnerabilities to individual devices in the \da\ data and therefore attempting to include device-specific vulnerabilities as well would introduce additional uncertainty in our results.
In contrast, with our chosen set of vulnerabilities, our analysis represents a lower-bound on the vulnerability of devices in the \da\ data set.

Tracking vulnerabilities is a manual task as they are not consistently recorded in other databases such as the CVE database.
In addition, the lack of a widely acknowledged unique identifier required manual analysis to identify whether two reports referenced the same vulnerability.
Previous work has assumed ``any security issue of relevance will eventually get a CVE number assigned"~\cite{Frei2010} which is currently not the case for critical Android vulnerabilities.
For some of the vulnerabilities without CVE numbers, Google confirmed that there was no CVE number and that they did not intend to get one, instead providing an internal Android bug number.


\subsection{Lifetime of a vulnerability}

Establishing when a vulnerability starts to pose a threat to users is difficult.
Frei et al.~\cite{Frei2010} propose the definition of the \textbf{time of disclosure}.
This occurs when the information about the vulnerability is available to the from an accepted source.
Unfortunately before we collated this information much of it was not published by an accepted source, even months or years after they had been actively used.

Symantec's 2012 analysis of desktop malware has shown that after public disclosure, exploitation rates increase by 5 orders of magnitude~\cite{Bilge2012} and so from the point of view of widespread danger, the period between public disclosure and the date of the fix being deployed to most devices is the most critical.
However they also show that zero-day vulnerabilities are typically used for 312 days before they are publicly disclosed, often to target particular organisations.

Therefore, we use the earliest of: discovery date, date when reported to be exploited, date of disclosure or date of fix in the source code; as the date at which we consider a vulnerability to start being dangerous.
A breakdown of the type of date used is shown in Table~\ref{tab:andvulns}.


\subsection{Distribution of vulnerabilities}
\begin{figure}
 \centering
 \includegraphics[width=\columnwidth]{figures/vulnerabilities_timeline}
 \caption{Timeline of vulnerabilities. For each vulnerability we show the dates of \textbf{discovery} and, when later, the dates of the first \textbf{fixing release}.}
 \label{fig:vulnerabilities_timeline}
\end{figure}

Figure~\ref{fig:vulnerabilities_timeline} shows the dates of \textbf{discovery} and, when later, the date of the first \textbf{fixing release}.
Some vulnerabilities (\avovuln{levitator}, \avovuln{zergRush}) were fixed in released versions of Android before they were discovered and so are shown as vertical lines, while others were known for months before a version of Android which fixed them was shipped.
During the period in which \da\ data was collected the date when a version of Android with the fix was observed on a \da\ device is taken as the date that version was released.
For vulnerabilities prior to the collection period we estimate the release date using publicly available data.
There is no canonical source of Android release dates, our best guesses and supporting references are available from \avo.

%The discovery dates of our vulnerabilities are not uniform. 
%In particular the data shows a large gap from 2011-10-06 to 2013-02-18 where we do not know of any discoveries of critical vulnerabilities affecting all Android devices.
%The cause of this quiet period is unclear.
%Possible explanations are that: (i) most devices were exposed to known vulnerabilities so there was reason to look for new ones;
%(ii) device manufacturers made it easier to install custom versions of Android, reducing the need for users to root their devices; and
%(iii) device manufacturer specific vulnerabilities (which are not in our analysis here) were easier to find and so attackers looking for vulnerabilities adjusted their focus.


\section{Analysis}
\label{sec:results}
We present the results of our analysis showing that, on average, \daMeanInsecurityPerc\ of Android devices are exposed to critical vulnerabilities and only \daUpdatednessPerc\ run the latest version of Android.
Devices, on average, apply \daUpdatesPerYear\ updates each year less than the rate of critical vulnerability discovery of between \avoVulnsPerYearAllAndroid\ and \avoVulnsPerYear.
\daPercUpdatesDowngrades\ of full version changes are downgrades to older versions.
We describe three analyses, examining the vulnerability of Android devices in general (\S\ref{sec:exp:versionsecurity}), explore the upgrade cycle and vulnerability cycle of the ecosystem (\S\ref{sec:exp:android_ecosystem}) and quantify the updates installed on particular devices (\S\ref{sec:exp:device_updates}).

\subsection{Analysis 1: vulnerability of Android devices}\label{sec:exp:versionsecurity}
\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/proportioninsecure}
\caption{Proportion of devices running insecure, maybe secure and secure versions of Android against time.
The red vertical lines are caused by vulnerabilities being discovered with those which have the biggest impact annotated.
}
\label{fig:proportioninsecure}
\end{figure}
In this analysis we calculate the proportion of Android devices which are exposed to critical vulnerabilities and and discuss how that has changed over time.
In Figure~\ref{fig:proportioninsecure} describes the proportion of Android devices susceptible to at least one critical vulnerability.

\subsubsection{Method} 
To investigate the vulnerability of Android devices, we used the OS version information from \da\ and the vulnerability data from \avo.
The \da\ data was collected between \daStartDate\ and \daEndDate.
The \avo\ data covers the period from \avoFirstDataDate\ to \avoLastDataDate.
For each device we collected daily version data and any vulnerabilities it was exposed to at that time.
We then normalise these totals for each day by dividing through by the total number of devices with version information on that day.

\subsubsection{Results}

Following time from left to right in Figure~\ref{fig:proportioninsecure} we see all devices are initially \emph{maybe secure} (yellow) since \da\ does not have historical data prior to May 2011. This means we cannot distinguish between devices which are running a version of Android which is known to be vulnerable from one which may have received a backported fix.
This demonstrates the importance of a longitudinal study: this type of analysis requires years of data.
Once \avovuln{zergRush} was discovered in October 2011 the most devices are recorded as \emph{insecure} (red) as they were exposed to that vulnerability.
The remaining devices were already running a version of Android which fixed the \avovuln{zergRush} vulnerability and are therefore marked as \emph{secure} (green).
From October 2011 until the discovery of \avovuln[APK_duplicate_file]{APK duplicate file} in February 2013 the graph shows progressive improvement as devices are upgraded.
This means more and more devices are marked as \emph{secure} because they are now running a secure version of Android, or marked as \emph{maybe secure} because they received a minor update which may have contained a backported fix.
From February 2013 onwards regular discovery of critical vulnerabilities ensures that most devices are exposed to known critical vulnerabilities.

This gives us an average exposure to critical vulnerabilities of Android devices of \daMeanInsecurityPerc.

\subsection{Analysis 2: behaviour of the Android ecosystem}\label{sec:exp:android_ecosystem}
In this analysis we examine how the distribution of Andriod OS versions changes over time and the impact that has on how different vulnerabilities affect the security of Android.
We show that some vulnerabilities continue to have a substantial effect long after they have been fixed and the importance of longitudinal studies for determining whether a particular device is exposed to a particular vulnerability.

\subsubsection{Method} As in Analysis 1, we used the version information for each device to calculate which critical vulnerabilities each device was susceptible to on a daily basis.

\subsubsection{Results}
The proportion of devices in the \da\ data running different versions of Android each day is shown in Figure~\ref{fig:norm_os}.\footnote{The anomaly beginning in August 2014 is explained in \S\ref{sec:da_changes}.}
It shows how old versions are gradually replaced by new ones, and the long tail of devices which do not see updates to more recent versions.
This gives a mean proportion of devices running the most recent version of Android is \daUpdatednessPerc.


\begin{figure}[!h]
 \centering
 \includegraphics[width=\textwidth]{figures/da_norm_os}
 \caption{Android versions in \da\ data over time. The anomaly beginning in August 2014 is explained in \S\ref{sec:da_changes}.}
 \label{fig:norm_os}
 \includegraphics[width=\textwidth]{figures/nvulnerabilities_heat.pdf}
 \caption{Proportion of devices affected by different vulnerabilities. The prefix `(maybe)' indicates `maybe secure' and `(definite)' indicates `definitely insecure'. The first few vulnerabilities are all `maybe secure' as we do not have data from before that vulnerability was discovered while later ones are mostly `definitely insecure' as we know no fixing update reached the devices.
 %The change in behaviour after August 2014 is explained in \S\ref{sec:da_changes}
 }
 \label{fig:nvulnerabilities_heat}
\end{figure}

The vulnerabilities devices are exposed to are shown in Figure~\ref{fig:nvulnerabilities_heat}.
For each vulnerability it shows the proportion of devices exposed to that vulnerability and how that changes over time.
The variation of the proportion of devices affected by a vulnerability with time tells us how badly a particular vulnerability affected the Android platform.
In July 2011 the \avovuln[exploid_udev]{exploid} and \avovuln{levitator} vulnerabilities both affect most Android devices, slowly these are fixed as updates roll out and devices are replaced until in January 2013 a much smaller proportion of devices are affected by known vulnerabilities.
However when in February 2013 the first APK signing vulnerability was found which affected all previous versions of Android and even in October 2013 most devices (\daVulnAPKDuplicateFileOctoberPerc) were still vulnerable.
%\begin{figure}%[!b]
%\centering
%\includegraphics[width=\columnwidth]{figures/vulnerabilities}
%\caption{Proportion of devices exposed to each vulnerability with time (1.0 is 100\%)}
%\label{fig:vulnerabilities}
%\end{figure}

In 2013 three vulnerabilities were found in the way which Android verified the signatures on APKs.
These allowed the creation of malicious APKs which appear to be signed as system APKs -- which have root equivalent privileges.
Figure~\ref{fig:nvulnerabilities_heat} shows how the the \emph{APK signing vulnerabilities} affected all devices and took months to get fixed for any device.
However what is perhaps more worrying is the long tail on the \avovuln{Gingerbreak}, \avovuln{levitator}, \avovuln[exploid_udev]{exploid} and \avovuln{zergRush} vulnerabilities which are more dangerous root vulnerabilities (not requiring new APK installation) and which affect a significant proportion of devices years later.
\todo{quantify this long tail and the APK numbers as headline numbers}

\subsection{Analysis 3: Updates to particular devices}\label{sec:exp:device_updates}
Previous graphs summarise data across all the devices, however one of the advantages of the \da\ data is that we can look at what happens to individual devices over time.
This allows us to determine whether newer OS versions are being used because people are buying new phones running newer OS versions or whether existing devices receive updates.

{\begin{figure}[p]
 \centering
 \begin{subfigure}[b]{\columnwidth}
  \includegraphics[width=\columnwidth]{figures/device-data-all-os}
  \caption{OS versions over time. Black lines show where only the build number changed.}
  \label{fig:device_data_os}
 \end{subfigure}
 \begin{subfigure}[b]{\columnwidth}
  \includegraphics[width=\columnwidth]{figures/device-data-all-security}
  \caption{Number of vulnerabilities affecting each device over time}
  \label{fig:device_data_security}
 \end{subfigure}
 \caption{The top \daNumDeviceDataDevices\ devices by days of contribution in the \da\ data. One strip per device handset.}
  \includegraphics[width=\columnwidth]{figures/nw_security_updates.pdf}
 \caption{Proportion of updates each week which (may have) fixed vulnerabilities}
 \label{fig:weekly_security_updates}
\end{figure}}

\subsubsection{Method}
As in Analysis 1, we used the version information for each device to calculate which critical vulnerabilities each device was susceptible to on a daily basis.
We also recorded when the version changed and which versions it changed from and to.
In the \da\ data we have over 1000 devices contributing data in any particular week.\todolater{Use the real average number of devices contributing each week}

However most devices only contribute for a short period of time and so we do not observe updates happening on every device.
Instead we have a hopefully representative sample of updates which happened while \da\ was installed on the devices.
\da\ cannot distinguish between a device being replaced and the \da\ app being removed as while multiple devices can be linked to the same user account, that is a manual process and few users do it.


\subsubsection{Results}

The longitudinal data on the number of vulnerabilities affecting the \daNumDeviceDataDevices\ devices which have contributed the most days of data to \da\ changes over time is shown in Figure~\ref{fig:device_data_security}.
The trend that we saw in Figure~\ref{fig:proportioninsecure} of security improving and then getting worse is also shown here.
It shows how some devices had vulnerabilities, which were fixed, and then further vulnerabilities were discovered, mostly not fixed.
This implies that these devices had been abandoned by the device manufacturer and were not receiving updates, this is confirmed by Figure~\ref{fig:device_data_os} which shows which OS versions those devices were running.
Some devices start off in 2011 exposed to known security vulnerabilities and are still exposed to those and additional ones in 2014.

We recorded \daNumFullVersionUpdates\ update events and found most are upgrades (\daNumUpdatesUpgrades).
While many upgrades are from one version to the next version there are also a fair number (\daNumUpdatesBigUpgrades, \daPercBigUpgradesNominal) which skip more than \daNumUpdatesSkippedBig\ versions.
Surprisingly there are also a small number of downgrade events (\daNumUpdatesDowngrades, \daPercUpdatesDowngradesNominal) when older versions of Android are installed on to devices.
Possible reasons why users are downgrading are to free up space on their device, to make it easier to root or because a new version introduced bugs.

The number of devices getting security updates each week, is shown in Figure~\ref{fig:weekly_security_updates}.
Updates which changed the Android version number so that the number of known vulnerabilities decreased are shown in red.
Updates which changed the build number but not the version number and so might contain a backported fix for a vulnerability are shown in yellow.
Updates which did not fix security vulnerabilities (because there were no known security vulnerabilities in the existing version of Android) are shown in green.

By taking the number of updates observed and the number of device days of data we have collected we can compute the number of updates received by a device per year to be \daUpdatesPerYear.
This compares badly with the number of critical vulnerabilities discovered per year of between \avoVulnsPerYearAllAndroid\ (affecting all Android) and \avoVulnsPerYear\ (including the device manufacturer specific ones).





\section{Threats to validity}
\label{sec:validity}
\subsubsection{Comparing \da\ data with the ground truth}
\label{sec:representative}

The data from \da\ we used to investigate the proportion of devices exposed to different vulnerabilities is the OS version.
Unfortunately there is no ground truth of OS version information.
However Google has published API version information almost every month since December 2009 and we have collated this information.\footnote{\url{http://androidvulnerabilities.org/play/historicplaydashboard}}
While API versions are too coarse grained to use for security update detection they are closely related to OS versions and so if the \da\ data on API versions are similar to the Google data on API versions then the \da\ data on OS versions should be representative.
We compared the data from Google and from \da\ and they appear similar, except for the anomaly discussed later.
We analysed the difference between the API version data from \da\ and Google Play, normalising for days since the API version was released.
This shows that the \da\ data systematically overestimates the prevalence of new API versions and underestimates the prevalence of old API versions (except for API version 17 which was particularly popular in a focused study discussed in the next section and so was temporarily overestimated when an old version).
This means that the OS version information from \da\ is likely to be overestimating the prevalence of new OS versions and hence our results are a conservative estimate of the security of Android.
Since most \da\ users are self selecting and install \da\ because they want to find out more about what their phone is doing or to aid research they may be biased and perhaps more likely to install updates.
This allows us to have confidence in the OS version information.
\todolater{we want a statistical metric to claim this strongly with.}


\subsubsection{The effect of focussed studies on \da}
\label{sec:da_changes}
The \da\ data is mostly generated by devices which have the \da\ app installed because their owner happened to come across the app as there has been no advertising and few other attempts to increase usage.
However two collaborations with network operators to install \da\ on customer devices resulted in large numbers of new \da\ users coming from particular network operators.
One study was conducted in Norway with 654 installs and one in Bangladesh where 2463 users installed \da.
This latter study is responsible for the sudden change in distribution of OS versions in \da\ beginning in August 2014 in Figures \ref{fig:norm_os}, \ref{fig:nvulnerabilities_heat} and \ref{fig:proportioninsecure} as for that period Bangladeshi users contributed over half of the \da\ data.
%We could normalise out the influence of the Bangladeshi users, however they are Android users too and they also need security updates.
To investigate the sensitivity of our results to the Bangladesh study we truncated our data before this study started and found the percentage of vulnerable devices to be 85.6\% rather than \daMeanInsecurityPercNominal, the percentage of devices running the latest version to be 5.71\% rather than \daUpdatednessPercNominal\ and the number of updates per year to be 1.48 rather than \daUpdatesPerYearNominal.
Hence removing this anomaly would have no effect on our main conclusions.

\subsubsection{The selection of vulnerabilities in \avo}
We have not included all the vulnerabilities from \avo. 
In particular, we have not included any device manufacturer specific vulnerabilities, even when these are widespread (such as vulnerabilities in Qualcomm\footnote{Qualcomm is particularly good at publicly disclosing vulnerabilities and the patches which fix them. \url{https://www.codeaurora.org/projects/security-advisories/}} chipsets) because it is difficult to work out which devices are affected.
There also tends to be less public information available about manufacturer-specific vulnerabilities which makes them harder to tie down.

For some other vulnerabilities which might affect all Android devices it is hard to work out which devices are affected.
For example, \avovuln[pty_race]{pty race} is a Linux kernel vulnerability. We found 48 commits which fixed this vulnerability on different branches. On some branches it was also accidentally fixed, and later reintroduced, before finally being fixed properly, and therefore determining which devices were vulnerable relies on knowing where, and on which branch, the kernel code for a specific release was taken from.

For some vulnerabilities the required patch is not in AOSP.
This is despite the fact that some device manufacturers have shipped builds containing the fix.
This makes it difficult to determine whether a specific device is vulnerable.
For \avovuln[RageAgainstTheCage_adb]{RageAgainstTheCage adb} and \avovuln[keystore_buffer]{keystore buffer} vulnerabilities we do not have sufficient data to determine whether they fit one of our attack vectors as the former may require physical ADB access and the latter may be thwarted by the sandbox.
However a sensitivity analysis showed that those two vulnerabilities make little difference to our results.

\subsubsection{Limitations}
We still do not know where new versions of Android come from.
Over time newer versions of Android come to dominate, but quantifying the proportion due to new phone purchases verses the proportion due to updates of existing devices is unknown.
Device Analyzer is the only available large data set we know of with longitudinal traces of Android OS version strings.
Unfortunately this data set only records \daNumUpdatesUpgrades\ upgrades which, broken down over \daOSMonthsOfData\ months and \daNumSigOSVersions\ OS versions is only \daUpdatesPerMonthPerVersion\ updates per version per month. This is not enough to build a statistically significant prediction of the expected transition to newer versions of Android.

 
\section{Related work}
\label{sec:related}
Using the methods and data described in this paper we have determined that, on average, \daMeanInsecurityPerc\ of devices were exposed to known critical vulnerabilities between 2011 and 2015.
Felt et al.\ studied 6 Android handsets in 2011 and found they were exposed to root vulnerabilities at least 74\% of the time~\cite{Felt2011}.
Our approach differs from their study because they used data from 6 handsets and assumed the best possible update distribution, while our work is based on a large sample of devices tracking the actual update distribution.
Nevertheless, our own analysis as well as comparison with their work suggests protection against critical vulnerabilities has not improved significantly over the last 4 years. 
Felt et al.\ also found that 4 of the 46 malware samples (8\%) they analysed contained root exploits, much lower than rates found in later (larger) studies which found rates of 36.7\%~\cite{Zhou2012b} and 40\%~\cite{Zhou2012a} in 2012.

Currently, finding and exploiting vulnerabilities is typically a time-consuming manual process.
Therefore an attacker has to invest significant human resource to first find a bug and then write code to exploit the vulnerability.
To reduce the effort involved in finding a bug, attackers can look at security-related commits made to open source repositories.
Attackers have taken this approach for the Firefox web browser~\cite{Barth2011}.
Google does not release updates to the Android source code until after the release of the relevant update.
This reduces the time available for an attacker to exploit a vulnerability by looking at security updates disclosed in the source code repository.
Reducing it from, the interval between the commit of the first fix and the fix being deployed to most devices, to the interval between the first fixing release and the fix being deployed to most devices; unfortunately this can still take months or years.
For example, the zergRush vulnerability was fixed in a release before it was publicly discovered but it still took 27 months for 90\% of the devices in our study to be definitely fixed\footnote{Definitely fixed is 1 $-$ (definitely insecure + maybe secure), maybe fixed is 1 $-$ definitely insecure} (25 months for 90\% of devices maybe fixed).

Brumley et al. has shown it is possible to automatically generate exploits from binary fixes, for example by using security updates issued by manufacturers~\cite{Brumley2008}. 
Similarly, the Woodpecker tool automatically finds permission leaks in stock Android phone images~\cite{Grace2012}.
Once such automated techniques mature, it will become even more important to provide security updates promptly to every Android device in the ecosystem because an attacker can turn the contents of a released fix into an exploit in a matter of minutes or hours.

Security in depth is also a useful strategy.
In this regard, iOS provides additional safeguards beyond those used in Android, including a pre-distribution code review, mandatory code-signing by the manufacturer, and (with the important exception of ROP-based attacks~\cite{Wang2013a}) the technical prohibition of dynamic code loading by an app.
These features, as well as Address Space Layout Randomisation (ASLR) and mandatory access controls, has resulted in a lower level of malware affecting iOS when compared to Android~\cite{Felt2011}.

There are continuing efforts to reduce the impact of critical vulnerabilities, both in Android and elsewhere.
SEAndroid~\cite{Smalley2013} which is included in Android from version 4.1~\cite{jelly-bean-release} claimed to prevent some root vulnerabilities and to reduce the impact of others.
Capability based enforcement systems such as Capsicum~\cite{Watson2010} substantially reduce the capabilities that an exploit has to try and gain increased privilege with and could be included in Linux\footnote{\url{https://github.com/google/capsicum-linux}} and hence Android.

Rather than fixing critical vulnerabilities, security can be obtained by detecting malicious apps and preventing their installation or execution.
Detection strategies include RiskRanker, which classified 3\,281 out of 118\,318 apps (2.8\%) as risky of which 718 (22\%) were malware and 322 (10\%) were previously unknown malware, an infection rate of 0.6\% across multiple markets~\cite{Grace2012a}.
DroidRanger also analysed apps finding 148 out of 182\,823 apps (0.08\%) to be malicious across multiple markets of which 29 were previously unknown~\cite{Zhou2012a}.
%DroidRanger: It used permission-based behavioural fingerprinting which looked at the permissions of known malware and heuristic-based filtering -- dynamic loading of both Dalvik and native code.
A common technique used by attackers is to include malicious code in repackaged popular apps. 
AnDarwin uses this insight to detect similar apps, and found 169 out of 265\,359 of all apps studied (0.06\%) were malicious clones~\cite{Crussell2013}.
%AnDarwin: It used clustering based on semantic vectors derived from the program dependence graphs to detect similar apps.

Unfortunately, whilst these tools were successful in finding critical vulnerabilities, such techniques are not perfect.
The Malware Genome project collected 1\,260 malware samples from 2010--2011~\cite{Zhou2012b} and found a best case anti-malware detection rate of 79.6\%.
Similarly, DroidChameleon found that antivirus products could not detect malware if the binary was automatically permuted~\cite{Rastogi2013}.
Therefore detecting risky apps which might contain critical vulnerabilities is a useful tool, but it does not replace the need to provide security updates.

%All these app analysis projects have been hampered by the difficulty of obtaining full datasets of Android apps as Google does not make these available (and researchers who automatically download them violate Google's Terms of Service).
%PlayDrone was a particularly effective project which circumvented Google's protective measures and downloaded over 1\,100\,000 apps from Google Play, allowing an in depth analysis~\cite{Viennot2014}.


The percentage of Android devices running the most recent version (\daUpdatednessPerc) compares unfavourably with the rate ($>90$\%) for Windows XP SP2 computers contacting the Microsoft update servers~\cite{Gkantsidis2006}.
A simple numerical comparison is unfair because only one major OS version was considered in the Microsoft analysis, and data was only collected from computers which contacted the update server, although this was the default.
More recent data demonstrates the difficulty of upgrading computers between major OS versions, with 27\% of Windows computers running Windows XP in July 2014,\footnote{\url{https://archive.today/PLGxn}} four months after Windows XP stopped receiving security updates.



\section{Conclusion}
\label{sec:conclusion}
We have investigated the security of the Android operating system with respect to security updates.
Android attempts to provide good security to end users through sandboxing apps.
However the latency in the security update process means that on average \daMeanInsecurityPerc\ of Android devices are exposed to known critical vulnerabilities which break out of the sandbox and only \daUpdatednessPerc\ of devices run the latest version of Android.
Devices apply \daUpdatesPerYear\ updates each year less than the rate of critical vulnerability discovery of between \avoVulnsPerYearAllAndroid\ and \avoVulnsPerYear.

\identifying{
\section*{Acknowledgements}
Thanks to Richard Clayton, the mobile security reading group and Anil Madhavapeddy for reading drafts.
Thanks to David Robertson for advice on statistical analysis.
Thanks to Laurent Simon, Thomas Coudray, Adrian Taylor, Justin Case, Giant Pune and Khilan Gudka for reporting vulnerabilities in Android.
This work was partly funded by the EPSRC and Google but the the work presented here does not necessarily reflect their views.
}

\printbibliography



\end{document}
