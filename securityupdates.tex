\documentclass[conference,a4paper,twoside]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[space]{grffile}
\graphicspath{figures/}
\usepackage{import}
\usepackage{url}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{siunitx}
\usepackage[disable]{todonotes}
\let\OldTodo\todo
\renewcommand{\todo}{\OldTodo[inline]}
\newcommand{\todolater}[1]{}%\todo
\RequirePackage[date=terse, isbn=true, doi=true, url=false, urldate=iso8601, maxbibnames=9, backref=false, backend=bibtex, style=ieee]{biblatex}
\addbibresource{securityupdates.bib}
\renewcommand{\bibfont}{\small}

\AtEveryBibitem{% Clean up the bibtex rather than editing it
 \clearname{editor} % remove editors
}

\author{Daniel R.\ Thomas, Alastair R.\ Beresford, Daniel T.\ Wagner and Andrew Rice}

\input{dastats}
\newcommand{\da}{Device Analyzer}
\newcommand{\dafoot}{\textsuperscript{\ref{foot:dadata}}}
\input{avostats}
\newcommand{\avo}{\texttt{androidvulnerabilities.org}}
\newcommand{\percMarketShare}{83.6\%~\footnote{\url{http://www.theinquirer.net/inquirer/news/2379036/android-hits-836-percent-marketshare-while-ios-windows-and-blackberry-slide}}}
\newcommand{\daNumDevices}{\daNumOSDevices}
\newcommand{\daDeviceDays}{\daOSTotalDaysData}
% Num versions since \daStartDate
\input{countversions}
\newcommand{\otherProjNum}{\avoNumExternalProjects}%TODO check we are doing the right calculation here and not overcounting

% Blinding function
\newcommand{\identifying}[1]{}%{#1}%
\newcommand{\blindauthors}[1]{Paper \#59}%{#1}%

\begin{document}
\title{Timeliness of security updates for Android}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\blindauthors{
\IEEEauthorblockN{Daniel R. Thomas,
Daniel T. Wagner,
Alastair R. Beresford,
Andrew Rice}
\IEEEauthorblockA{
Computer Laboratory\\
University of Cambridge\\
Cambridge, United Kingdom\\
Firstname.Lastname@cl.cam.ac.uk
}
}
}

% Terminology

% Android, Unix, adb
% update, release, patch: what do we actually mean and what relevance does that have to security?
% Device manufacturers
% Network operators
% Device model TODO check
% Device handset TODO check


\maketitle

% Hypothesis
% Attempts at fine grained restrictions on running arbitrary code are hampered by updates for security vulnerabilities not reaching users in a timely fashion.

\begin{abstract}
Modern smartphone operating systems protect users from malicious applications by providing a protected execution environment or sandbox.
This approach relies on the absence of active exploits which allow apps to break out of the sandbox.
Many such exploits have been found, and therefore the security of a smartphone operating system relies on the prompt delivery of security updates.
In this paper we tease apart the Android software ecosystem and quantify the extent to which the security sandbox provided by Android protects devices from malicious apps.
We analysed \da\ data from over \daOSYearsOfData\ years and \daNumOSDevices\ devices and found that on average \daMeanInsecurityPercNominal\ of devices were exposed to known root privilege vulnerabilities and only \daUpdatednessPercNominal\ of devices run the most recent version of Android.
We find there is significant variability in the timely delivery of security updates across different device manufacturers and mobile network operators, and we define a security metric to rank the performance of device manufacturers and network operators in our data set.
\end{abstract}

\section{Introduction}
%Android is the most popular smartphone operating system today with \percMarketShare\ marketshare.

Support for third-party apps is a key feature of modern smartphone operating systems.
Such apps are written by many developers from a wide range of backgrounds, which means neither operating system vendors nor users can fully trust app developers.
Therefore, in order to secure personal data and prevent theft, such as the sending of premium-rate text messages, operating system vendors provide a protected execution environment, or \emph{sandbox}, for apps.

In this paper we quantify the extent to which the app sandbox provided by Android protects devices from malicious apps attempting to gain control over the entire handset.
%We have analysed Android because it is the most popular smartphone operating system by market share (~\percMarketShare) and 
Previous research has shown that in 2012, between 36.7\%~\cite{Zhou2012b} and 40\%~\cite{Zhou2012a} of malware for Android contained exploits designed to enable a malicious app to break the sandbox.
What is not known however is the proportion of Android devices which are vulnerable to these exploits over time.
To the best of our knowledge, this is the first paper to provide detailed numbers.

Not all malicious apps need to break the sandbox in order to misbehave.
Indeed, the above figures suggest the majority of malicious apps do not attempt to do so.
We focus on the issue of apps breaking out of the sandbox because malware which is able to take full control of a handset can do significantly more harm and is much harder to remove.
Ordinary malware can be uninstalled by the user, or remotely by Google through the Play Store, and returns the device to a secure state. 
Removing an app which has used an exploit to take control of the handset is unlikely to return the device to secure state.

The development of Android is distributed among many parties and the security of Android relies on many open source projects, include the Linux kernel, OpenSSL and BouncyCastle as well as Google who build the core platform. 
In addition, device manufacturers (we know of \daNumManufacturers\footnote{\label{foot:dadata}We computed this from the \da~\cite{Wagner2013} data, see \S\ref{sec:android_update_process}.}) and network operators (\daNumOperators\dafoot) may make further modifications before devices are shipped to customers. 
Understanding this ecosystem is important as device manufacturers have introduced additional vulnerabilities in the past~\cite{Grace2012}. 
We present a better understanding of both the ecosystem of Android development and associated vulnerabilities more fully in \S\ref{sec:android_ecosystem}.
 
\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{figures/proportioninsecure}
\caption{Proportion of devices running insecure, maybe insecure and secure versions of Android against time.
The red vertical lines are caused by vulnerabilities being discovered with those which have the biggest impact annotated.
This graph is explained further in \S\ref{sec:exp:versionsecurity}.
}
\label{fig:proportioninsecure}
\end{figure}

In order to determine whether an individual smartphone is vulnerable to a particular exploit, we need to combine vulnerability data with the operating system version string and additional update information from the handset. 
For this we use handset data gathered from \daNumOSDevices\ devices in the \da~\cite{Wagner2013} project.
This analysis allows us to plot the proportion of Android devices in the \da\ data which were running versions of Android known to have vulnerabilities at the time and is shown in Figure~\ref{fig:proportioninsecure}.
The Figure shows the proportion of devices split into three categories: 
(1)~\emph{secure} because they are running a version of Android with no known vulnerabilities; 
(2)~\emph{insecure} because the device was running an insecure version of Android with a build released before the vulnerability was fixed or discovered; and 
(3)~\emph{maybe insecure} because the device is running a version of Android known to be insecure but has received an update which might contain a backported fix as we did not observe that build number until after the vulnerability was known.
Further analysis into the propagation of updates in Android is presented in \S\ref{sec:exp:android_ecosystem}.

It is clear from Figure~\ref{fig:proportioninsecure} that Android devices are often exposed to known security vulnerabilities.
One solution is regulation, and indeed there is ongoing legal action to force network operators to ship updates for security vulnerabilities~\cite{Soghoian2013}.\todolater{Check on the status of this legal action}
Indeed, many smartphones are sold on 12--24 month contracts, and yet our data shows many devices do not receive many security updates (\daUpdatesPerYear\ per year). 
In contrast, Windows XP could be purchased for a one-off payment in October 2001 and received security updates until April 2014.

An alternative to regulation is access to publicly available data. 
Comparative data would provide an incentive to both device manufacturers and network operators to provide updates.
Currently corporate and public sector buyers are encouraged to purchase secure devices, but we have found little concrete guidance on the specific makes and models which provide the best security. 
For example, CESG, which advises the UK government on how to secure its computer systems, recommends picking Android devices from device manufactures which are good at shipping security updates promptly~\cite{CESG2013} but it does not state which device manufacturers these are.
To address this, we developed a scoring system and provide numbers on the historic performance of devices in the \da\ project in~\S\ref{sec:security_scoring}.

%REMOVED BY ARB
%The device manufacturer has little financial incentive to perform this work as they have already sold the device.
%Network operators are cautious because if they ship a broken update then they will get many support requests which is expensive.
%
%In the past users of Microsoft IIS were advised to switch to a different web server due to the frequent discovery of vulnerabilities~\cite{Pescatore2001}.
%This pressure encouraged Microsoft to improve the security of their products~\cite{TODO}.

In summary, the contributions of this paper are:
\begin{itemize}
 \item We characterise the Android update ecosystem, showing how updates flow between entities, and quantify vulnerabilities by determining what proportion of devices they affected and how that changes over time.
 \item We created an open database to collate quantitative information on vulnerabilities which affect Android, and investigate their time-lines.
 \item We measure the security of Android according to three metrics and compare different device manufacturers and device models to allow device purchasers to differentiate between them based on security.
\end{itemize}

\section{Threat model}
\label{sec:threatmodel}

In this paper we measure whether an attacker can take control of a handset by breaking out of the app sandbox on Android using a known vulnerability.
We consider two attack vectors.
The first attack vector is through the installation of a malicious app on the device.
Android devices support the installation of apps through a number of app marketplaces, email attachments, URLs and via the Android Debug Bridge (ADB).
By default, many Android devices with Google Play installed will prevent the installation of apps from other sources.

Controlling potential sources of app installation is a good security feature because app marketplaces provide additional protection to prevent the listing of malicious apps.
For example, the Google Play marketplace uses Bouncer to automatically analyse apps as well as removing any apps which are reported as malicious.
Nevertheless, Google Play is not immune: 0.02\% of apps are malicious~\cite{Zhou2012a}.
Alternative markets are also popular, particularly in countries such as China where the Google Play is not available. 
Previous work has shown that on alternative markets between 0.20\% and 0.47\% of apps are malicious~\cite{Zhou2012a}.

The second attack vector is to persuade an existing app to download and execute code at runtime.
The most direct method available to an attacker is to upload to a marketplace a seemingly innocent app which contains support for dynamic code loading from a remote server under control of the attacker.
Neither static nor dynamic analysis of this app by the marketplace will uncover any malicious code, since it does exist in the app binary.
Instead the attacker can chose to send a malicious payload directly to the app for execution at a later point in time. Note that dynamic code loading is not actually needed for this to work---it just makes the task easier---since previous work has shown that even on a platform such as iOS, which does not permit dynamic code loading, a ROP-based attack is relatively easy if the attacker creates an app with carefully crafted flaws~\cite{}.

Support for dynamic code loading on Android also permits an indirect method where malicious code can be injected directly into existing apps already installed on the handset. 
For example, the addJavascriptInterface vulnerability (CVE-2012-6636) allows Javascript running in an Android WebView to execute arbitrary code in the same process address space as the vulnerable app.
This attack works when: (1) the WebView has the Javascript-to-Java bridge enabled; and (2) the attacker is able to inject a malicious Javascript payload into the network traffic between the phone and the web server. 
Many apps are vulnerable to this type of attack because ad network libraries typically embed adverts into apps by displaying HTML and Javascript inside a WebView with the Javascript-to-Java bridge enabled. 
The fix for the addJavascriptInterface vulnerability breaks backwards compatibility, and therefore apps are only immune to this attack if their target API level is greater than 16 and they are running on an Android device with an OS version of 4.2 or greater.
Later analysis in Figure~\ref{fig:da_api} in this paper shows that 40\% of handsets connecting to the Google Play store are currently vulnerable to this attack.

\section{Data sources}
\label{sec:background}

We require two sources of data for this study: (1) information on the distribution of installed versions of Android over time across the Android ecosystem and (2) information on the critical vulnerabilities found to affect specific versions of Android.
These two datasets can then be combined to determine the proportion of handsets at risk of attack from specific vulnerabilities for particular periods of time.

\subsection{Versions of Android running on devices}

In our analysis we use historical data collected by the \da\ project~\cite{Wagner2013}.
Device Analyzer collects data from study participants who install the project Android app from the Google Play store.
Many participants allow researchers around the world to access a subset of their data.

The \da\ app collects a range of metadata from Android devices.\footnote{\url{https://deviceanalyzer.cl.cam.ac.uk/collected.html}}
For this paper, we extracted the build string and API version on the device each day.
The API version is a positive integer which increases when new features are added to the API.
Consequently security (bug) fixes do not result in a change in the API version.
The build string is a user-readable version string.
Fortunately most (\daOSVersionPercValidLines) entries in the data have a build string of the form `x.y.z opaque\_marker' and so it is possible to extract the Android version number `x.y.z'.
On a large proportion of devices `opaque\_marker' is a well defined build number\footnote{\url{https://source.android.com/source/build-numbers.html}} however different device manufacturers use different schema.

The \da\ project has collected data from \daNumDevices\ devices with a total of \daDeviceDays\footnote{Here we are only counting devices and days for which we have valid OS version data.} device days. The majority of devices only contribute data for a short period of time, however \daMonthsDevices\ devices have contributed data for more than \daMonths~months.

Where possible we indicate the uncertainty in our results by presenting them $\pm$ one standard deviation, this occasionally results in `${} \pm 0$' when the standard deviation is less than the number of significant figures we are reporting.
This technique cannot account for systematic errors and therefore we explore the potential for systematic errors in the \da\ data in \S\ref{sec:representative}.



\subsection{Critical vulnerabilities}

We compiled a list of critical vulnerabilities in Android, containing information on the discovery and publication dates, the versions affected and which versions fixed the problem.
We only looked for critical vulnerabilities such as root vulnerabilities which did not require USB debugging to exploit.
Critical vulnerabilities allow a program to gain privileges equivalent in scope to root.
If an application exploits a critical vulnerability then it gains control of the device.
Some phones can be `rooted' by enabling USB debugging and using the special privileges of the ADB shell to root the device but only \daAdbEnabledPerc\dafoot\ of devices have USB debugging enabled.
This is not something that applications running on the phone can exploit to break out of the app sandbox and so we do not include those vulnerabilities.
Unfortunately, many published exploits use ADB for convenience and so determining whether the use of ADB is necessary to exploit the vulnerability can be difficult.

Some critical vulnerabilities are not traditional kernel vulnerabilities, for example the discovery of flaws in the verification of signatures on Android applications in February 2013~\cite{Forristal2013} meant that applications could pretend to be signed with system keys and hence gain root equivalent privileges.
On some versions of Android (below version 4.1) malware could use known system-to-root escalation mechanisms but on all versions they have a greatly increased attack area for further privilege escalation and also have the ability to control all user internet traffic (via VPNs), brick the phone, remove and install apps, steal user credentials, read the screen and make as well as receive calls.
\todolater{break vulnerabilities down by attack vector?}
\avoTabAndVulns

We developed and maintain an open platform for filing critical vulnerabilities in a machine readable format, \texttt{\url{http://androidvulnerabilities.org/}}.
We seeded it with data from the CVE database, vendor lists, reports from the literature and various forums.
We have received submissions or amendments from \avoNumSubmitters\ individuals.
We collected this data between \avoStartDate\ and \avoEndDate\ and so any information lost before the start of that period cannot be included.
\avo\ currently contains \avoNumVulnerabilities\ vulnerabilities of which \avoNumVulnAllAndroid\ affect all Android devices and \avoNumVulnSpecific\ are specific to particular devices or device manufacturers.
We only use the \daNumVulnsUsed\ vulnerabilities which we have sufficient data to use for this analysis because they affect all Android devices rather than particular device manufacturers and we know enough information about the vulnerability to tie it to the particular versions it affects.
We summarise the \daNumVulnsUsed\ vulnerabilities used for this analysis in Table~\ref{tab:andvulns}.\todolater{We have published full details of the \daNumVulnsUsed\ vulnerabilities used for this analysis in an accompanying technical report~\cite{TODO}}


Tracking vulnerabilities is a manual task as they are not consistently recorded in other databases such as the CVE database and the lack of a widely acknowledged unique identifier made identifying whether two reports referenced the same vulnerability difficult.
Previous work has assumed ``any security issue of relevance will eventually get a CVE number assigned"~\cite{Frei2010} which is currently not the case for critical Android vulnerabilities.
For some of the vulnerabilities without CVE numbers, Google confirmed that there was no CVE number and that they did not intend to get one, instead providing an Android bug number.


\subsection{Lifetime of a vulnerability}

The key events in the lifetime of a vulnerability do not always occur in the same order and are:\\
\textbf{creation} When a vulnerability was created in the source code.\\
\textbf{introducing release} When the first release was made containing the vulnerability.\\
\textbf{discovery} When the vulnerability is first discovered\\
\textbf{exploit} When the vulnerability is first exploited\\
\textbf{disclosure} When the vulnerability is first disclosed.\\ % publically or to a smaller set of people?
\textbf{fix} When a vulnerability was first fixed in the source code.\\
\textbf{fixing release} When the first release containing the fix was made (equivalent to `patch available'~\cite{Frei2010}).\\
\textbf{fix deployed} When the fix has been deployed to a sufficiently large proportion of the population that the vulnerability can be ignored (the ecosystem equivalent to the per instance `patch installed'~\cite{Frei2010}).
\todolater{Does this look nice?}


Establishing when a vulnerability started posing a threat to users is difficult.
Frei et al.~\cite{Frei2010} propose the definition of the {\bf time of disclosure} when the information about the vulnerability is freely available to the public, from a widely accepted and independent source and has been validated by security experts so that it has a risk rating.
Unfortunately before we collated this information much of it was not published by an independent source and lacked risk rating information, even months or years after they had been actively used.
Therefore this measure does not work.

Symantec's 2012 analysis of desktop malware has shown that after public disclosure exploitation rates increase by 5 orders of magnitude~\cite{Bilge2012} and so from the point of view of widespread danger, the period between public disclosure and the update reaching the user's device is the most critical.
However they also show that zero day vulnerabilities are typically used for 312 days before they are publicly disclosed, often to target particular organisations.
Hence when considering vulnerability from the point of view of an organisation which cares about Advanced Persistent Threats, such as those the CESG advice~\cite{CESG2013} is aimed at, the critical period is from when people could have started using the vulnerability to when the update hits the user device.
So for our vulnerability calculations we use the earliest date we can find recorded evidence that the vulnerability was known about, even if that knowledge might have been confined to a particular device manufacturer or hobbyist.
%We cannot know if someone reported the vulnerability to the device manufacturer and we do know that various agencies are engaged in widespread monitoring of communications and compromise of civilian infrastructure~\cite{TODO} and so they may know.

There are several plausible points from which a vulnerability poses a threat to users.
{\bf Creation} and {\bf introducing release} are the earliest points which could be used but the risk is mostly latent until someone discovers them.
Unfortunately {\bf discovery} is the hardest point to obtain concrete data on as discovery may happen multiple times independently and not all discoverers will report their discovery, for example entities with high value targets may keep databases of unknown vulnerabilities for later use, in which case there is a high risk to potential targets from the never disclosed point of discovery.
However if the discoverer never discloses the vulnerability to anyone or makes any use of it then there is little danger.
The date of first {\bf exploit} is a point when the risk is definitely high, but again a good adversary will not be detected when using such exploits.
The date of first {\bf fix} is, assuming that the fix is deliberate, a point at which the vulnerability is known at least within the organisation performing the fix and frequently implies an earlier discovery and notification by a third party.
It can, for example, be determined from the authored-on date of the fixing commit in the git repository.
Once a {\bf fixing release} has been made then the vulnerability is widely known because it can be reverse engineered from the changes in the release~\cite{Brumley2008}.
When the {\bf fix deployed} to a sufficiently large proportion of devices then the remaining risk is minimal.

Hence we use the earliest date we know about for discovery, exploit, disclosure or fix as the date from which a vulnerability poses a substantial risk to users.
This is shown in Table~\ref{tab:andvulns}.


\subsection{Distribution of vulnerabilities}
\begin{figure}
 \centering
 \includegraphics[width=\columnwidth]{figures/vulnerabilities_timeline}
 \caption{Timeline of vulnerabilities}
 \label{fig:vulnerabilities_timeline}
\end{figure}

The dates of discovery of vulnerabilities in the \avo\ is not uniform.
Figure~\ref{fig:vulnerabilities_timeline} shows the dates of discovery and, when later, the dates when a version of Android which fixed the vulnerability was shipped.
Some vulnerabilities (\emph{levitator}, \emph{zergRush}) were fixed in released versions of Android before they were discovered and so are shown as vertical lines while others were known for months before a version of Android which fixed them was shipped.
During the period in which \da\ data was collected the date when a version of Android with the fix was observed on a \da\ device is taken as the date that version was released.
For vulnerabilities prior to the collection period the release date as best as we can determine is used.
There is no canonical source of Android release dates, our best guesses and supporting references are available from \avo.

This data shows a large gap from 2011-10-06 to 2013-02-18 where we do not know of any discoveries of critical vulnerabilities affecting Android devices.
The cause of this quiet period is unclear.
Possible explanations are: That since most devices were exposed to known vulnerabilities there was no point in looking for new ones (from Figure~\ref{fig:proportioninsecure}).
That device manufacturers made it easier to install custom versions of Android, reducing the need for users to root their devices?
That device manufacturer specific vulnerabilities (which we are ignoring) proved to be easier to find and so people looking for vulnerabilities adjusted their focus.

\section{Android Ecosystem}\label{sec:android_ecosystem}
There is a complex Android ecosystem which creates and distributes updates to Android which fix vulnerabilities.
In this section we rectify the lack of public information about the nature of the Android ecosystem.


\subsection{Android update process}

\label{sec:android_update_process}
\begin{figure}
 \centering
 \def\svgwidth{\columnwidth}
 \import{figures/}{update_ecosystem.pdf_tex}
 \caption{Flow of updates between participants in the Android ecosystem.
 Numbers on edges indicate updates shipped between \daStartDate\ and \daEndDate, numbers in brackets represent number of such entities in our data.
 Dotted arrows indicate flows where we do not know how many updates are being produced as we can't measure those flows directly as they are not public.\todolater{Turn into a sankey diagram}}
 \label{fig:update_ecosystem}
\end{figure}
To understand how vulnerabilities in Android are fixed we must examine the Android update process which we model in Figure~\ref{fig:update_ecosystem}.
There are five entities or groups which contribute towards Android updates: the network operators, the device manufacturers, the hardware developers, Google and the upstream open source projects.
Android builds on various open source projects such as the Linux kernel, the OpenSSL and BouncyCastle cryptography libraries and so can include any compatible versions of those projects, including those which fix security vulnerabilities.
Android also incorporates various drivers for different bits of hardware.
The Android platform is then built on top of those with kernel and userspace components by Google.
The code for each update is kept secret\footnote{\url{https://source.android.com/source/code-lines.html}}\todolater{Can we quantify this keeping the code secret? Is it worth it?} until after the update has been published.
Device manufacturers may receive advance copies in order to prepare handsets.
Then the device manufacturers take the update and customise it before passing it on to the network operator.
The network operator may then make further customisations and do further testing before shipping the update to the Device.
Sometimes device manufactures ship direct to the user, sometimes the device manufacturer and Google collaborate closely for the purpose of a particular phone, such as with Nexus phones, and hence are harder to separate.
Sometimes device manufacturers incorporate upstream open source project releases directly, and sometimes incorrectly -- for example including a broken daily build of sqlite in their release of Android~\cite{Wagner2013}.
\todolater{use statistics from samsung-updates.com -> how many binaries are there per device?}

The numbers of devices (\daNumOSDevices), network operators (\daNumOperators) and device manufacturers (\daNumManufacturers) in Figure~\ref{fig:update_ecosystem} come from the \da\ data.
Device manufacturer and network operator counts were obtained by normalising the results reported by Android to \da\ of the device manufacturer and active network operator.
This normalisation is a manual task involves removing invalid values (such as `manufacturer' or `airplane mode is on'), collating across company name changes (e.g.\ `lge' to `LG'), normalising punctuation, removing extra strings sometimes added such as (`(2g)' or `communications') and mapping some incorrectly placed model names back to their manufacturer.
This normalisation is not perfect and so these are overestimates on the \da\ data but they are likely still underestimates as there will be some device manufacturers and network operators which are not included in the \da\ data.

In Figure~\ref{fig:update_ecosystem} the number of updates received by devices (\daNumFullVersions) is the number of different full version strings observed in \da.
The number of updates shipped by Google (\daNumSigOSVersions) is the number of Android versions reported in \da\ which affected more than \daSigVersionPerc\ of devices for more than \daSigVersionDays\ days.
This significance test is to remove spurious versions recorded in \da\ such as `5.2.0' in 2012 which has still not been released in 2014.

We extracted data on the external projects used in Android and have included this and the scripts which generated it in \avo.
These scripts analysed the Android Open Source Project's source tree to examine the source code of each of the external projects to find the project version associated with each Android version tag on the repository.
There are \avoNumExternalProjects\ external open source projects in Android, contributing \avoTotalExternalLines\ lines of code.\footnote{Lines of code were measured using David A. Wheeler's \texttt{sloccount}.}
We analysed the top \avoNumBigExternalProjects\ by lines of code (\avoBigExternalLinesOfCodePerc\ of the total) and were able to automatically extract the versions of those projects included in different versions of Android for \avoNumAnalysedExternalProjects\ of these (\avoAnalysedExternalLinesOfCodePerc\ of the total).
We found \avoBigExternalTotalVersions\ distinct versions, a median of \avoBigExternalMedianVersions\ and mean of \avoBigExternalMeanVersions\ versions per project.
Android rarely changes the version of external projects it includes.

%An analysis by Vidas et al.~\cite{Vidas2011} of the Android 2.1 to 2.2 update found that it took 11 months from when Google released 2.2 for the last device which they were investigating to get the update.
To compute the latency between upstream releases and their inclusion in Android we scraped the release pages for those projects, to obtain the version numbers and release dates.
This allows us to compute the latency between an upstream project being released and it being included in Android, this is shown in Table~\ref{tab:update_ecosystem}.
The versions included in Android were about half a year old when the first version of Android containing it was released.
\begin{table}
\centering
\normalsize
\begin{tabular}{l|r|r}
Project	&	\# releases	&	latency (days) \\ \hline
linux	&	\linuxNumVersions	&	\linuxMeanUpdateLatency \\
openssl	&	\opensslNumVersions	&	\opensslMeanUpdateLatency \\
bouncycastle	&	\bouncycastleNumVersions	&	\bouncycastleMeanUpdateLatency \\
\end{tabular}
\caption{Flow of updates from upstream projects into Android. Number of updates as in Figure~\ref{fig:update_ecosystem}, latency in days for all pairs of versions we have data on.\todolater{scrape the other 26 websites... is it worth it?}}
\label{tab:update_ecosystem}
\end{table}






\section{Experiments}
\label{sec:results}
We present the results of our analysis showing \daMeanInsecurityPerc\ of devices to have critical vulnerabilities on average.
On average only \daUpdatesPerYear\ updates reach a device each year and \daPercUpdatesDowngrades\ of version changes are downgrades to older versions.
Nexus devices are better than others, \emph{\daSecScoreBestmanufacturer} is the highest scoring device manufacturer and \emph{\daSecScoreBestoperator} is the highest scoring network operator.
%\todo{comparison of nexus update rates with iOS}
We conducted three experiments examining the behaviour of the Android ecosystem as a whole (\S\ref{sec:exp:android_ecosystem}), updates reaching particular devices (\S\ref{sec:exp:device_updates}) and comparisons between different device manufacturers and network operators (\S\ref{sec:exp:security_score}).

%% In an experiment you test a hypothesis, it needs to be clear what the hypothesis is and what the conclusion of the test is

\subsection{Experiment 0: vulnerability of Android devices}\label{sec:exp:versionsecurity}
In Figure~\ref{fig:proportioninsecure} we showed the vulnerability of devices in \da\ to known critical Android vulnerabilities.
Initially the plot is all `maybe insecure' (yellow) as since \da\ does not have historical data from before that point we cannot distinguish between devices which are running a version of Android which is known to be vulnerable but which have a backported fix and those which do not have a backported fix as we do not have data on what builds existed before the vulnerability was discovered.
This shows the importance of a longitudinal study as this analysis requires years of data.
Once \emph{zergRush} was discovered the plot goes mostly `insecure' (red) as most devices were exposed to that vulnerability but some were already running a version of Android which fixed that vulnerability and so from that point until the discovery of \emph{APK duplicate file} the graph shows progressively more `secure' green.
From that point onwards the more regular discovery of critical vulnerabilities ensures that most devices are exposed to known critical vulnerabilities.


\subsection{Experiment 1: behaviour of the Android ecosystem}\label{sec:exp:android_ecosystem}

\subsubsection{Method}
To investigate the behaviour of the Android ecosystem as a whole with respect to Android versions and vulnerabilities we used the OS version information from \da\ and the vulnerability data from \avo.
The \da\ data used here was collected between \daStartDate\ and \daEndDate.
The \avo\ data covers the period from \avoFirstDataDate\ to \avoLastDataDate.
For each device, for every day with version data we record what version it was running and which vulnerabilities it was exposed to at that time (if any).
We then normalise these totals for each day by the total number of devices with version information seen on that day.

\subsubsection{Results}
The proportion of devices in the \da\ data running different versions of Android each day is shown in Figure~\ref{fig:norm_os}.
It shows how old versions are gradually replaced by new ones, and the long tail of devices which do not see updates to more recent versions.

\begin{figure*}
 \centering
 \includegraphics[width=\textwidth]{figures/da_norm_os}
 \caption{Android versions in \da\ data over time. The change in behaviour after August 2014 is explained in \S\ref{sec:da_changes}}
 \label{fig:norm_os}
\end{figure*}

The vulnerabilities devices are exposed to are shown in Figure~\ref{fig:nvulnerabilities_heat}.
For each vulnerability it shows the proportion of devices exposed to that vulnerability and how that changes over time.
The variation of the proportion of devices affected by a vulnerability with time tells us how badly a particular vulnerability affected the Android platform.
In July 2011 at the beginning of the \da\ data the \emph{exploid}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/exploid_udev}} and \emph{levitator}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/levitator}} vulnerabilities both affect most Android devices, slowly these are fixed as updates roll out and devices are replaced until in January 2013 a much smaller proportion of devices are affected by known vulnerabilities.
However when in February 2013 the first APK signing vulnerability was found which affected all previous versions of Android and even in October 2013 most devices (\daVulnAPKDuplicateFileOctoberPerc) were still vulnerable.
%\begin{figure}%[!b]
%\centering
%\includegraphics[width=\columnwidth]{figures/vulnerabilities}
%\caption{Proportion of devices exposed to each vulnerability with time (1.0 is 100\%)}
%\label{fig:vulnerabilities}
%\end{figure}

In 2013 three vulnerabilities were found in the way which Android verified the signatures on APKs.
These allowed the creation of malicious APKs which appear to be signed as system APKs -- which have root equivalent privileges.
Figure~\ref{fig:nvulnerabilities_heat} shows how the the \emph{APK signing vulnerabilities} affected all devices and took months to get fixed for any device.
However what is perhaps more worrying is the long tail on the \emph{Gingerbreak}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/Gingerbreak}}, \emph{levitator}, \emph{exploid} and \emph{zergRush}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/zergRush}} vulnerabilities which are more dangerous root vulnerabilities (not requiring new APK installation) and which still affect a significant proportion of devices years later.


\begin{figure*}
 \includegraphics[width=\textwidth]{figures/nvulnerabilities_heat.pdf}
 \caption{Proportion of devices affected by different vulnerabilities. The prefix `(maybe)' indicates `maybe insecure' and `(definite)' indicates `definitely insecure'. The first few vulnerabilities are all `maybe insecure' as we do not have data from before that vulnerability was discovered while later ones are mostly `definitely insecure' as we know no fixing update reached the devices. The change in behaviour after August 2014 is explained in \S\ref{sec:da_changes}}
 \label{fig:nvulnerabilities_heat}
\end{figure*}


\subsection{Experiment 2: Updates to particular devices}\label{sec:exp:device_updates}
Those graphs summarise data across all the devices, however one of the advantages of the \da\ data is that it allows us to look at what happens to individual devices over time.

\subsubsection{Method}
As in Experiment 1, for each device we used the version information from each day to calculate which vulnerabilities it was vulnerable to that day.
We also recorded when the version changed and which versions it changed from and to.
In the \da\ data we have over 1000 devices contributing data in any particular week.
However most devices only contribute for a short period of time and so we do not observe updates happening on every device.
Instead we have a hopefully representative sample of upgrades which happened while \da\ was installed on the devices.
\da\ cannot distinguish between a device being replaced and the \da\ app being removed as while multiple devices can be linked to the same user account, that is a manual process and few users do it.


\subsubsection{Results}
\begin{figure}
 \centering
 \begin{subfigure}[b]{\columnwidth}
  \includegraphics[width=\columnwidth]{figures/device-data-all-os}
  \caption{OS versions over time. Black vertical lines indicate that the build number changed without changing the OS version at that point.}
  \label{fig:device_data_os}
 \end{subfigure}
 \begin{subfigure}[b]{\columnwidth}
  \includegraphics[width=\columnwidth]{figures/device-data-all-security}
  \caption{Number of vulnerabilities affecting each device over time}
  \label{fig:device_data_security}
 \end{subfigure}
 \caption{The top \daNumDeviceDataDevices\ devices by days of contribution in the \da\ data. One strip per device handset.}
\end{figure}
The longitudinal data on the number of vulnerabilities affecting the \daNumDeviceDataDevices\ devices which have contributed the most days of data to \da\ changes over time is shown in Figure~\ref{fig:device_data_security}.
The trend that we saw in Figure~\ref{fig:proportioninsecure} of security improving and then getting worse is also shown here.
It shows how some devices had vulnerabilities, which were fixed, and then further vulnerabilities were discovered, and for these devices, mostly not fixed.
This implies that these devices had been abandoned by the device manufacturer and were not receiving updates which is confirmed by Figure~\ref{fig:device_data_os} which shows which OS versions those devices were running.
Some devices start off in 2011 exposed to known security vulnerabilities and are still exposed to those and additional ones in 2014.


\begin{figure}
 \includegraphics[width=\columnwidth]{figures/from_to_updates.pdf}
 \caption{Updates between different Android versions in the \da\ data}
 \label{fig:from_to_updates}
\end{figure}
\begin{figure}
 \includegraphics[width=\columnwidth]{figures/nw_security_updates.pdf}
 \caption{Proportion of updates each week which fixed or may have fixed security vulnerabilities}
 \label{fig:weekly_security_updates}
\end{figure}
We recorded update events and Figure~\ref{fig:from_to_updates} shows how devices upgrade between different versions of Android.
Mostly the dark cells are upgrades (above the diagonal) (\daNumUpdatesUpgrades).
While many upgrades are from one version to the next version there are also a fair number (\daNumUpdatesBigUpgrades, \daPercBigUpgrades) which skip more than \daNumUpdatesSkippedBig\ versions.
Surprisingly there are also a small number of downgrade events (\daNumUpdatesDowngrades, \daPercUpdatesDowngrades) when older versions of Android are installed on to devices.
Possible reasons why users are downgrading are to free up space on their device, to make it easier to root or because a new version introduced bugs.

The number of devices getting security updates each week, is shown in Figure~\ref{fig:weekly_security_updates}.
\begin{itemize}
 \item Updates which changed the Android version number from a version with known vulnerabilities to one which had fewer known vulnerabilities are shown in red.
 \item Updates which changed the build number but not the version number and so might contain a backported fix for a vulnerability are shown in yellow.
\item Updates which did not fix security vulnerabilities (because there were no known security vulnerabilities in the version of Android they were already running) are shown in green.

\end{itemize}

By taking the number of updates observed and the number of device days of data we have collected we can compute the number of updates received by a device per year to be \daUpdatesPerYear.
This compares badly with the number of critical vulnerabilities discovered per year of between \avoVulnsPerYearAllAndroid\ (affecting all Android) and \avoVulnsPerYear\ (including the device manufacturer specific ones in \avo).


\input{security_scoring}


\section{Threats to validity}
\label{sec:validity}
\subsection{The \da\ data gives a conservative estimate of the Android version distribution}
\label{sec:representative}
\begin{figure}
 \centering
 \begin{subfigure}[b]{\columnwidth}
 \includegraphics[width=\columnwidth]{figures/googleplayapi}
 \caption{Google Play data on proportion of devices running different Android API versions}
 \label{fig:play_api}
\end{subfigure}
\begin{subfigure}[b]{\columnwidth}
 \includegraphics[width=\columnwidth]{figures/norm_api_gpcomp}
 \caption{\da\ data on proportion of devices running different Android API versions}
 \label{fig:da_api}
\end{subfigure}
\caption{Monthly Android API version data}
\end{figure}
\begin{figure}
 \centering
 \includegraphics[width=\columnwidth]{figures/api_gpcomp_rdiff}
 \caption{Difference between \da\ and Google Play data on the proportion of devices running different Android API versions}
 \label{fig:da_gp_comp_diff}
\end{figure}
The data from \da\ we used to investigate the proportion of devices exposed to different vulnerabilities is the OS version.
Unfortunately there is no authoritative source of OS version information and so we cannot check directly whether our data is representative.
However Google has published API version information every month since December 2009 and we have collated this information.\footnote{\url{http://androidvulnerabilities.org/play/historicplaydashboard}}
While API versions are too coarse grained to use for security update detection they are closely related to OS versions and so if the \da\ data on API versions is similar to the Google Data on API versions then the \da\ data on OS versions should be representative.
Figure~\ref{fig:play_api} shows the data from Google and Figure~\ref{fig:da_api} shows the data from \da\ and they appear similar.
Figure~\ref{fig:da_gp_comp_diff} shows the difference between Figures~\ref{fig:play_api} and \ref{fig:da_api}, normalising for days since the API version was released.
It shows that the \da\ data systematically overestimates the prevalence of new API versions and underestimates the prevalence of old API versions.
This means that the OS version information from \da\ is likely to be overestimating the prevalence of new OS versions and hence our results are a conservative estimate of the security of Android.
\todolater{we want a statistical metric to claim this strongly with.}
This allows us to have confidence in the OS version information.


\subsection{Changes in the \da\ sample}
\label{sec:da_changes}
The \da\ data is mostly generated by devices which have the \da\ app installed because their owner happened to come across the app on Google Play as there has been no advertising and few other attempts to increase usage.
However two collaborations with network operators to install \da\ on customer devices resulted in large numbers of new \da\ users coming from particular areas and network operators.
One study was conducted in Norway with 654 installs of \da\ and one was conducted in Bangladesh where 2463 users installed \da.
This is responsible for the sudden change in distribution of OS versions in \da\ shown towards the end of Figures \ref{fig:norm_os}, \ref{fig:nvulnerabilities_heat} and \ref{fig:proportioninsecure} as for that period Bangladeshi users contributed over half of the \da\ data.
%We could normalise out the influence of the Bangladeshi users, however they are Android users too and they also need security updates.
Since most \da\ users are self selecting and install \da\ because they want to find out more about what their phone is doing or to aid research they may be biased and perhaps more likely to install updates.


\section{Discussion}
There are continuing efforts to reduce the impact of critical vulnerabilities, both in Android and more widely.
SEAndroid~\cite{Smalley2013} which is included in Android from version 4.1~\cite{jelly-bean-release} claimed to prevent some root vulnerabilities and to reduce the impact of others.
Capability based enforcement systems such as Capsicum~\cite{Watson2010} substantially reduce the capabilities that an exploit has to try and gain increased privilege with.
When Capsicum is included in Linux\footnote{\url{https://github.com/google/capsicum-linux}} and hence in Android, it could be used to place fine grained restrictions on system daemons, preventing vulnerabilities becoming critical vulnerabilities.

We have not included all the vulnerabilities from \avo\, in particular we have not included any device manufacturer specific vulnerabilities, even when these are widespread (such as vulnerabilities affecting Qualcomm\footnote{Qualcomm is particularly good at publicly disclosing the vulnerabilities affecting their code and the patches which fix them.\url{https://www.codeaurora.org/projects/security-advisories/}} chipsets) because it is difficult to work out which devices are affected.
There also tends to be less public information available about device manufacturer specific vulnerabilities which makes them harder to tie down.
For other vulnerabilities which might affect all Android devices it is hard to work out which devices they affect.
For example \emph{pty race}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/pty_race}} is a Linux kernel vulnerability, we found 48 commits which fixed it in different branches, it was also accidentally fixed and later reintroduced and so determining which devices were vulnerable relies on knowing where on which branch the kernel was taken from.
For some vulnerabilities the corresponding patch is not in AOSP despite some device manufacturers having shipped builds containing the fix, which makes working out what is going on more difficult.
For \emph{RageAgainstTheCage adb}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/RageAgainstTheCage_adb}} and \emph{keystore buffer}\footnote{\url{http://androidvulnerabilities.org/vulnerabilities/keystore_buffer}} vulnerabilities which we do have sufficient data it is not clear whether they are truly critical vulnerabilities as the former may require physical \texttt{adb} access and the latter may be protected by a sandbox.
However those two vulnerabilities make little difference to our results as they affect few devices.

\subsection{Open questions}
There are several open questions which we have not yet been able to answer and remain future work.
\begin{itemize}
 \item Why was there a gap in vulnerability discovery in Android in 2012?
 \item Why do so many devices have \texttt{adb} enabled? \daAdbEnabledPerc\ seems rather high for a developer feature. This could be a selection bias or device manufacturers could be enabling it by default.
 \item How much of updating is new handsets and how much is updates being deployed? Over time newer versions of Android come to dominate, but quantifying what proportion of that is due to new phones being purchased and what proportion is due to updates to existing devices is a question we cannot answer.
 The only available large data set we know of with longitudinal traces of Android devices OS version numbers is \da\ but that only records \daNumUpdatesUpgrades\ upgrades which broken down over \daOSMonthsOfData\ months and \daNumSigOSVersions\ OS versions is only \daUpdatesPerMonthPerVersion\ updates per version per month which is not enough to build a statistically significant prediction of the expected transition to newer versions of Android.
 \item Why do users downgrade their phones?
\end{itemize}


\section{Related work}
\label{sec:related}
We found that since 2011 \daMeanInsecurityPerc\ of devices on average were exposed to known critical vulnerabilities.
In 2011 Felt et al.\ \cite{Felt2011} studied 6 Android handsets and found that they were exposed to root vulnerabilities at least 74\% of the time.
This might indicate that over the last 3 years the security of Android has not improved, but these data are not directly comparable as their study was on 6 handsets considering the best possible update distribution while ours is on a large sample of devices with the real update distribution.
They also found that 4 of the 46 malware samples (8\%) they analysed contained root exploits, much lower than rates found in later larger studies which found rates of 36.7\%~\cite{Zhou2012b} and 40\%~\cite{Zhou2012a}.
Our results show root exploits are still a severe threat.

Finding vulnerabilities is frequently a time consuming manual process but, Brumley et al. showed that it is possible to automatically generate exploits from binary patches~\cite{Brumley2008}.
In a similar way some of the vulnerabilities\todolater{which?} in \avo\ which have been exploited were publicly found by examining the commit made to the Android which fixed the vulnerability.
This effect has been observed before in the Firefox source code repositories~\cite{Barth2011}, Google does not release the source code until after the release of the update reducing this effect to the delay between an update being released and it reaching the last end user device.
There have been other attempts to automatically find vulnerabilities.
The Woodpecker tool automatically finds permission leaks in stock Android phone images~\cite{Grace2012}.
The update process itself can allow Android apps to gain privilege through `Pileup' vulnerabilities by registering for new permissions before the update which creates that permission is installed~\cite{Xing2014}.

The security protections used in iOS such as app review, code signing, Data Execution Prevention (DEP) and Address Space Layout Randomisation (ASLR) and mandatory access controls has resulted in a lower level of malware affecting iOS~\cite{Felt2011} but can still be bypassed~\cite{Wang2013a}.

Various attempts have been made to detect malware.
RiskRanker classified 3\,281/118\,318 (2.8\%) apps as risky of which 718 (22\%) were malware and 322 (10\%) were previously unknown malware, an infection rate of 0.6\% across multiple markets~\cite{Grace2012a}.
It uses signatures of exploits, static analysis of calls to high risk operations, detection of encrypted native code execution and dynamic Dalvik code loading to detect risky apps.
DroidRanger found 148/182\,823 (0.08\%) apps to be malicious across multiple markets of which 29 were previously unknown~\cite{Zhou2012a}.
It used permission-based behavioural fingerprinting -- looking at the permissions of known malware and heuristic-based filtering -- dynamic loading of both Dalvik and native code.
AnDarwin detects similar apps, it found 169/265\,359 (0.06\%) malicious apps based on the difference in permissions between the malicious app and the app which had been cloned~\cite{Crussell2013}.
It used clustering based on semantic vectors derived from the program dependence graphs to detect similar apps.
The Malware Genome project collected 1\,260 malware samples from 2010--2011~\cite{Zhou2012b}.
They found that the best case for anti-malware detection on this data was 79.6\%.
However DroidChameleon found that antivirus products could not detect malware if it was simply automatically permuted~\cite{Rastogi2013}.
All these app analysis projects have been hampered by the difficulty of obtaining full datasets of Android apps as Google does not make these available (and researchers who automatically download them violate Google's Terms of Service).
PlayDrone was a particularly effective project which circumvented Google's protective measures and downloaded over 1\,100\,000 apps from Google Play, allowing an in depth analysis~\cite{Viennot2014}.

Examining security update mechanisms has been used to assess security for many years.
Many software update systems have been found not to authenticate the connection to the update server and/or do not authenticate the downloaded binaries~\cite{Bellissimo2006}.
Even package management systems designed to provide secure updates have been found to have vulnerabilities~\cite{Cappos2008}.
Fortunately Android does authenticate the update binaries (though the APK vulnerabilities circumvented this) and Google Play downloads them over a secure connection~\cite{Viennot2014}.

The updatedness rate for Android of \daUpdatednessPerc\ compares unfavourably with the more than 90\% rate for Windows XP SP2 computers contacting the Microsoft update servers~\cite{Gkantsidis2006} though that is within one OS version and only for those computers which did connect to the servers -- but that is the default.
However 27\% of Windows computers were still running Windows XP in July 2014\footnote{\url{https://archive.today/PLGxn}\todolater{Get updated figures before publication}} -- four months after it went out of security support.

User-Agent strings have been used to investigate how web browser versions change with updates~\cite{Frei2008} and found that at most 80\% of Firefox users were running the most recent version.
The same analysis was used to show that Chrome's use of silent updates seems to increase uptake of upgrades~\cite{Duebendorfer2010} with 97\% of users running the latest version within 3 weeks of release.
Android's update process is manual, the user is notified but must action the upgrade which will then download the update and install it, the phone is rendered inoperable during the update process which is inconvenient for users and the phone must have sufficient charge (users are advised to plug it in) so that it will not run out during the update process.
Partly this is the result of the fact that an operating system update is being installed and so a reboot is required, but Chrome installs the new version side by side with the old one and switches the next time it is restarted.
The same technique would be more difficult on phones with limited storage space (as many cheap Android phones have barely enough space to install just the update) but is a plausible improvement for more high-end devices.
Google is deploying the same silent update technique through Google Play Services\footnote{\href{http://lifehacker.com/why-google-play-services-are-now-more-important-than-an-975970197}{http://lifehacker.com/why-google-play-services-are-now-more-important-than-an-975970197}} which automatically installs updates for core Google components of Android, this also bypasses the device manufacturer and network operator.



\section{Conclusion}
\label{sec:conclusion}
We have investigated the security of the Android operating system with respect to security updates and examined how the Android ecosystem results in different devices receiving different levels of security due to whether or not they get security updates.
We have compared different models, device manufacturers and network operators and found that there are differences between them which the discerning purchaser might use to influence their decision about which device to buy from which device manufacturer and network operator.
We hope that this analysis will encourage device manufacturers and network operators to improve the support they provide for devices after sale.
Android attempts to provide good security to end users but the latency in the security update process means that on average \daMeanInsecurityPerc\ of Android devices are exposed to known critical vulnerabilities.

\identifying{
\section*{Acknowledgements}
Thanks to David Robertson for helpful advice on statistical analysis.
Thanks to Laurent Simon, Thomas Coudray, Adrian Taylor, Justin Case, Giant Pune and Khilan Gudka for reporting vulnerabilities in Android.
}

\printbibliography


\listoftodos


\end{document}
