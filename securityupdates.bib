@article{1952012,
    author = "\#195",
    abstract = "We advocate unikernels: specialized virtual machines that run directly in the cloud without needing a traditional guest OS. Our Shroud implementation produces uniker- nels that offer an order of magnitude reduction in code size and smaller VM memory footprints without signif- icant performance penalty, and can run on commodity cloud deployments such as Amazon’s EC2. At the same time, they eliminate several classes of security threats via pervasive type-safety and a single-address space which can be made immutable at run-time (via an optional hy- pervisor extension). We describe the implementation of Shroud, our uniker- nel prototype, including the structure of appliances and how we map them efficiently onto Xen. Shroud pro- vides a suite of safe protocol libraries including Open- Flow, TCP/IP, DNS, SSH and HTTP, and we find that the overall performance of Shroud unikernels matches or surpasses the standard Linux VM equivalents, despite the Shroud code being type-safe.",
    year = "2012",
    journal = "OSDI",
    file = ":auto/homes/drt24/Downloads/unikernels-submitted.pdf:pdf",
    title = "{Unikernels: Extreme Specialization of Virtual Appliances}"
}

@inproceedings{Aaron2011,
    author = "Aaron, Samuel and Blackwell, Alan F and Hoadley, Richard and Regan, Tim",
    title = "{A Principled Approach to Developing New Languages For Live Coding}",
    booktitle = "NIME",
    mendeley-tags = "Liveness",
    number = "June",
    file = "::",
    year = "2011",
    keywords = "Liveness,abstractions,collabora-,concurrency,controllers,eu-,figure 1,improvisation,live coding,monome,performing live at the,the,tion,tones,$\lambda$",
    pages = "381--386"
}

@inproceedings{Abadi1994,
    author = "Abadi, Martin and Needham, Roger M.",
    publisher = "IEEE",
    title = "{Prudent engineering practice for cryptographic protocols}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=296587",
    abstract = "We present principles for designing cryptographic protocols. The principles are neither necessary nor suffcient for correctness. They are however helpful, in that adherence to them would have prevented a number of published errors. Our principles are informal guidelines; they complement formal methods, but do not assume them. In order to demonstrate the actual applicability of these guidelines, w e discuss some instructive examples from the literature.",
    pages = "122--136",
    file = ":auto/homes/drt24/Downloads/AbadiNeedham.pdf:pdf",
    year = "1994",
    booktitle = "Research in Security and Privacy, 1994. Proceedings., 1994 IEEE Computer Society Symposium on"
}

@article{Abadi2012,
    author = "Abadi, Daniel J.",
    doi = "10.1109/MC.2012.33",
    title = "{Consistency Tradeoffs in Modern Distributed Database System Design: CAP is Only Part of the Story}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6127847",
    abstract = "As time has passed since the initial formal proof of the CAP theorem, the theorem has become increasingly misunderstood and misapplied, potentially causing significant harm. In particular, many people incorrectly conclude that CAP forces a distributed system to have certain limitations during normal operation of the system, and therefore unnecessarily implement a limited system. In reality, CAP only proves that there must be limitations in the face of certain types of failures, and does not constrain system capabilities in any way during normal operation. Nonetheless, there do exist fundamental tradeoffs that limit the capabilities of distributed systems during normal operation, and these tradeoffs have influenced the different design choices of the well-known distributed database systems. This paper explores one particular tradeoff --- between consistency and latency --- and argues that it has been more influential on the design of these systems than the tradeoffs proved by the CAP theorem.",
    issn = "0018-9162",
    number = "99",
    pages = "1--1",
    file = "::",
    year = "2012",
    journal = "Computer"
}

@article{AbbinavPathakY.CharlieHuMingZhangParamvirBahl2011,
    author = "{Abbinav Pathak, Y. Charlie Hu, Ming Zhang, Paramvir Bahl}, Yi-Min Wang",
    journal = "ECE Technical Reports",
    year = "2011",
    title = "{Enabling automatic offloading of resource-intensive smartphone applications}"
}

@article{Abe2002,
    author = "Abe, Q C F D J and Jenson, Scott",
    journal = "Library",
    year = "2002",
    file = "::",
    title = "{The Simplicity Shift in a Corporate World}"
}

@article{Abowd1999,
    editor = "Gellersen, Hans-W",
    author = "Abowd, G D and Dey, A K and Brown, P J and Davies, N and Smith, M E and Steggles, P",
    publisher = "Springer-Verlag Berlin",
    title = "{Towards a better understanding of context and context-awareness}",
    url = "http://dx.doi.org/10.1007/3-540-48157-5",
    series = "Lecture Notes in Computer Science",
    journal = "CHI 2000 workshop on the what who where when and how of contextawareness",
    number = "What, Who, Where, When and How of Context-Awareness",
    institution = "Georgia Institution of Technology",
    volume = "4",
    pages = "1--6",
    file = "::",
    year = "1999",
    keywords = "computer programming,qa 76 software",
    abstract = "The use of context is important in interactive applications. It is par- ticularly important for applications where the users context is changing rap- idly, such as in both handheld and ubiquitous computing. In order to better un- derstand how we can use context and facilitate the building of context-aware applications, we need to more fully understand what constitutes a context- aware application and what context is. Towards this goal, we have surveyed existing work in context-aware computing. In this paper, we provide an over- view of the results of this survey and, in particular, definitions and categories of context and context-aware. We conclude with recommendations for how this better understanding of context inform a framework for the development of context-aware applications."
}

@article{Acer2010,
    author = "Acer, Mustafa and Jackson, Collin",
    title = "{Critical vulnerability in browser security metrics}",
    url = "http://www.w2spconf.com/2010/papers/p21.pdf",
    abstract = "Every time a browser vendor releases a patch for a critical vulnerability, the popular news media publishes a slew of negative press article detail- ing the security holes that have been announced in the product. Users who read these articles of- ten decide to switch to a “safer” browser. The negative press associated with security patch re- leases has a number of unhealthy effects on the industry. We challenge the conventional wis- dom of the current browser security evaluation paradigm: that browsers that receive infrequent security patches are safer than browsers that receive frequent patches, that browsers with a lower bug count are safer, and that reducing browser vulnerabilities is the only path that a browser vendor can follow to improve security. We argue that patch deployment matters vastly more than patch frequency, that bug count fails to take into account differences in severity and vendor reporting methodologies, and that the security features that matter most are ignored by negative news articles. We propose methods for evaluating browser security that take into ac- count new industry best practices such as silent patch deployment and sandboxing.",
    file = ":home/drt24/Downloads/p21.pdf:pdf",
    year = "2010",
    journal = "Proceedings of W2SP"
}

@article{Adams1999,
    author = "Adams, Anne and Sasse, Martina Angela",
    publisher = "ACM",
    doi = "10.1145/322796.322806",
    title = "{Users are not the enemy}",
    journal = "Communications of the ACM",
    abstract = "Why users compromise computer security mechanisms and how to take remedial measures.",
    number = "12",
    volume = "42",
    url = "http://dl.acm.org/citation.cfm?id=322796.322806",
    file = ":auto/homes/drt24/Downloads/p40-adams.pdf:pdf",
    year = "1999",
    pages = "40--46"
}

@article{Adya2011,
    author = "Adya, Atul and Cooper, Gregory and Myers, Daniel and Piatek, Michael",
    doi = "10.1145/2043556.2043570",
    isbn = "9781450309776",
    title = "{Thialfi: A Client Notification Service for Internet-Scale Applications}",
    url = "http://www.michaelpiatek.com/papers/thialfi-sosp11.pdf",
    abstract = "Ensuring the freshness of client data is a fundamental problem for applications that rely on cloud infrastructure to store data and mediate sharing. Thialfi is a notification service developed at Google to simplify this task. Thialfi supports applications written in multiple programming languages and running on multiple platforms, e.g., browsers, phones, and desktops. Applications register their interest in a set of shared objects and receive notifications when those objects change. Thialfi servers run in multiple Google data centers for availability and replicate their state asynchronously. Thialfi's approach to recovery emphasizes simplicity: all server state is soft, and clients drive recovery and assist in replication. A principal goal of our design is to provide a straightforward API and good semantics despite a variety of failures, including server crashes, communication failures, storage unavailability, and data center failures. Evaluation of live deployments confirms that Thialfi is scalable, efficient, and robust. In production use, Thialfi has scaled to millions of users and delivers notifications with an average delay of less than one second.",
    pages = "129--142",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adya et al. - 2011 - Thialfi A Client Notification Service for Internet-Scale Applications.pdf:pdf",
    year = "2011",
    keywords = "Distributed systems,performance,reliability,scalability",
    journal = "Proceedings of the 23rd ACM Symposium on Operating Systems Principles (SOSP)"
}

@inproceedings{Agarwal2009,
    author = "Agarwal, Yuvraj and Weng, Thomas",
    isbn = "9781605588247",
    title = "{The Energy Dashboard : Improving the Visibility of Energy Consumption at a Campus-Wide Scale}",
    abstract = "Presenting a fairly controlled environment for instrumen- tation and implementation of energy use policies, the Univer- sity of California at San Diego provides an excellent testbed to characterize and understand energy consumption of build- ings at the scale of a small town with over 45,000 residents. We present data collected from four selected buildings that are archetypes of diverse buildings from residence halls to data centers. In particular, we focus on ‘mixed-use’ build- ings where the energy consumption of IT equipment ac- counts for more than a quarter of the total energy use. Our detailed observations identify the primary components of the baseline energy use and the sources of peaks in energy con- sumption. Surprisingly, computing accounts for a large frac- tion of the baseline energy use, thus giving insights in how to significantly reduce power consumption by creating effec- tively duty-cycled buildings.",
    mendeley-tags = "Experimentation,Human Factors,Management,Measurement",
    pages = "55--60",
    file = ":home/drt24/Library/papers/BuildSys/Agarwal, Weng/Agarwal, Weng - 2009 - The Energy Dashboard Improving the Visibility of Energy Consumption at a Campus-Wide Scale.pdf:pdf",
    year = "2009",
    keywords = "Experimentation,Human Factors,Management,Measurement,buildings,energy,power",
    booktitle = "BuildSys"
}

@inproceedings{Agarwal2010,
    author = "Agarwal, Yuvraj and Balaji, Bharathan and Gupta, Rajesh and Lyles, Jacob and Wei, Michael and Weng, Thomas",
    isbn = "9781450304580",
    title = "{Occupancy-Driven Energy Management for Smart Building Automation}",
    abstract = "Buildings are among the largest consumers of electricity in the US. A significant portion of this energy use in build- ings can be attributed to HVAC systems used to maintain comfort for occupants. In most cases these building HVAC systems run on fixed schedules and do not employ any fine grained control based on detailed occupancy information. In this paper we present the design and implementation of a presence sensor platform that can be used for accurate occu- pancy detection at the level of individual offices. Our pres- ence sensor is low-cost, wireless, and incrementally deploy- able within existing buildings. Using a pilot deployment of our system across ten offices over a two week period we identify significant opportunities for energy savings due to periods of vacancy. Our energy measurements show that our presence node has an estimated battery lifetime of over five years, while detecting occupancy accurately. Furthermore, using a building simulation framework and the occupancy information from our testbed, we show potential energy sav- ings from 10\% to 15\% using our system.",
    file = ":home/drt24/Library/papers/BuildSys/Agarwal et al/Agarwal et al. - 2010 - Occupancy-Driven Energy Management for Smart Building Automation.pdf:pdf",
    year = "2010",
    keywords = "occupancy detection system,wireless sensor networks",
    booktitle = "BuildSys"
}

@inproceedings{Agarwal2011,
    author = "Agarwal, Yuvraj and Weng, Thomas and Gupta, R.K.",
    publisher = "IEEE",
    isbn = "9783981080179",
    title = "{Understanding the role of buildings in a smart microgrid}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5763195",
    abstract = "A ‘smart microgrid’ refers to a distribution network for electrical energy, starting from electricity generation to its transmission and storage with the ability to respond to dynamic changes in energy supply through co-generation and demand ad- justments. At the scale of a small town, a microgrid is connected to the wide-area electrical grid that may be used for ‘baseline’ energy supply; or in the extreme case only as a storage system in a completely self-sufficient microgrid. Distributed generation, storage and intelligence are key components of a smart microgrid. In this paper, we examine the significant role that buildings play in energy use and its management in a smart microgrid. In particular, we discuss the relationship that IT equipment has on energy usage by buildings, and show that control of various building subsystems (such as IT and HVAC) can lead to significant energy savings. Using the UCSD as a prototypical smart microgrid, we discuss how buildings can be enhanced and interfaced with the smart microgrid, and demonstrate the benefits that this relationship can bring as well as the challenges in implementing this vision.",
    pages = "1--6",
    file = ":home/drt24/Library/papers/Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2011/Agarwal, Weng, Gupta/Agarwal, Weng, Gupta - 2011 - Understanding the role of buildings in a smart microgrid.pdf:pdf",
    year = "2011",
    keywords = "HVAC,smart grid",
    booktitle = "Design, Automation \& Test in Europe Conference \& Exhibition (DATE), 2011"
}

@article{Ahmad2008,
    author = "Trends, Attack and Ahmad, D",
    doi = "10.1109/MSP.2008.131",
    title = "{Two Years of Broken Crypto: Debian's Dress Rehearsal for a Global PKI Compromise}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true\&arnumber=4639029",
    abstract = "A patch to the OpenSSL package maintained by Debian GNU/Linux (an operating system composed of free and open source software that can be used as a desktop or server OS) submitted in 2006 weakened its pseudo-random number generator (PRNG), a critical component for secure key generation. Putting both servers and users at risk, this vulnerability affected OpenSSH, Apache (modssl), the onion router (TOR), OpenVPN, and other applications. In this article, the author examines these issue and its consequences. OpenSSL is an open source library implementing the SSL (Secure Socket Layer) and TLS (Transport Layer Security) protocols. Several widely deployed applications on many OSs rely on it for secure communications, particularly Linux and BSD-based systems. Where in use, it's a critical part of the OS's security subsystem.",
    issn = "15407993",
    number = "5",
    pages = "70--73",
    volume = "6",
    file = ":home/drt24/Downloads/04639029.pdf:pdf",
    year = "2008",
    keywords = "cryptography,debian,gnu,linux,pki,ssh,ssl,vulnerability",
    journal = "IEEE Security Privacy Magazine"
}

@techreport{Ahrens2005a,
    author = "Ahrens, James and Geveci, Berk and Law, Charles",
    title = "{ParaView : An End-User Tool for Large Data Visualization}",
    abstract = "This paper describes the design and features of a visualization tool, called ParaViewi, a tool for scientists to visualize and analysis extremely large data sets. The tool provides a graphical user interface for the creation and dynamic execution of visualization tasks. ParaView transparently supports the visualization and rendering of large data sets by executing these programs in parallel on shared or distributed memory machines. ParaView supports hardware-accelerated parallel rendering and achieves interactive rendering performance via level-of-detail techniques. The design balances and integrates a number of diverse requirements including the ability to handle large data, ease of use and extensibility by developers. This paper describes the requirements that guided the design, identifies their importance to scientific users, and discusses key design decision and tradeoffs.",
    mendeley-tags = "End-User Programming,Visualisation",
    volume = "836",
    file = "::",
    year = "2005",
    keywords = "End-User Programming,Visualisation",
    booktitle = "Energy"
}

@inproceedings{Akoush2011,
    author = "Akoush, Sherif and Sohan, Ripduman and Rice, Andrew C. and Moore, Andrew W. and Hopper, Andy",
    title = "{Free Lunch : Exploiting Renewable Energy For Computing}",
    abstract = "This paper argues for “Free Lunch”, a computation architecture that exploits otherwise wasted renewable energy by (i) colocating datacentres with these remote energy sources, (ii) connecting them over a dedicated network, and (iii) providing a software framework that supports the seamless execution and migration of virtual machines in the platform according to power availability. This work motivates and outlines the architecture and demonstrates its viability with a case study. Additionally, we discuss the major technical challenges facing the successful deployment of Free Lunch and the limiting factors inherent in its design.",
    pages = "1--5",
    file = ":home/drt24/Library/papers/HOTOS/Akoush et al/Akoush et al. - 2011 - Free Lunch Exploiting Renewable Energy For Computing.pdf:pdf",
    year = "2011",
    booktitle = "HOTOS"
}

@inproceedings{Al-Fedaghi2010,
    author = "Al-Fedaghi, Sabah",
    publisher = "IEEE",
    doi = "10.1109/SocialCom.2010.159",
    isbn = "9780769542119",
    title = "{System-based approach to software vulnerability}",
    abstract = "The focus of vulnerability research has been conceptualization of the lifecycle of software vulnerability as errors in software that can be used by an attacker to gain access to a system or network. This lifecycle is described in terms of its phases: creation, discovery, exploitation, disclosure, patch availability, and patch installed. The objective of this paper is to clarify the notion of vulnerability so it complements current error-focused conceptualization. The paper proposes a fine-grained lifecycle of a vulnerable system in terms of a flowsystem that includes five basic stages and is defined by a flow transition diagram. A software system is first created, released, and transferred to users; it is then activated until it fails as a result of vulnerability to an attack. Several other phases lead to re-creation of the system. Accordingly, vulnerability is defined as the state of a system where it can be damaged when it receives a certain type of attack.",
    pages = "1072--1079",
    file = ":home/drt24/Downloads/05590497.pdf:pdf",
    year = "2010",
    keywords = "Flow system,Risk,Software error,Software vulnerability lifecycle",
    booktitle = "IEEE International Conference on Social Computing (SocialCom), IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT)"
}

@inproceedings{AldecoPerez2008,
    author = "{Aldeco Perez}, R. and Moreau, Luc",
    publisher = "BCS",
    title = "{Provenance-based auditing of private data use}",
    url = "http://eprints.ecs.soton.ac.uk/16580",
    file = "::",
    year = "2008",
    keywords = "audit,data protection act,private data,provenance",
    pages = "1--12"
}

@article{Alexa2007,
    author = "Alexa, Marc",
    title = "{Extracting the Essence from Sets of Images}",
    abstract = "We use a set of photographs taken from similar viewpoints as a model for a single photograph from this viewpoint. A distance measure for this model is defined by correlating the neigborhoods of pixels in similar positions. A cross analysis of the source images yields confidence values for their pixels. The confidence values together with the distances in pixels are used to steer a variable bandwidth mean shift algorithm that moves an arbitrary image towards one conforming with the model. Furthermore, distances are also used for a non-local means reconstruction of image areas that have no consistent explanation in the source images. This allows reconstructing images of scenes that are occluded in the majority of images.",
    pages = "113--120",
    file = ":auto/homes/drt24/Downloads/E2-paper.pdf:pdf",
    year = "2007",
    journal = "Computational Aesthetics"
}

@article{Aliferis1995,
    author = "Aliferis, C F and Cooper, G F",
    title = "{A new formalism for temporal modeling in medical decision-support systems.}",
    url = "http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2579086\&tool=pmcentrez\&rendertype=abstract",
    abstract = "We present a new mathematical formalism, which we call modifiable temporal belief networks (MTBNs) that extends the concept of an ordinary belief network (BN) to incorporate a dynamic causal structure and explicit temporal semantics. An important feature of MTBNs is that they allow portions of the model to be abstract and portions of it to be temporally explicit. We show how this property can lead to substantial knowledge acquisition and computational complexity savings. In addition to temporal modeling, the language of MTBNs can be an important analytical tool, as well as temporal language for causal discovery.",
    issn = "0195-4210",
    month = "1",
    pages = "213--7",
    file = "::",
    year = "1995",
    keywords = "Computer-Assisted,Decision Making,Decision Support Techniques,Humans,Models,Neural Networks (Computer),Theoretical,Tilidine,Time",
    pmid = "8563270",
    journal = "Proceedings / the ... Annual Symposium on Computer Application [sic] in Medical Care. Symposium on Computer Applications in Medical Care"
}

@inproceedings{Alto1995,
    author = "Nichols, David A and Curtis, Pavel and Dixon, Michael and Lamping, John",
    publisher = "ACM Press",
    doi = "10.1145/215585.215706",
    isbn = "089791709X",
    title = "{High-latency, low-bandwidth windowing in the Jupiter collaboration system}",
    url = "http://portal.acm.org/citation.cfm?id=215585.215706",
    abstract = "Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.",
    pages = "111--120",
    file = ":auto/homes/drt24/Downloads/p111-nichols.pdf:pdf",
    year = "1995",
    keywords = "cscw,groupware,mistic concurrency control,uims,window toolkits",
    booktitle = "UIST"
}

@online{Anderson,
    author = "Anderson, Ross",
    url = "http://www.cl.cam.ac.uk/~rja14/Papers/SmartMetering-Feb82012.pdf",
    title = "{Smart Metering - Ed Milliband's Poisoned Chalice}"
}

@article{Anderson1995,
    author = "Anderson, Ross and Needham, Roger",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-44750-4_19",
    title = "{Robustness principles for public key protocols}",
    url = "http://link.springer.com/chapter/10.1007/3-540-44750-4_19",
    abstract = "We present a number of attacks, some new, on public key protocols. We also advance a number of principles which may help designers avoid many of the pitfalls, and help attackers spot errors which can be exploited.",
    pages = "236--247",
    volume = "963",
    file = ":home/drt24/Downloads/10.1007\_3-540-44750-4\_19.pdf:pdf",
    year = "1995",
    journal = "Advances in Cryptology—CRYPT0'95"
}

@inproceedings{Anderson1996,
    author = "Anderson, Ross and Others",
    title = "{The eternity service}",
    url = "http://www.formation.jussieu.fr/ars/2000-2001/UNIX/cours/5/COMPLEMENTS/DOC/why-cryptosystems-fail/eternity.pdf",
    abstract = "The Internet was designed to provide a communications chan- nel that is as resistant to denial of service attacks as human ingenuity can make it. In this note, we propose the construction of a storage medium with similar properties. The basic idea is to use redundancy and scattering techniques to replicate data across a large set of machines (such as the Internet), and add anonymity mechanisms to drive up the cost of selective service denial attacks. The detailed design of this service is an interesting scientific problem, and is not merely academic: the service may be vital in safeguarding individual rights against new threats posed by the spread of electronic publishing.",
    file = ":home/drt24/Library/papers/Computer/Anderson/Anderson - Unknown - The Eternity Service.pdf:pdf",
    year = "1996",
    booktitle = "Pragocrypt"
}

@article{Anderson1997,
    author = "Anderson, Jennifer M. and Weihl, William E. and Berc, Lance M. and Dean, Jeffrey and Ghemawat, Sanjay and Henzinger, Monika R. and Leung, Shun-Tak A. and Sites, Richard L. and Vandevoorde, Mark T. and Waldspurger, Carl A.",
    title = "{Continuous profiling: where have all the cycles gone?}",
    url = "http://dl.acm.org/citation.cfm?id=265924.265925",
    journal = "ACM Transactions on Computer Systems",
    issn = "07342071",
    number = "4",
    month = "11",
    volume = "15",
    year = "1997",
    keywords = "performance understanding,performance-monitoring hardware,profiling,program analysis",
    pages = "357--390"
}

@inproceedings{Anderson1998,
    author = "Anderson, Ross and Kuhn, Markus",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/BFb0028165",
    title = "{Low cost attacks on tamper resistant devices}",
    url = "http://link.springer.com/chapter/10.1007/BFb0028165",
    abstract = "There has been considerable recent interest in the level of tamper resistance that can be provided by low cost devices such as smart-cards. It is known that such devices can be reverse engineered using chip testing equipment, but a state of the art semiconductor laboratory costs millions of dollars. In this paper, we describe a number of attacks that can be mounted by opponents with much shallower pockets. Three of them involve special (but low cost equipment: differential fault analysis, chip rewriting, and memory remanence. There are also attacks based on good old fashioned protocol failure which may not require any special equipment at all. We describe and give examples of each of these. Some of our attacks are significant improvements on the state of the art; others are useful cautionary tales. Together, they show that building tamper resistant devices, and using them effectively, is much harder than it looks.",
    pages = "125--136",
    file = ":home/drt24/Downloads/10.1007\_BFb0028165.pdf:pdf",
    year = "1998",
    booktitle = "Security Protocols"
}

@article{Anderson2001,
    author = "Anderson, Ross",
    isbn = "9781450313124",
    title = "{Security Economics – A Personal Perspective}",
    url = "http://www.acsac.org/2012/openconf/modules/request.php?module=oc_program\&action=page.php\&id=14\&OPENCONF=c6c60b8edbdabf15845a6cdbb3a0fd47",
    abstract = "This paper describes the origins of security economics. The birth of this thriving new discipline is sometimes credited to a talk I gave at ACSAC in December 2001, but the story is more complex. After sabbatical visits to Berkeley in 2001– 2 to work with Hal Varian, we organised the first Work- shop on the Economics of Information Security in June 2002. Since then the field has grown to encompass arguments over open versus proprietary systems, the econometrics of online crime, the behavioural economics of security and much else. It has started to have a significant impact on policy, with security-economics studies of cybercrime and infrastructure vulnerability being adopted as policy in the EU, while secu- rity economics PhDs have got influential jobs in the White House and elsewhere.",
    file = ":home/drt24/Downloads/252.pdf:pdf",
    year = "2001",
    keywords = "economics,information security",
    pages = "139--144"
}

@article{Anderson2001a,
    author = "Anderson, Ross",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-44810-1_17",
    isbn = "978-3-540-42566-3",
    title = "{The correctness of crypto transaction sets}",
    url = "http://link.springer.com/chapter/10.1007/3-540-44810-1_18",
    abstract = "This talk follows on more from the talks by Larry Paulson and Giampaolo Bella that we had earlier. The problem I’m going to discuss is, what’s the next problem to tackle once we’ve done crypto protocols? We keep on saying that crypto-protocols appear to be “done” and then some new application comes along to give us more targets to work on — multi-media, escrow, you name it. But sooner or later, it seems reasonable to assume, crypto will be done. What’s the next thing to do?",
    number = "April 2000",
    pages = "125--127",
    volume = "2133",
    file = ":home/drt24/Downloads/10.1007\_3-540-44810-1\_17.pdf:pdf",
    year = "2001",
    journal = "Security Protocols"
}

@article{Anderson2001b,
    author = "Anderson, Ross",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-44810-1_18",
    isbn = "978-3-540-42566-3",
    title = "{The correctness of crypto transaction sets (Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/3-540-44810-1_18",
    abstract = "This talk follows on more from the talks by Larry Paulson and Giampaolo Bella that we had earlier. The problem I’m going to discuss is, what’s the next problem to tackle once we’ve done crypto protocols? We keep on saying that crypto-protocols appear to be “done” and then some new application comes along to give us more targets to work on — multi-media, escrow, you name it. But sooner or later, it seems reasonable to assume, crypto will be done. What’s the next thing to do?",
    number = "April 2000",
    pages = "128--141",
    volume = "2133",
    file = ":home/drt24/Downloads/10.1007\_3-540-44810-1\_18.pdf:pdf",
    year = "2001",
    journal = "Security Protocols"
}

@book{Anderson2004,
    author = "Anderson, Ross and Bond, Michael",
    publisher = "Springer New York",
    doi = "10.1007/0-387-21821-1_3",
    isbn = "978-0-387-20170-2",
    title = "{Protocol Analysis, Composability and Computation}",
    url = "http://link.springer.com/chapter/10.1007/0-387-21821-1_3",
    abstract = "The protocol work that started off a quarter of a century ago may have seemed at the time like a minor detail within the larger project of designing robust distributed systems. Yet it has already grown into the main unifying theme of security engineering. Application-level protocols, and especially those from which an attacker can harvest data over many runs, open up new problems. The resulting analysis techniques are set to invade the world of composable security and the world of multiparty computation. The influence and consequences of Roger’s contribution just keep on growing.",
    file = ":home/drt24/Downloads/bond-anderson.pdf:pdf",
    year = "2004"
}

@article{Anderson2007,
    author = "Anderson, Ross",
    doi = "10.1007/978-3-540-77156-2_42",
    isbn = "978-3-540-77155-5",
    title = "{The initial costs and maintenance costs of protocols}",
    url = "http://link.springer.com/chapter/10.1007/978-3-540-77156-2_43",
    abstract = "Software-engineering academics focussed for many years on the costs of developing the first version of a product, and ignored the costs of subsequent maintenance. We taught our students the ‘waterfall model’, and biased research towards the sort of tools and ideas that complemented it, such as formal methods. Meanwhile the economics of software had changed. Software is now so complex that the only way to build version N is to start with version N-1. Iterative development methodologies now rule, and the tools that real developers say have helped them most in the last fifteen years are not theorem provers, but automated regression-testing and bug-reporting systems. Nowadays, the maintenance is the product. Security engineers have been falling into a similar trap. For years, we thought that the problem of authentication began and ended with trustworthy bootstrapping. Once Alice and Bob shared that elusive session key - and could prove mathematically that no-one else did - we could type up the research paper and head for the pub. Again, the real world has changed. Security maintainability is the elephant in the living room; people know there’s an awful problem but are generally too polite to mention it (especially as we don’t really know what to do with the beast). Vendors used to not care very much; after all, people replace their mobile phones every year, and their PCs every three to five years, so why not just wait for the vulnerable equipment to be thrown on the skip? With luck, vulnerability scares might even help stoke the upgrade cycle.",
    pages = "333--335",
    volume = "4631",
    file = ":home/drt24/Downloads/10.1007\_978-3-540-77156-2\_42.pdf:pdf",
    year = "2007",
    journal = "Security Protocols"
}

@article{Anderson2007a,
    author = "Anderson, Ross",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-540-77156-2_43",
    isbn = "978-3-540-77155-5",
    title = "{The Initial Costs and Maintenance Costs of (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/978-3-540-77156-2_43",
    abstract = "I’d planned to talk about usability and maintainability – in my view, likely to be the two most important research topics in security over the next five years. As everybody’s talked about usability, I will talk a bit more about maintainability. In the old days we always considered that security was about bootstrapping. Once Alice and Bob could be induced to share a key, job done: we go off down the pub and the following day we write the paper. This is a bit like software engineering 30 years ago where people just studied the waterfall model. But the real world nowadays is different. Nobody’s interested in waterfall; everybody’s interested in evolutionary development, extreme programming and so on. The maintenance is the product - because almost all your costs fall at points in the system development lifecycle other the first one.",
    number = "October 2004",
    pages = "336--343",
    volume = "4631",
    file = ":home/drt24/Downloads/10.1007\_978-3-540-77156-2\_43.pdf:pdf",
    year = "2007",
    journal = "Security Protocols"
}

@incollection{Anderson2008,
    author = "Anderson, Ross",
    publisher = "Wiley",
    isbn = "978-0-470-06852-6",
    title = "{API Attacks}",
    booktitle = "Security Engineering: A Guide to Building Dependable Distributed Systems",
    file = ":auto/homes/drt24/Downloads/SEv2-c18.pdf:pdf",
    year = "2008",
    pages = "547--558"
}

@incollection{Anderson2008distributed,
    author = "Anderson, Ross",
    publisher = "Wiley",
    isbn = "978-0-470-06852-6",
    title = "{Distributed Systems}",
    abstract = "We’ve seen in the last few chapters how people can authenticate themselves to systems (and systems can authenticate themselves to each other) using security protocols; how access controls can be used to manage which principals can perform which operations in a system; and some of the mechanics of how crypto can be used to underpin access control in distributed systems. But there’s much more to building a secure distributed systems than just implementing access controls, protocols, and crypto. When systems become large, the scale-up problems are not linear; there is often a qualitative change in complexity, and some things that are trivial to deal with in a network of only a few machines and principals (such as naming) suddenly become a big deal. Over the last 35 years, computer science researchers have built many distributed systems and studied issues such as concurrency, failure recovery, and naming. The theory is also supplemented by growing body of experience from industry, commerce, and government. These issues are central to the design of effective secure systems, but are often handled rather badly. I’ve already described attacks on security protocols that can be seen as concurrency failures. If we replicate data to make a system fault- tolerant, then we may increase the risk of a compromise of confidentiality. Finally, naming difficulties are probably the main impediment to the construction of public key infrastructures.",
    pages = "115--133",
    edition = "2",
    file = ":home/drt24/Downloads/SE-06.pdf:pdf",
    year = "2008",
    booktitle = "Security Engineering: A Guide to Building Dependable Distributed Systems"
}

@incollection{Anderson2008managing,
    author = "Anderson, Ross",
    publisher = "Wiley",
    isbn = "978-0-470-06852-6",
    title = "{Managing the Development of Secure Systems}",
    url = "http://www.cl.cam.ac.uk/~rja14/Papers/SEv2-c25.pdf",
    abstract = "So far we’ve discussed a great variety of security applications, techniques and concerns. If you’re a working ITmanager or consultant, paid to build a secure system, you will by now be looking for a systematic way to select protection aims andmechanisms. This brings us to the topics of system engineering, risk analysis and, finally, the secret sauce: how you manage a teamtowrite secure code. Business schools reckon that management training should be conducted largely through case histories, stiffened with focussed courses on basic topics such as law, economics and accounting. I have broadly followed their model in this book. We went over the fundamentals, such as protocols, access control and crypto, and then looked at a lot of different applications with a lot of case histories. Nowwe have to pull the threads together and discuss how to go about solv- ing a general security engineering problem.Organizational issues matter here as well as technical ones. It’s important to understand the capabilities of the staffwho’ll operate your control systems, such as guards and auditors, to take account of the managerial and work-group pressures on them, and get feed- back from them as the system evolves. You also have to instil suitable ways of thinking andworking into your development team. Success is about attitudes andwork practices as well as skills. There are tensions: how do you get people to think like criminals, yet work enthusiastically for the good of the product?",
    pages = "815--856",
    edition = "2",
    file = ":home/drt24/Downloads/SEv2-c25.pdf:pdf",
    year = "2008",
    booktitle = "Security Engineering: A Guide to Building Dependable Distributed Systems"
}

@article{Anderson2009,
    author = "Anderson, Ross and Moore, Tyler",
    doi = "10.1098/rsta.2009.0027",
    title = "{Information security: where computer science, economics and psychology meet.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/19487207",
    abstract = "Until ca. 2000, information security was seen as a technological discipline, based on computer science but with mathematics helping in the design of ciphers and protocols. That perspective started to change as researchers and practitioners realized the importance of economics. As distributed systems are increasingly composed of machines that belong to principals with divergent interests, incentives are becoming as important to dependability as technical design. A thriving new field of information security economics provides valuable insights not just into 'security' topics such as privacy, bugs, spam and phishing, but into more general areas of system dependability and policy. This research programme has recently started to interact with psychology. One thread is in response to phishing, the most rapidly growing form of online crime, in which fraudsters trick people into giving their credentials to bogus websites; a second is through the increasing importance of security usability; and a third comes through the psychology-and-economics tradition. The promise of this multidisciplinary research programme is a novel framework for analysing information security problems-one that is both principled and effective.",
    issn = "1364-503X",
    number = "1898",
    month = "7",
    volume = "367",
    pages = "2717--27",
    file = ":auto/homes/drt24/Downloads/Phil. Trans. R. Soc. A-2009-Anderson-2717-27.pdf:pdf",
    year = "2009",
    pmid = "19487207",
    journal = "Philosophical transactions. Series A, Mathematical, physical, and engineering sciences"
}

@inproceedings{Anderson2010,
    author = "Anderson, Ross",
    abstract = "There has been much academic discussion of federated authentication, and quite some political manoeuvring about ‘e-ID’. The grand vision, which has been around for years in various forms but was recently articulated in the US National Strategy for Trustworthy Identities in Cyberspace (NSTIC), is that a single logon should work everywhere [1]. You should be able to use your identity provider of choice to log on anywhere; so you might use your driver’s license to log on to Gmail, or use your Facebook logon to file your tax return. More restricted versions include the vision of governments of places like Estonia and Germany (and until May 2010 the UK) that a government-issued identity card should serve as a universal logon. Yet few systems have been fielded at any scale. In this paper I will briefly discuss the four existing examples we have of federated authentication, and then go on to discuss a much larger, looming problem. If the world embraces the Apple vision of your mobile phone becoming your universal authentication device – so that your phone contains half-a dozen credit cards, a couple of gift cards, a dozen coupons and vouchers, your AA card, your student card and your driving license, how will we manage all this? A useful topic for initial discussion, I argue, is revocation. Such a phone will become a target for bad guys, both old and new. What happens when someone takes your phone off you at knifepoint, or when it gets infested with malware? Who do you call, and what will they do to make the world right once more?",
    year = "2010",
    booktitle = "Nineteenth International Workshop on Security Protocols",
    file = ":home/drt24/Library/papers/Nineteenth International Workshop on Security Protocols/Anderson/Anderson - 2010 - Can We Fix the Security Economics of Federated Authentication.pdf:pdf",
    title = "{Can We Fix the Security Economics of Federated Authentication?}"
}

@article{Anderson2010a,
    author = "Anderson, Jonathan and Bonneau, Joseph and Stajano, Frank",
    title = "{Inglorious Installers: Security in the Application Marketplace.}",
    url = "http://www.cl.cam.ac.uk/~jra40/publications/2010-WEIS-inglorious-installers.pdf",
    abstract = "From mobile phones to social networks, installing and running third-party applications can be risky. Installing applications often requires running unverified, untrustworthy code with the privilege of a system administrator, allowing it to compromise the security of user data and the operating system. Once installed, applications on most platforms can access anything that a user can: a web browser can read users’ e-mail and an e-mail client can access browsing history. Computer scientists have been developing systems for decades which follow the “principle of least authority,” yet few consumer computing platforms adopt their techniques. In this paper, we examine the application markets for ten computing platforms, including personal computers, mobile phones, social networks and web browsers. We identify economic causes for the wide variation in their installation and sandboxing techniques, and we propose measures to align the incentives of market actors such that providing better application security guarantees is in everyone’s interest.",
    pages = "0--44",
    file = ":home/drt24/Downloads/weis2010\_anderson\_j.pdf:pdf",
    year = "2010",
    journal = "WEIS"
}

@article{Andrus2011,
    author = "Andrus, Jeremy and Dall, Christoffer and Hof, Alexander Van and Laadan, Oren and Nieh, Jason",
    publisher = "ACM",
    doi = "10.1145/2043556.2043574",
    isbn = "9781450309776",
    title = "{Cells : A Virtual Mobile Smartphone Architecture}",
    url = "http://dl.acm.org/citation.cfm?id=2043574",
    abstract = "Smartphones are increasingly ubiquitous, and many users carry multiple phones to accommodate work, personal, and geographic mobility needs. We present Cells, a virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical cellphone in an isolated, secure manner. Cells introduces a usage model of having one foreground virtual phone and multiple background virtual phones. This model enables a new device namespace mechanism and novel device proxies that integrate with lightweight operating system virtualization to multiplex phone hardware across multiple virtual phones while providing native hardware device performance. Cells virtual phone features include fully accelerated 3D graphics, complete power, management features, and full telephony functionality with separately assignable telephone numbers and caller ID support. We have implemented a prototype of Cells that supports multiple Android virtual phones on the same phone. Our performance results demonstrate that Cells imposes only modest runtime and memory overhead, works seamlessly across multiple hardware devices including Google Nexus 1 and Nexus S phones, and transparently runs Android applications at native speed without any modifications.",
    pages = "173--187",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrus et al. - 2011 - Cells A Virtual Mobile Smartphone Architecture Categories and Subject Descriptors.pdf:pdf",
    year = "2011",
    keywords = "android,smartphones,virtualization",
    journal = "SOSP"
}

@inproceedings{Andrus2011a,
    author = "Andrus, Jeremy and Dall, Christoffer and Hof, Alexander Van't and Laadan, Oren and Nieh, Jason",
    publisher = "ACM Press",
    doi = "10.1145/2043556.2043574",
    isbn = "9781450309776",
    title = "{Cells: a virtual mobile smartphone architecture}",
    url = "http://dl.acm.org/citation.cfm?id=2043556.2043574",
    booktitle = "Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles - SOSP '11",
    year = "2011",
    month = "10",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrus et al. - 2011 - Cells A Virtual Mobile Smartphone Architecture Categories and Subject Descriptors.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "Android,smartphones,virtualization",
    pages = "173"
}

@article{Arora2004,
    author = "Arora, Ashish and Krishnan, Ramayya and Nandkumar, Anand and Telang, Rahul and Yang, Yubao",
    title = "{Impact of Vulnerability Disclosure and Patch Availability - An Empirical Analysis}",
    journal = "Proceedings of the Third Annual Workshop on Economics and Information Security (WEIS)",
    file = ":home/drt24/Downloads/telang.pdf:pdf",
    year = "2004",
    keywords = "attackers,full disclosure policy,patching behavior,software vulnerability",
    pages = "1--20"
}

@article{Arora2008,
    author = "Arora, a. and Telang, R. and Xu, H.",
    doi = "10.1287/mnsc.1070.0771",
    title = "{Optimal Policy for Software Vulnerability Disclosure}",
    abstract = {Software vulnerabilities represent a serious threat to cybersecurity, most cyberattacks exploit known vulnerabilities. Unfortunately, there is no agreed-upon policy for their disclosure. Disclosure policy (which sets a protected period given to a vendor to release the patch for the vulnerability) indirectly affects the speed and quality of the patch that a vendor develops. Thus, CERT/CC and similar bodies acting in the public interest can use disclosure to influence the behavior of vendors and reduce social cost. This paper develops a framework to analyze the optimal timing of disclosure. We formulate a model involving a social planner who sets the disclosure policy and a vendor who decides on the patch release. We show that the vendor typically releases the patch less expeditiously than is socially optimal. The social planner optimally shrinks the protected period to push the vendor to deliver the patch more quickly, and sometimes the patch release time coincides with disclosure. We extend the model to allow the proportion of users implementing patches to depend upon the quality (chosen by the vendor) of the patch. We show that a longer protected period does not always result in a better patch quality. Another extension allows for some fraction of users to use "work-arounds." We show that the possibility of work-arounds can provide the social planner with more leverage, and hence the social planner shrinks the protected period. Interestingly, the possibility of work-arounds can sometimes increase the social cost due to the negative externalities imposed by the users who are able to use the work-arounds on the users who are not.},
    issn = "0025-1909",
    number = "July 2014",
    pages = "642--656",
    volume = "54",
    file = ":home/drt24/Downloads/mnsc\%2E1070\%2E0771.pdf:pdf",
    year = "2008",
    keywords = "disclosure policy,economics of cybersecurity,instant disclosure,patching,software vulnerability",
    journal = "Management Science"
}

@inproceedings{Arslan2012,
    author = "Arslan, Mustafa Y. and Singh, Indrajeet and Singh, Shailendra and Madhyastha, Harsha V. and Sundaresan, Karthikeyan and Krishnamurthy, Srikanth V.",
    publisher = "ACM Press",
    doi = "10.1145/2413176.2413199",
    isbn = "9781450317757",
    title = "{Computing while charging: Building a Distributed Computing Infrastructure Using Smartphones}",
    url = "http://dl.acm.org/citation.cfm?id=2413176.2413199",
    abstract = "Every night, a large number of idle smartphones are plugged into a power source for recharging the battery. Given the increasing computing capabilities of smartphones, these idle phones consti- tute a sizeable computing infrastructure. Therefore, for an enter- prise which supplies its employees with smartphones, we argue that a computing infrastructure that leverages idle smartphones be- ing charged overnight is an energy-efficient and cost-effective alter- native to running tasks on traditional server infrastructure. While parallel execution and scheduling models exist for servers (e.g., MapReduce), smartphones present a unique set of technical chal- lenges due to the heterogeneity in CPU clock speed, variability in network bandwidth, and lower availability compared to servers. In this paper, we address many of these challenges to develop CWC—a distributed computing infrastructure using smartphones. Specifically, our contributions are: (i) we profile the charging be- haviors of real phone owners to show the viability of our approach, (ii)we enable programmers to execute parallelizable tasks on smart- phones with little effort, (iii) we develop a simple task migration model to resume interrupted task executions, and (iv) we imple- ment and evaluate a prototype of CWC (with 18 Android smart- phones) that employs an underlying novel scheduling algorithm to minimize the makespan of a set of tasks. Our extensive eval- uations demonstrate that the performance of our approach makes our vision viable. Further, we explicitly evaluate the performance of CWC’s scheduling component to demonstrate its efficacy com- pared to other possible approaches.",
    year = "2012",
    month = "12",
    pages = "193",
    file = "::",
    address = "New York, New York, USA",
    keywords = "distributed computing,scheduling,smartphone",
    booktitle = "Proceedings of the 8th international conference on Emerging networking experiments and technologies - CoNEXT '12"
}

@inproceedings{Arvo2005,
    author = "Arvo, James and Novins, Kevin",
    publisher = "ACM",
    title = "{Appearance-Preserving Manipulation of Hand-Drawn Graphs}",
    abstract = "We describe a sketching system that allows users to create and ma- nipulate directed graphs, such as those depicting state diagrams, using pen-input alone. The system exactly preserves the user’s strokes, which may be entered in any order, and depicts them with a chalk texture to evoke a blackboard metaphor. The system automat- ically interprets the geometry of the sketch, distinguishing vertices, edges, and arrow heads, then tacitly imparts the intended graph se- mantics based on the two-dimensional placement of these elements. Once drawn, the user can manipulate the directed graph gesturally using the pen. The system responds to vertices or edges being picked and dragged by adjusting all adjacent edges appropriately. The original appearance of the hand-drawn vertices and edges is maintained even while their shapes are continually morphed in re- sponse to rearrangement of these elements. All edges exhibit shape memory, which is the proclivity to return to their original hand- drawn shape despite repeated stretching and compression.",
    year = "2005",
    file = "::",
    address = "Dunedin, New Zealand",
    keywords = "appearance preservation,interactive graph drawing",
    booktitle = "Proceedings of the 3rd international conference on Computer graphics and interactive techniques in Australasia and South East Asia",
    pages = "61--68"
}

@article{Atkeson1997,
    author = "Atkeson, Christopher G and Moore, Andrew W and Schaal, Stefan",
    title = "{Locally Weighted Learning}",
    abstract = "This paper surveys locally weighted learning, a form of lazy learning and memory- based learning, andfocusesonlocallyweighted linear regression.The survey discussesdistance functions, smoothing parameters, weighting functions, local model structures, regularization of the estimates and bias, assessing predictions, handling noisy data and outliers, improving the quality of predictions by tuning fit parameters, interference between old and new data, implementing locally weighted learning efficiently, and applications of locally weighted learning. A companion paper surveys how locally weighted learning can be used in robot learning and control.",
    pages = "11--73",
    file = ":home/drt24/Library/papers/Artificial Intelligence/Atkeson, Moore, Schaal/Atkeson, Moore, Schaal - 1997 - Locally Weighted Learning.pdf:pdf",
    year = "1997",
    keywords = "LOESS,LWR,distance functions,global tuning,interference,lazy learning,least commitment learning,local tuning,locally weighted regression,memory-based learning,smoothing parameters,weighting functions",
    journal = "Artificial Intelligence"
}

@article{Ayewah2008,
    author = "Ayewah, Nathaniel and Hovemeyer, David and Morgenthaler, J. David and Penix, John and Pugh, William",
    doi = "10.1109/MS.2008.130",
    title = "{Using Static Analysis to Find Bugs}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4602670",
    abstract = "Static analysis examines code in the absence of input data and without running the code. It can detect potential security violations (SQL injection), runtime errors (dereferencing a null pointer) and logical inconsistencies (a conditional test that can't possibly be true). Although a rich body of literature exists on algorithms and analytical frameworks used by such tools, reports describing experiences in industry are much harder to come by. The authors describe FindBugs, an open source static-analysis tool for Java, and experiences using it in production settings. FindBugs evaluates what kinds of defects can be effectively detected with relatively simple techniques and helps developers understand how to incorporate such tools into software development.",
    issn = "0740-7459",
    number = "5",
    month = "9",
    volume = "25",
    pages = "22--29",
    year = "2008",
    journal = "IEEE Software"
}

@inproceedings{Badger1995,
    author = "Badger, Lee and Sterne, Daniel F. and Sherman, David L. and Walker, Kenneth M.",
    publisher = "USENIX Association",
    title = "{A domain and type enforcement UNIX prototype}",
    url = "http://dl.acm.org/citation.cfm?id=1267603 http://www.usenix.org/publications/compsystems/1996/win_badger.pdf",
    abstract = {UNIX system security today often relies on correct operation of numerous privileged subsys- tems and careful attention by expert system adminis- trators. In the context of global and possibly hostile networks, these traditional UNIX weaknesses raise a legitimate question about whether UNIX systems are appropriate platforms for processing and safeguarding important information tesources. Domain and Type En- forcement (DTE) is an access control technology for partitioning host oper\'{a}ting systems such as UNIX into access control domains. Such partitioning has promise both to enforce organizational\`{\i}ecurity p\'{o}\"{u}cies that protect special classes of information and to generi- cally strengthen operating systems against penetration attacks. This paper presents the primary DTE concepts, discusses their application to single hosts, IP networks, and NFS, and then describes the design and implemen- tation of a DTE IINIX prototype system.},
    number = "1",
    volume = "9",
    file = ":auto/homes/drt24/Downloads/win\_badger.pdf:pdf",
    year = "1995",
    booktitle = "Proceedings of the 5th conference on USENIX UNIX Security Symposium-Volume 5",
    pages = "12--12"
}

@inproceedings{Bahl2000,
    author = "Bahl, P. and Padmanabhan, V.N.",
    publisher = "IEEE",
    doi = "10.1109/INFCOM.2000.832252",
    isbn = "0-7803-5880-5",
    title = "{RADAR: an in-building RF-based user location and tracking system}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=832252",
    abstract = "The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. In this paper we present RADAR, a radio-frequency (RF)-based system for locating and tracking users inside buildings. RADAR operates by recording and processing signal strength information at multiple base stations positioned to provide overlapping coverage in the area of interest. It combines empirical measurements with signal propagation modeling to determine user location and thereby enable location-aware services and applications. We present experimental results that demonstrate the ability of RADAR to estimate user location with a high degree of accuracy",
    pages = "775--784",
    volume = "2",
    file = "::",
    year = "2000",
    booktitle = "Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064)"
}

@inproceedings{Baker2011,
    author = "Baker, Jason and Bond, Chris and Corbett, James C and Furman, J J and Khorlin, Andrey and Larson, James and Leon, Jean-Michel and Li, Yawei and Lloyd, Alexander and Yushprakh, Vadim",
    title = "{Megastore: Providing Scalable, Highly Available Storage for Interactive Services}",
    abstract = "Megastore is a storage system developed to meet the requirements of today’s interactive online services. Megastore blends the scalability of a NoSQL datastore with the convenience of a traditional RDBMS in a novel way, and provides both strong consistency guarantees and high availability. We provide fully serializable ACID semantics within fine-grained partitions of data. This partitioning allows us to synchronously replicate each write across a wide area network with reasonable latency and support seamless failover between datacenters. This paper describes Megastore’s semantics and replication algorithm. It also describes our experience supporting a wide range of Google production services built with Megastore.",
    pages = "223--234",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker et al. - 2011 - Megastore Providing Scalable, Highly Available Storage for Interactive Services.pdf:pdf",
    year = "2011",
    keywords = "bigtable,distributed transactions,large databases,paxos",
    booktitle = "Conference on Innovative Data Systems Research CIDR"
}

@inproceedings{Balan2002,
    author = "Balan, Rajesh and Flinn, Jason and Satyanarayanan, M. and Sinnamohideen, Shafeeq and Yang, Hen-I",
    publisher = "ACM Press",
    doi = "10.1145/1133373.1133390",
    title = "{The case for cyber foraging}",
    url = "http://dl.acm.org/citation.cfm?id=1133373.1133390",
    abstract = "In this paper, we propose cyber foraging: a mechanism to augment the computational and storage capabilities of mobile devices. Cyber foraging uses opportunistically discovered servers in the environment to improve the performance of interactive applications and distributed file systems on mobile clients. We show how the performance of distributed file systems can be improved by staging data at these servers even though the servers are not trusted. We also show how the performance of interactive applications can be improved via remote execution. Finally, we present VERSUDS: a virtual interface to heteregeneous service discovery protocols that can be used to discover these servers.",
    year = "2002",
    month = "7",
    pages = "87",
    file = ":auto/homes/drt24/Downloads/p87-balan.pdf:pdf",
    address = "New York, New York, USA",
    booktitle = "Proceedings of the 10th workshop on ACM SIGOPS European workshop: beyond the PC - EW10"
}

@article{Balasubramanian2009,
    author = "Balasubramanian, Niranjan",
    publisher = "ACM",
    doi = "10.1145/1644893.1644927",
    isbn = "9781605587707",
    title = "{Energy Consumption in Mobile Phones : A Measurement Study and Implications for Network Applications}",
    url = "http://portal.acm.org/citation.cfm?id=1644927",
    series = "IMC '09",
    journal = "Energy",
    institution = "ACM",
    pages = "280--293",
    year = "2009",
    keywords = "cellular networks,energy savings,mo,power measurement,wifi",
    abstract = "In this paper, we present a measurement study of the energy consumption characteristics of three widespread mobile networking technologies: 3G, GSM, and WiFi. We find that 3G and GSM incur a high tail energy overhead because of lingering in high power states after completing a transfer. Based on these measurements, we develop a model for the energy consumed by network activity for each technology. Using this model, we develop TailEnder, a protocol that reduces energy consumption of common mobile applications. For applications that can tolerate a small delay such as e-mail, TailEnder schedules transfers so as to minimize the cumulative energy consumed meeting user-specified deadlines. We show that the TailEnder scheduling algorithm is within a factor 2x of the optimal and show that any online algorithm can at best be within a factor 1.62x of the optimal. For applications like web search that can benefit from prefetching, TailEnder aggressively prefetches several times more data and improves user-specified response times while consuming less energy. We evaluate the benefits of TailEnder for three different case study applications - email, news feeds, and web search - based on real user logs and show significant reduction in energy consumption in each case. Experiments conducted on the mobile phone show that TailEnder can download 60\% more news feed updates and download search results for more than 50\% of web queries, compared to using the default policy."
}

@article{Baliga2009,
    author = "Baliga, J and Ayre, R and Hinton, K and Sorin, W V and Tucker, R S",
    publisher = "OSA",
    doi = "10.1109/JLT.2008.2010142",
    shorttitle = "J. Lightwave Technol.",
    title = "{Energy Consumption in Optical IP Networks}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4815495",
    abstract = "As community concerns about global energy consumption grow, the power consumption of the Internet is becoming an issue of increasing importance. In this paper, we present a network-based model of power consumption in optical IP networks and use this model to estimate the energy consumption of the Internet. The model includes the core, metro and edge, access and video distribution networks, and takes into account energy consumption in switching and transmission equipment. We include a number of access technologies, including digital subscriber line with ADSL2+, fiber to the home using passive optical networks, fiber to the node combined with very high-speed digital subscriber line and point-to-point optical systems. In addition to estimating the power consumption of today's Internet, we make predictions of power consumption in a future higher capacity Internet using estimates of improvements in efficiency in coming generations of network equipment. We estimate that the Internet currently consumes about 0.4\% of electricity consumption in broadband-enabled countries. While the energy efficiency of network equipment will improve, and savings can be made by employing optical bypass and multicast, the power consumption of the Internet could approach 1\% of electricity consumption as access rates increase. The energy consumption per bit of data on the Internet is around 75bm muJ at low access rates and decreases to around 2-4 bm muJ at an access rate of 100 Mb/s.",
    issn = "07338724",
    number = "13",
    pages = "2391--2403",
    volume = "27",
    file = ":home/drt24/Downloads/04815495.pdf:pdf",
    year = "2009",
    keywords = "access networks,internet power consumption,ip routers,optical bypass",
    journal = "Journal of Lightwave Technology"
}

@inproceedings{Ball2002,
    author = "Ball, Thomas and Rajamani, Sriram K.",
    publisher = "ACM Press",
    doi = "10.1145/503272.503274",
    isbn = "1581134509",
    title = "{The S LAM project}",
    url = "http://dl.acm.org/citation.cfm?id=503272.503274",
    booktitle = "Proceedings of the 29th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '02",
    issn = "0362-1340",
    year = "2002",
    number = "1",
    month = "1",
    volume = "37",
    address = "New York, New York, USA",
    pages = "1--3"
}

@inproceedings{Ball2006,
    author = "Ball, Thomas and Bounimova, Ella and Cook, Byron and Levin, Vladimir and Lichtenberg, Jakob and McGarvey, Con and Ondrusek, Bohus and Rajamani, Sriram K. and Ustuner, Abdullah",
    publisher = "ACM Press",
    doi = "10.1145/1217935.1217943",
    isbn = "1595933220",
    title = "{Thorough static analysis of device drivers}",
    url = "http://dl.acm.org/citation.cfm?id=1217935.1217943",
    booktitle = "Proceedings of the 2006 EuroSys conference on - EuroSys '06",
    issn = "0163-5980",
    year = "2006",
    number = "4",
    month = "4",
    volume = "40",
    file = "::",
    address = "New York, New York, USA",
    keywords = "formal verification,software model checking",
    pages = "73"
}

@inproceedings{Ball2006a,
    author = "Ball, Thomas and Bounimova, Ella and Cook, Byron and Levin, Vladimir and Lichtenberg, Jakob and McGarvey, Con and Ondrusek, Bohus and Rajamani, Sriram K. and Ustuner, Abdullah",
    publisher = "ACM Press",
    doi = "10.1145/1217935.1217943",
    isbn = "1595933220",
    title = "{Thorough static analysis of device drivers}",
    url = "http://dl.acm.org/citation.cfm?id=1217935.1217943",
    booktitle = "Proceedings of the 2006 EuroSys conference on - EuroSys '06",
    issn = "0163-5980",
    year = "2006",
    number = "4",
    month = "4",
    volume = "40",
    file = "::",
    address = "New York, New York, USA",
    keywords = "formal verification,software model checking",
    pages = "73"
}

@article{Baltsavias1999,
    author = "Baltsavias, E",
    doi = "10.1016/S0924-2716(99)00015-5",
    title = "{Airborne laser scanning: basic relations and formulas}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S0924271699000155",
    journal = "ISPRS Journal of Photogrammetry and Remote Sensing",
    issn = "09242716",
    number = "2-3",
    month = "7",
    volume = "54",
    file = "::",
    year = "1999",
    keywords = "3d accuracy analysis,airborne laser scanning,basic relations,formulas,terminology",
    pages = "199--214"
}

@article{Baltsavias1999a,
    author = "Baltsavias, EP",
    isbn = "4116333042",
    title = "{Airborne laser scanning: basic relations and formulas}",
    url = "http://champs.cecs.ucf.edu/Library/Journal_Articles/pdfs/Airborne laser scanning basic relations and formulas.pdf",
    abstract = "An overview of basic relations and formulas concerning airborne laser scanning is given. They are divided into two main parts, the first treating lasers and laser ranging, and the second one referring to airborne laser scanning. A separate discussion is devoted to the accuracy of 3D positioning and the factors influencing it. Examples are given for most relations, using typical values for ALS and assuming an airplane platform. The relations refer mostly to pulse lasers, but CW lasers are also treated. Different scan patterns, especially parallel lines, are treated. Due to the complexity of the relations, some formulas represent approximations or are based on assumptions like constant flying speed, vertical scan, etc.",
    pages = "199--214",
    file = ":auto/homes/drt24/Downloads/Airborne laser scanning basic relations and formulas.pdf:pdf",
    year = "1999",
    keywords = "3d accuracy analysis,airborne laser scanning,basic relations,formulas,terminology",
    journal = "ISPRS Journal of Photogrammetry and Remote Sensing"
}

@inproceedings{Barham2003,
    editor = "Scott, Michael L and Peterson, Larry L",
    author = "Barham, Paul and Dragovic, Boris and Fraser, Keir and Hand, Steven and Harris, Tim and Ho, Alex and Neugebauer, Rolf and Pratt, Ian and Warfield, Andrew",
    publisher = "ACM",
    doi = "10.1145/1165389.945462",
    isbn = "1581137575",
    title = "{Xen and the art of virtualization}",
    url = "http://portal.acm.org/citation.cfm?id=945462",
    series = "SOSP '03",
    abstract = "Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100\% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be ported with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.",
    issn = "01635980",
    number = "5",
    pages = "164--177",
    volume = "37",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barham et al. - 2003 - Xen and the art of virtualization.pdf:pdf",
    year = "2003",
    keywords = "hypervisors,paravirtualization,virtual machine monitors",
    organization = "ACM",
    pmid = "685953",
    booktitle = "SOSP"
}

@article{Barker2007,
    author = "Barker, Elaine and Barker, William and Burr, William and Polk, William and Smid, Miles",
    title = "{SP 800-57 Recommendation for Key Management – Part 1: General}",
    url = "http://csrc.nist.gov/groups/ST/toolkit/documents/SP800-57Part1-Revision3_May2011.pdf",
    abstract = "This Recommendation provides cryptographic key management guidance. It consists of three parts. Part 1 provides general guidance and best practices for the management of cryptographic keying material. Part 2 provides guidance on policy and security planning requirements for U.S. government agencies. Finally, Part 3 provides guidance when using the cryptographic features of current systems.",
    pages = "1--142",
    file = ":auto/homes/drt24/Downloads/sp800-57-Part1-revised2\_Mar08-2007.pdf:pdf",
    year = "2007",
    keywords = "2,assurances,authentication,authorization,availability,backup,compromise,confidentiality,cryptanalysis,cryptographic key,cryptographic module,digital signature,hash function,key agreement,key management,key management policy,key recovery,key transport,originator usage period,private key,public key,recipient usage period,secret key,split knowledge,trust anchor",
    journal = "NIST special publication"
}

@techreport{Barnes2011,
    author = "Barnes, R",
    title = "{Use Cases and Requirements for DNS-based Authentication of Named Entities (DANE)}",
    url = "http://ebook.tools.ietf.org/html/rfc6394",
    abstract = "Many current applications use the certificate-based authentication features in Transport Layer Security (TLS) to allow clients to verify that a connected server properly represents a desired domain name. Typically, this authentication has been based on PKIX certificate chains rooted in well-known certificate authorities (CAs), but additional information can be provided via the DNS itself. This document describes a set of use cases in which the DNS and DNS Security Extensions (DNSSEC) could be used to make assertions that support the TLS authentication process. The main focus of this document is TLS server authentication, but it also covers TLS client authentication for applications where TLS clients are identified by domain names.",
    pages = "1--12",
    file = ":auto/homes/drt24/Downloads/rfc6394.txt.pdf:pdf",
    year = "2011",
    institution = "IETF"
}

@article{Barr2006a,
    author = "Barr, Kenneth C. and Asanovi\'{c}, Krste",
    doi = "10.1145/1151690.1151692",
    title = "{Energy-aware lossless data compression}",
    url = "http://dl.acm.org/citation.cfm?id=1151690.1151692 http://portal.acm.org/citation.cfm?doid=1151690.1151692",
    abstract = "Wireless transmission of a single bit can require over 1000 times more energy than a single computation. It can therefore be beneficial to perform additional computation to reduce the number of bits transmitted. If the energy required to compress data is less than the energy required to send it, there is a net energy savings and an increase in battery life for portable computers. This article presents a study of the energy savings possible by losslessly compressing data prior to transmission. A variety of algorithms were measured on a StrongARM SA-110 processor. This work demonstrates that, with several typical compression algorithms, there is a actually a net energy increase when compression is applied before transmission. Reasons for this increase are explained and suggestions are made to avoid it. One such energy-aware suggestion is asymmetric compression, the use of one compression algorithm on the transmit side and a different algorithm for the receive path. By choosing the lowest-energy compressor and decompressor on the test platform, overall energy to send and receive data can be reduced by 11\% compared with a well-chosen symmetric pair, or up to 57\% over the default symmetric zlib scheme.",
    issn = "07342071",
    number = "3",
    month = "8",
    volume = "24",
    pages = "250--291",
    file = "::",
    year = "2006",
    keywords = "Compression,energy-aware,lossless,low-power,power-aware",
    journal = "ACM Transactions on Computer Systems"
}

@article{Barrenetxea2008,
    author = "Barrenetxea, Guillermo and Ingelrest, Fran\c{c}ois and Schaefer, Gunnar and Vetterli, Martin",
    publisher = "ACM Press",
    doi = "10.1145/1460412.1460418",
    isbn = "9781595939906",
    title = "{The hitchhiker's guide to successful wireless sensor network deployments}",
    url = "http://portal.acm.org/citation.cfm?doid=1460412.1460418",
    journal = "Proceedings of the 6th ACM conference on Embedded network sensor systems - SenSys '08",
    year = "2008",
    file = "::",
    address = "New York, New York, USA",
    keywords = "architecture,deployment,environmental monitoring,im-,plementation,wireless sensor network",
    pages = "43"
}

@incollection{Barrere2013,
    author = {Barr\`{e}re, Mart\'{\i}n and Hurel, Ga\"{e}tan and Badonnel, R\'{e}mi and Festor, Olivier},
    chapter = "3",
    publisher = "Springer",
    doi = "10.1007/978-3-319-01433-3",
    isbn = "9783319014333",
    title = "{Increasing Android Security using a Lightweight OVAL-based Vulnerability Assessment Framework}",
    url = "http://link.springer.com/chapter/10.1007/978-3-319-01433-3_3",
    abstract = "Mobile computing devices and the services offered by them are utilized by millions of users on a daily basis. However, they operate in hostile environ- ments getting exposed to a wide variety of threats. Accordingly, vulnerability management mechanisms are highly required. We present in this paper a novel approach for increasing the security of mobile devices by efficiently detecting vulnerable configurations. In that context, we propose a modeling for performing vulnerability assessment activities as well as an OVAL-based distributed framework for ensuring safe configurations within the Android platform.We also describe an implementation prototype and evaluate its performance through an extensive set of experiments.",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-319-01433-3\_3.pdf:pdf",
    year = "2013",
    booktitle = "Automated Security Management"
}

@article{Barreto2006,
    author = "Barreto, PSLM and Naehrig, Michael",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11693383_22",
    isbn = "978-3-540-33108-7",
    title = "{Pairing-friendly elliptic curves of prime order}",
    url = "http://link.springer.com/chapter/10.1007/11693383_22",
    abstract = "Previously known techniques to construct pairing-friendly curves of prime or near-prime order are restricted to embedding degree \$k \backslash leqslant 6 \$ . More general methods produce curves over \$\{\backslash mathbb F\}\_\{p\}\$ where the bit length of p is often twice as large as that of the order r of the subgroup with embedding degree k; the best published results achieve $\rho$ ≡ log(p)/log(r) \~{} 5/4. In this paper we make the first step towards surpassing these limitations by describing a method to construct elliptic curves of prime order and embedding degree k = 12. The new curves lead to very efficient implementation: non-pairing operations need no more than \$\{\backslash mathbb F\}\_\{p\^{}4\}\$ arithmetic, and pairing values can be compressed to one third of their length in a way compatible with point reduction techniques. We also discuss the role of large CM discriminants D to minimize $\rho$; in particular, for embedding degree k = 2q where q is prime we show that the ability to handle log(D)/log(r) \~{} (q–3)/(q–1) enables building curves with $\rho$ \~{} q/(q–1).",
    pages = "319--331",
    volume = "3897",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F11693383\_22.pdf:pdf",
    year = "2006",
    keywords = "elliptic curves,pairing-based cryptosystems",
    journal = "Lecture Notes in Computer Science: Selected areas in cryptography"
}

@techreport{Barth2008,
    author = "Barth, Adam and Jackson, Collin and Reis, Charles and Team, Google Chrome",
    url = "http://css.csail.mit.edu/6.858/2010/readings/chromium.pdf",
    abstract = "Most current web browsers employ a monolithic architec- ture that combines “the user” and “the web” into a single protection domain. An attacker who exploits an arbitrary code execution vulnerability in such a browser can steal sen- sitive files or install malware. In this paper, we present the security architecture of Chromium, the open-source browser upon which Google Chrome is built. Chromium has two modules in separate protection domains: a browser kernel, which interacts with the operating system, and a rendering engine, which runs with restricted privileges in a sandbox. This architecture helps mitigate high-severity attacks with- out sacrificing compatibility with existing web sites. We define a threat model for browser exploits and evaluate how the architecture would have mitigated past vulnerabilities.",
    year = "2008",
    file = ":home/drt24/Downloads/chromium-security-architecture.pdf:pdf",
    title = "{The security architecture of the Chromium browser}"
}

@article{Barth2011,
    author = "Barth, Adam and Li, Saung and Rubinstein, Benjamin I. P. and Song, Dawn",
    title = "{How Open Should Open Source Be?}",
    abstract = "Many open-source projects land security fixes in public repositories before shipping these patches to users. This paper presents attacks on such projects—taking Firefox as a case-study—that exploit patch metadata to efficiently search for security patches prior to shipping. Using access-restricted bug reports linked from patch descriptions, security patches can be immediately identified for 260 out of 300 days of Firefox 3 development. In response to Mozilla obfuscating descriptions, we show that machine learning can exploit metadata such as patch author to search for security patches, extending the total window of vulnerability by 5 months in an 8 month period when examining up to two patches daily. Finally we present strong evidence that further metadata obfuscation is unlikely to prevent information leaks, and we argue that open-source projects instead ought to keep security patches secret until they are ready to be released.",
    eprint = "arXiv:1109.0507v1",
    file = ":home/drt24/Downloads/1109.0507v1.pdf:pdf",
    year = "2011",
    keywords = "information leakage,learning-based attacks,open-source software security",
    archiveprefix = "arXiv",
    arxivid = "arXiv:1109.0507v1"
}

@techreport{Bartlett2012,
    author = "Bartlett, Jamie",
    url = "http://www.demos.co.uk/files/The_Data_Dialogue.pdf?1347544233",
    year = "2012",
    institution = "Demos",
    file = ":home/drt24/Downloads/The\_Data\_Dialogue.pdf:pdf",
    title = "{The Data Dialogue}"
}

@techreport{BartlettJamie2012,
    author = "{Bartlett Jamie}",
    url = "http://www.demos.co.uk/files/The_Data_Dialogue.pdf?1347544233",
    abstract = "We live in an age of sharing. As consumers and online, we regularly share personal information, and generate new data through our browsing or purchasing history. Businesses and government are increasingly aware of the value of this information, which can result in better and cheaper services for customers, new sources of income for businesses and improved public services. But the question of who owns this information, and how it is collected, stored and used, is becoming a major consumer rights issue. It is crucial, therefore, that people are at the heart of any new settlement. The Data Dialogue sets out the results of the largest ever poll of public attitudes on personal information and data- sharing. Based on a representative sample of 5,000 adults, the report finds a growing crisis in consumer confidence over how government and business handle personal data, and discomfort about the way in which personal information and data are currently being used. The report argues that this loss of confidence could have a knock-on effect on the economy and on the quality of services available to consumers. However, it also finds that views about sharing change when people are given more control and choice about what data is shared, and when the benefit of sharing that data is made clear to them. It therefore suggests that consumers should be engaged in an honest dialogue about how data are collected and used, and be given meaningful choice and control over the information they share. That will be good for business and consumers alike.",
    year = "2012",
    isbn = "978-1-909037-16-8",
    title = "{The Data Dialogue}"
}

@article{Batyuk2009,
    author = "Batyuk, Leonid and Schmidt, Aubrey-derrick and Schmidt, Hans-gunther",
    keywords = "android,c,java,performance,smartphones,software",
    year = "2009",
    pages = "381--392",
    file = "::",
    title = "{Developing and Benchmarking Native Linux Applications on Android}"
}

@article{Beattie2002,
    author = "Beattie, S and Arnold, S and Cowan, C and Wagle, P and Wright, C and Shostack, a",
    title = "{Timing the application of security patches for optimal uptime}",
    url = "http://www.ibm.com/developerworks/websphere/library/techarticles/0108_botzum/botzum.html",
    abstract = "Security vulnerabilities are discovered, become publicly known, get exploited by attackers, and patches, come out. When should one apply security patches? Patch too soon, and you may suffer from instability induced by bugs in the patches. Patch too late, and you get hacked by attackers exploiting the vulnerability. We explore the factors affecting when it is best to apply security patches, providing both mathematical models of the factors affecting when to patch, and collecting empirical data to give the model practical value. We conclude with a model that we hope will help provide a formal foundation for when the practitioner should apply security updates.",
    pages = "233--242",
    file = ":home/drt24/Downloads/beattie.pdf:pdf",
    year = "2002",
    journal = "Proceedings of the 16th USENIX conference on System administration"
}

@incollection{Becker2012,
    author = "Neuhaus, Stephan and Plattner, Bernhard",
    chapter = "4",
    publisher = "Springer",
    doi = "10.1007/978-3-642-39498-0",
    isbn = "978-3-642-39497-3",
    title = "{Software Security Economics: Theory, in Practice}",
    url = "http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2041492",
    abstract = "Proof-of-Work (PoW), a well-known principle to ration resource access in client-server relations, is about to experience a renaissance as a mechanism to protect the integrity of a global state in distributed transaction systems under decentralized control. Most prominently, the Bitcoin cryptographic currency protocol leverages PoW to 1) prevent double spending and 2) establish scarcity, two essential properties of any electronic currency. This paper asks the important question whether this approach is generally viable. Citing actual data, it provides a first cut of an answer by estimating the resource requirements, in terms of operating cost and ecological footprint, of a suitably dimensioned PoW infrastructure and comparing them to three attack scenarios. The analysis is inspired by Bitcoin, but generalizes to potential successors, which fix Bitcoin’s technical and economic teething troubles discussed in the literature.",
    pages = "75--92",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-39498-0\_4.pdf:pdf",
    year = "2013",
    booktitle = "The Economics of Information Security and Privacy"
}

@book{Beckert2011,
    editor = "Beckert, Bernhard and March\'{e}, Claude",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-18070-5",
    isbn = "978-3-642-18069-9",
    title = "{Formal Verification of Object-Oriented Software}",
    url = "http://www.springerlink.com/content/9t4r84636062l355/",
    series = "Lecture Notes in Computer Science",
    year = "2011",
    volume = "6528",
    address = "Berlin, Heidelberg"
}

@techreport{Bell1976,
    author = "Bell, D.Elliot",
    title = "{Secure computer system: Unified exposition and multics interpretation}",
    url = "http://oai.dtic.mil/oai/oai?verb=getRecord\&amp;metadataPrefix=html\&amp;identifier=ADA023588",
    abstract = "A unified narrative exposition of the ESD/MITRE computer security model is presented. A suggestive interpretation of the model in the context of Multics and a discussion of several other important topics (such as communication paths, sabotage and integrity) conclude the report.",
    file = ":auto/homes/drt24/Downloads/bell76.pdf:pdf",
    year = "1976",
    keywords = "Asterisk-property,mathematical model,secure computer system,security,trusted subject",
    institution = "DTIC Document"
}

@article{Bella2005,
    author = "Bella, Giampaolo and Bistarelli, Stefano and Massacci, Fabio",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11542322_2",
    isbn = "978-3-540-28389-8",
    title = "{A protocol's life after attacks...}",
    url = "http://link.springer.com/chapter/10.1007/11542322_3",
    abstract = "In the analysis of security protocols, it is customary to stop as soon as we find an attack. Tons of ink can be spilled on whether an “attack” is really an attack, but it goes without saying that there is no life after that, hence no interest in continuing the analysis. If the protocol is broken, then we ought to fix it. Yet, fixing things is expensive and other measures may be more effective. In the physical world, most ATM safes would not resist heavy shelling with anti-tank bazookas, but banks don’t worry about that. The attack will be noisy enough that cops will come within seconds from its start. To secure ourselves, we rely on a mixture of measures including the protection from attacks but also countermeasures after detection. In the light of these considerations, the following question becomes of interest: what can happen after an attack? Does the villain leave enough traces that we can retaliate it on-the-fly? Or, if we can’t or won’t, does a subsequent forensic analysis allow us to discover who did it (and send the cops behind him)? If even this is impossible, can we discover that we have been hacked by looking at the logs? To address these issues, we introduce the notions of retaliation, detection, and suspicion, which can be applied after an attack. These properties introduce more sophisticated formal relations between traces of actions, which go beyond the simple existentials that formal methods have made us used to. These concepts should allow for a more comprehensive evaluation of security protocols. A protocol may well be vulnerable to an attack, but if we can retaliate afterwards, maybe fixing it isn’t that necessary: the concrete possibilities of retaliation or detection may be enough to convince potential hackers to refrain from mounting the attack.",
    pages = "3--10",
    volume = "3364",
    file = ":home/drt24/Downloads/10.1007\_11542322\_2.pdf:pdf",
    year = "2005",
    journal = "Security Protocols"
}

@article{Bella2005a,
    author = "Bella, Giampaolo",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11542322_3",
    isbn = "978-3-540-28389-8",
    title = "{A Protocol’s Life After Attacks... (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/11542322_3",
    abstract = "I am going to be speaking about protocol verification again; I’m going to take a rather different perspective from the one we normally take, and I’ll be talking about what happens after an attack takes place. Is there a life for a protocol beyond the attacks? We all know about verification. On the one hand we have the model checking community trying to find a witness of an attack, trying to find if something went wrong and why the specific property of interest failed. On the other hand we have the opposite approach, assuring that there’s no such witness therefore the specific property holds. But the question here is, is this the whole story? It appears that everything is about finding the attack: is there an attack, is there no attack against confidentiality or authentication? It appears kind of weird. Is it only the attack we are really interested in? Is this really all we should look at? I’ll try and convince you that there’s something more. So, let’s suppose for a minute we own a jewellers, and one day we find that the main window has been completely smashed by someone. In the worst case there is no-one around and basically all we can do is suspect anyone, any passer-by, because there’s really no evidence against anyone. If we’re luckier, we could find the people there while they’re still at work carrying away the stuff. Basically we detect who actually mounted the attack and we’re kind of happy with that, as we’re sure who the attacker is because we saw them. But we can even do more than that, maybe we have time to call the police, and the attackers will be caught, punished, and sent to jail, so we basically retaliate against them. If you move this to a different context perhaps retaliating means that I go up to the attacker’s window and smash the window. Anyway, this is just a general notion of punishment and retaliation. This is certainly about the best we can do. This line attempts to convince us that there are some measures we normally take after an attack takes place in the real world. So the idea here is to apply these very same concepts to the world of security protocols and see what we can get out of it.",
    pages = "11--18",
    volume = "3364",
    file = ":home/drt24/Downloads/10.1007\_11542322\_3.pdf:pdf",
    year = "2005",
    journal = "Security Protocols"
}

@article{Bella2005b,
    author = "Bella, Giampaolo",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11542322_35",
    isbn = "978-3-540-28389-8",
    title = "{What We Can Learn from API Security (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/11542322_35",
    abstract = "During the period when Mike and Bruce were looking for position papers for this workshop, I was rather busy because of a court case some of you may have heard about, so I’m going to go over the slides that I gave at Roger Needham’s farewell do last month, with some extra material added. The subject is what API security teaches us in the wider world of protocols; so it’s about protocol analysis, composability, computation, and the effects in the real world. How do we define a security protocol’s world? Well that’s changing: in the classic literature there are rules for dealing with information used to verify principals’ claims to identity, such as passwords, PINs, crypto keys and timestamps. Now it’s expanding to include other claims: such as claims to authorisation, or claims to creditworthiness, or claims to have a particular bank balance available for an electronic payment.",
    pages = "288--300",
    volume = "3364",
    file = ":home/drt24/Downloads/10.1007\_11542322\_35.pdf:pdf",
    year = "2005",
    journal = "Security Protocols"
}

@inproceedings{Bellare1997,
    author = "Bellare, M. and Desai, A. and Jokipii, E. and Rogaway, P.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/SFCS.1997.646128",
    isbn = "0-8186-8197-7",
    title = "{A concrete security treatment of symmetric encryption}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=646128",
    abstract = "We study notions and schemes for symmetric (ie. private key) encryption in a concrete security framework. We give four different notions of security against chosen plaintext attack and analyze the concrete complexity of reductions among them, providing both upper and lower bounds, and obtaining tight relations. In this way we classify notions (even though polynomially reducible to each other) as stronger or weaker in terms of concrete security. Next we provide concrete security analyses of methods to encrypt using a block cipher, including the most popular encryption method, CBC. We establish tight bounds (meaning matching upper bounds and attacks) on the success of adversaries as a function of their resources",
    month = "10",
    pages = "394--403",
    file = ":home/drt24/Downloads/00646128.pdf:pdf",
    year = "1997",
    booktitle = "Proceedings 38th Annual Symposium on Foundations of Computer Science"
}

@inproceedings{Bellissimo2006,
    author = "Bellissimo, Anthony and Burgess, John and Fu, Kevin",
    publisher = "USENIX",
    title = "{Secure software updates: disappointments and new challenges}",
    url = "http://www.usenix.org/event/hotsec06/tech/full_papers/bellissimo/bellissimo.pdf$\backslash$nhttps://www.usenix.org/legacy/events/sec06/tech/$\backslash$nhttp://www.usenix.org/event/hotsec06/tech/full_papers/bellissimo/bellissimo.pdf",
    abstract = "A client can use a content distribution network to securely download software updates. These updates help to patch everyday bugs, plug security vulnerabilities, and secure critical infrastructure. Yet challenges remain for secure content distribution: many deployed software update mechanisms are insecure, and emerging technologies pose further hurdles for deployment. Our analysis of several popular software update mechanisms shows that deployed systems often rely on trusted networks to distribute critical software updates — despite the research progress in secure content distribution. We demonstrate how many deployed systems are susceptible to weak man-in-the-middle attacks. Furthermore, emerging technologies such as mobile devices, sensors, medical devices, and RFID tags present new challenges for secure software updates. Sporadic network connectivity and limited power, computation, and storage require a rethinking of traditional approaches for secure content distribution on embedded devices.",
    pages = "37--43",
    file = ":home/drt24/Downloads/bellissimo.pdf:pdf",
    year = "2006",
    booktitle = "Proceedings of USENIX Hot Topics in Security"
}

@inproceedings{Bellovin1992,
    author = "Bellovin, Steven M. and Merritt, Michael",
    publisher = "IEEE",
    doi = "10.1109/RISP.1992.213269",
    isbn = "0818628251",
    title = "{Encrypted Key Exchange : Password-Based Protocols Secure Against Dictionary Attacks}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=213269\&tag=1",
    abstract = "Classic cryptographic protocols based on user-chosen keys allow an attacker to mount password-guessing attacks. A combination of asymmetric (public-key) and symmetric (secret-key) cryptography that allow two parties sharing a common password to exchange confidential and authenticated information over an insecure network is introduced. In particular, a protocol relying on the counter-intuitive motion of using a secret key to encrypt a public key is presented. Such protocols are secure against active attacks, and have the property that the password is protected against offline dictionary attacks",
    year = "1992",
    month = "5",
    pages = "72 -- 84",
    file = ":home/drt24/Downloads/00213269.pdf:pdf",
    address = "Oakland, California",
    booktitle = "IEEE Security and Privacy"
}

@article{Bellovin1995,
    author = "Bellovin, Steven M.",
    title = "{Using the domain name system for system break-ins}",
    url = "http://www.usenix.org/publications/library/proceedings/security95/full_papers/bellovin.pdf",
    abstract = "The DARPA Internet uses the Domain Name System (DNS), a distributed database, to map host names to network addresses, and vice-versa. Using a vulnerability first noticed by P.V. Mockapetris, we demonstrate how the DNS can be abused to subvert system security. We also show what tools are useful to the attacker. Possible defences against this attack, including one implemented by Berkley in response to our reports of this problem, are discussed, and the limitations of their applicability are demonstrated.",
    file = ":auto/homes/drt24/Downloads/dnshack.ps:ps",
    year = "1995",
    journal = "Proceedings of the Fifth Usenix UNIX Security"
}

@techreport{Beresford2005,
    author = "Beresford, Alastair R",
    title = "{Location privacy in ubiquitous computing}",
    url = "http://www.cl.cam.ac.uk/research/dtg/publications/public/arb33/UCAM-CL-TR-612.pdf",
    abstract = "The field of ubiquitous computing envisages an era when the average consumer owns hun- dreds or thousands of mobile and embedded computing devices. These devices will perform actions based on the context of their users, and therefore ubiquitous systems will gather, col- late and distribute much more personal information about individuals than computers do today. Much of this personal information will be considered private, and therefore mechanisms which allow users to control the dissemination of these data are vital. Location information is a par- ticularly useful form of context in ubiquitous computing, yet its unconditional distribution can be very invasive. This dissertation develops novel methods for providing location privacy in ubiquitous com- puting. Much of the previous work in this area uses access control to enable location privacy. This dissertation takes a different approach and argues that many location-aware applications can function with anonymised location data and that, where this is possible, its use is preferable to that of access control. Suitable anonymisation of location data is not a trivial task: under a realistic threat model simply removing explicit identifiers does not anonymise location information. This dissertation describes why this is the case and develops two quantitative security models for anonymising location data: the mix zone model and the variable quality model. A trusted third-party can use one, or both, models to ensure that all location events given to untrusted applications are suitably anonymised. The mix zone model supports untrusted applications which require accurate location information about users in a set of disjoint physical locations. In contrast, the variable quality model reduces the temporal or spatial accuracy of location information to maintain user anonymity at every location. Both models provide a quantitative measure of the level of anonymity achieved; therefore any given situation can be analysed to determine the amount of information an attacker can gain through analysis of the anonymised data. The suitability of both these models is demon- strated and the level of location privacy available to users of real location-aware applications is measured.",
    issn = "1466-447X",
    month = "10",
    file = ":auto/homes/drt24/Downloads/UCAM-CL-TR-612.pdf:pdf",
    year = "2005",
    keywords = "location,privacy,ubiquitous",
    institution = "University of Cambridge, Computer Laboratory"
}

@inproceedings{Beresford2011,
    author = "Beresford, Alastair R and Rice, Andrew C. and Skehin, Nicholas and Sohan, Ripduman",
    publisher = "ACM",
    doi = "10.1145/2184489.2184500",
    isbn = "9781450306492",
    title = "{MockDroid: trading privacy for application functionality on smartphones}",
    abstract = "MockDroid is a modified version of the Android operating system which allows a user to ‘mock’ an application’s ac- cess to a resource. This resource is subsequently reported as empty or unavailable whenever the application requests access. This approach allows users to revoke access to par- ticular resources at run-time, encouraging users to consider the trade-off between functionality and the disclosure of per- sonal information whilst they use an application. Existing applications continue to work on MockDroid, possibly with reduced functionality, since existing applications are already written to tolerate resource failure, such as network unavail- ability or lack of a GPS signal. We demonstrate the prac- ticality of our approach by successfully running a random sample of twenty-three popular applications from the An- droid Market.",
    file = ":auto/homes/drt24/Downloads/beresford-mockdroid.pdf:pdf",
    year = "2011",
    booktitle = "Proceedings of the 11th Workshop on Mobile Computing Systems and Applications HotMobile"
}

@article{Berger2012,
    author = "Berger, Emery D.",
    doi = "10.1145/2330667.2330683",
    title = "{Software needs seatbelts and airbags}",
    url = "http://dl.acm.org/ft_gateway.cfm?id=2330683\&type=html http://dl.acm.org/citation.cfm?doid=2330667.2330683",
    abstract = "Finding and fixing bugs in deployed software is difficult and time-consuming. Here are some alternatives.",
    issn = "00010782",
    number = "9",
    month = "9",
    volume = "55",
    pages = "48",
    file = "::",
    year = "2012",
    journal = "Communications of the ACM"
}

@article{Berger2012a,
    author = "Berger, Emery D.",
    title = "{Software needs seatbelts and airbags}",
    url = "http://dl.acm.org/ft_gateway.cfm?id=2330683\&type=html",
    journal = "Communications of the ACM",
    issn = "00010782",
    number = "9",
    month = "9",
    volume = "55",
    year = "2012",
    pages = "48"
}

@article{Berger2012b,
    author = "Berger, Emery D.",
    title = "{Software needs seatbelts and airbags}",
    journal = "Communications of the ACM",
    abstract = "Finding and fixing bugs in deployed software is difficult and time-consuming. Here are some alternatives.",
    issn = "00010782",
    number = "9",
    month = "9",
    volume = "55",
    url = "http://dl.acm.org/ft_gateway.cfm?id=2330683\&type=html http://dl.acm.org/citation.cfm?doid=2330667.2330683",
    year = "2012",
    pages = "48"
}

@online{Bergman2012,
    author = "Bergman, Neil",
    url = "http://d3adend.org/blog/?p=314",
    urldate = "2015-01-09",
    title = "{Abusing WebView JavaScript Bridges}",
    year = "2012",
    month = "12"
}

@article{Berkel2009,
    author = "van Berkel, C.H. (Kees)",
    year = "2009",
    isbn = "9783981080155",
    pages = "1260--1265",
    file = "::",
    title = "{Multi-Core for Mobile Phones}"
}

@inproceedings{Bernat2011,
    author = "Bernat, A.R. and Miller, B.P.",
    publisher = "ACM",
    isbn = "9781450308496",
    title = "{Anywhere, any-time binary instrumentation}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Anywhere+,+Any-Time+Binary+Instrumentation\#0",
    booktitle = "Proceedings of the 10th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools",
    file = "::",
    year = "2011",
    keywords = "binary,binary instrumentation,dynamic instrumentation",
    pages = "9--16"
}

@inproceedings{Bernstein2012,
    author = "Bernstein, DJ and Lange, Tanja and Schwabe, Peter",
    doi = "10.1007/978-3-642-33481-8_9",
    title = "{The security impact of a new cryptographic library}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-33481-8_9 http://cr.yp.to/highspeed/coolnacl-20120725.pdf",
    abstract = "This paper introduces a new cryptographic library, NaCl, and explains how the design and implementation of the library avoid various types of cryptographic disasters suffered by previous cryptographic libraries such as OpenSSL. Specifically, this paper analyzes the security impact of the following NaCl features: no data flow from secrets to load addresses; no data flow from secrets to branch conditions; no padding oracles; centralizing randomness; avoiding unnecessary randomness; ex- tremely high speed; and cryptographic primitives chosen conservatively in light of the cryptanalytic literature.",
    pages = "1--18",
    file = ":home/drt24/Downloads/coolnacl-20120725.pdf:pdf",
    year = "2012",
    keywords = "confidentiality,integrity,security,simplicity,speed",
    booktitle = "LatinCrypt"
}

@book{Berry2001,
    editor = "Berry, G\'{e}rard and Comon, Hubert and Finkel, Alain",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-44585-4",
    isbn = "978-3-540-42345-4",
    title = "{Computer Aided Verification}",
    url = "http://www.springerlink.com/content/53ypg8hgxy7tpywj/",
    series = "Lecture Notes in Computer Science",
    year = "2001",
    month = "7",
    volume = "2102",
    address = "Berlin, Heidelberg"
}

@article{Bhansali2006,
    author = "Bhansali, Sanjay and Chen, Wen-Ke and de Jong, Stuart and Edwards, Andrew and Murray, Ron and Drini\'{c}, Milenko and Miho\v{c}ka, Darek and Chau, Joe",
    doi = "10.1145/1134760.1220164",
    isbn = "1-59593-332-8",
    title = "{Framework for instruction-level tracing and analysis of program executions}",
    url = "http://dl.acm.org/citation.cfm?id=1134760.1220164",
    month = "6",
    file = "::",
    year = "2006",
    keywords = "callback,code emulation,code replay,time-travel debugging,tracing",
    pages = "154--163"
}

@article{Bhatotia2011,
    author = "Bhatotia, Pramod and Wieder, Alexander and Rodrigues, Rodrigo",
    url = "http://dl.acm.org/citation.cfm?id=2038923",
    journal = "Proceedings of the 2nd",
    year = "2011",
    file = "::",
    title = "{Incoop: Mapreduce for incremental computations}"
}

@article{Bilge2012,
    author = "Bilge, Leyla and Dumitras, Tudor",
    doi = "10.1145/2382196.2382284",
    isbn = "9781450316514",
    title = "{Before We Knew It: an Empirical Study of Zero-Day Attacks in the Real World}",
    url = "http://dl.acm.org/citation.cfm?doid=2382196.2382284",
    abstract = "Little is known about the duration and prevalence of zero-day attacks, which exploit vulnerabilities that have not been disclosed publicly. Knowledge of new vulnerabilities gives cyber criminals a free pass to attack any target of their choosing, while remaining undetected. Unfortunately, these serious threats are difficult to analyze, because, in general, data is not available until after an attack is discovered. Moreover, zero-day attacks are rare events that are unlikely to be observed in honeypots or in lab experiments. In this paper, we describe a method for automatically identifying zero-day attacks from field-gathered data that records when benign and malicious binaries are downloaded on 11 million real hosts around the world. Searching this data set for malicious files that exploit known vulnerabilities indicates which files appeared on the Internet before the corresponding vulnerabilities were disclosed. We identify 18 vulnerabilities exploited before disclosure, of which 11 were not previously known to have been employed in zero-day attacks. We also find that a typical zero-day attack lasts 312 days on average and that, after vulnerabilities are disclosed publicly, the volume of attacks exploiting them increases by up to 5 orders of magnitude.",
    pages = "833--844",
    file = ":home/drt24/Downloads/p833-bilge.pdf:pdf",
    year = "2012",
    keywords = "all or part of,full disclosure,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for,vulnerabilities,zero-day attacks",
    journal = "Proceedings of the 2012 ACM Conference on Computer and Communications Security -- CCS'12"
}

@article{Binkert2006,
    author = "Binkert, N.L. and Dreslinski, R.G. and Hsu, L.R. and Lim, K.T. and Saidi, A.G. and Reinhardt, S.K.",
    doi = "10.1109/MM.2006.82",
    title = "{The M5 Simulator: Modeling Networked Systems}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1677503",
    abstract = "The M5 simulator is developed specifically to enable research in TCP/IP networking. The M5 simulator provides features necessary for simulating networked hosts, including full-system capability, a detailed I/O subsystem, and the ability to simulate multiple networked systems deterministically. M5's usefulness as a general-purpose architecture simulator and its liberal open-source license has led to its adoption by several academic and commercial groups",
    issn = "0272-1732",
    number = "4",
    month = "7",
    volume = "26",
    pages = "52--60",
    file = "::",
    year = "2006",
    journal = "IEEE Micro"
}

@article{Birrell1982,
    author = "Birrell, Andrew D and Levin, Roy and Schroeder, Michael D. and Needham, Roger M.",
    publisher = "ACM",
    doi = "10.1145/358468.358487",
    isbn = "0897910621",
    title = "{Grapevine: an exercise in distributed computing}",
    url = "http://portal.acm.org/citation.cfm?doid=358468.358487",
    abstract = "Grapevine is a multicomputer system on the Xerox Research Internet. It provides facilities for the delivery of digital messages such as computer mail; for naming people, machines, and services; for authenticating people and machines; and for locating services on the internet. This paper has two goals: to describe the system itself and to serve as a case study of a real application of distributed computing. Part I describes the set of services provided by Grapevine and how its data and function are divided among computers on the internet. Part II presents in more detail selected aspects of Grapevine that illustrate novel facilities or implementation techniques, or that provide insight into the structure of a distributed system. Part III summarizes the current state of the system and the lessons learned from it so far.",
    issn = "00010782",
    number = "4",
    pages = "260--274",
    volume = "25",
    file = ":auto/homes/drt24/Downloads/p260-birrell.pdf:pdf",
    year = "1982",
    journal = "Communications of the ACM"
}

@techreport{BisbeyII1978,
    author = "BisbeyII, R. and Hollingworth, D.",
    publisher = "UNIVERSITY OF SOUTHERN CALIFORNIA MARINA DEL REY INFORMATION SCIENCES INST",
    title = "{Protection analysis: Final report}",
    url = "http://www.stormingmedia.us/61/6186/A618650.html http://csrc.nist.gov/publications/history/bisb78.pdf",
    abstract = {The Protection Analysis project was initiated at ISI by ARPA IPTO to further understand operating system security vunlnerabilities and, where possible, identify automatable techniques for detecting such vulnerabilities in existing system software. The primary goal of the project was to make protection evaluation both more effective and more economical by decomposing it into more managable and methodical subtasks so as to drastically reduce teh requirement for protection expertise and make it as independent as possible of the skills and motivations of the actual individuals involved. The project focusssed on near-term solutions to the problem of improving the security of existing and future operating systems in an attempt to have some impact on security of the systems which woulod be in use in the next ten years. A general strategy was identfified, referred to as "pattern-directed protection evaluation" and tailored to the problem of evaluating existing systems. The approach provided a basis for categorizing protection errors according to the security-relevant properties; it was successfully applied for one such category to the MULTICS operating system, resulting in the detection of previously unknown security vulnerabilities.},
    file = ":auto/homes/drt24/Downloads/bisb78.pdf:pdf",
    year = "1978",
    keywords = "access control,computer security,error analysis,error types,error-driven evaluation,operating system security,protection evaluation,protection policy,software security"
}

@inproceedings{Biswas2012,
    author = "Biswas, Debmalya",
    publisher = "IEEE",
    doi = "10.1109/PerComW.2012.6197606",
    isbn = "978-1-4673-0907-3",
    title = "{Privacy policies change management for smartphones}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6197606\&contentType=Conference+Publications\&searchField=Search_All\&queryText=privacy+policies+change",
    abstract = "The ever increasing popularity of apps stems from their ability to provide highly customized services for the user. The flip side is that to provide such customized services, apps need access to very sensitive personal user information. This has led to a lot of rogue apps that e.g. pass personal information to 3rd party Ad servers in the background. Studies have shown that current app vetting processes which are mainly restricted to install time verification mechanisms are incapable of detecting and preventing such attacks. We argue that the missing fundamental aspect here is the inability to capture and control runtime characteristics of apps, e.g. we need to know not only the list of sensors that need to be accessed by an app but also their frequency of access. This leads to the need for an expressive policy language that in addition to the list of sensors, also allows specifying when, where and how frequently can they be accessed. An expressive policy language has the disadvantage of making the task of an average user more difficult in setting and analyzing the consequences of his privacy settings. Further, privacy polices evolve over time. Over time, users are likely to change their privacy settings, as a response to a recently discovered vulnerability, or to be able to install that “much desired” app, etc. Such a policy change affects both already installed (may no longer be compliant) and previously rejected apps (may be compliant now). In this paper, we propose an integrated privacy add-on that (i) compares the apps profiles vs. user's privacy settings, outlining the points of conflict as well as the different ways in which they can be resolved. And (ii) provides efficient change management with respect to any changes in user privacy settings.",
    month = "3",
    year = "2012",
    booktitle = "2012 IEEE International Conference on Pervasive Computing and Communications Workshops",
    pages = "70--75"
}

@inproceedings{Bitsch2012,
    author = "Bitsch, Jannick and Bouvin, Niels Olof",
    publisher = "IEEE",
    doi = "10.1109/PerCom.2012.6199849",
    isbn = "978-1-4673-0258-6",
    title = "{Ad-hoc symbiotic interactive displays through DLNA}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp;jsessionid=Jt4JPpqKMkd6tM6J9snZpmm1J1TBJ1KQGylTD21Hnc3xCNvlQZDd!-888385466?arnumber=6199849\&contentType=Conference+Publications",
    abstract = "The concept of symbiotic displays covers the opportunistic pairing of mobile devices with screen devices that can be discovered and controlled across a network. Mobile applications that use symbiotic displays can offer the user an improved experience, but the lack of a widely deployed infrastructure means that the concept has seen little use. We design and implement a solution for using DLNA playback devices as symbiotic screens. DLNA devices are not designed to support interactive content, but to share and play media content in the home. Our work includes constructing a mechanism for real time generation of a video stream containing screen content, as well as a buffer starving mechanism that reduces buffer induced playback latency. The resulting system allows Android applications to use DLNA devices as a secondary screens. Latencies and update rates are such, that only applications that do not depend on quick and frequent updates to the remote screen content can be supported.",
    month = "3",
    pages = "57--65",
    file = "::",
    year = "2012",
    booktitle = "2012 IEEE International Conference on Pervasive Computing and Communications"
}

@techreport{Blackburn2012,
    author = "Blackburn, Stephen M. and Diwan, Amer and Hauswirth, Matthias and Sweeney, Peter F. and Amaral, Jos\'{e} Nelson and Babka, Vlastimil and Binder, Walter and Brecht, Tim and Bulej, Lubom\'{\i}r and Eeckhout, Lieven and Fischmeister, Sebastian and Frampton, Daniel and Garner, Robin and Georges, Andy and Hendren, Laurie J. and Hind, Michael and Hosking, Antony L. and Jones, Richard and Kalibera, Tomas and Moret, Philippe and Nystrom, Nathaniel and Pankratius, Victor and Tuma, Petr",
    title = "{Can you trust your experimental results?}",
    url = "http://evaluate.inf.usi.ch/technical-reports/1",
    abstract = "Many contributions in computer science rely on quantitative experiments to validate their efficacy. Well‐designed experiments provide useful insights while poorly‐designed experiments can mislead. Unfortunately, experiments are difficult to design and even seasoned experimenters can make mistakes. This paper presents a framework that enables us to talk and reason about experimental evaluation. As such, we hope it will help our community to avoid and recognize mistakes in our experiments. This paper is the outcome of the Evaluate 2011 workshop whose goal was to improve experimental methodology in computer science.",
    pages = "1--8",
    file = ":home/drt24/Downloads/EvaluateCollaboratoryTR1.pdf:pdf",
    year = "2012",
    institution = "Evaluate Collaboratory"
}

@article{Blackwell2002,
    author = "Blackwell, A.F.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/HCC.2002.1046334",
    isbn = "0-7695-1644-0",
    title = "{First Steps in Programming: A Rationale for Attention Investment Models}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1046334",
    abstract = "Research into the cognitive aspects of programming originated in the study of professional programmers (whether experts or students). Even “end-user” programmers in previous studies have often worked in organizations where programming is recognized to be demanding professional work – the term “power-user” recognizes this technical kudos. But as personal computers become widespread, and most new domestic appliances incorporate microprocessors, many people are engaging in programming-like activities in domestic or non- professional contexts. Such users often have less motivation and more obstacles to programming, meaning that they may be unlikely even to take the first steps. This paper analyses the generic nature of those first steps, and identifies the cognitive demands that characterize them. On the basis of this analysis we propose the Attention Investment model, a cognitive model of programming that offers a consistent account of all programming behaviour, from professionals to end-users.",
    pages = "2--10",
    file = "::",
    year = "2002",
    journal = "Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments"
}

@article{Blackwell2008a,
    author = "Blackwell, Alan and Church, Luke and Plimmer, Beryl and Gray, Dave",
    title = "{Formality in Sketches and Visual Representation : Some Informal Reflections}",
    abstract = "This paper provides an overview of the ways that sketches function as informal representation tools, especially when used in design contexts. We then consider the tension between this essentially informal practical function of sketches, and two different factors that drive toward formalization. These are 1) the need for a computational interpretation, and 2) the desire to specify visual formalisms as scientific, critical or technical tools",
    mendeley-tags = "Blackwell",
    pages = "11--18",
    file = "::",
    year = "2008",
    keywords = "Blackwell,Sketching,Visual Representation",
    journal = "Creativity Research Journal"
}

@inproceedings{Blewitt2005a,
    author = "Blewitt, Alex and Bundy, Alan and Stark, Ian",
    publisher = "ACM Press",
    doi = "10.1145/1101908.1101943",
    isbn = "1595939934",
    title = "{Automatic verification of design patterns in Java}",
    url = "http://dl.acm.org/citation.cfm?id=1101908.1101943",
    booktitle = "Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering - ASE '05",
    year = "2005",
    month = "11",
    address = "New York, New York, USA",
    keywords = "Java,design pattern,specification,verification",
    pages = "224"
}

@book{Boer2006,
    editor = "Boer, Frank S. and Bonsangue, Marcello M. and Graf, Susanne and Roever, Willem-Paul",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11804192",
    isbn = "978-3-540-36749-9",
    title = "{Beyond Assertions: Advanced specifications and verification with JML and ESC/Java2}",
    url = "http://link.springer.com/chapter/10.1007/11804192_16",
    series = "Lecture Notes in Computer Science",
    year = "2006",
    volume = "4111",
    address = "Berlin, Heidelberg",
    pages = "342--363"
}

@article{Bohmer2011,
    author = {B\"{o}hmer, Matthias and Hecht, Brent and Sch\"{o}ning, Johannes and Kr\"{u}ger, Antonio and Bauer, Gernot},
    isbn = "9781450305419",
    title = "{Falling Asleep with Angry Birds, Facebook and Kindle–A Large Scale Study on Mobile Application Usage}",
    url = "http://www.brenthecht.com/papers/bhecht_mobilehci2011_sleepbirds.pdf",
    abstract = "While applications for mobile devices have become extremely important in the last few years, little public information exists on mobile application usage behavior. We describe a large-scale deployment-based research study that logged detailed application usage information from over 4,100 users of Android-powered mobile devices. We present two types of results from analyzing this data: basic descriptive statistics and contextual descriptive statistics. In the case of the former, we find that the average session with an application lasts less than a minute, even though users spend almost an hour a day using their phones. Our contextual findings include those related to time of day and location. For instance, we show that news applications are most popular in the morning and games are at night, but communication applications dominate through most of the day. We also find that despite the variety of apps available, communication applications are almost always the first used upon a device's waking from sleep. In addition, we discuss the notion of a virtual application sensor, which we used to collect the data.",
    file = "::",
    year = "2011",
    journal = "Proceedings of the 13th International Conference on Human-Computer Interaction with Mobile Devices and Services"
}

@book{Boiten2004,
    editor = "Boiten, Eerke A. and Derrick, John and Smith, Graeme",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/b96106",
    isbn = "978-3-540-21377-2",
    title = "{Integrated Formal Methods}",
    url = "http://www.springerlink.com/content/ek3l4u815vl3aexk/",
    series = "Lecture Notes in Computer Science",
    year = "2004",
    volume = "2999",
    address = "Berlin, Heidelberg"
}

@article{Bolliger2009,
    author = "Bolliger, Philipp and Partridge, Kurt and Chu, Maurice and Langheinrich, Marc",
    publisher = "Springer",
    title = "{Improving location fingerprinting through motion detection and asynchronous interval labeling}",
    url = "http://www.springerlink.com/index/1284305247222k43.pdf",
    journal = "Location and Context Awareness",
    file = "::",
    year = "2009",
    pages = "37--51"
}

@inproceedings{Bolosky2000,
    author = "Bolosky, William J and Douceur, John R and Ely, David and Theimer, Marvin M.",
    publisher = "ACM Press",
    doi = "10.1145/339331.339345",
    isbn = "1581131941",
    title = "{Feasibility of a serverless distributed file system deployed on an existing set of desktop PCs}",
    url = "http://portal.acm.org/citation.cfm?id=339331.339345",
    abstract = "We consider an architecture for a serverless distributed file system that does not assume mutual trust among the client computers. The system provides security, availability, and reliability by distributing multiple encrypted replicas of each file among the client machines. To assess the feasibility of deploying this system on an existing desktop infrastructure, we measure and analyze a large set of client machines in a commercial environment. In particular, we measure and report results on disk usage and content; file activity; and machine uptimes, lifetimes, and loads. We conclude that the measured desklop infrastructure would passably support our proposed system, providing availability on the order of one unfilled file request per user per thousand days.",
    number = "1",
    pages = "34--43",
    volume = "28",
    file = ":auto/homes/drt24/Downloads/p34-bolosky.pdf:pdf",
    year = "2000",
    keywords = "analytical modeling,architecture,availability,characterization,feasibility analysis,personal computer,reliability,security,serverless distributed file system,trust,usage data,workload",
    booktitle = "SIGMETRICS"
}

@article{Bond2001,
    author = "Bond, M. and Anderson, R.",
    doi = "10.1109/2.955101",
    title = "{API-level attacks on embedded systems}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=955101",
    journal = "Computer",
    issn = "00189162",
    number = "10",
    volume = "34",
    file = ":home/drt24/Downloads/Bond.API-Attacks.2001.pdf:pdf",
    year = "2001",
    pages = "67--75"
}

@article{Bond2006,
    author = "Bond, Mike and Clulow, Jolyon",
    doi = "10.1016/j.istr.2006.03.003",
    title = "{Integrity of intention (a theory of types for security APIs)}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1363412706000173",
    journal = "Information Security Technical Report",
    issn = "13634127",
    number = "2",
    month = "1",
    volume = "11",
    file = ":home/drt24/Downloads/Integrity-of-Intention.pdf:pdf",
    year = "2006",
    pages = "93--99"
}

@article{Boneh2001,
    author = "Boneh, Dan and Lynn, Ben and Shacham, Hovav",
    title = "{Short signatures from the Weil pairing}",
    journal = "Journal of Cryptography",
    abstract = "We introduce a short signature scheme based on the Computational Diffie-Hellman assumption on certain elliptic and hyper-elliptic curve groups. The signature length is half the size of a DSA signature for a similar level of security. Our short signature scheme is designed for systems where signatures are typed in by a human or signatures are sent over a low bandwidth channel. We survey a number of properties of our signature scheme such as signature aggregation and batch verification.",
    number = "4",
    volume = "17",
    url = "http://link.springer.com/chapter/10.1007/3-540-45682-1_30 https://crypto.stanford.edu/~dabo/abstracts/weilsigs.html",
    file = ":home/drt24/Downloads/weilsigs.ps:ps",
    year = "2004",
    pages = "297--319"
}

@article{Bonneau2009,
    author = "Bonneau, Joseph and Anderson, J and Anderson, Ross and Stajano, Frank",
    publisher = "ACM",
    isbn = "9781605584638",
    title = "{Eight Friends Are Enough : Social Graph Approximation via Public Listings}",
    url = "http://portal.acm.org/citation.cfm?id=1578002.1578005",
    journal = "Computers and Society",
    institution = "ACM",
    pages = "1--6",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonneau et al. - 2009 - Eight Friends Are Enough Social Graph Approximation via Public Listings.pdf:pdf",
    year = "2009",
    keywords = "data breaches,privacy,social networks,web crawling",
    abstract = "The popular social networking website Facebook exposes a public view of user proﬁles to search engines which includes eight of the users friendship links. We examine what interesting properties of the complete social graph can be inferred from this public view. In experiments on real social network data, we were able to accurately approximate the degree and centrality of nodes, compute small dominating sets, ﬁnd short paths between users, and detect community structure. This work demonstrates that it is difﬁcult to safely reveal limited information about a social network"
}

@online{Bonneau2009a,
    author = "Bonneau, Joseph",
    url = "http://www.lightbluetouchpaper.org/2009/02/11/new-facebook-photo-hacks/",
    urldate = "2013",
    booktitle = "LightBlueTouchpaper",
    title = "{New Facebook Photo Hacks}"
}

@inproceedings{Bonneau2010,
    author = {Bonneau, Joseph and Preibusch, S\"{o}ren},
    title = "{The password thicket: technical and market failures in human authentication on the web}",
    url = "http://www.preibusch.de/publications/Bonneau_Preibusch__password_thicket.pdf",
    abstract = "We report the results of the first large-scale empirical analysis of password implementations deployed on the Internet. Our study included 150 websites which offer free user accounts for a variety of purposes, including the most popular destinations on the web and a random sample of e-commerce, news, and communication websites. Although all sites evaluated relied on user-chosen textual passwords for authentication, we found many subtle but important technical variations in im- plementation with important security implications. Many poor practices were commonplace, such as a lack of encryption to protect transmitted passwords, storage of cleartext passwords in server databases, and little protection of passwords from brute force attacks. While a spectrum of imple- mentation quality exists with a general co-occurrence of more-secure and less-secure implementa- tion choices, we find a surprising number of inconsistent choices within individual sites, suggesting that the lack of a standards is harming security. We observe numerous ways in which the technical failures of lower-security sites can compromise higher-security sites due to the well-established ten- dency of users to re-use passwords. Our data confirms that the worst security practices are indeed found at sites with few security incentives, such as newspaper websites, while sites storing more sensitive information such as payment details or user communication implement more password se- curity. From an economic viewpoint, password insecurity is a negative externality that the market has been unable to correct, undermining the viability of password-based authentication. We also speculate that some sites deploying passwords do so primarily for psychological reasons, both as a justification for collecting marketing data and as a way to build trusted relationships with customers. This theory suggests that efforts to replace passwords with more-secure protocols or federated iden- tity systems may fail because they don’t recreate the entrenched ritual of password authentication.",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonneau, Preibusch - 2010 - The password thicket technical and market failures in human authentication on the web.pdf:pdf",
    year = "2010",
    booktitle = "The Ninth Workshop on the Economics of Information Security, WEIS"
}

@article{Bonneau2011,
    author = "Bonneau, Joseph",
    publisher = "Springer",
    doi = "10.1007/978-3-642-25867-1_8",
    isbn = "978-3-642-25866-4",
    title = "{Getting Web Authentication Right A Best-Case Protocol for the Remaining Life of Passwords}",
    url = "http://www.cl.cam.ac.uk/~jcb82/doc/web_auth_right.pdf http://www.springerlink.com/index/92L0T8JH2086303H.pdf",
    abstract = "We outline an end-to-end password authentication protocol for the web designed to be stateless and as secure as possible given legacy limitations of the web browser and performance constraints of commercial web servers. Our scheme is secure against very strong but passive attackers able to observe both network traffic and the server’s database state. At the same time, our scheme is simple for web servers to imple- ment and requires no changes to modern, HTML5-compliant browsers. We assume TLS is available for initial login and no other public-key cryptographic operations, but successfully defend against cookie-stealing and cookie-forging attackers and provide strong resistance to password guessing attacks.",
    year = "2011",
    pages = "98--104",
    volume = "7114",
    file = ":home/drt24/Library/papers/Nineteenth International Workshop on Security Protocols/Bonneau/Bonneau - 2011 - Getting web authentication right A best-case protocol for the remaining life of passwords.pdf:pdf;:auto/homes/drt24/Downloads/fulltext (3).pdf:pdf",
    address = "Cambridge, UK",
    journal = "Security Protocols XIX"
}

@inproceedings{Bonneau2012,
    author = "Bonneau, Joseph and Preibusch, Soren and Anderson, Ross",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-32946-3_3",
    isbn = "978-3-642-32945-6",
    title = "{A birthday present every eleven wallets? The security of customer-chosen banking PINs}",
    url = "http://www.cl.cam.ac.uk/~jcb82/doc/BPA12-FC-banking_pin_security.pdf",
    abstract = "We provide the first published estimates of the difficulty of guessing a human-chosen 4-digit PIN. We begin with two large sets of 4-digit sequences chosen outside banking for online passwords and smart- phone unlock-codes. We use a regression model to identify a small num- ber of dominant factors influencing user choice. Using this model and a survey of over 1,100 banking customers, we estimate the distribution of banking PINs as well as the frequency of security-relevant behaviour such as sharing and reusing PINs. We find that guessing PINs based on the victims’ birthday, which nearly all users carry documentation of, will enable a competent thief to gain use of an ATM card once for every 11– 18 stolen wallets, depending on whether banks prohibit weak PINs such as 1234. The lesson for cardholders is to never use one’s date of birth as a PIN. The lesson for card-issuing banks is to implement a denied PIN list, which several large banks still fail to do. However, blacklists cannot effectively mitigate guessing given a known birth date, suggesting banks should move away from customer-chosen banking PINs in the long term.",
    pages = "1--15",
    volume = "7397",
    file = ":auto/homes/drt24/Downloads/BPA12-FC-banking\_pin\_security.pdf:pdf",
    year = "2012",
    booktitle = "Financial Cryptography and Data Security"
}

@article{Bonneau2012a,
    author = "Bonneau, Joseph and Shutova, Ekaterina",
    title = "{Linguistic properties of multi-word passphrases}",
    url = "http://www.cl.cam.ac.uk/~jcb82/doc/BS12-USEC-passphrase_linguistics.pdf",
    abstract = "We examine patterns of human choice in a passphrase-based authentication system deployed by Amazon, a large online merchant. We tested the availability of a large corpus of over 100,000 possible phrases at Amazon’s registration page, which prohibits using any phrase already registered by another user. A number of large, readily-available lists such as movie and book titles prove effective in guessing attacks, suggesting that passphrases are vulnerable to dictionary attacks like all schemes involving human choice. Extending our analysis with natural language phrases extracted from linguistic corpora, we find that phrase selection is far from random, with users strongly preferring simple noun bigrams which are common in natural language. The distribution of cho- sen passphrases is less skewed than the distribution of bigrams in English text, indicating that some users have attempted to choose phrases ran- domly. Still, the distribution of bigrams in natural language is not nearly random enough to resist offline guessing, nor are longer three- or four- word phrases for which we see rapidly diminishing returns.",
    file = ":auto/homes/drt24/Downloads/BS12-USEC-passphrase\_linguistics.pdf:pdf",
    year = "2012",
    journal = "cl.cam.ac.uk"
}

@inproceedings{Bonneau2012b,
    author = "Bonneau, Joseph and Herley, Cormac and van Oorschot, Paul C. and Stajano, Frank",
    doi = "10.1109/SP.2012.44",
    title = "{The quest to replace passwords: A framework for comparative evaluation of web authentication schemes}",
    url = "http://www-test.cl.cam.ac.uk/techreports/UCAM-CL-TR-817.pdf",
    abstract = "We evaluate two decades of proposals to replace text passwords for general-purpose user authentication on the web using a broad set of twenty-five usability, deployability and security benefits that an ideal scheme might provide. The scope of proposals we survey is also extensive, including password management software, federated login protocols, graphical password schemes, cognitive authentication schemes, one-time passwords, hardware tokens, phone-aided schemes and biometrics. Our comprehensive approach leads to key insights about the difficulty of replacing passwords. Not only does no known scheme come close to providing all desired benefits: none even retains the full set of benefits that legacy passwords already provide. In particular, there is a wide range from schemes offering minor security benefits beyond legacy passwords, to those offering significant security benefits in return for being more costly to deploy or more difficult to use. We conclude that many academic proposals have failed to gain traction because researchers rarely consider a sufficiently wide range of real-world constraints. Beyond our analysis of current schemes, our framework provides an evaluation methodology and benchmark for future web authentication proposals. This report is an extended version of the peer-reviewed paper by the same name. In about twice as many pages it gives full ratings for 35 authentication schemes rather than just 9.",
    file = ":auto/homes/drt24/Downloads/UCAM-CL-TR-817.pdf:pdf",
    year = "2012",
    keywords = "authentication,computer security,deployability,economics,human computer interaction,security and usability,software engineering",
    booktitle = "IEEE Symposium on Security and Privacy"
}

@inproceedings{Bonneau2012c,
    author = "Bonneau, Joseph",
    title = "{The science of guessing: analyzing an anonymized corpus of 70 million passwords}",
    url = "http://www.cl.cam.ac.uk/~jcb82/doc/B12-IEEESP-analyzing_70M_anonymized_passwords.pdf",
    abstract = "We report on the largest corpus of user-chosen passwords ever studied, consisting of anonymized password histograms representing almost 70 million Yahoo! users, mit- igating privacy concerns while enabling analysis of dozens of subpopulations based on demographic factors and site usage characteristics. This large data set motivates a thorough sta- tistical treatment of estimating guessing difficulty by sampling from a secret distribution. In place of previously used metrics such as Shannon entropy and guessing entropy, which cannot be estimated with any realistically sized sample, we develop partial guessing metrics including a new variant of guesswork parameterized by an attacker’s desired success rate. Our new metric is comparatively easy to approximate and directly relevant for security engineering. By comparing password distributions with a uniform distribution which would provide equivalent security against different forms of guessing attack, we estimate that passwords provide fewer than 10 bits of security against an online, trawling attack, and only about 20 bits of security against an optimal offline dictionary attack. We find surprisingly little variation in guessing difficulty; every identifiable group of users generated a comparably weak password distribution. Security motivations such as the registration of a payment card have no greater impact than demographic factors such as age and nationality. Even pro- active efforts to nudge users towards better password choices with graphical feedback make little difference. More surpris- ingly, even seemingly distant language communities choose the same weak passwords and an attacker never gains more than a factor of 2 efficiency gain by switching from the globally optimal dictionary to a population-specific lists.",
    file = ":auto/homes/drt24/Downloads/B12-IEEESP-analyzing\_70M\_anonymized\_passwords.pdf:pdf",
    year = "2012",
    keywords = "authentication,computer security,data mining,information theory,statistics",
    booktitle = "IEEE Symp. Security and Privacy"
}

@inproceedings{Bonneau2012d,
    author = "Bonneau, Joseph and Xu, Rubin",
    title = "{Of contrase\~{n}as, סיסמאות, and 密码: Character encoding issues for web passwords}",
    abstract = "Password authentication remains ubiquitous on the web, primarily because of its low cost and compatibility with any device which allows a user to input text. Yet text is not universal. Computers must use a character encoding system to convert human-comprehensible writing into bits. We examine for the first time the lingering effects of character encoding on the password ecosystem. We report a number of bugs at large websites which reveal that non-ASCII passwords are often poorly supported, even by websites otherwise correctly sup- porting the recommended Unicode/UTF-8 character encoding system. We also study user behaviour through several leaked data sets of passwords chosen by English, Chinese, Hebrew and Spanish speakers as case studies. Our findings suggest that most users still actively avoid using characters outside of the original ASCII character set even when allowed to. Coping strategies include transliterating non-ASCII passwords using ASCII, changing keyboard mappings to produce nonsense ASCII passwords, and using passwords consisting entirely of numbers or of a geometric pattern on the keyboard. These last two strategies may reduce resistance to guessing attacks for passwords chosen by non-English speakers.",
    year = "2012",
    month = "5",
    file = ":auto/homes/drt24/Downloads/BX12-W2SP-passwords\_character\_encoding.pdf:pdf",
    address = "San Francisco, CA, USA",
    booktitle = "Web 2.0 Security \& Privacy"
}

@inproceedings{Bonneau2012e,
    author = "Bonneau, Joseph",
    doi = "10.1007/978-3-642-35694-0_10",
    title = "{Statistical metrics for individual password strength}",
    url = "http://www.cl.cam.ac.uk/~jcb82/doc/B12-SPW-statistical_password_strength_metrics.pdf",
    abstract = "We propose several possible metrics for measuring the strength of an individual password or any other secret drawn from a known, skewed distribution. In contrast to previous ad hoc approaches which rely on textual properties of passwords, we consider the problem without any knowledge of password structure. This enables rating the strength of a password given a large sample distribution without assuming any- thing about password semantics. We compare the results of our generic metrics against those of the NIST metrics and other previous “entropy- based” metrics for a large password dataset, which suggest over-fitting in previous metrics.",
    file = ":auto/homes/drt24/Downloads/B12-SPW-statistical\_password\_strength\_metrics.pdf:pdf",
    year = "2012",
    booktitle = "20th International Workshop on Security Protocols"
}

@techreport{Bonneau2012f,
    author = "Bonneau, Joseph",
    title = "{Guessing human-chosen secrets}",
    url = "http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-819.html http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-819.pdf",
    abstract = "Authenticating humans to computers remains a notable weak point in computer security despite decades of effort. Although the security research community has explored dozens of proposals for replacing or strengthening passwords, they appear likely to remain entrenched as the standard mechanism of human-computer authentication on the Internet for years to come. Even in the optimistic scenario of eliminating passwords from most of today's authentication protocols using trusted hardware devices or trusted servers to perform federated authentication, passwords will persist as a means of “last-mile” authentication between humans and these trusted single sign-on deputies. This dissertation studies the difficulty of guessing human-chosen secrets, introducing a sound mathematical framework modeling human choice as a skewed probability distribution. We introduce a new metric, alpha-guesswork, which can accurately model the resistance of a distribution against all possible guessing attacks. We also study the statistical challenges of estimating this metric using empirical data sets which can be modeled as a large random sample from the underlying probability distribution. This framework is then used to evaluate several representative data sets from the most important categories of human-chosen secrets to provide reliable estimates of security against guessing attacks. This includes collecting the largest-ever corpus of user-chosen passwords, with nearly 70 million, the largest list of human names ever assembled for research, the largest data sets of real answers to personal knowledge questions and the first data published about human choice of banking PINs. This data provides reliable numbers for designing security systems and highlights universal limitations of human-chosen secrets.",
    number = "819",
    month = "5",
    file = ":home/drt24/Downloads/UCAM-CL-TR-819.pdf:pdf",
    year = "2012",
    institution = "University of Cambridge, Computer Laboratory"
}

@online{Bonneau2012g,
    author = "Bonneau, Joseph",
    title = "{Authentication is machine learning}",
    url = "http://www.lightbluetouchpaper.org/2012/12/14/authentication-is-machine-learning/",
    abstract = "Authenticating humans is becoming a machine learning problem.",
    month = "12",
    year = "2012",
    urldate = "2013-06-26",
    booktitle = "LightBlueTouchpaper"
}

@article{Bose2005,
    author = "Bose, R. and Frew, J.",
    publisher = "ACM",
    title = "{Lineage retrieval for scientific data processing: a survey}",
    url = "http://portal.acm.org/citation.cfm?id=1057978",
    journal = "ACM Computing Surveys (CSUR)",
    number = "1",
    volume = "37",
    file = "::",
    year = "2005",
    pages = "1--28"
}

@article{Bostock2009,
    author = "Bostock, Michael and Heer, Jeffrey",
    doi = "10.1109/TVCG.2009.174",
    title = "{Protovis: a graphical toolkit for visualization.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/19834180",
    abstract = "Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency--the effort required to specify a visualization--and accessibility--the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.",
    issn = "1077-2626",
    number = "6",
    pages = "1121--8",
    volume = "15",
    file = "::",
    year = "2009",
    pmid = "19834180",
    journal = "IEEE transactions on visualization and computer graphics"
}

@inproceedings{Boyapati2002,
    author = "Boyapati, Chandrasekhar and Lee, Robert and Rinard, Martin",
    publisher = "ACM Press",
    doi = "10.1145/582419.582440",
    isbn = "1581134711",
    title = "{Ownership types for safe programming}",
    url = "http://dl.acm.org/citation.cfm?id=582419.582440",
    booktitle = "Proceedings of the 17th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications - OOPSLA '02",
    issn = "0362-1340",
    year = "2002",
    number = "11",
    month = "11",
    volume = "37",
    file = "::",
    address = "New York, New York, USA",
    keywords = "data races,deadlocks,encapsulation,ownership types",
    pages = "211"
}

@article{Boyd2011,
    author = "Boyd, Colin and Cremers, Cas and Feltz, M and Paterson, KG",
    title = "{ASICS: Authenticated Key Exchange Security Incorporating Certification Systems}",
    journal = "Computer Security–ESORICS 2013",
    abstract = "Most security models for authenticated key exchange (AKE) do not explicitly model the associated certification system, which includes the certification authority (CA) and its behaviour. However, there are several well-known and realistic attacks on AKE protocols which exploit various forms of malicious key registration and which therefore lie outside the scope of these models. We provide the first systematic analysis of AKE security incorporating certification systems (ASICS). We define a family of security models that, in addition to allowing different sets of standard AKE adversary queries, also permit the adversary to register arbitrary bitstrings as keys. For this model family we prove generic results that enable the design and verification of protocols that achieve security even if some keys have been produced maliciously. Our approach is applicable to a wide range of models and protocols; as a concrete illustration of its power, we apply it to the CMQV protocol in the natural strengthening of the eCK model to the ASICS setting.",
    number = "July",
    url = "https://eprint.iacr.org/2013/398.pdf",
    file = ":home/drt24/Downloads/398.pdf:pdf",
    year = "2011",
    keywords = "ake,attacks,authenticated key exchange,authority,ca,certification,invalid public keys,pki,uks,unknown key share",
    pages = "1--21"
}

@inproceedings{Bozorgi2010,
    author = "Bozorgi, Mehran and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.",
    publisher = "ACM",
    isbn = "9781450300551",
    title = "{Beyond heuristics: learning to classify vulnerabilities and predict exploits}",
    url = "http://dl.acm.org/citation.cfm?id=1835821",
    abstract = "The security demands on modern system administration are enor- mous and getting worse. Chief among these demands, adminis- trators must monitor the continual ongoing disclosure of software vulnerabilities that have the potential to compromise their systems in some way. Such vulnerabilities include buffer overflow errors, improperly validated inputs, and other unanticipated attack modal- ities. In 2008, over 7,400 new vulnerabilities were disclosed— well over 100 per week. While no enterprise is affected by all of these disclosures, administrators commonly face many outstanding vulnerabilities across the software systems they manage. Vulner- abilities can be addressed by patches, reconfigurations, and other workarounds; however, these actions may incur down-time or un- foreseen side-effects. Thus, a key question for systems adminis- trators is which vulnerabilities to prioritize. From publicly avail- able databases that document past vulnerabilities, we show how to train classifiers that predict whether and how soon a vulnerability is likely to be exploited. As input, our classifiers operate on high di- mensional feature vectors that we extract from the text fields, time stamps, cross-references, and other entries in existing vulnerability disclosure reports. Compared to current industry-standard heuris- tics based on expert knowledge and static formulas, our classifiers predict much more accurately whether and how soon individual vulnerabilities are likely to be exploited.",
    year = "2010",
    month = "7",
    pages = "105--113",
    file = ":home/drt24/Downloads/p105-bozorgi.pdf:pdf",
    address = "Washington, DC, USA",
    keywords = "SVM,exploits,supervised learning,vulnerabilities",
    booktitle = "KDD"
}

@techreport{Bradner1996,
    author = "Bradner, S (Harvard University)",
    title = "{The Internet Standards Process}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Internet+Standards+Process\#0",
    abstract = "This memo documents the process used by the Internet community for the standardization of protocols and procedures. It defines the stages in the standardization process, the requirements for moving a document between stages and the types of documents used during this process. It also addresses the intellectual property rights and copyright issues associated with the standards process.",
    mendeley-tags = "BCP,RFC",
    pages = "1--37",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradner - 1996 - The Internet Standards Process.pdf:pdf",
    year = "1996",
    keywords = "BCP,RFC",
    institution = "Network Working Group"
}

@article{Braun2006,
    author = "Braun, Uri and Garfinkel, Simson and Holland, D. and Muniswamy-Reddy, K.K. and Seltzer, M.",
    publisher = "Springer",
    doi = "10.1007/11890850_18",
    title = "{Issues in automatic provenance collection}",
    url = "http://www.springerlink.com/index/b2485117n600p047.pdf",
    journal = "Provenance and annotation of data",
    file = "::",
    year = "2006",
    pages = "171--183"
}

@article{Brazdil2015,
    author = "Brazdil, David and Xu, Rubin and Beresford, Alastair R.",
    abstract = "Apps for smartphones today come with a fixed fea- ture set and consequently users are unable to fix bugs, customise their apps, or explore what apps do with their data. In this paper we introduce Dexter, a binary rewriting framework for Android apps which can run on a PC or Android device. Dexter enables developers to add features, explore privacy issues, or fix security flaws in existing apps. Dexter is currently able to recompile 3600 (99\%) out of 3650 apps in our sample database. We showcase the capability of our framework through two case studies. In the first, we demonstrate a method of rewriting an app so that the modified version tracks the informa- tion flows of personal data inside the app itself. In- strumented apps produced by our implementation are, on average, 48\% larger than the original and incur a performance overhead factor of between 1 and 4 times the original for CPU and graphics microbenchmarks. In our second case study we describe how Dexter can be used to fix a serious security vulnerability in Android WebViews. Neither of our case studies require a custom version of Android or a rooted handset, and therefore apps rebuilt using Dexter, as well as Dexter itself, can be run on a normal device.",
    year = "2015",
    journal = "Under submission",
    file = ":home/drt24/Downloads/BrazdilEtAl-Dexter.pdf:pdf",
    title = "{Dexter: a rewriting framework for Android binaries}"
}

@article{Bresciani2008,
    author = "Bresciani, Sabrina and Blackwell, Alan and Eppler, Martin",
    publisher = "Ieee",
    doi = "10.1109/HICSS.2008.7",
    isbn = "0-7695-3075-8",
    title = "{A Collaborative Dimensions Framework: Understanding the Mediating Role of Conceptual Visualizations in Collaborative Knowledge Work}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4439069",
    abstract = "Facilitating collaborative knowledge work is a crucial issue in management: knowledge is a key corporate asset, but it is typically spread across various people in different organizational functions. In this paper we explore how conceptual visualizations (such as diagrams, visual metaphors, charts, sketches) can be constructed and used as cognitive artefacts that support collaborative knowledge work. In order to facilitate tasks such as the creation and sharing of knowledge in teams, we propose a collaborative dimensions framework as a tool for understanding how visual artefacts can facilitate collaboration in circumstances that involve distributed knowledge. The framework is based on the widespread Cognitive Dimensions of Notation framework and is enriched with criteria from the boundary object paradigm discussed in organization science. The dimensions of the framework are described and then applied to three different visualizations that are used in collaborative knowledge work. A discussion of future research needs concludes the paper.",
    issn = "1530-1605",
    month = "1",
    pages = "364--364",
    file = "::",
    year = "2008",
    keywords = "A Collaborative Dimensions Framework: Understandin",
    journal = "Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)"
}

@article{Brieler2010a,
    author = "Brieler, Florian and Minas, Mark",
    doi = "10.1016/j.jvlc.2009.12.002",
    title = "{A model-based recognition engine for sketched diagrams}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X09000780",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "2",
    month = "4",
    volume = "21",
    file = "::",
    year = "2010",
    pages = "81--97"
}

@article{Brooks2007,
    author = "Brooks, Stephen and Saunders, Ian and Dodgson, Neil a.",
    publisher = "Spie",
    doi = "10.1117/12.703056",
    title = "{Image compression using sparse colour sampling combined with nonlinear image processing}",
    url = "http://link.aip.org/link/PSISDG/v6492/i1/p64920F/s1\&Agg=doi",
    abstract = "We apply two recent non-linear, image-processing algorithms to colour image compression. The two algorithms are colorization and joint bilateral filtering. Neither algorithm was designed for image compression. Our investigations were to ascertain whether their mechanisms could be used to improve the image compression rate for the same level of visual quality. Both show interesting behaviour, with the second showing a visible improvement in visual quality, over JPEG, at the same compression rate. In both cases, we store luminance as a standard, lossily compressed, greyscale image and store colour at a very low sampling rate. Each of the non-linear algorithms then uses the information from the luminance channel to determine how to propagate the colour information appropriately to reconstruct a full colour image.",
    issn = "0277786X",
    pages = "64920F--64920F--12",
    volume = "6492",
    file = ":auto/homes/drt24/Downloads/SPIE07-lowres.pdf:pdf",
    year = "2007",
    keywords = "bilateral filter,colorization,colour,compression,non-linear,sparse",
    journal = "Proceedings of SPIE"
}

@inproceedings{Brown2002,
    author = "Brown, Aaron B. and Patterson, D.A.",
    publisher = "ACM",
    title = "{Rewind, repair, replay: three R's to dependability}",
    url = "http://dl.acm.org/citation.cfm?id=1133387",
    abstract = "Motivated by the growth of web and infrastructure services and their susceptibility to human operator-related failures, we introduce system-level undo as a recovery mechanism designed to improve service dependability. Undo enables system operators to recover from their inevitable mistakes and furthermore enables retroactive repair of problems that were not fixed quickly enough to prevent detrimental effects. We present the “three R’s”, a model of undo that matches the needs of human error recovery and retroactive repair; discuss several of the issues raised by this undo model; and introduce an initial architectural framework for undoable systems using the example of an undoable e-mail service system.",
    pages = "70--77",
    file = ":auto/homes/drt24/Downloads/p70-brown.pdf:pdf",
    year = "2002",
    booktitle = "Proceedings of the 10th workshop on ACM SIGOPS European workshop"
}

@techreport{Brown2003,
    author = "Brown, Aaron B.",
    title = "{Toward System-Wide Undo for Distributed Services}",
    abstract = "In this report, we extend the concept of system-wide undo from self-contained services to collec- tions of distributed, interacting services, thereby providing an undo-based recovery mechanism to the operators and administrators of distributed services. The extended undo mechanism is targeted at human operator error and other state-affecting problems like software bugs, misconfigurations, and external attack, and provides retroactive repair of past problems. We achieve the distributed extension by appealing to the concept of spheres of undo: spheres of undo surround each compo- nent of a distributed service and provide a structuring mechanism that helps identify when undo of one component can affect others. We propose two approaches for composing interacting spheres of undo: one assumes coordination and cascades undo-based recovery from the first undone sphere to all others affected; the other approach assumes independence and handles interacting spheres by compensating for previous communications that become invalid following an invocation of undo. We present criteria that can be used to decide which approach is most appropriate, and give an example using them to choose the appropriate undo approach for a distributed e-shopping service. Finally, we describe initial thoughts on how the compositions might be implemented and propose algorithms for interacting-sphere undo.",
    number = "December",
    file = ":auto/homes/drt24/Downloads/CSD-03-1298.pdf:pdf",
    year = "2003",
    institution = "EECS Computer Science Division University of California, Berkeley"
}

@inproceedings{Browne2001,
    author = "Browne, H K and Arbaugh, W a and McHugh, J and Fithen, W L",
    doi = "10.1109/SECPRI.2001.924300",
    isbn = "0-7695-1046-9",
    title = "{A trend analysis of exploitations}",
    abstract = "We have conducted an empirical study of a number of computer security exploits and determined that the rates at which incidents involving the exploit are reported to CERT can be modeled using a common mathematical framework. Data associated with three significant exploits involving vulnerabilities in phf, imap, and bind can all be modeled using the formula C=I+S\&times;\&radic;M where C is the cumulative count of reported incidents, M is the time since the start of the exploit cycle, and I and S are the regression coefficients determined by analysis of the incident report data. Further analysis of two additional exploits involving vulnerabilities in mountd and statd confirm the model. We believe that the models will aid in predicting the severity of subsequent vulnerability exploitations, based on the rate of early incident reports",
    pages = "214--229",
    file = ":home/drt24/Downloads/CS-TR-4200.pdf:pdf",
    year = "2001",
    booktitle = "IEEE Symposium on Security and Privacy"
}

@inproceedings{Brumley2003,
    author = "Brumley, David and Boneh, Dan",
    publisher = "USENIX",
    title = "{Remote timing attacks are practical}",
    abstract = "Timing attacks are usually used to attack weak computing devices such as smartcards. We show that timing attacks apply to general software systems. Specifically, we devise a timing attack against OpenSSL. Our experiments show that we can extract private keys from an OpenSSL-based web server running on a machine in the local network. Our results demonstrate that timing attacks against network servers are practical and therefore security systems should defend against them.",
    address = "Washington, DC",
    year = "2003",
    booktitle = "Proceedings of the 12th conference on USENIX Security Symposium"
}

@article{Brumley2008,
    author = "Brumley, David and Poosankam, Pongsin and Song, Dawn and Zheng, Jiang",
    doi = "10.1109/SP.2008.17",
    isbn = "9780769531687",
    title = "{Automatic patch-based exploit generation is possible: Techniques and implications}",
    abstract = "The automatic patch-based exploit generation problem is: given a program P and a patched version of the program P', automatically generate an exploit for the potentially unknown vulnerability present in P but fixed in P'. In this paper, we propose techniques for automatic patch-based exploit generation, and show that our techniques can automatically generate exploits for 5 Microsoft programs based upon patches provided via Windows Update. Although our techniques may not work in all cases, a fundamental tenant of security is to conservatively estimate the capabilities of attackers. Thus, our results indicate that automatic patch-based exploit generation should be considered practical. One important security implication of our results is that current patch distribution schemes which stagger patch distribution over long time periods, such as Windows Update, may allow attackers who receive the patch first to compromise the significant fraction of vulnerable hosts who have not yet received the patch.",
    issn = "10816011",
    pages = "143--157",
    file = ":home/drt24/Downloads/04531150.pdf:pdf",
    year = "2008",
    journal = "Proceedings - IEEE Symposium on Security and Privacy"
}

@inproceedings{Brumley2011,
    author = "Brumley, Billy Bob and Tuveri, Nicola",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-23822-2_20",
    isbn = "978-3-642-23821-5",
    title = "{Remote timing attacks are still practical}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-23822-2_20",
    abstract = "For over two decades, timing attacks have been an active area of research within applied cryptography. These attacks exploit cryptosystem or protocol implementations that do not run in constant time. When implementing an elliptic curve cryptosystem with a goal to provide side-channel resistance, the scalar multiplication routine is a critical component. In such instances, one attractive method often suggested in the literature is Montgomery’s ladder that performs a fixed sequence of curve and field operations. This paper describes a timing attack vulnerability in OpenSSL’s ladder implementation for curves over binary fields. We use this vulnerability to steal the private key of a TLS server where the server authenticates with ECDSA signatures. Using the timing of the exchanged messages, the messages themselves, and the signatures, we mount a lattice attack that recovers the private key. Finally, we describe and implement an effective countermeasure.",
    pages = "355--371",
    volume = "6879",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-23822-2\_20.pdf:pdf",
    year = "2011",
    keywords = "elliptic curve cryptography,lattice attacks,side-channel attacks,timing attacks",
    booktitle = "Computer Security–ESORICS 2011"
}

@article{Brun2004,
    author = "Brun, Y. and Ernst, M.D.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/ICSE.2004.1317470",
    isbn = "0-7695-2163-0",
    title = "{Finding latent code errors via machine learning over program executions}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1317470",
    journal = "Proceedings. 26th International Conference on Software Engineering",
    file = "::",
    year = "2004",
    pages = "480--490"
}

@article{Bugiel2011,
    author = "Bugiel, Sven and Davi, Lucas and Dmitrienko, Alexandra and Heuser, Stephan and Sadeghi, Ahmad-Reza and Shastry, Bhargava",
    publisher = "ACM Press",
    doi = "10.1145/2046614.2046624",
    isbn = "9781450310000",
    title = "{Practical and lightweight domain isolation on Android}",
    url = "http://dl.acm.org/citation.cfm?doid=2046614.2046624",
    journal = "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices - SPSM '11",
    year = "2011",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bugiel et al. - 2011 - Practical and lightweight domain isolation on Android.pdf:pdf",
    address = "New York, New York, USA",
    pages = "51"
}

@inproceedings{Bugiel2011a,
    author = "Bugiel, Sven and Davi, Lucas and Dmitrienko, Alexandra and Heuser, Stephan and Sadeghi, Ahmad-Reza and Shastry, Bhargava",
    publisher = "ACM Press",
    doi = "10.1145/2046614.2046624",
    isbn = "9781450310000",
    title = "{Practical and lightweight domain isolation on Android}",
    url = "http://dl.acm.org/citation.cfm?id=2046614.2046624",
    booktitle = "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices - SPSM '11",
    year = "2011",
    month = "10",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bugiel et al. - 2011 - Practical and lightweight domain isolation on Android.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "access control,android,domain isolation,enterprise",
    pages = "51"
}

@inproceedings{Burckhardt2012,
    author = "Burckhardt, Sebastian and Leijen, Daan and Manuel, F and Wood, Benjamin P",
    publisher = "Springer",
    doi = "10.1007/978-3-642-31057-7_14",
    title = "{Cloud Types for Eventual Consistency}",
    url = "http://research.microsoft.com/apps/pubs/default.aspx?id=163842 http://link.springer.com/chapter/10.1007/978-3-642-31057-7_14",
    abstract = "Mobile devices commonly access shared data stored on a server. To ensure responsiveness, many applications maintain local replicas of the shared data that remain instantly accessible even if the server is slow or temporarily unavailable. Despite its apparent simplicity and commonality, this scenario can be surprisingly challenging. In particular, a correct and reliable implementation of the communication protocol and the conflict resolution to achieve eventual consistency is daunting even for experts. To make eventual consistency more programmable, we propose the use of specialized cloud data types. These cloud types provide eventually consistent storage at the programming language level, and thus abstract the numerous implementation details (servers, networks, caches, protocols). We demonstrate (1) how cloud types enable simple programs to use eventually consistent storage without introducing undue complexity, and (2) how to provide cloud types using a system and protocol comprised of multiple servers and clients.",
    month = "6",
    file = ":home/drt24/Downloads/final-with-color.pdf:pdf;:home/drt24/Downloads/CloudTypes-ECOOP12.pdf:pdf",
    year = "2012",
    booktitle = "Proceedings of the 26th European Conference on Object-Oriented Programming (ECOOP)",
    pages = "283--307"
}

@article{Burdy2003,
    author = "Burdy, Lilian and Cheon, Yoonsik and Cok, David and Ernst, Michael D. and Kiniry, Joe and Leavens, Gary T. and Rustan, K. and Leino, M. and Poll, Erik",
    doi = "10.1016/S1571-0661(04)80810-7",
    title = "{An overview of JML tools and applications}",
    url = "http://dx.doi.org/10.1016/S1571-0661(04)80810-7",
    abstract = "The Java Modeling Language (JML) can be used to specify the detailed design of Java classes and interfaces by adding annotations to Java source files. The aim of JML is to provide a specification language that is easy to use for Java programmers and that is supported by a wide range of tools for specification type-checking, runtime debugging, static analysis, and verification. This paper gives an overview of the main ideas behind JML, the different groups collaborating to provide tools for JML, and the existing applications of JML. Thus far, most applications have focused on code for programming smartcards written in the Java Card dialect of Java.",
    issn = "15710661",
    number = "null",
    month = "8",
    volume = "80",
    pages = "75--91",
    year = "2003",
    keywords = "formal methods,formal specification,java,program verification,runtime assertion checking,static checking",
    journal = "Electronic Notes in Theoretical Computer Science"
}

@inproceedings{Burguera2011,
    author = "Burguera, Iker and Zurutuza, Urko and Nadjm-Tehrani, Simin",
    publisher = "ACM Press",
    doi = "10.1145/2046614.2046619",
    isbn = "9781450310000",
    title = "{Crowdroid}",
    url = "http://dl.acm.org/citation.cfm?id=2046614.2046619",
    booktitle = "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices - SPSM '11",
    year = "2011",
    month = "10",
    file = "::",
    address = "New York, New York, USA",
    keywords = "anomaly detection,crowdsourcing,data mining,dynamic analysis,intrusion detection,malware detection,smartphone security",
    pages = "15"
}

@article{Burigat2008,
    author = "Burigat, S and Chittaro, L",
    doi = "10.1016/j.jvlc.2007.04.001",
    title = "{Interactive visual analysis of geographic data on mobile devices based on dynamic queries}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X07000328",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "1",
    month = "2",
    volume = "19",
    file = "::",
    year = "2008",
    keywords = "dynamic queries,geographic information systems,mobile devices,visualization",
    pages = "99--122"
}

@article{Burigat2008a,
    author = "Burigat, Stefano and Chittaro, Luca and Ieronutti, Lucio",
    title = "{Mobrex: visualizing users' mobile browsing behaviors.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/18240784",
    journal = "IEEE computer graphics and applications",
    issn = "0272-1716",
    number = "1",
    volume = "28",
    file = "::",
    year = "2008",
    keywords = "Computer Graphics,Databases, Factual,Documentation,Documentation: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Internet,Microcomputers,Software,Travel",
    pmid = "18240784",
    pages = "24--32"
}

@article{Burrows1989,
    author = "Burrows, Mike and Abadi, M. and Needham, Roger M.",
    doi = "10.1098/rspa.1989.0125",
    title = "{A Logic of Authentication}",
    url = "http://rspa.royalsocietypublishing.org/cgi/doi/10.1098/rspa.1989.0125",
    abstract = "Questions of belief are essential in analysing protocols for the authentication of principals in distributed computing systems. In this paper we motivate, set out, and exemplify a logic specifically, designed for this analysis: we sho who various protocols differ subtly with respect to the required initial assumptions of the participanst and their final beliefs. Our formalism has enabled us to isolate and express these differences with a precision that ws not previously possible. It has drawn attention to features of protocols of which we and their authors were previously unaware, and allowed us to suggest improvements to the protocols. The reasoning about some protocols has been mechanically verified. This paper starts with an informal account fo the problem, goes on to explain the formalism to be used, and gives examples of its appplication to protocols from the literature, both with shared-key cryptography and with public-key cryptography. Some examples are chosedn because of their practical importance, whereas others server to illustrate subtle points of the logic and to explain how we use it. We discuss extensions oft he logic motivated by actual practice; for example, to accoutn for the use of hash functions in signatures. The final sections contain a formal semantics of the logic and some conclusions.",
    issn = "1364-5021",
    number = "1871",
    month = "12",
    volume = "426",
    pages = "233--271",
    file = ":auto/homes/drt24/Downloads/Proc. R. Soc. Lond. A-1989-Burrows-233-71.pdf:pdf",
    year = "1989",
    journal = "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences"
}

@inproceedings{Burrows2006,
    author = "Burrows, Mike",
    publisher = "USENIX Association",
    title = "{The Chubby lock service for loosely-coupled distributed systems}",
    url = "http://portal.acm.org/citation.cfm?id=1298487 http://labs.google.com/papers/chubby.html",
    abstract = "We describe our experiences with the Chubby lock service, which is intended to provide coarse-grained locking as well as reliable (though low-volume) storage for a loosely-coupled distributed system. Chubby provides an interface much like a distributed file system with advisory locks, but the design emphasis is on availability and reliability, as opposed to high performance. Many instances of the service have been used for over a year, with several of them each handling a few tens of thou- sands of clients concurrently. The paper describes the initial design and expected use, compares it with actual use, and explains how the design had to be modified to accommodate the differences.",
    pages = "335--350",
    file = ":home/drt24/Downloads/chubby-osdi06.pdf:pdf",
    year = "2006",
    booktitle = "Proceedings of the 7th symposium on Operating systems design and implementation"
}

@techreport{CESG2013,
    author = "CESG",
    url = "https://www.gov.uk/government/publications/end-user-devices-security-guidance-android-42/end-user-devices-security-guidance-android-42",
    title = "{End User Devices Security Guidance: Android 4.2}",
    year = "2013",
    institution = "CESG",
    month = "10"
}

@article{Cachin2007,
    author = "Cachin, Christian and Shraer, Alexander and Shelat, Abhi",
    isbn = "9781595936165",
    title = "{Efficient fork-linearizable access to untrusted shared memory}",
    url = "http://portal.acm.org/citation.cfm?id=1281100.1281121",
    abstract = "When data is stored on a faulty server that is accessed concurrently by multiple clients, the server may present inconsistent data to different clients. For example, the server might complete a write operation of one client, but respond with stale data to another client. Mazi` eres and Shasha (PODC 2002) introduced the notion of fork- consistency, also called fork-linearizability, which ensures that the operations seen by every client are linearizable and guarantees that if the server causes the views of two clients to differ in a single operation, they may never again see each other’s updates after that without the server being exposed as faulty. In this paper, we im- prove the communication complexity of their fork-linearizable stor- age access protocol with n clients from Ω(n2) to O(n).We also prove that in every such protocol, a reader must wait for a con- current writer. This explains a seeming limitation of their and of our improved protocol. Furthermore, we give novel characteriza- tions of fork-linearizability and prove that it is neither stronger nor weaker than sequential consistency.",
    pages = "129--138",
    file = ":auto/homes/drt24/Downloads/p129-cachin.pdf:pdf",
    year = "2007",
    keywords = "arbitrary failures,fork-consistency,storage emulations",
    journal = "PODC 07 Proceedings of the twentysixth annual ACM symposium on Principles of distributed computing"
}

@article{Cachin2009,
    author = "Cachin, Christian and Keidar, Idit and Shraer, Alexander",
    publisher = "Ieee",
    doi = "10.1109/DSN.2009.5270299",
    isbn = "978-1-4244-4422-9",
    title = "{Fail-Aware Untrusted Storage}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5270299",
    abstract = "We consider a set of clients collaborating through an online service provider that is subject to attacks and hence not fully trusted by the clients. We introduce the abstraction of a failaware untrusted service, with meaningful semantics even when the provider is faulty. In the common case, when the provider is correct, such a service guarantees consistency (linearizability) and liveness (wait-freedom) of all operations. In addition, the service always provides accurate and complete consistency and failure detection. We illustrate our new abstraction by presenting a Fail-Aware Untrusted STorage service (FAUST). Existing storage protocols in this model guarantee so-called forking semantics. We observe, however, that none of the previously suggested protocols suffices for implementing fail-aware untrusted storage with the desired liveness and consistency properties (at least wait-freedom and linearizability when the server is correct). We present a new storage protocol, which does not suffer from this limitation, and implements a new consistency notion, called weak fork-linearizability. We show how to extend this protocol to provide eventual consistency and failure awareness in FAUST. Copyright by SIAM.",
    issn = "00975397",
    number = "2",
    month = "6",
    volume = "40",
    pages = "494--503",
    file = ":auto/homes/drt24/Downloads/05270299.pdf:pdf",
    year = "2009",
    journal = "2009 IEEE/IFIP International Conference on Dependable Systems \& Networks"
}

@inproceedings{Calder2011,
    author = "Calder, Brad and Wang, Ju and Ogus, Aaron and Nilakantan, Niranjan and Skjolsvold, Arild and McKelvie, Sam and Xu, Yikang and Srivastav, Shashwat and Wu, Jiesheng and Simitci, Huseyin and Haridas, Jaidev and Uddaraju, Chakravarthy and Khatri, Hemal and Edwards, Andrew and Bedekar, Vaman and Mainali, Shane and Abbasi, Rafay and Agarwal, Arpit and {Fahim ul Haq}, Mian and {Ikram ul Haq}, Muhammad and Bhardwaj, Deepali and Dayanand, Sowmya and Adusumilli, Anitha and McNett, Marvin and Sankaran, Sriram and Manivannan, Kavitha and Rigas, Leonidas",
    isbn = "9781450309776",
    title = "{Windows Azure Storage: a highly available cloud storage service with strong consistency}",
    url = "http://dl.acm.org/citation.cfm?id=2043571",
    abstract = "Windows Azure Storage (WAS) is a cloud storage system that provides customers the ability to store seemingly limitless amounts of data for any duration of time. WAS customers have access to their data from anywhere at any time and only pay for what they use and store. In WAS, data is stored durably using both local and geographic replication to facilitate disaster recovery. Currently, WAS storage comes in the form of Blobs (files), Tables (structured storage), and Queues (message delivery). In this paper, we describe the WAS architecture, global namespace, and data model, as well as its resource provisioning, load balancing, and replication systems.",
    file = ":auto/homes/drt24/Downloads/11-calder-online.pdf:pdf",
    year = "2011",
    keywords = "cloud storage,distributed storage systems,windows azure",
    booktitle = "SOSP"
}

@techreport{Cappos2008,
    author = "Cappos, Justin and Samuel, Justin",
    title = "{Package management security}",
    url = "http://www.cs.arizona.edu/people/jsamuel/papers/TR08-02.pdf",
    abstract = "Package management is the task of determining which packages should be installed on a host and then downloading and installing those packages. This paper examines the popular package managers APT and YUM and presents nine feasible attacks on them. There are attacks that install malicious packages, deny users package updates, or cause the host to crash. This work identifies three rules of package management security: don’t trust the repository, the trusted entity with the most information should be the one who signs, and don’t install untrusted packages. The violation of these rules leads to the described vulnerabilities. Unfortunately, many of the flaws are architectural in nature, so repair requiresmore than patches to APT and YUM. While the rules of packagemanagement security argue that the design of existing packagemanagers is insufficient, they do not prescribe how to provide security. This led to the development of three de- sign principles for building a secure packagemanager: selective trust delegation, customized repository views, and explicitly treating the repository as untrusted. These principleswere used to construct a pack- age manager Stork which is not vulnerable to the attacks identified for YUM and APT. Stork has been in use for four years and has managed over half a million clients.",
    pages = "1--20",
    file = ":home/drt24/Downloads/TR08-02.pdf:pdf",
    year = "2008",
    booktitle = "University of Arizona, Computer Science Department"
}

@inproceedings{Carneiro2008,
    author = "Carneiro, Glauco De F",
    title = "{The Importance of Cognitive and Usability Elements in Designing Software Visualization Tools}",
    abstract = "Modern IDEs offer built-in support for developing plug-ins. More recently, we have seen a growing number of plug-ins that offer non-conventional software visualization interfaces. They usually aim to help programmers to understand unfamiliar source code by representing it in visual structures such as trees, scatter-plots or graphs. Although very attractive visually, we need to know more about the effectiveness of these interfaces in conveying information to software engineers. In this paper, we discuss some concepts and guidelines regarding the requirements of visualization tools for software comprehension as well as the set-up of an infrastructure to empirically evaluate how useful are those tools in supporting software comprehension activities.",
    number = "c",
    file = "::",
    year = "2008",
    keywords = "b observation,b program comprehension,d visualization pop-v,pop-ii,pop-iii",
    booktitle = "Psychology of Programming Languages Interest Group"
}

@article{Carroll2010,
    author = "Carroll, Aaron and Heiser, Gernot",
    url = "http://dl.acm.org/citation.cfm?id=1855840.1855861",
    title = "{An analysis of power consumption in a smartphone}",
    year = "2010",
    pages = "21",
    month = "6"
}

@inproceedings{Casalicchio2012,
    author = "Casalicchio, E and Caselli, M. and Coletta, A. and {Nai Fovino}, I. and Fovino, I Nai",
    title = "{Aggregation of DNS health indicators : issues , expectations and results}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Casalicchio.pdf http://conferences.npl.co.uk/satin/presentations/satin2012slides-Casalicchio.pdf",
    abstract = "Today DNS community is debating on the issue of Measuring Naming System Health and Security. There are several initiatives in this field, all claiming to be able to measure the DNS health state from a local perspective. The reality is a bit different and many challenges are still open: no standard metrics exists (only a shared list of five health indicators); no common agreement of how to compute health indicators; no common concept of normality of the DNS behavior; no standard framework for data/information sharing. The Measuring the Naming System (MeNSa) project proposes to realize a framework providing a formal and structured methodology, metrics and tools for the measurement of DNS health and security level. In this paper we concentrate our attention on the measurement aggregation problem. This paper is a work in progress aiming to stimulate discussions. The contribution we provide is twofold. First we provide a brief description of the MeNSa project Second, we propose a methodology to combine different health and security metrics in aggregated indexes. Ex- perimental results show what is possible to obtain, what are the open issues and what we expect.",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Casalicchio.pdf:pdf;:auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Casalicchio.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@inproceedings{Chakraborty2012b,
    author = "Chakraborty, Supriyo and Charbiwala, Zainul and Choi, Haksoo and Raghavan, Kasturi Rangan and Srivastava, Mani B.",
    doi = "10.1016/j.pmcj.2012.03.002",
    title = "{Balancing behavioral privacy and information utility in sensory data flows}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1574119212000429",
    booktitle = "Pervasive and Mobile Computing",
    issn = "15741192",
    number = "3",
    month = "6",
    volume = "8",
    file = "::",
    year = "2012",
    pages = "331--345"
}

@inproceedings{Chakravorty2004,
    author = "Chakravorty, Rajiv and Banerjee, Suman and Rodriguez, Pablo and Chesterfield, Julian and Pratt, Ian",
    publisher = "ACM Press",
    doi = "10.1145/1023720.1023737",
    isbn = "1581138687",
    title = "{Performance optimizations for wireless wide-area networks}",
    url = "http://dl.acm.org/citation.cfm?id=1023720.1023737",
    abstract = "We present a comparative performance study of a wide selection of optimization techniques to enhance application performance in the context of wide-area wireless networks (WWANs). Unlike in traditional wired and wireless IP-based networks, applications running over WWAN cellular environments are significantly affected by the vagaries of the cellular wireless medium. Prior research has proposed and analyzed optimizations at individual layers of the protocol stack. In contrast, we introduce the first detailed experiment-based evaluation and comparison of all such optimization techniques in a commercial WWAN testbed. This paper, therefore, summarizes our experience in implementing and deploying an infrastructure to improve WWAN performance.The goals of this paper are: (1) to perform an accurate benchmark of application performance over such commercially deployed WWAN environments, (2) to implement and characterize the impact of various optimization techniques across different layers of the protocol stack, and (3) to quantify their interdependencies in realistic scenarios. Additionally, we also discuss measurement pitfalls that we experienced and provide guidelines that may be useful for future experimentation in WWAN environments.",
    year = "2004",
    month = "9",
    pages = "159",
    file = "::",
    address = "New York, New York, USA",
    keywords = "3G,CDMA 2000,GPRS,HTTP,TCP,UMTS,cellular,cross-layer interactions,multi-layer performance optimizations,proxy",
    booktitle = "Proceedings of the 10th annual international conference on Mobile computing and networking - MobiCom '04"
}

@inproceedings{Chakravorty2004a,
    author = "Chakravorty, Rajiv and Banerjee, Suman and Rodriguez, Pablo and Chesterfield, Julian and Pratt, Ian",
    publisher = "ACM Press",
    doi = "10.1145/1023720.1023737",
    isbn = "1581138687",
    title = "{Performance optimizations for wireless wide-area networks}",
    abstract = "We present a comparative performance study of a wide selection of optimization techniques to enhance application performance in the context of wide-area wireless networks (WWANs). Unlike in traditional wired and wireless IP-based networks, applications running over WWAN cellular environments are significantly affected by the vagaries of the cellular wireless medium. Prior research has proposed and analyzed optimizations at individual layers of the protocol stack. In contrast, we introduce the first detailed experiment-based evaluation and comparison of all such optimization techniques in a commercial WWAN testbed. This paper, therefore, summarizes our experience in implementing and deploying an infrastructure to improve WWAN performance.The goals of this paper are: (1) to perform an accurate benchmark of application performance over such commercially deployed WWAN environments, (2) to implement and characterize the impact of various optimization techniques across different layers of the protocol stack, and (3) to quantify their interdependencies in realistic scenarios. Additionally, we also discuss measurement pitfalls that we experienced and provide guidelines that may be useful for future experimentation in WWAN environments.",
    year = "2004",
    month = "9",
    pages = "159",
    file = "::",
    address = "New York, New York, USA",
    keywords = "3G,CDMA 2000,GPRS,HTTP,TCP,UMTS,cellular,cross-layer interactions,multi-layer performance optimizations,proxy",
    booktitle = "Proceedings of the 10th annual international conference on Mobile computing and networking - MobiCom '04"
}

@inproceedings{Chambers2010,
    author = "Chambers, Craig and Raniwala, Ashish and Perry, Frances and Adams, Stephen and Henry, Robert R. and Bradshaw, Robert and Weizenbaum, Nathan",
    publisher = "ACM",
    doi = "10.1145/1806596.1806638",
    isbn = "9781450300193",
    title = "{FlumeJava: easy, efficient data-parallel pipelines}",
    url = "http://dl.acm.org/citation.cfm?id=1806638 http://portal.acm.org/citation.cfm?id=1809028.1806638",
    series = "PLDI '10",
    abstract = "MapReduce and similar systems significantly ease the task of writ- ing data-parallel code. However, many real-world computations require a pipeline of MapReduces, and programming and managing such pipelines can be difficult. We present FlumeJava, a Java library that makes it easy to develop, test, and run efficient data- parallel pipelines. At the core of the FlumeJava library are a cou- ple of classes that represent immutable parallel collections, each supporting a modest number of operations for processing them in parallel. Parallel collections and their operations present a simple, high-level, uniform abstraction over different data representations and execution strategies. To enable parallel operations to run effi- ciently, FlumeJava defers their evaluation, instead internally constructing an execution plan dataflow graph. When the final results of the parallel operations are eventually needed, FlumeJava first op- timizes the execution plan, and then executes the optimized operations on appropriate underlying primitives (e.g., MapReduces). The combination of high-level abstractions for parallel data and computation, deferred evaluation and optimization, and efficient parallel primitives yields an easy-to-use system that approaches the efficiency of hand-optimized pipelines. FlumeJava is in active use by hundreds of pipeline developers within Google.",
    issn = "03621340",
    year = "2010",
    number = "6",
    pages = "363--375",
    volume = "45",
    file = ":home/drt24/Downloads/p363-chambers.pdf:pdf",
    address = "Toronto, Ontario, Canada",
    keywords = "1,3,algorithms,concurrent pro,d,data parallel programming,data-parallel programming,java,languages,mapreduce,performance",
    organization = "ACM",
    booktitle = "PLDI"
}

@inproceedings{Chandra2007,
    author = "Chandra, Tushar D. and Griesemer, R. and Redstone, J.",
    publisher = "ACM",
    doi = "10.1145/1281100.1281103",
    title = "{Paxos made live: an engineering perspective}",
    url = "http://www.cl.cam.ac.uk/research/dtg/www/files/paperparties/acr31/paxos_made_live.pdf http://portal.acm.org/citation.cfm?id=1281100.1281103",
    abstract = "We describe our experience building a fault-tolerant data-base using the Paxos consensus algorithm. Despite the existing literature in the field, building such a database proved to be non-trivial. We describe selected algorithmic and engineering problems encountered, and the solutions we found for them. Our measurements indicate that we have built a competitive system.",
    file = ":home/drt24/Downloads/paxos\_made\_live.pdf:pdf",
    year = "2007",
    booktitle = "Proceedings of the twenty-sixth annual ACM symposium on Principles of distributed computing",
    pages = "398--407"
}

@article{Chang2006,
    author = "Chang, Kevin and Yau, Nathan and Hansen, Mark and Estrin, D",
    title = "{SensorBase.org - A Centralized Repository to Slog Sensor Network Data}",
    url = "http://escholarship.org/uc/item/4dt82690",
    abstract = "Various sensor networks use different data storage and management mechanisms. In particular, UCLA’s ESS2 mechanism forwards information from low powered 8-bit Mica2 motes to one or more low powered sinks that then push log files to a secure and centralized repository. While this data storage and management mechanism is straightforward to implement, publishing and sharing various data to various users has been a challenge. Users that need to parse the data often find it time consuming and error prone to have to log-on to different systems, calibrate different units, and to understand the different semantics of various log files. Similar to blog sites, SensorBase.org is our solution for a certain domain of sensor networks that allows users to “slog” sensor network data and other relevant information. It is a centralized common data storage and management system that provides a uniform and consistent method for publishing and sharing data. It allows users to define a subset of EML data types, project groups, and permission levels. It also serves as a search engine that provides APIs a way to easily query for specific data sets based on geographic location, sensor type, date/time range, and other relevant fields. eScholarship",
    month = "5",
    file = ":home/drt24/Downloads/eScholarship UC item 4dt82690.pdf:pdf",
    year = "2006",
    keywords = "data sharing,management,sensor networks"
}

@article{Chang2008,
    author = "Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, W.C. and Wallach, D.A. and Burrows, Mike and Chandra, Tushar D. and Fikes, Andrew and Gruber, Robert E.",
    publisher = "ACM",
    doi = "10.1145/1365815.1365816",
    title = "{Bigtable: A distributed storage system for structured data}",
    journal = "ACM Transactions on Computer Systems (TOCS)",
    abstract = "Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Fi- nance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the sim- ple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we de- scribe the design and implementation of Bigtable.",
    number = "2",
    volume = "26",
    url = "http://portal.acm.org/citation.cfm?id=1365816",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang et al. - 2008 - Bigtable A distributed storage system for structured data.pdf:pdf",
    year = "2008",
    pages = "1--26"
}

@article{Chase2003,
    author = "Chase, Jeffery S. and Irwin, David E. and Grit, Laura E. and Moore, Justin D. and Sprenkle, Sara E.",
    publisher = "IEEE Computer Society",
    doi = "10.1109/HPDC.2003.1210019",
    isbn = "0769519652",
    title = "{Dynamic Virtual Clusters in a Grid Site Manager}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1210019",
    abstract = "This paper presents new mechanisms for dynamic resource management in a cluster manager called Cluster-on-Demand (COD). COD allocates servers from a common pool to multiple virtual clusters (vclusters), with independently configured software environments, name spaces, user access controls, and network storage volumes. We present experiments using the popular Sun GridEngine batch scheduler to demonstrate that dynamic virtual clusters are an enabling abstraction for advanced resource management in computing utilities and grids. In particular, they support dynamic, policy-based cluster sharing between local users and hosted Grid services, resource reservation and adaptive provisioning, scavenging of the idle resources, and dynamic instantiation of Grid services. These goals are achieved in a direct and general way through a new set of fundamental cluster management functions, with minimal impact on the Grid middleware itself.",
    issn = "10828907",
    pages = "90--100",
    file = ":auto/homes/drt24/Downloads/01210019.pdf:pdf",
    year = "2003",
    journal = "High Performance Distributed Computing 2003 Proceedings 12th IEEE International Symposium on"
}

@inproceedings{Chaudhuri2009,
    author = "Chaudhuri, Avik",
    publisher = "ACM Press",
    doi = "10.1145/1554339.1554341",
    isbn = "9781605586458",
    title = "{Language-based security on Android}",
    url = "http://dl.acm.org/citation.cfm?id=1554339.1554341",
    booktitle = "Proceedings of the ACM SIGPLAN Fourth Workshop on Programming Languages and Analysis for Security - PLAS '09",
    year = "2009",
    month = "6",
    address = "New York, New York, USA",
    keywords = "certified compilation,data-flow security,hybrid type system,mobile code",
    pages = "1"
}

@inproceedings{Chaudhuri2009a,
    author = "Chaudhuri, Avik",
    publisher = "ACM Press",
    doi = "10.1145/1554339.1554341",
    isbn = "9781605586458",
    title = "{Language-based security on Android}",
    booktitle = "Proceedings of the ACM SIGPLAN Fourth Workshop on Programming Languages and Analysis for Security - PLAS '09",
    year = "2009",
    month = "6",
    address = "New York, New York, USA",
    keywords = "certified compilation,data-flow security,hybrid type system,mobile code",
    pages = "1"
}

@article{Chen2008,
    author = "Chen, Qi and Hosking, John",
    title = "{SUMLOW : Early Design-Stage Sketching of UML Diagrams on an E-whiteboard}",
    journal = "Practice",
    number = "9",
    volume = "38",
    file = "::",
    year = "2008",
    pages = "961--994"
}

@inproceedings{Chen2012,
    author = "Chen, Yu-Yuan and Jamkhedkar, Pramod a. and Lee, Ruby B.",
    publisher = "ACM Press",
    doi = "10.1145/2382196.2382201",
    isbn = "9781450316514",
    title = "{A software-hardware architecture for self-protecting data}",
    url = "http://dl.acm.org/citation.cfm?doid=2382196.2382201",
    abstract = "We propose a software-hardware architecture, DataSafe, that realizes the concept of self-protecting data: data that is protected by a given policy whenever it is accessed by any application -- including unvetted third-party applications. Our architecture provides dynamic instantiations of secure data compartments (SDCs), with hardware monitoring of the information flows from the compartment using hardware policy tags associated with the data at runtime. Unbypassable hardware output control prevents confidential information from being leaked out. Unlike previous hardware information flow tracking systems, DataSafe software architecture bridges the semantic gap by supporting flexible, high-level software policies for the data, seamlessly translating these policies to efficient hardware tags at runtime. Applications need not be modified to interface to these software-hardware mechanisms. DataSafe architecture is designed to prevent illegitimate secondary dissemination of protected plaintext data by authorized recipients, to track and protect data derived from sensitive data, and to provide lifetime enforcement of the confidentiality policies associated with the sensitive data.",
    year = "2012",
    pages = "14",
    file = ":home/drt24/Downloads/p14-chen.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "architecture,information flow tracking,self-protecting data",
    booktitle = "Proceedings of the 2012 ACM conference on Computer and communications security - CCS '12"
}

@article{Cheney2009,
    author = "Cheney, James and Chong, Stephen and Foster, Nate and Seltzer, M",
    isbn = "9781605587684",
    title = "{Provenance: a future history}",
    url = "http://portal.acm.org/citation.cfm?id=1640064",
    journal = "Proceeding of the 24th ACM SIGPLAN conference companion on Object oriented programming systems languages and applications",
    file = "::",
    year = "2009",
    keywords = "a future history of,by,inaudible,integrity,provenance,provenance conference,semantics,the 2019 federated,transcribed keynote remarks from",
    pages = "1--8"
}

@article{Cheng2005,
    author = "Cheng, Yu-Chung and Chawathe, Yatin and LaMarca, Anthony and Krumm, John",
    publisher = "ACM Press",
    doi = "10.1145/1067170.1067195",
    isbn = "1931971315",
    title = "{Accuracy characterization for metropolitan-scale Wi-Fi localization}",
    url = "http://portal.acm.org/citation.cfm?doid=1067170.1067195",
    series = "MobiSys '05",
    journal = "MobiSys '05 Proceedings of the 3rd international conference on Mobile systems, applications, and services",
    institution = "Intel Research",
    pages = "233--245",
    file = "::",
    year = "2005",
    abstract = "Location systems have long been identified as an important component of emerging mobile applications. Most research on location systems has focused on precise location in indoor environments. However, many location applications (for example, location-aware web search) become interesting only when the underlying location system is available ubiquitously and is not limited to a single office environment. Unfortunately, the installation and calibration overhead involved for most of the existing research systems is too prohibitive to imagine deploying them across, say, an entire city. In this work, we evaluate the feasibility of building a wide-area 802.11 Wi-Fi-based positioning system. We compare a suite of wireless-radio-based positioning algorithms to understand how they can be adapted for such ubiquitous deployment with minimal calibration. In particular, we study the impact of this limited calibration on the accuracy of the positioning algorithms. Our experiments show that we can estimate a user's position with a median positioning error of 13-40 meters (depending upon the characteristics of the environment). Although this accuracy is lower than existing positioning systems, it requires substantially lower calibration overhead and provides easy deployment and coverage across large metropolitan areas."
}

@article{Chi2000,
    author = "Chi, E.H.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/INFVIS.2000.885092",
    isbn = "0-7695-0804-9",
    title = "{A taxonomy of visualization techniques using the data state reference model}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=885092",
    journal = "IEEE Symposium on Information Visualization 2000. INFOVIS 2000. Proceedings",
    number = "Table 2",
    volume = "94301",
    file = "::",
    year = "2000",
    keywords = "data state model,information visualization,operators,reference model,taxonomy,techniques",
    pages = "69--75"
}

@book{Chisnall2007,
    author = "Chisnall, David",
    publisher = "Prentice Hall",
    isbn = "013234971X",
    title = "{The Definitive Guide to the Xen Hypervisor}",
    url = "http://www.amazon.com/The-Definitive-Guide-Xen-Hypervisor/dp/013234971X",
    year = "2007",
    pages = "320"
}

@article{Choudary2012,
    author = "Choudary, Omar and Grobert, Felix and Metz, Joachim",
    title = "{Infiltrate the Vault : Security Analysis and Decryption of Lion Full Disk Encryption}",
    url = "http://eprint.iacr.org/2012/374.pdf",
    abstract = "he closed-source software, e.g. its use of the AES-XTS tweakable encryption, but a publicly available security evaluation and detailed description was unavailable until now. We have performed an extensive analysis of FileVault 2 and we have been able to find all the algorithms and parameters needed to successfully read an encrypted volume. This allows us to perform forensic investigations on encrypted volumes using our own tools. In this paper we present the architecture of FileVault 2, giving details of the key derivation, encryption process and metadata structures needed to perform the volume decryption. Besides the analysis of the system, we have also built a library that can mount a volume encrypted with FileVault 2. As a contribution to the research and forensic communities we have made this library open source. Additionally, we present an informal security evalua- tion of the system and comment on some of the design and implementation features. Among others we analyze the random number generator used to create the recovery password. We have also analyzed the entropy of each 512-byte block in the encrypted volume and discovered that part of the user data was left unencrypted.",
    file = ":home/drt24/Downloads/374.pdf:pdf",
    year = "2012",
    journal = "eprint"
}

@inproceedings{Choudhuri2004,
    author = "Choudhuri, Siddharth and Mahapatra, Rabi N.",
    publisher = "ACM Press",
    doi = "10.1145/996566.996722",
    isbn = "1581138288",
    title = "{Energy characterization of filesystems for diskless embedded systems}",
    url = "http://dl.acm.org/citation.cfm?id=996566.996722",
    booktitle = "Proceedings of the 41st annual conference on Design automation - DAC '04",
    year = "2004",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    keywords = "diskless,flash,macromodel",
    pages = "566"
}

@online{Christensen,
    author = "Christensen, Erik (Microsoft) and Curbera, Francisco (IBM Research) and Meredith, Greg (Microsoft) and Weerawarana, Sanjiva (IBM Research)",
    url = "http://www.w3.org/TR/wsdl",
    publisher = "WC3",
    abstract = "WSDL is an XML format for describing network services as a set of endpoints operating on messages containing either document-oriented or procedure-oriented information. The operations and messages are described abstractly, and then bound to a concrete network protocol and message format to define an endpoint. Related concrete endpoints are combined into abstract endpoints (services). WSDL is extensible to allow description of endpoints and their messages regardless of what message formats or network protocols are used to communicate, however, the only bindings described in this document describe how to use WSDL in conjunction with SOAP 1.1, HTTP GET/POST, and MIME.",
    file = ":auto/homes/drt24/Downloads/Web Service Definition Language (WSDL).html:html",
    title = "{Web Service Definition Language (WSDL)}"
}

@techreport{Christensen2001,
    author = "Christensen, Erik (Microsoft) and Curbera, Francisco (IBM Research) and Meredith, Greg (Microsoft) and Weerawarana, Sanjiva (IBM Research)",
    publisher = "WC3",
    title = "{Web Service Definition Language (WSDL)}",
    url = "http://www.w3.org/TR/wsdl",
    abstract = "WSDL is an XML format for describing network services as a set of endpoints operating on messages containing either document-oriented or procedure-oriented information. The operations and messages are described abstractly, and then bound to a concrete network protocol and message format to define an endpoint. Related concrete endpoints are combined into abstract endpoints (services). WSDL is extensible to allow description of endpoints and their messages regardless of what message formats or network protocols are used to communicate, however, the only bindings described in this document describe how to use WSDL in conjunction with SOAP 1.1, HTTP GET/POST, and MIME.",
    month = "3",
    file = ":auto/homes/drt24/Downloads/Web Service Definition Language (WSDL).html:html",
    year = "2001",
    institution = "W3C"
}

@online{Christey2001,
    author = "Christey, Steve and Pease, Barbara",
    title = "{An informal analysis of vendor acknowledgement of vulnerabilities}",
    url = "http://seclists.org/bugtraq/2001/Mar/154 https://archive.today/O3Y5I",
    abstract = "Many disclosure debates focus on researchers who discover vulnerabilities. Little attention is given to the impact on busy security analysts who must determine which vulnerabilities exist, and if they can be patched. There is little or no emphasis on the role of vendors of the vulnerable software. Given continued discussions of vulnerability disclosure practices, most recently regarding vendor contacts on the PEN-TEST list, we decided to offer some results of an informal analysis we performed in October 2000. We also make some recommendations for improvements.",
    month = "3",
    file = ":home/drt24/Downloads/An informal analysis of vendor acknowledgement of vulnerabilities.pdf:pdf",
    year = "2001",
    urldate = "2014-06-09",
    booktitle = "Bugtraq mailing list"
}

@article{Christianson1995,
    author = "Christianson, B and Low, MR",
    publisher = "IEEE",
    doi = "10.1049/el:19950719",
    title = "{Key-spoofing attacks on nested signature blocks}",
    journal = "Electronics Letters",
    abstract = "For a given signature block and any other data, there exists a key which produces the same signature block. The threat that this poses to schemes which use nested signature blocks as pointers to other tokens is identified, using a theft-proof capability mechanism as an illustration. A modification to public key certificates is then proposed to eliminate this threat",
    number = "13",
    volume = "31",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=392697",
    file = ":home/drt24/Downloads/00392697.pdf:pdf",
    year = "1995",
    pages = "1043--1044"
}

@article{Christianson2005,
    author = "Christianson, Bruce",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11542322_25",
    isbn = "978-3-540-28389-8",
    title = "{Secure Sessions from Weak Secrets (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/11542322_25",
    abstract = "This story starts with a specific protocol, which we thought up in the Eagle back in 1997, and which was inspired by an earlier Security Protocol Workshop. Here’s the protocol, which is intended to leverage a weak shared password k up into a fresh random strong shared secret s",
    pages = "206--212",
    volume = "3364",
    file = ":home/drt24/Downloads/10.1007\_11542322\_25.pdf:pdf",
    year = "1998",
    journal = "Security Protocols"
}

@article{Christianson2013,
    author = "Christianson, Bruce",
    doi = "10.1007/s13347-013-0128-5",
    title = "{Living in an Impossible World: Real-izing the Consequences of Intransitive Trust}",
    url = "http://link.springer.com/10.1007/s13347-013-0128-5",
    abstract = "Many accounts of online trust are based upon mechanisms for building reputation. Trust is portrayed as desirable, and handing off trust is easier if trust is modelled to be transitive. But in the analysis of cyber-security protocols, trust is usually used as a substitute for certain knowledge: it follows that if there is no residual risk, then there is no need for trust. On this grimmer understanding, the less that users are required to trust, the better. Involuntary transitivity of trust becomes corrosive, because it prevents participants from having control—or even knowledge—of the risks to which their trust assumptions expose them. In this paper, we take the stance that controlling the transitivity of trust requires us to recognise trust as a non-referentially transparent modality, similar to but significantly weaker than the epistemic modalities, and to accept the corollary that imaginary (indeed—even impossible) threats can have real consequences that adversely affect online security. An apparently paradoxical outcome is that the desire of principals to keep their trust assumptions private can actually assist the design of systems to satisfy multiple security agendas. However, this approach requires agents to have the capability to predicate accurately about states of affairs that are logically inconsistent with their beliefs, and consequently, designing systems in this way becomes more akin to diplomacy than engineering.",
    issn = "2210-5433",
    month = "8",
    file = ":home/drt24/Downloads/10.1007-s13347-013-0128-5.pdf:pdf",
    year = "2013",
    keywords = "counterfactual reasoning,doxastic logic,intensional properties,privacy",
    journal = "Philosophy \& Technology"
}

@inproceedings{Chun2012,
    author = "Chun, Byung-gon and Shraer, Alexander and Curino, Carlo and Madden, Samuel and Sears, Russell",
    isbn = "9781450313018",
    title = "{Mobius : Unified Messaging and Data Serving for Mobile Apps Categories and Subject Descriptors}",
    abstract = "Mobile application development is challenging for several reasons: intermittent and limited network connectivity, tight power con- straints, server-side scalability concerns, and a number of fault- tolerance issues. Developers handcraft complex solutions that in- clude client-side caching, conflict resolution, disconnection toler- ance, and backend database sharding. To simplify mobile app de- velopment, we present Mobius, a system that addresses the messag- ing and data management challenges of mobile application devel- opment. Mobius introduces MUD (Messaging Unified with Data). MUD presents the programming abstraction of a logical table of data that spans devices and clouds. Applications using Mobius can asynchronously read from/write to MUD tables, and also receive notifications when tables change via continuous queries on the ta- bles. The system combines dynamic client-side caching (with intel- ligent policies chosen on the server-side, based on usage patterns across multiple applications), notification services, flexible query processing, and a scalable and highly available cloud storage sys- tem. We present an initial prototype to demonstrate the feasibility of our design. Even in our initial prototype, remote read and write latency overhead is less than 52\% when compared to a hand-tuned solution. Our dynamic caching reduces the number of messages by a factor of 4 to 8.5 when compared to fixed strategies, thus re- ducing latency, bandwidth, power, and server load costs, while also reducing data staleness.",
    file = ":auto/homes/drt24/Downloads/mud.pdf:pdf",
    year = "2012",
    keywords = "caching,data management,fication,messaging,mobile apps,mobile cloud computing,push noti-",
    booktitle = "MobiSys"
}

@inproceedings{Chung2011,
    author = "Chung, Yi-Fan and Lin, Chun-Yu and King, Chung-Ta",
    publisher = "IEEE",
    doi = "10.1109/ICPADS.2011.28",
    isbn = "978-0-7695-4576-9",
    title = "{ANEPROF: Energy Profiling for Android Java Virtual Machine and Applications}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6121300",
    abstract = "Battery energy is one of the most critical resources in a handheld device. Modern designs for handheld devices thus call for optimized use of system power. To develop power-efficient systems, it is essential to understand how power is consumed throughout the system. A promising approach is to measure the power consumption of the system and then match the measurements with the profiled system events. The latter then provides information about how the system consumes power. However, existing tools mostly profile only at the process level due to problems such as profiling overhead and event synchronization. Modern handheld systems, such as Android, complicate the problem further because of the extra layers of software such as Java runtime environment and libraries. To address the above challenges, this paper presents ANEPROF, Android Energy Profiler - a profiling tool for Android that allows energy profiling down to the function level. The design issues and considerations are discussed and its implementation is described. The performance of the tool is evaluated by comparing with other profiling methods.",
    month = "12",
    year = "2011",
    booktitle = "2011 IEEE 17th International Conference on Parallel and Distributed Systems",
    pages = "372--379"
}

@inproceedings{Church2008,
    author = "Church, Karen and Smyth, Barry",
    publisher = "ACM Press",
    doi = "10.1145/1409240.1409325",
    isbn = "9781595939524",
    title = "{Understanding mobile information needs}",
    url = "http://dl.acm.org/citation.cfm?id=1409240.1409325",
    booktitle = "Proceedings of the 10th international conference on Human computer interaction with mobile devices and services - MobileHCI '08",
    year = "2008",
    month = "9",
    file = "::",
    address = "New York, New York, USA",
    keywords = "diary study,information needs,intent,mobile",
    pages = "493"
}

@inproceedings{Church2011a,
    author = "Church, Luke and Blackwell, Alan",
    title = "{Computation, Visualisation and Critical Reflection}",
    booktitle = "Visualisation in the Age of Computerisation",
    year = "2011",
    mendeley-tags = "Data Visualisation",
    file = "::",
    address = "Oxford",
    keywords = "Data Visualisation",
    pages = "33,46"
}

@techreport{Citrix2011,
    author = "Citrix",
    year = "2011",
    number = "September",
    file = ":auto/homes/drt24/Downloads/XenServer-6.0.0-quickstartguide.pdf:pdf",
    title = "{Citrix XenServer ® 6.0 Quick Start Guide}"
}

@techreport{Citrix2011a,
    author = "Citrix",
    year = "2011",
    number = "September",
    file = ":auto/homes/drt24/Downloads/XenServer-6.0.0-guest.pdf:pdf",
    title = "{Citrix XenServer ® 6 . 0 Virtual Machine Installation Guide}"
}

@techreport{Citrix2012,
    author = "Citrix",
    year = "2012",
    number = "March",
    file = ":auto/homes/drt24/Downloads/XenServer-6.0.0-reference.pdf:pdf",
    title = "{Citrix XenServer ® 6.0 Administrator's Guide}"
}

@inproceedings{Clark2010,
    author = "Clark, Sandy and Frei, Stefan and Blaze, Matt and Smith, Jonathan",
    publisher = "ACM",
    isbn = "9781450301336",
    title = "{Familiarity breeds contempt: The honeymoon effect and the role of legacy code in zero-day vulnerabilities}",
    url = "http://dl.acm.org/citation.cfm?id=1920299",
    abstract = "Work on security vulnerabilities in software has primarily focused on three points in the software life-cycle: (1) finding and removing software defects, (2) patching or hardening software after vulnerabilities have been discovered, and (3) measuring the rate of vulnerability exploitation. This paper examines an earlier period in the software vulnerability life- cycle, starting from the release date of a version through to the disclosure of the fourth vulnerability, with a particular focus on the time from release until the very first disclosed vulnerability. Analysis of software vulnerability data, including up to a decade of data for several versions of the most popular operating systems, server applications and user applications (both open and closed source), shows that properties ex- trinsic to the software play a much greater role in the rate of vulnerability discovery than do intrinsic properties such as software quality. This leads us to the observation that (at least in the first phase of a product’s existence), soft- ware vulnerabilities have different properties from software defects. We show that the length of the period after the release of a software product (or version) and before the discovery of the first vulnerability (the ’Honeymoon’ period) is primarily a function of familiarity with the system. In addition, we demonstrate that legacy code resulting from code re-use is a major contributor to both the rate of vulnerability dis- covery and the numbers of vulnerabilities found; this has significant implications for software engineering principles and practice.",
    year = "2010",
    month = "12",
    pages = "251--260",
    file = ":home/drt24/Downloads/p251-clark.pdf:pdf",
    address = "Austin, Texas, USA",
    booktitle = "ACSAC"
}

@article{Clark2013,
    author = "Clark, Jeremy and van Oorschot, Paul C.",
    publisher = "IEEE Computer Society",
    doi = "10.1109/SP.2013.41",
    title = "{SoK: SSL and HTTPS: Revisiting past challenges and evaluating certificate trust model enhancements}",
    url = "http://www.ieee-security.org/TC/SP2013/papers/4977a511.pdf",
    abstract = "Internet users today depend daily on HTTPS for secure communication with sites they intend to visit. Over the years, many attacks on HTTPS and the certificate trust model it uses have been hypothesized, executed, and/or evolved. Meanwhile the number of browser-trusted (and thus, de facto, user-trusted) certificate authorities has proliferated, while the due diligence in baseline certificate issuance has declined. We survey and categorize prominent security issues with HTTPS and provide a systematic treatment of the history and on-going challenges, intending to provide context for future directions. We also provide a comparative evaluation of current proposals for enhancing the certificate infrastructure used in practice.",
    pages = "511--525",
    file = ":home/drt24/Downloads/4977a511.pdf:pdf",
    year = "2013",
    keywords = "TLS,browser trust model,certificates,ssl,usability",
    journal = "IEEE Symposium on Security and Privacy"
}

@article{Clarke2002,
    author = "Clarke, Ian. and Miller, Scott.G. and Hong, Theodore W. and Sandberg, Oskar and Wiley, Brandon",
    publisher = "IEEE",
    title = "{Protecting free expression online with Freenet}",
    journal = "Internet Computing, IEEE",
    abstract = "Freenet uses a decentralized P2P architecture to create an uncensorable and secure global information storage system.",
    number = "1",
    volume = "6",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=978368",
    file = ":auto/homes/drt24/Downloads/ieee-final.pdf:pdf",
    year = "2002",
    pages = "40--49"
}

@inproceedings{Clayton2005,
    author = "Clayton, Richard",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11507840_11",
    isbn = "978-3-540-26656-3",
    title = "{Who'd Phish from the Summit of Kilimanjaro?}",
    url = "http://link.springer.com/chapter/10.1007/11507840_11",
    abstract = "Phishing emails are now so convincing that even experts cannot tell what is or is not genuine; though one of my own quiz answering errors resulted from failing to believe that genuine marketeers could possibly be so clueless! Thus I believe that education of end users will be almost entirely ineffective and education of marketing departments – to remove “click on this” (and HTML generally) from the genuine material – is going to take some time.",
    pages = "91--92",
    volume = "3570",
    file = ":home/drt24/Downloads/10.1007\_11507840\_11.pdf:pdf",
    year = "2005",
    booktitle = "Financial Cryptography and Data Security"
}

@article{Clulow2003,
    author = "Clulow, Jolyon",
    title = "{On the security of PKCS\# 11}",
    url = "http://www.springerlink.com/index/g8kpqlkpug4d71vu.pdf",
    abstract = "Public Key Cryptography Standards (PKCS) \#11 has gained wide acceptance within the cryptographic security device community and has become the interface of choice for many applications. The high esteem in which PKCS \#11 is held is evidenced by the fact that it has been selected by a large number of companies as the API for their own devices. In this paper we analyse the security of the PKCS \#11 standard as an interface (e.g. an application-programming interface (API)) for a security device.We show that PKCS \#11 is vulnerable to a number of known and new API attacks and exhibits a number of design weaknesses that raise questions as to its suitability for this role. Finally we present some design solutions.",
    pages = "411--425",
    file = ":home/drt24/Downloads/SecurityOfPKCS11.pdf:pdf",
    year = "2003",
    journal = "CHES"
}

@book{Cock2011,
    editor = "Bobaru, Mihaela and Havelund, Klaus and Holzmann, Gerard J. and Joshi, Rajeev",
    author = "Cock, David R.",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-20398-5",
    isbn = "978-3-642-20397-8",
    title = "{OpenJML: JML for Java 7 by Extending OpenJDK}",
    url = "http://www.springerlink.com/content/50p463l035ltv072/",
    series = "Lecture Notes in Computer Science",
    year = "2011",
    volume = "6617",
    address = "Berlin, Heidelberg",
    pages = "472--479"
}

@phdthesis{Cohen1985,
    author = "Cohen, Fred",
    school = "University of Southern California",
    title = "{Computer viruses}",
    url = "https://all.net/books/Dissertation.pdf",
    abstract = {In this thesis, we open the new topics of viruses and protection from viruses in computer systems. We define a class of computing mechanisms called "viruses",1 and explore many of their properties, particularly in regard to the threat they pose to the integrity of information in information systems. The present work concentrates, at the surface level, on integrity problems in computer systems, but strong analogies may be drawn to biological systems and other systems with the information characteristics necessary to support viruses. Where possible, analogies to other systems will be drawn at a philosophical level, but no attempt will be made to demonstrate these analogies with mathematical rigor. We begin our discussion by briefly reviewing the relevant literature in "computer security", and conclude that no serious previous work has been found in the open literature on the problem of computer viruses. It thus appears that the concept of computer viruses is a novelty in scientific literature at this point, and that little effective protection against viruses is currently available. We begin the discussion of viruses with an informal discussion based on an English language definition. We give "pseudo-program" examples of viruses as they might appear in modern computer systems, and use these examples to demonstrate some of the potential damage that could result from their use in attacking systems. It is because of this potential damage that we give our examples in pseudo-code rather than an actual computer language for an actual computer system. We formally define viruses for "Turing machines", and explore some of their properties. We define a Turing machine and a set of (machine,tape-set) pairs which comprise "viral sets" (VS). We show that the union of VSs is also a VS, and that therefor a "largest" VS (LVS) exists for any machine with a viral set. We define a "smallest" VS (SVS), as a VS of which no subset is a VS, and show that for any finite integer "i", there is an SVS with exactly i elements. We show that any self replicating tape sequence is a one element SVS, that there are countably infinite VSs and non VSs, that machines exist for which all tape sequence are viruses and for which no tape sequences are viruses, and that any finite sequence of tape symbols is a virus with respect to some machine. We show that determining whether a given (machine,tape-set) pair is a VS is undecidable (by reduction from the halting problem), that it is undecidable whether or not a given "virus" evolves into another virus, that any number that can be "computed" by a TM can be "evolved" by a virus, and that therefor, viruses are at least as powerful as Turing machines as a means for computation. We then move into a discussion of the relevance of viruses to modern computer protection techniques. We modify the "subject object" protection model @cite[Harrison] to allow computation to be modeled along with protection, by defining a new class of protection machines called "Universal Protection Machines" (UPMs). We show several examples of UPM viruses, and prove that a virus can spread to the transitive closure of information paths from any given source. The paths of sharing, transitivity of information flow, and generality of information interpretation are identified as the key properties in the spread of computer viruses, and a case by case analysis of these properties is shown. We show that the only systems with potential for limiting viral spreading are systems with limited transitivity and limited sharing, systems with no sharing, and systems without general interpretation of information (Turing capability). Only the first case appears to be of practical interest to current computer systems. Several protection techniques are explored for their effect on limiting viral spread in computer systems, and some previously unexposed properties of the combination of the "security" and "integrity" models are shown. Difficulties with "imprecise" protection schemes are presented, the most injurious being their tendency to move towards isolationism. These results are extended to the design of secure computer networks which implement distributed isolationism, and which allow the connection of trusted and untrusted computers to form trusted computer networks. Simple design rules are derived which allow the configuration of secure networks from pictures. Two classes of attacks against these types of computer networks are examined, and an example network is shown under various attack assumptions. We examine the generalization and combination of security and integrity lattices to partial orderings, and show that a partial ordering is as general a classification scheme as is necessary to model protection in a transitive information network. We extend the previous results to include the effects of modifications of a protection system over time, show techniques for generalized evaluation of the effects of collusions, and demonstrate a method by which a provably correct information management system for automating administration of protection in information networks may be implemented. We explore viral detection and removal methods which don't depend on the prevention of sharing, limitations on transitivity of information flow, or restricted functionality. Undecidability issues presented earlier are presented in a different form to demonstrate the potential difficulties with detection and cure of computer viruses. Although certain classes of viruses, predominantly those with trivial or simplistic evolutionary characteristics, appear to be defensible through detection and removal, more complex or highly evolutionary viruses appear to present unscalable barriers. The biological analogy to rapidly mutating viruses such as those which comprise the common cold appears to be very strong here. We examine a complexity based integrity maintenance method with the possibility of detecting corruption through built in self test. A method is shown whereby copyright notices and other aspects of programs and data may be maintained even in a system with no built in defenses. Integrity corruption in such a system is show to be extremely complex, and the technique appears to present a costly but viable defense. The results of several experiments with computer viruses are used to demonstrate that viruses are a formidable threat in both normal and high security operating systems. Detailed descriptions of experiments are given for three examples, an example of a very short virus for an actual operating system is given, and summary tables are presented. We explore the use of the results in computer viruses in biological and other domains, and consider the use of the fundamental viral definition as a definition of life. Living systems are considered as a combination of an environment and information within that environment which reproduces and evolves, and several philosophical questions are explored. It is concluded that the study of computer viruses is an important research area with potential applications to other fields, that current systems offer little or no protection from viral attack, and that the only perfectly 'safe' policy as of this time is isolationism. Extensions of this work are suggested, and several conjectures are presented.},
    number = "January",
    file = ":home/drt24/Downloads/Dissertation (2).pdf:pdf",
    year = "1985",
    pages = "1--152"
}

@inproceedings{Colp2011,
    author = "Colp, Patrick and Nanavati, Mihir and Zhu, Jun and Aiello, William and Coker, George and Deegan, Tim and Loscocco, Peter and Warfield, Andrew",
    doi = "10.1145/2043556.2043575",
    isbn = "9781450309776",
    title = "{Breaking up is hard to do: security and functionality in a commodity hypervisor}",
    url = "http://dl.acm.org/citation.cfm?id=2043575",
    abstract = "Cloud computing uses virtualization to lease small slices of large-scale datacenter facilities to indi- vidual paying customers. These multi-tenant environments, on which numerous large and popular web-based applications run today, are founded on the belief that the virtualization platform is sufficiently secure to prevent breaches of isolation between different userswho are co-located on the same host. Hypervisors are believed to be trustworthy in this role because of their small size and narrow interfaces. We observe that despite the modest footprint of the hypervisor itself, these platforms have a large aggregate trusted computing base (TCB) that includes a monolithic control VM with numerous interfaces exposed to VMs. We present Xoar, a modified version of Xen that retrofits the modularity and isolation principles used in microkernels onto a mature virtualization platform. Xoar breaks the control VM into single-purpose components called service VMs. We show that this componentized abstraction brings a number of benefits: sharing of service components by guests is configurable and auditable, making exposure to risk explicit, and access to the hypervisor is restricted to the least privilege required for each component. Microrebooting components at configurable frequencies reduces the temporal attack surface of individual components. Our approach incurs little performance overhead, and does not require functionality to be sacrificed or components to be rewritten from scratch.",
    year = "2011",
    file = ":auto/homes/drt24/Downloads/14-colp-online.pdf:pdf",
    address = "Cascais, Portugal",
    booktitle = "SOSP"
}

@book{Committee2008,
    author = "Committee, Microprocessor Standards",
    isbn = "9780738157528",
    title = "{IEEE Std 754™-2008 (Revision of IEEE Std 754-1985), IEEE Standard for Floating-Point Arithmetic}",
    abstract = "This standard specifies interchange and arithmetic formats and methods for binary and decimal floating-point arithmetic in computer programming environments. This standard specifies exception conditions and their default handling. An implementation of a floating-point system conforming to this standard may be realized entirely in software, entirely in hardware, or in any combination of software and hardware. For operations specified in the normative part of this standard, numerical results and exceptions are uniquely determined by the values of the input data, sequence of operations, and destination formats, all under user control.",
    number = "August",
    volume = "2008",
    file = ":home/drt24/Library/papers/Society/Standards, Society/Standards, Society - 2008 - IEEE Std 754™-2008 (Revision of IEEE Std 754-1985), IEEE Standard for Floating-Point Arithmetic.pdf:pdf",
    year = "2008",
    keywords = "NaN,arithmetic,binary,computer,decimal,exponent,floating-point,format,interchange,number,rounding,significand,subnormal",
    booktitle = "Society"
}

@article{Conti2010,
    author = "Conti, Mauro and Thien, Vu and Nguyen, Nga and Crispo, Bruno",
    publisher = "Springer",
    doi = "10.1007/978-3-642-18178-8-29",
    isbn = "9783642181771",
    title = "{CRePE : Context-Related Policy Enforcement for Android}",
    url = "http://www.springerlink.com/index/574882RN4T65364M.pdf",
    abstract = "Most of the research work for enforcing security policies on smartphones considered coarse-grained policies, e.g. either to allow an application to run or not. In this paper we present CRePE, the first system that is able to enforce fine-grained policies, e.g. that vary while an application is running, that also depend on the context of the smartphone. A context can be defined by the status of some variables (e.g. location, time, temperature, noise, and light), the presence of other devices, a particular interaction between the user and the smartphone, or a combination of these. CRePE allows context-related policies to be defined either by the user or by trusted third parties. Depending on the authorization, third parties can set a policy on a smartphone at any moment or just when the phone is within a particular context, e.g. within a building, or a plane. \&copy; 2011 Springer-Verlag.",
    issn = "03029743",
    pages = "331--345",
    volume = "6531",
    file = ":home/drt24/Downloads/fulltext (9).pdf:pdf",
    year = "2010",
    keywords = "android security,context policy,policy enforcement",
    journal = "LNCS"
}

@article{Conti2012,
    author = "Conti, M. and Crispo, B. and Fernandes, E. and Zhauniarovich, Y.",
    doi = "10.1109/TIFS.2012.2204249",
    title = "{CR\^{e}PE: A System for Enforcing Fine-Grained Context-Related Policies on Android}",
    url = "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06215040",
    abstract = "Current smartphone systems allow the user to use only marginally contextual information to specify the behavior of the applications: this hinders the wide adoption of this technology to its full potential. In this paper, we fill this gap by proposing CRêPE, a fine-grained Context-Related Policy Enforcement System for Android. While the concept of context-related access control is not new, this is the first work that brings this concept into the smartphone environment. In particular, in our work, a context can be defined by: the status of variables sensed by physical (low level) sensors, like time and location; additional processing on these data via software (high level) sensors; or particular interactions with the users or third parties. CRêPE allows context-related policies to be set (even at runtime) by both the user and authorized third parties locally (via an application) or remotely (via SMS, MMS, Bluetooth, and QR-code). A thorough set of experiments shows that our full implementation of CRêPE has a negligible overhead in terms of energy consumption, time, and storage, making our system ready for a production environment.",
    issn = "1556-6013",
    number = "5",
    month = "10",
    volume = "7",
    pages = "1426--1438",
    file = ":home/drt24/Downloads/06215040.pdf:pdf",
    year = "2012",
    journal = "IEEE Transactions on Information Forensics and Security"
}

@article{Cooper2008,
    author = "Cooper, Brian F and Ramakrishnan, Raghu and Srivastava, Utkarsh and Silberstein, Adam and Bohannon, Philip and Jacobsen, Hans-arno and Puz, Nick and Weaver, Daniel and Yerneni, Ramana and Cooper",
    publisher = "VLDB Endowment",
    doi = "10.1145/1454159.1454167",
    title = "{PNUTS: Yahoo!'s hosted data serving platform}",
    url = "http://portal.acm.org/citation.cfm?id=1454159.1454167",
    abstract = "We describe PNUTS, a massively parallel and geographically distributed database system for Yahoo!s web applications. PNUTS provides data storage organized as hashed or ordered tables, low latency for large numbers of concurrent requests including updates and queries, and novel per-record consistency guarantees. It is a hosted, centrally managed, and geographically distributed service, and utilizes automated load-balancing and failover to reduce operational complexity. The first version of the system is currently serving in production. We describe the motivation for PNUTS and the design and implementation of its table storage and replication layers, and then present experimental results.",
    issn = "21508097",
    number = "2",
    pages = "1277--1288",
    volume = "1",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cooper et al. - 2008 - PNUTS Yahoo!'s hosted data serving platform.pdf:pdf",
    year = "2008",
    journal = "PVLDB"
}

@article{Coppersmith1997,
    author = "Coppersmith, Don and Shamir, Adi",
    doi = "10.1007/3-540-69053-0_5",
    isbn = "978-3-540-62975-7",
    title = "{Lattice attacks on NTRU}",
    url = "http://link.springer.com/chapter/10.1007/3-540-69053-0_5",
    abstract = "NTRU is a new public key cryptosystem proposed at Crypto 96 by Hoffstein, Pipher and Silverman from the Mathematics department of Brown University. It attracted considerable attention, and is being advertised over the Internet by NTRU Cryptosystems. Its security is based on the difficulty of analyzing the result of polynomial arithmetic modulo two unrelated moduli, and its correctness is based on clustering properties of the sums of random variables. In this paper, we apply new lattice basis reduction techniques to cryptanalyze the scheme, to discover either the original secret key, or an alternative secret key which is equally useful in decoding the ciphertexts.",
    pages = "52--61",
    volume = "1233",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F3-540-69053-0\_5.pdf:pdf",
    year = "1997",
    journal = "Advances in Cryptology—EUROCRYPT'97"
}

@inproceedings{Corbett2012,
    author = "Corbett, James C and Dean, Jeffrey and Epstein, Michael and Fikes, Andrew and Frost, Christopher and Furman, J J and Ghemawat, Sanjay and Gubarev, Andrey and Heiser, Christopher and Hochschild, Peter and Hsieh, Wilson and Kanthak, Sebastian and Kogan, Eugene and Li, Hongyi and Lloyd, Alexander and Melnik, Sergey and Mwaura, David and Nagle, David and Quinlan, Sean and Rao, Rajesh and Rolig, Lindsay and Saito, Yasushi and Szymaniak, Michal and Taylor, Christopher and Wang, Ruth and Woodford, Dale",
    title = "{Spanner : Google ’ s Globally-Distributed Database}",
    abstract = "Spanner is Google’s scalable, multi-version, globally- distributed, and synchronously-replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This paper describes howSpanner is structured, its feature set, the rationale underlying various design decisions, and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: non- blocking reads in the past, lock-free read-only transactions, and atomic schema changes, across all of Spanner.",
    pages = "1--14",
    file = ":home/drt24/Downloads/spanner-osdi2012.pdf:pdf",
    year = "2012",
    booktitle = "OSDI"
}

@article{Cortier2007,
    author = "Cortier, V\'{e}ronique and Keighren, Gavin and Steel, Graham",
    title = "{Automatic analysis of the security of XOR-based key management schemes}",
    url = "http://www.springerlink.com/index/qg5q1564032m4646.pdf",
    abstract = "We describe a new algorithm for analysing security protocols that use XOR, such as key-management APIs. As a case study, we consider the IBM 4758 CCA API, which is widely used in the ATM(cash machine) network. Earlier versions of the CCA API were shown to have serious flaws, and the fixes introduced by IBM in version 2.41 had not previously been formally analysed. We first investigate IBM’s proposals using a model checker for security protocol analysis, uncovering some important issues about their implementation. Having identified configurations we believed to be safe, we describe the formal verification of their security. We first define a new class of protocols, containing in particular all the versions of the CCA API. We then show that secrecy after an unbounded number of sessions is decidable for this class. Implementing the decision procedure requires some improvements, since the procedure is exponential. We describe a change of representation that leads to an implementation able to verify a configuration of the API in a few seconds. As a consequence, we obtain the first security proof of the fixed IBM 4758 CCA API with unbounded sessions.",
    pages = "1--15",
    file = ":home/drt24/Downloads/CKS-tacas07.pdf:pdf",
    year = "2007",
    journal = "TACAS"
}

@article{Costagliola2005,
    author = "Costagliola, G. and Deufemia, V. and Risi, M.",
    publisher = "Ieee",
    doi = "10.1109/ICDAR.2005.218",
    isbn = "0-7695-2420-6",
    title = "{Sketch Grammars: a formalism for describing and recognizing diagrammatic sketch languages}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1575738",
    abstract = "Sketch-based user interfaces are increasingly common and are being built for a variety of different disciplines. However, at present the implementation of sketch recogniz- ers is quite time consuming since they are mostly based on specific techniques, as opposed to several other fields such as textual/visual languages and speech recognition, which benefit from the availability of compiler generation tech- niques and tools. This paper proposes a grammar formal- ism, namely Sketch Grammars (SkGs), for describing both the shape of the symbols’ language and the syntax of sketch languages. Recognizers are automatically generated from the sketch grammar descriptions",
    pages = "1226--1230 Vol. 2",
    file = "::",
    year = "2005",
    journal = "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
}

@inproceedings{Costagliola2006,
    author = "Costagliola, Gennaro and Deufemia, Vincenzo and Risi, Michele",
    isbn = "0769525865",
    title = "{A Multi-layer Parsing Strategy for On-line Recognition of Hand-drawn Diagrams}",
    abstract = "The existing sketch recognizers perform only a limited drawing recognition since they process simple sketches, or rely on drawing style assumptions that reduce the recognition complexity, and in most cases they require a substantial amount of training data. In this paper we present a parsing strategy for the recognition of hand-drawn diagrams that can be used in interactive sketch interfaces. The approach is based on a grammar formalism, namely Sketch Grammars (SkGs), for describing both the symbols’ shape and the syntax of diagrammatic notations, and from which recognizers are automatically generated. The recognition system was evaluated in the domain of UML use case diagrams and the results highlight the recognition accuracy improvements produced by the use of context in the disambiguation process.",
    file = "::",
    year = "2006",
    booktitle = "VL-HCC'06)"
}

@inproceedings{Cousot1977,
    author = "Cousot, Patrick and Cousot, Radhia",
    publisher = "ACM Press",
    doi = "10.1145/512950.512973",
    title = "{Abstract interpretation}",
    url = "http://dl.acm.org/citation.cfm?id=512950.512973",
    booktitle = "Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages - POPL '77",
    year = "1977",
    month = "1",
    file = "::",
    address = "New York, New York, USA",
    pages = "238--252"
}

@inproceedings{Crussell2013,
    author = "Crussell, Jonathan and Gibler, Clint and Chen, Hao",
    title = "{Scalable Semantics-Based Detection of Similar Android Applications}",
    url = "http://www.cs.ucdavis.edu/research/tech-reports/2012/CSE-2013-73.pdf",
    abstract = "The popularity and utility of smartphones rely on their vibrant application markets; however, plagiarism threatens the long-term health of these markets. In this paper, we present a scalable approach to detecting similar Android apps based on semantic information. We implement our approach in a tool called AnDarwin and evaluate it on 265,359 apps collected from 17 markets including Google Play and numerous third-party markets. In contrast with earlier approaches, AnDarwin does not compare apps pairwise, thus greatly increasing its scalability. Additionally, AnDarwin does not rely on information other than the app code — such as the app’s market, signature, or description — thus greatly increasing its reliability. AnDarwin can automatically detect library code and remove it from the similarity analysis. We present two use cases for AnDarwin: finding similar apps by different developers (“clones”) and similar apps from the same developer (“rebranded”). In ten hours, AnDarwin detected at least 4,295 apps which have been the victims of cloning and 36,106 apps that are rebranded. By analyzing the clusters found by AnDarwin, we found 88 new variants of malware and identified 169 malicious apps based on differences in the requested permissions. In contrast to earlier approaches, AnDarwin can detect both full and partial app similarity. Additionally, AnDarwin can automatically detect similar code that is injected into many apps, which may indicate the spread of malware. Our evaluation demonstrates AnDarwin’s ability to accurately detect similar apps on a large scale.",
    file = ":home/drt24/Downloads/CSE-2013-73.pdf:pdf",
    year = "2013",
    booktitle = "Computer Security–ESORICS"
}

@online{CryptoI,
    author = "Boneh, Dan",
    url = "https://www.coursera.org/course/crypto",
    abstract = "Cryptography is an indispensable tool for protecting information in computer systems. This course explains the inner workings of cryptographic primitives and how to correctly use them. Students will learn how to reason about the security of cryptographic constructions and how to apply this knowledge to real-world applications. The course begins with a detailed discussion of how two parties who have a shared secret key can communicate securely when a powerful adversary eavesdrops and tampers with traffic. We will examine many deployed protocols and analyze mistakes in existing systems. The second half of the course discusses public-key techniques that let two or more parties generate a shared secret key. We will cover the relevant number theory and discuss public-key encryption and basic key-exchange. Throughout the course students will be exposed to many exciting open problems in the field. The course will include written homeworks and programming labs. The course is self-contained, however it will be helpful to have a basic understanding of discrete probability theory.",
    year = "2013",
    booktitle = "Coursera",
    title = "{Cryptogrphy I}"
}

@inproceedings{Cuervo2010,
    author = "Cuervo, Eduardo and Balasubramanian, Aruna and Cho, Dae-ki and Wolman, Alec and Saroiu, Stefan and Chandra, Ranveer and Bahl, Paramvir",
    publisher = "ACM Press",
    doi = "10.1145/1814433.1814441",
    isbn = "9781605589855",
    title = "{MAUI: making smartphones last longer with code offload}",
    url = "http://dl.acm.org/citation.cfm?id=1814433.1814441",
    abstract = "This paper presents MAUI, a system that enables fine-grained energy-aware offload of mobile code to the infrastructure. Previous approaches to these problems either relied heavily on programmer support to partition an application, or they were coarse-grained requiring full process (or full VM) migration. MAUI uses the benefits of a managed code environment to offer the best of both worlds: it supports fine-grained code offload to maximize energy savings with minimal burden on the programmer. MAUI decides at run-time which methods should be remotely executed, driven by an optimization engine that achieves the best energy savings possible under the mobile device's current connectivity constrains. In our evaluation, we show that MAUI enables: 1) a resource-intensive face recognition application that consumes an order of magnitude less energy, 2) a latency-sensitive arcade game application that doubles its refresh rate, and 3) a voice-based language translation application that bypasses the limitations of the smartphone environment by executing unsupported components remotely.",
    year = "2010",
    month = "6",
    pages = "49",
    file = "::",
    address = "New York, New York, USA",
    keywords = "code offload,energy management,partitioning,smartphones",
    booktitle = "Proceedings of the 8th international conference on Mobile systems, applications, and services - MobiSys '10"
}

@techreport{Cybenko1988,
    author = "Cybenko, George",
    abstract = "In this paper we demonstrate that continuous valued neural networks with two hidden layers and any fied continious gigmoidal nonlinearity can approximate any continuous function arbitarily well on a compact set. This mathmatical results confirms the common belief taht two hidden layers in a feedforward net are sufficient for most applications.",
    year = "1988",
    file = ":home/drt24/Library/papers/Unknown/Cybenko/Cybenko - 1988 - Continuous Valued Neural Networks with Two Hidden Layers are Sufficient.pdf:pdf",
    title = "{Continuous Valued Neural Networks with Two Hidden Layers are Sufficient}"
}

@inproceedings{Danezis2003,
    author = "Danezis, George and Dingledine, Roger and Mathewson, Nick",
    publisher = "IEEE",
    title = "{Mixminion: Design of a type III anonymous remailer protocol}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1199323",
    abstract = "We present Mixminion, a message-based anonymous re- mailer protocol with secure single-use reply blocks. Mix nodes cannot distinguish Mixminion forward messages from reply messages, so forward and reply messages share the same anonymity set. We add directory servers that allow users to learn public keys and performance statistics of par- ticipating remailers, and we describe nymservers that pro- vide long-term pseudonyms using single-use reply blocks as a primitive. Our design integrates link encryption be- tween remailers to provide forward anonymity. Mixminion works in a real-world Internet environment, requires little synchronization or coordination between nodes, and pro- tects against known anonymity-breaking attacks as well as or better than other systems with similar design parameters.",
    pages = "2--15",
    file = ":auto/homes/drt24/Downloads/minion-design.pdf:pdf",
    year = "2003",
    booktitle = "Security and Privacy, 2003. Proceedings. 2003 Symposium on"
}

@article{Danezis2010,
    author = "Danezis, George and Laurie, Ben",
    title = "{Private yet abuse resistant open publishing}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-17773-6_28",
    journal = "Security Protocols",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-17773-6\_28.pdf:pdf",
    year = "2010",
    pages = "222--243"
}

@article{Danezis2010a,
    author = "Danezis, George",
    title = "{Private Yet Abuse Resistant Open Publishing (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-17773-6_29",
    journal = "Security Protocols",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-17773-6\_29.pdf:pdf",
    year = "2010",
    pages = "244--255"
}

@inproceedings{Datta2012a,
    author = "Datta, Soumya Kanti and Bonnet, Christian and Nikaein, Navid",
    publisher = "IEEE",
    doi = "10.1109/ETSIoT.2012.6311253",
    isbn = "978-1-4673-2557-8",
    title = "{Android power management: Current and future trends}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true\&arnumber=6311253",
    abstract = "Saving power of Android enabled devices have become a significant issue with 400,000 such devices being activated daily. Android smartphones and tablets offer several power hungry hardware components and the app developers are exploiting these components at disposal to provide revolutionary user experience. But the battery life has not increased at the same pace to support the power demand. Thus many researches have been carried out to investigate how to minimize the power consumption in smartphones. This paper reports four different research themes towards the reduction of smartphone power consumption. Efforts have been made to survey Android power saving apps available in Google play Apps store as the basis to find out different power saving approaches, operations and limitations. Then we present four different avenues to prolong the batter life of Android devices. The first two approaches include usage pattern analysis to generate power saving profiles. The advantage being that the power saving profiles are customized to actual user behavior. Integrating a photovoltaic film on top of the smartphone and tablet touch screen to generate electricity is also mentioned. The usage pattern based power saving profile generation has several privacy concerns which are discussed and countermeasures are proposed. Some emerging security attacks are also briefed.",
    month = "6",
    year = "2012",
    booktitle = "2012 The First IEEE Workshop on Enabling Technologies for Smartphone and Internet of Things (ETSIoT)",
    pages = "48--53"
}

@article{Davi2011,
    author = "Davi, Lucas and Dmitrienko, Alexandra and Sadeghi, Ahmad-Reza and Winandy, Marcel",
    title = "{Privilege escalation attacks on android}",
    url = "http://www.springerlink.com/index/D275570090NG72JT.pdf",
    abstract = "Android is a modern and popular software platform for smartphones. Among its predominant features is an advanced security model which is based on application-oriented mandatory access control and sandboxing. This allows developers and users to restrict the execu- tion of an application to the privileges it has (mandatorily) assigned at installation time. The exploitation of vulnerabilities in program code is hence believed to be confined within the privilege boundaries of an application’s sandbox. However, in this paper we show that a privilege es- calation attack is possible.We show that a genuine application exploited at runtime or a malicious application can escalate granted permissions. Our results immediately imply that Android’s securitymodel cannot deal with a transitive permission usage attack and Android’s sandbox model fails as a last resort against malware and sophisticated runtime attacks.",
    pages = "346--360",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-18178-8\_30.pdf:pdf",
    year = "2011",
    journal = "Information Security"
}

@article{Davidson1985,
    author = "Davidson, Susan B and Garcia-Molina, Hector and Skeen, Dale",
    publisher = "ACM",
    doi = "10.1145/5505.5508",
    title = "{Consistency in a partitioned network: a survey}",
    url = "http://portal.acm.org/citation.cfm?id=5505.5508",
    abstract = "Recently, several strategies have been proposed for transaction processing in partitioned distributed database systems with replicated data. These strategies are surveyed in light of the competing goals of maintaining correctness and achieving high availability. Extensions and combinations are then discussed, and guidelines are presented for selecting strategies for particular applications.",
    issn = "03600300",
    number = "3",
    pages = "341--370",
    volume = "17",
    file = ":auto/homes/drt24/Downloads/p341-davidson.pdf:pdf",
    year = "1985",
    keywords = "and phrases,consistency",
    journal = "ACM Computing Surveys"
}

@inproceedings{Dawson-Haggerty2010,
    author = "Dawson-Haggerty, Stephen and Jiang, Xiaofan and Tolle, Gilman and Ortiz, Jorge and Culler, David",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1870003",
    isbn = "9781450303446",
    title = "{sMAP: a simple measurement and actuation profile for physical information}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1870003",
    abstract = "As more and more physical information becomes available, a critical problem is enabling the simple and efficient exchange of this data. We present our design for a simple RESTful web service called the Simple Measuring and Actuation Profile (sMAP) which allows instruments and other producers of physical information to directly publish their data. In our design study, we consider what information should be represented, and how it fits into the RESTful paradigm. To evaluate sMAP, we implement a large number of data sources using this profile, and consider how easy it is to use to build new applications. We also design and evaluate a set of adaptations made at each layer of the protocol stack which allow sMAP to run on constrained devices.",
    year = "2010",
    mendeley-tags = "energy,measure,protocol",
    month = "11",
    pages = "197",
    file = ":auto/homes/drt24/Downloads/p197-dawson-haggerty.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "energy,instrumentation,measure,protocol,sensor data",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10"
}

@inproceedings{Dawson-Haggerty2010a,
    author = "Dawson-Haggerty, Stephen and Jiang, Xiaofan and Tolle, Gilman and Ortiz, Jorge and Culler, David",
    publisher = "ACM Press",
    title = "{sMAP: a simple measurement and actuation profile for physical information}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1870003",
    abstract = "As more and more physical information becomes available, a critical problem is enabling the simple and efficient exchange of this data. We present our design for a simple RESTful web service called the Simple Measuring and Actuation Profile (sMAP) which allows instruments and other producers of physical information to directly publish their data. In our design study, we consider what information should be represented, and how it fits into the RESTful paradigm. To evaluate sMAP, we implement a large number of data sources using this profile, and consider how easy it is to use to build new applications. We also design and evaluate a set of adaptations made at each layer of the protocol stack which allow sMAP to run on constrained devices.",
    year = "2010",
    month = "11",
    pages = "197",
    file = ":auto/homes/drt24/Downloads/p197-dawson-haggerty.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "instrumentation,sensor data",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10"
}

@article{DeCandia2007,
    author = "DeCandia, Giuseppe and Hastorun, Deniz and Jampani, Madan and Kakulapati, Gunavardhan and Lakshman, Avinash and Pilchin, Alex and Sivasubramanian, Swaminathan and Vosshall, Peter and Vogels, Werner",
    publisher = "ACM",
    doi = "10.1145/1294261.1294281",
    isbn = "9781595935915",
    title = "{Dynamo: Amazon's highly available key-value store}",
    journal = "ACM SIGOPS Operating Systems Review",
    series = "SOSP '07",
    abstract = "Reliability at massive scale is one of the biggest challenges we face at Amazon.com, one of the largest e-commerce operations in the world; even the slightest outage has significant financial consequences and impacts customer trust. The Amazon.com platform, which provides services for many web sites worldwide, is implemented on top of an infrastructure of tens of thousands of servers and network components located in many datacenters around the world. At this scale, small and large components fail continuously and the way persistent state is managed in the face of these failures drives the reliability and scalability of the software systems. This paper presents the design and implementation of Dynamo, a highly available key-value storage system that some of Amazons core services use to provide an always-on experience. To achieve this level of availability, Dynamo sacrifices consistency under certain failure scenarios. It makes extensive use of object versioning and application-assisted conflict resolution in a manner that provides a novel interface for developers to use.",
    issn = "01635980",
    mendeley-tags = "available,distributed,key value,store",
    number = "6",
    pages = "205--220",
    volume = "41",
    url = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.6956",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/DeCandia et al. - 2007 - Dynamo amazon's highly available key-value store(3).pdf:pdf",
    year = "2007",
    keywords = "Algorithms,Design,Management,Measurement,Performance,Reliability.,available,distributed,key value,store",
    institution = "New York, NY, USA"
}

@article{DeMontjoye2013,
    author = "de Montjoye, Yves-Alexandre and Hidalgo, C\'{e}sar a. and Verleysen, Michel and Blondel, Vincent D.",
    doi = "10.1038/srep01376",
    title = "{Unique in the Crowd: The privacy bounds of human mobility}",
    url = "http://www.nature.com/doifinder/10.1038/srep01376",
    journal = "Scientific Reports",
    issn = "2045-2322",
    month = "3",
    volume = "3",
    file = "::",
    year = "2013",
    pages = "1--5"
}

@article{Dean2008,
    author = "Dean, Jeffrey and Ghemawat, Sanjay",
    publisher = "ACM",
    doi = "10.1145/1327452.1327492",
    title = "{MapReduce: simplified data processing on large clusters}",
    url = "http://portal.acm.org/citation.cfm?id=1327492",
    journal = "Communications of the ACM",
    issn = "00010782",
    number = "1",
    institution = "Google Inc",
    volume = "51",
    pages = "107--113",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean, Ghemawat - 2008 - MapReduce simplified data processing on large clusters.pdf:pdf",
    year = "2008",
    abstract = "MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day."
}

@article{Dean2010,
    author = "Dean, Jeffrey",
    publisher = "ACM Press",
    doi = "10.1145/1807128.1807130",
    isbn = "9781450300360",
    title = "{Evolution and future directions of large-scale storage and computation systems at Google}",
    url = "http://portal.acm.org/citation.cfm?doid=1807128.1807130",
    journal = "Proceedings of the 1st ACM symposium on Cloud computing SoCC 10",
    year = "2010",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean - 2010 - Evolution and future directions of large-scale storage and computation systems at Google.pdf:pdf",
    address = "New York, New York, USA",
    pages = "1"
}

@article{Demers1988,
    author = "Demers, Alan J. and Greene, Dan and Hauser, Carl H. and Irish, Wes and Larson, John and Houser, Carl and Shenker, Scott and Sturgis, Howard and Swinehart, Dan and Terry, Douglas B.",
    publisher = "ACM",
    doi = "10.1145/43921.43922",
    isbn = "089791239X",
    title = "{Epidemic algorithms for replicated database maintenance}",
    journal = "ACM SIGOPS Operating Systems Review",
    abstract = "When a database is replicated at many sites, maintaining nmtual consistency mnong the sites in the face of updates is a significant problem. This paper describes several randomized algorithms for distributing updates and driving the replicas toward consistency. The algorithms are very simple and require few guarantees from the underlying conmmnication system, yet they ensure that the effect of every update is eventually reflected in all replicas. The cost and performance of the algorithms are tuned by choosing appropriate distributions in the randonfization step. The algorithms are closely analogous to epidemics, and the epidenfiology literature aids in understanding their behavior. One of the algorithms has been implemented hl the Clearinghouse servers of the Xerox Corporate Internet. solving long-standing problems of high traffic and database inconsistency.",
    issn = "01635980",
    number = "1",
    pages = "8--32",
    volume = "22",
    url = "http://portal.acm.org/citation.cfm?doid=43921.43922",
    file = ":auto/homes/drt24/Downloads/p8-demers.pdf:pdf",
    year = "1988",
    institution = "ACM"
}

@inproceedings{Demers1994,
    author = "Demers, Alan J. and Petersen, Karin and Spreitzer, Mike J. and Terry, Douglas B. and Theimer, Marvin M. and Welch, Brent",
    publisher = "IEEE",
    doi = "10.1109/WMCSA.1994.37",
    isbn = "9780769534510",
    title = "{The Bayou architecture: Support for data sharing among mobile users}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4624416",
    abstract = "The Bayou System is a platform of replicated, highlyavailable, variable-consistency, mobile databases on which to build collaborative applications. This paper presents the preliminary system architecture along with the design goals that influenced it. We take a fresh, bottom-up and critical look at the requirements of mobile computing applications and carefully pull together both new and existing techniques into an overall architecture that meets these requirements. Our emphasis is on...",
    pages = "2--7",
    file = ":auto/homes/drt24/Downloads/04624416.pdf:pdf",
    year = "1994",
    organization = "IEEE",
    booktitle = "First Workshop on Mobile Computing Systems and Applications"
}

@book{Denning1982,
    author = "Denning, Dorothy Elizabeth Robling",
    publisher = "Addison-Wesley",
    isbn = "0-201-10150-5",
    title = "{Cryptography and Data Security}",
    url = "http://dl.acm.org/citation.cfm?id=539308",
    file = ":home/drt24/Downloads/crypto-robling\_denning.pdf:pdf",
    year = "1982",
    pages = "i--xiii,1--400"
}

@inproceedings{DenzilFerreira2011,
    editor = "Lyons, Kent and Hightower, Jeffrey and Huang, Elaine M.",
    author = "{Denzil Ferreira}, Anind K. Dey and Kostakos, Vassilis",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-21726-5",
    isbn = "978-3-642-21725-8",
    title = "{Understanding Human-Smartphone Concerns: A Study of Battery Life}",
    url = "http://www.springerlink.com/content/n2t1257557j50716/",
    series = "Lecture Notes in Computer Science",
    year = "2011",
    volume = "6696",
    address = "Berlin, Heidelberg"
}

@article{Deutsch1996,
    author = "Deutsch, LP",
    url = "http://gamay.tools.ietf.org/html/rfc1951",
    year = "1996",
    title = "{DEFLATE compressed data format specification version 1.3}"
}

@online{Dey2008,
    author = "Dey, Arkajit and Weis, Stephen",
    title = "{Keyczar : A Cryptographic Toolkit}",
    url = "http://keyczar.googlecode.com/files/keyczar05b.pdf",
    abstract = "Keyczar’s goal is to make it easier for application developers to safely use cryptography. Keyczar defaults to safe algorithms, key lengths, and modes, and prevents developers from inadvertently exposing key material. It uses a simple, extensible key versioning system that allows developers to easily rotate and retire keys.",
    file = ":home/drt24/Downloads/keyczar05b.pdf:pdf",
    year = "2008",
    institution = "Keyczar"
}

@inproceedings{Dey2011,
    author = "Dey, Anind K. and Wac, Katarzyna and Ferreira, Denzil and Tassini, Kevin and Hong, Jin-Hyuk and Ramos, Julian",
    publisher = "ACM Press",
    doi = "10.1145/2030112.2030135",
    isbn = "9781450306300",
    title = "{Getting closer: an empirical investigation of the proximity of user to their smart phones}",
    url = "http://dl.acm.org/citation.cfm?id=2030112.2030135",
    abstract = "Much research in ubiquitous computing assumes that a user's phone will be always on and at-hand, for collecting user context and for communicating with a user. Previous work with the previous generation of mobile phones has shown that such an assumption is false. Here, we investigate whether this assumption about users' proximity to their mobile phones holds for a new generation of mobile phones, smart phones. We conduct a data collection field study of 28 smart phone owners over a period of 4 weeks. We show that in fact this assumption is still false, with the within arm's reach proximity being true close to 50\% of the time, similar to the earlier work. However, we also show that smart phone proximity within the same room (arm+room) as the user is true almost 90\% of the time. We discuss the reasons for these phone proximities and the implications of this on the development of mobile phone applications, particularly those that collect user and environmental context, and delivering notification to users. We also show that we can accurately predict the proximity at the arm level and arm+room level with 75 and 83\% accuracy, respectively, with features simple to collect and model on a mobile phone. Further we show that for several individuals who are almost always within the arm+room level, we can predict this level with over 90\% accuracy.",
    year = "2011",
    month = "9",
    pages = "163",
    file = "::",
    address = "New York, New York, USA",
    keywords = "mobile devices,mobility,proximity,smart phone",
    booktitle = "Proceedings of the 13th international conference on Ubiquitous computing - UbiComp '11"
}

@inproceedings{Dey2014,
    author = "Dey, Sanorita and Roy, Nirupam and Xu, Wenyuan and Choudhury, Romit Roy and Nelakuditi, Srihari",
    publisher = "Internet Society",
    isbn = "1891562355",
    title = "{AccelPrint: Imperfections of Accelerometers Make Smartphones Trackable}",
    url = "http://web.engr.illinois.edu/~nroy8/PDF/AccelPrint_Presentation.pdf",
    abstract = "As mobile begins to overtake the fixed Internet access, ad networks have aggressively sought methods to track users on their mobile devices. While existing countermeasures and regulation focus on thwarting cookies and various device IDs, this paper submits a hypothesis that smartphone/tablet accelerometers possess unique fingerprints, which can be ex- ploited for tracking users.We believe that the fingerprints arise from hardware imperfections during the sensor manufacturing process, causing every sensor chip to respond differently to the same motion stimulus. The differences in responses are subtle enough that they do not affect most of the higher level func- tions computed on them. Nonetheless, upon close inspection, these fingerprints emerge with consistency, and can even be somewhat independent of the stimulus that generates them. Measurements and classification on 80 standalone accelerom- eter chips, 25 Android phones, and 2 tablets, show precision and recall upward of 96\%, along with good robustness to real- world conditions. Utilizing accelerometer fingerprints, a crowd- sourcing application running in the cloud could segregate sensor data for each device, making it easy to track a user over space and time. Such attacks are almost trivial to launch, while simple solutions may not be adequate to counteract them.",
    number = "February",
    file = ":home/drt24/Downloads/AccelPrint\_NDSS14.pdf:pdf",
    year = "2014",
    booktitle = "Network and Distributed System Security Symposium (NDSS)",
    pages = "23--26"
}

@article{Dietz2011,
    author = "Dietz, Michael and Shekhar, Shashi and Pisetsky, Yuliy and Shu, Anhei and Wallach, Dan S",
    title = "{Quire: Lightweight Provenance for Smart Phone Operating Systems}",
    url = "http://arxiv.org/abs/1102.2445",
    abstract = "Smartphone apps often run with full privileges to access the network and sensitive local resources, making it difficult for remote systems to have any trust in the provenance of network connections they receive. Even within the phone, different apps with different privileges can communicate with one another, allowing one app to trick another into improperly exercising its privileges (a Confused Deputy attack). In Quire, we engineered two new security mechanisms into Android to address these issues. First, we track the call chain of IPCs, allowing an app the choice of operating with the diminished privileges of its callers or to act explicitly on its own behalf. Second, a lightweight signature scheme allows any app to create a signed statement that can be verified anywhere inside the phone. Both of these mechanisms are reflected in network RPCs, allowing remote systems visibility into the state of the phone when an RPC is made. We demonstrate the usefulness of Quire with two example applications. We built an advertising service, running distinctly from the app which wants to display ads, which can validate clicks passed to it from its host. We also built a payment service, allowing an app to issue a request which the payment service validates with the user. An app cannot not forge a payment request by directly connecting to the remote server, nor can the local payment service tamper with the request.",
    file = ":home/drt24/Downloads/1102.2445v1.pdf:pdf",
    year = "2011",
    journal = "Computing"
}

@article{Dietz2011a,
    author = "Dietz, Michael and Shekhar, Shashi and Pisetsky, Yuliy and Shu, Anhei and Wallach, Dan S.",
    url = "http://dl.acm.org/citation.cfm?id=2028067.2028090",
    title = "{Quire: lightweight provenance for smart phone operating systems}",
    year = "2011",
    pages = "23",
    month = "8"
}

@article{Diffie1976,
    author = "Diffie, Whitfield and Hellman, Martin E.",
    publisher = "IEEE",
    title = "{New directions in cryptography}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1055638",
    journal = "Information Theory, IEEE Transactions on",
    number = "6",
    volume = "22",
    file = ":auto/homes/drt24/Downloads/24.pdf:pdf",
    year = "1976",
    pages = "644--654"
}

@article{Dijkstra1974,
    author = "Dijkstra, Edsger W",
    publisher = "ACM",
    doi = "10.1145/361179.361202",
    title = "{Self-stabilizing systems in spite of distributed control}",
    url = "http://dl.acm.org/citation.cfm?id=361202",
    abstract = "The synchronization task between loosely coupled cyclic sequential processes (as can be distinguished in, for instance, operating systems) can be viewed as keeping the relation “the system is in a legitimate state” invariant. As a result, each individual process step that could possibly cause violation of that relation has to be preceded by a test deciding whether the process in question is allowed to proceed or has to be delayed. The resulting design is readily—and quite systematically—implemented if the different processes can be granted mutually exclusive access to a common store in which “the current system state” is recorded.",
    number = "11",
    pages = "643--644",
    volume = "17",
    file = ":home/drt24/Downloads/p643-Dijkstra.pdf:pdf",
    year = "1974",
    keywords = "distributed control,error recovery,harmonious cooperation,multiprocessing,mutual exclusion,networks,robustness,self-repair,self-stabilization,sharing,synchronization",
    journal = "Communications of the ACM"
}

@article{Dillig2007,
    author = "Dillig, Isil and Dillig, Thomas and Aiken, Alex",
    doi = "10.1145/1273442.1250784",
    isbn = "9781595936332",
    title = "{Static error detection using semantic inconsistency inference}",
    url = "http://portal.acm.org/citation.cfm?doid=1273442.1250784",
    abstract = "Inconsistency checking is a method for detecting software errors that relies only on examining multiple uses of a value.We propose that inconsistency inference is best understood as a variant of the older and better understood problem of type inference. Using this insight, we describe a precise and formal framework for discover- ing inconsistency errors. Unlike previous approaches to the prob- lem, our technique for finding inconsistency errors is purely se- mantic and can deal with complex aliasing and path-sensitive con- ditions. We have built a null dereference analysis of C programs based on semantic inconsistency inference and have used it to find hundreds of previously unknown null dereference errors in widely used C programs.",
    issn = "03621340",
    number = "6",
    month = "6",
    volume = "42",
    pages = "435",
    file = ":home/drt24/Downloads/p435-dillig.pdf:pdf",
    year = "2007",
    keywords = "error detection,inconsis-,satisfiability,static analysis",
    journal = "ACM SIGPLAN Notices"
}

@article{Ding2013,
    author = "Ding, Ning and Wagner, Daniel and Chen, Xiaomeng and Hu, Y. Charlie and Rice, Andrew",
    doi = "10.1145/2494232.2466586",
    isbn = "9781450319003",
    title = "{Characterizing and modeling the impact of wireless signal strength on smartphone battery drain}",
    url = "http://dl.acm.org/citation.cfm?id=2494232.2466586",
    abstract = "Despite the tremendous market penetration of smartphones, their utility has been and will remain severely limited by their battery life. A major source of smartphone battery drain is accessing the Internet over cellular or WiFi connection when running various apps and services. Despite much anecdotal evidence of smartphone users experiencing quicker battery drain in poor signal strength, there has been limited understanding of how often smartphone users experience poor signal strength and the quantitative impact of poor signal strength on the phone battery drain. The answers to such questions are essential for diagnosing and improving cellular network services and smartphone battery life and help to build more accurate online power models for smartphones, which are building blocks for energy profiling and optimization of smartphone apps. In this paper, we conduct the first measurement and modeling study of the impact of wireless signal strength on smartphone energy consumption. Our study makes four contributions. First, through analyzing traces collected on 3785 smartphones for at least one month, we show that poor signal strength of both 3G and WiFi is routinely experienced by smartphone users, both spatially and temporally. Second, we quantify the extra energy consumption on data transfer induced by poor wireless signal strength. Third, we develop a new power model for WiFi and 3G that incorporates the signal strength factor and significantly improves the modeling accuracy over the previous state of the art. Finally, we perform what-if analysis to quantify the potential energy savings from opportunistically delaying network traffic by exploring the dynamics of signal strength experienced by users.",
    issn = "01635999",
    pages = "29",
    volume = "41",
    file = ":home/drt24/Downloads/ding-signalstrength.pdf:pdf",
    year = "2013",
    keywords = "battery drain,energy,power model,signal strength,smartphone",
    journal = "ACM SIGMETRICS Performance Evaluation Review"
}

@inproceedings{Dingledine2004,
    author = "Dingledine, Roger and Mathewson, Nick and Syverson, Paul F.",
    publisher = "USENIX Association",
    title = "{Tor: The second-generation onion router}",
    url = "http://dl.acm.org/citation.cfm?id=1251396",
    abstract = "We present Tor, a circuit-based low-latency anonymous com- munication service. This second-generation Onion Routing system addresses limitations in the original design by adding perfect forward secrecy, congestion control, directory servers, integrity checking, configurable exit policies, and a practi- cal design for location-hidden services via rendezvous points. Torworks on the real-world Internet, requires no special priv- ileges or kernel modifications, requires little synchronization or coordination between nodes, and provides a reasonable tradeoff between anonymity, usability, and efficiency. We briefly describe our experiences with an international network of more than 30 nodes. We close with a list of open problems in anonymous communication.",
    pages = "21--21",
    file = ":auto/homes/drt24/Downloads/tor-design.pdf:pdf",
    year = "2004",
    booktitle = "Proceedings of the 13th conference on USENIX Security Symposium-Volume 13"
}

@inproceedings{Distefano2008,
    author = "Distefano, Dino and {Parkinson J}, Matthew J.",
    publisher = "ACM Press",
    doi = "10.1145/1449764.1449782",
    isbn = "9781605582153",
    title = "{jStar}",
    url = "http://dl.acm.org/citation.cfm?id=1449764.1449782",
    booktitle = "Proceedings of the 23rd ACM SIGPLAN conference on Object oriented programming systems languages and applications - OOPSLA '08",
    issn = "0362-1340",
    year = "2008",
    number = "10",
    month = "10",
    volume = "43",
    address = "New York, New York, USA",
    keywords = "classes,design patterns,moduarity,separation logic",
    pages = "213"
}

@article{Dolev1983,
    author = "Dolev, D. and Yao, A.",
    doi = "10.1109/TIT.1983.1056650",
    title = "{On the security of public key protocols}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1056650",
    abstract = "Rcently the use of public key encryption to provide secure network communication has received considerable attention. Such public key systems are usually effective against passive eavesdroppers, who merely tap the lines and try to decipher the message. It has been pointed out, however, that an improperly designed protocol could be vulnerable to an active saboteur, one who may impersonate another user or alter the message being transmitted. Several models are formulated in which the security of protocols can be discussed precisely. Algorithms and characteri- zations that can be used to determine protocol security in these models are given.",
    issn = "0018-9448",
    number = "2",
    month = "3",
    volume = "29",
    pages = "198--208",
    file = ":home/drt24/Downloads/01056650.pdf:pdf",
    year = "1983",
    journal = "IEEE Transactions on Information Theory"
}

@inproceedings{Dong2011,
    author = "Dong, Mian and Zhong, Lin",
    publisher = "ACM Press",
    doi = "10.1145/1999995.2000027",
    isbn = "9781450306430",
    title = "{Self-constructive high-rate system energy modeling for battery-powered mobile systems}",
    url = "http://www.mendeley.com/share/viewDocument/webLibrary/3177171_4400342585:/1329994914/fe4ac8156bffe5cd82c3d739e531c47b648f7566/",
    booktitle = "Proceedings of the 9th international conference on Mobile systems, applications, and services - MobiSys '11",
    year = "2011",
    address = "New York, New York, USA",
    pages = "335"
}

@article{Dong2011a,
    editor = "Wakeman, Ian and Gudes, Ehud and Jensen, Christian Damsgaard and Crampton, Jason",
    author = "Dong, Changyu and Dulay, Naranker",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-22200-9",
    isbn = "9783642221996",
    title = "{Longitude : a Privacy-preserving Location Sharing Protocol for Mobile Applications}",
    url = "http://www.springerlink.com/content/40695704n614pw21/",
    series = "IFIP Advances in Information and Communication Technology",
    abstract = "Location sharing services are becoming increasingly popular. Although many location sharing services allow users to set up privacy policies to control who can access their location, the use made by service providers remains a source of concern. Ideally, location sharing providers and middleware should not be able to access users location data without their consent. In this paper, we propose a new location sharing protocol called Longitude that eases privacy concerns by making it possible to share a users location data blindly and allowing the user to control who can access her location, when and to what degree of precision. The underlying cryptographic algorithms are designed for GPS-enabled mobile phones. We describe and evaluate our implementation for the Nexus One Android mobile phone.",
    pages = "133----148",
    volume = "358",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Dulay - 2011 - Longitude a Privacy-preserving Location Sharing Protocol for Mobile Applications.pdf:pdf",
    year = "2011",
    journal = "Trust Management V"
}

@inproceedings{Dong2013,
    author = "Dong, Xinshu and Hu, Hong and Saxena, Prateek and Liang, Zhenkai",
    publisher = "Springer",
    title = "{A quantitative evaluation of privilege separation in web browser designs}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-40203-6_5",
    abstract = "Privilege separation is a fundamental security concept that has been used in designing many secure systems. A number of recent works propose redesigning web browsers with greater privilege separation for better security. In practice, however, privilege-separated designs require a fine balance between security benefits and other competing concerns, such as performance. In fact, performance overhead has been a main cause that prevents many privilege separation proposals from being adopted in real systems. In this paper, we develop a new measurement-driven methodology that quantifies security benefits and performance costs for a given privilege-separated browser design. Our measurements on a large corpus of web sites provide key insights on the security and perfor- mance implications of partitioning dimensions proposed in 9 recent browser designs. Our results also provide empirical guidelines to resolve several design decisions being debated in recent browser re-design efforts. Keywords:",
    year = "2013",
    month = "9",
    file = ":home/drt24/Downloads/esorics13.pdf:pdf",
    address = "London",
    keywords = "browser design,measurement,privilege separation",
    booktitle = "Computer Security–ESORICS 2013"
}

@inproceedings{Drimer2007,
    author = "Drimer, Saar and Murdoch, Steven J.",
    publisher = "USENIX Association",
    title = "{Keep your enemies close: Distance bounding against smartcard relay attacks}",
    url = "http://dl.acm.org/citation.cfm?id=1362910",
    abstract = "Modern smartcards, capable of sophisticated cryptogra- phy, provide a high assurance of tamper resistance and are thus commonly used in payment applications. Although extracting secrets out of smartcards requires resources beyond the means of many would-be thieves, the manner in which they are used can be exploited for fraud. Cardholders authorize financial transactions by presenting the card and disclosing a PIN to a terminal without any assurance as to the amount being charged or who is to be paid, and have no means of discerning whether the terminal is authentic or not. Even the most advanced smartcards cannot protect customers from being defrauded by the simple relaying of data from one location to another. We describe the development of such an attack, and show results from live experiments on the UK’s EMV implementation, Chip \& PIN.We discuss previously proposed defences, and show that these cannot provide the required security assurances. A new defence based on a distance bounding protocol is described and implemented, which requires only modest alterations to current hardware and software. As far as we are aware, this is the first complete design and imple- mentation of a secure distance bounding protocol. Future smartcard generations could use this design to provide cost-effective resistance to relay attacks, which are a genuine threat to deployed applications. We also discuss the security-economics impact to customers of enhanced authentication mechanisms.",
    pages = "7",
    file = ":auto/homes/drt24/Downloads/sc\_relay.pdf:pdf",
    year = "2007",
    booktitle = "Proceedings of 16th USENIX Security Symposium on USENIX Security Symposium"
}

@article{Drimer2009,
    author = "Drimer, Saar and Murdoch, Steven J. and Anderson, Ross",
    publisher = "Springer",
    doi = "10.1007/978-3-642-03549-4_11",
    title = "{Optimised to fail: Card readers for online banking}",
    url = "http://www.springerlink.com/index/dx7j53p7211216wr.pdf",
    abstract = "The Chip Authentication Programme (CAP) has been introduced by banks in Europe to deal with the soaring losses due to online banking fraud. A handheld reader is used together with the customer’s debit card to generate one-time codes for both login and transaction authentication. The CAP protocol is not public, and was rolled out without any public scrutiny. We reverse engineered the UK variant of card readers and smart cards and here provide the first public description of the protocol. We found numerous weaknesses that are due to design errors such as reusing authentication tokens, overloading data semantics, and failing to ensure freshness of responses. The overall strategic error was excessive optimisation. There are also policy implications. The move from signature to PIN for authorising point-of-sale transactions shifted liability from banks to customers; CAP introduces the same problem for online banking. It may also expose customers to physical harm.",
    number = "February",
    pages = "184--200",
    file = ":home/drt24/Library/papers/Banking/Drimer, Murdoch, Anderson/Drimer, Murdoch, Anderson - 2009 - Optimised to Fail Card Readers for Online Banking.pdf:pdf",
    year = "2009",
    keywords = "authentication,banking security,liability,reverse engineering",
    journal = "Financial Cryptography and Data Security"
}

@inproceedings{Duan2012,
    author = "Duan, Haixin and Weaver, Nicholas and Zhao, Zongxu and Hu, Meng and Liang, Jinjin and Jiang, Jian and Li, Kang and Paxson, Vern",
    title = "{Hold-On : Protecting Against On-Path DNS Poisoning}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Duan.pdf",
    abstract = "Several attacks on DNS inject forged DNS replies without suppressing the legitimate replies. Current implementa- tions of DNS resolvers are vulnerable to accepting the injected replies if the attacker’s reply arrives before the legitimate one. In the case of regular DNS, this behavior allows an attacker to corrupt a victim’s interpretation of a name; for DNSSEC- protected names, it enables denial-of-service. We argue that the resolver should wait after receiving an initial reply for a “Hold-On” period to allow a subsequent legitimate reply to also arrive. We evaluate the feasibility of such an approach and discuss our implementation of a prototype stub resolver/forwarder that validates DNS replies using Hold-On. By validating the IP TTL and the timing of the replies, we show that the resolver can identify DNS packets injected by a nation- state censorship system, and that it functions without perceptible performance decrease for undisrupted lookups.",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Duan.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@article{Ducas2012,
    author = "Ducas, L\'{e}o and Nguyen, Phong Q.",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-34961-4_27",
    isbn = "978-3-642-34960-7",
    title = "{Learning a Zonotope and More: Cryptanalysis of NTRUSign Countermeasures}",
    abstract = "NTRUSign is the most practical lattice signature scheme. Its basic version was broken by Nguyen and Regev in 2006: one can efficiently recover the secret key from about 400 signatures. However, countermeasures have been proposed to repair the scheme, such as the perturbation used in NTRUSign standardization proposals, and the deformation proposed by Hu et al. at IEEE Trans. Inform. Theory in 2008. These two countermeasures were claimed to prevent the NR attack. Surprisingly, we show that these two claims are incorrect by revisiting the NR gradient-descent attack: the attack is more powerful than previously expected, and actually breaks both countermeasures in practice, e.g. 8,000 signatures suffice to break NTRUSign-251 with one perturbation as submitted to IEEE P1363 in 2003. More precisely, we explain why the Nguyen-Regev algorithm for learning a parallelepiped is heuristically able to learn more complex objects, such as zonotopes and deformed parallelepipeds.",
    issn = "0302-9743",
    pages = "433--450",
    volume = "7658",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-34961-4\_27.pdf:pdf",
    year = "2012",
    journal = "Lecture Notes in Computer Science: Advances in Cryptology - ASIACRYPT"
}

@techreport{Duebendorfer2009,
    author = "Duebendorfer, Thomas and Frei, Stefan",
    title = "{Why silent updates boost security}",
    url = "ftp://129.132.2.249/pub/publications/TIK-Report-302.pdf",
    abstract = "Security fixes and feature improvements don’t benefit the end user of software if the update mechanism and strategy is not effective. In this paper we analyze the effectiveness of different Web browsers update mechanisms; from Google Chrome’s silent update mechanism to Opera’s update re- quiring a full re-installation. We use anonymized logs from Google’s world wide distributed Web servers. An analysis of the logged HTTP user-agent strings that Web browsers report when requesting anyWeb page is used to measure the daily browser version shares in active use. To the best of our knowledge, this is the first global scale measurement ofWeb browser update effectiveness comparing four different Web browser update strategies including Google Chrome. Our measurements prove that silent updates and little depen- dency on the underlying operating system are most effective to get users ofWeb browsers to surf theWeb with the latest browser version. However, there is still room for improve- ment as we found. Google Chrome’s advantageous silent update mechanism has been open sourced in April 2009. We recommend any software vendor to seriously consider deploying silent updates as this benefits both the vendor and the user, especially for widely used attack-exposed ap- plications like Web browsers and browser plug-ins.",
    number = "April",
    institution = "ETH Zurich",
    file = ":home/drt24/Downloads/TIK-Report-302.pdf:pdf",
    year = "2009",
    booktitle = "TIK, ETH Zurich, Tech. Rep"
}

@article{Duebendorfer2010,
    author = "Duebendorfer, Thomas and Frei, Stefan",
    publisher = "Springer-Verlag",
    doi = "10.1007/978-3-642-14379-3_11",
    isbn = "3642143784",
    title = "{Web browser security update effectiveness}",
    abstract = "We analyze the effectiveness of differentWeb browser update mechanisms on various operating systems; from Google Chrome’s silent update mechanism to Opera’s update requiring a full re-installation. We use anonymized logs from Google’s world wide distributed Web servers. An analysis of the logged HTTP user-agent strings thatWeb browsers re- port when requesting anyWeb page is used to measure the daily browser version shares in active use. To the best of our knowledge, this is the first global scale measurement ofWeb browser update effectiveness comparing four different Web browser update strategies including Google Chrome. Our measurements prove that silent updates and little dependency on the underlying operating system are most effective to get users of Web browsers to surf the Web with the latest browser version.",
    issn = "03029743",
    pages = "124--137",
    volume = "6027 LNCS",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-14379-3\_11.pdf:pdf",
    year = "2010",
    journal = "Lecture Notes in Computer Science"
}

@article{Dunagan2004,
    author = "Dunagan, John and Roussev, Roussi and Daniels, Brad and Johnson, Aaron and Verbowski, Chad and Wang, Yi Min",
    doi = "10.1109/ICAC.2004.1301353",
    isbn = "0769521142",
    title = "{Towards a self-managing software patching process using black-box persistent-state manifests}",
    abstract = "We describe an approach to self-managing software patching. We identify visibility into patch impact as the key missing component in automating the current patching process, and we present a suite of components that provides this visibility by constructing black-box persistent-state manifests through self-monitoring of dependencies. Additionally, we use the component suite to measure the actual impact of recent patches on several important commercial applications.",
    pages = "106--113",
    file = ":home/drt24/Downloads/01301353.pdf:pdf",
    year = "2004",
    journal = "Proceedings - International Conference on Autonomic Computing"
}

@inproceedings{Duong2011,
    author = "Duong, Thai and Rizzo, Juliano",
    title = "{Here Come The ⊕ Ninjas Chaining of Predictable IVs}",
    abstract = "This paper introduces a fast blockwise chosen-plaintext attack against SSL 3.0 and TLS 1.0. We also describe one application of the attack that allows an attacker to efficiently decrypt and obtain authentication tokens embedded in HTTPS requests The resulting exploits work for major web browsers at the time of writing.",
    pages = "1--10",
    file = ":home/drt24/Downloads/ssl\_jun21.pdf:pdf",
    year = "2011",
    booktitle = "Ekoparty"
}

@inproceedings{Durr2011,
    author = "Durr, Frank and Skvortsov, Pavel and Rothermel, Kurt",
    publisher = "IEEE",
    doi = "10.1109/PERCOM.2011.5767584",
    isbn = "9781424495283",
    title = "{Position sharing for location privacy in non-trusted systems}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5767584",
    abstract = "Many novel location-based services (LBS) such as a friend finder service require knowledge about the positions of mobile users. Usually, location services are used to manage these positions, and for providing basic functionality like spatial range queries or spatial events to the LBS. Managing and using the positions of mobile users raises privacy issues, in particular, if the providers of LBS and location services are only partially trusted. Many different approaches for preserving a user's privacy have been proposed in the literature, e.g. location obfuscation and the k-anonymity concept. However, most of them are not suitable if both LBS and location service providers are non-trusted. In contrast to these approaches, we present a novel approach for the secure management of private position information in partially trusted system environments. The main contribution in this paper is a position sharing concept which allows for the distribution of position information (shares) of strictly limited accuracy onto several location servers of different providers. With this approach, a compromised server will only reveal information of limited accuracy. Moreover, we will show how position shares of coarse granularity from multiple location servers can be fused into information of higher precision to satisfy the accuracy requirements of different LBS.",
    pages = "189--196",
    year = "2011",
    keywords = "location based service,location management,obfuscation,privacy,sharing",
    organization = "Institute of Parallel \&amp; Distributed Systems, Universit\&\#x00E4;t Stuttgart, Germany",
    booktitle = "2011 IEEE International Conference on Pervasive Computing and Communications PerCom"
}

@inproceedings{Dutta2008a,
    author = "Dutta, Prabal and Feldmeier, Mark and Paradiso, Joseph and Culler, David",
    publisher = "IEEE",
    doi = "10.1109/IPSN.2008.58",
    isbn = "978-0-7695-3157-1",
    title = "{Energy Metering for Free: Augmenting Switching Regulators for Real-Time Monitoring}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4505481",
    abstract = "We present iCount, a new energy meter design. For many systems that have a built-in switching regulator, adding a single wire between the regulator and the microcontroller enables real-time energy metering. iCount measures energy usage by counting the switching cycles of the regulator. We show that the relationship between load current and switching frequency is quite linear and demonstrate that this simple design can be applied to a variety of regulators. Our particular implementation exhibits a maximum error of less than plusmn20\% over five decades of current draw, a resolution exceeding 1 muJ, a read latency of 15 mus, and a power overhead that ranges from 1\% when the node is in standby to 0.01 \% when the node is active, for a typical workload. The basic iCount design requires only a pulse frequency modulated switching regulator and a microcontroller with an externally-clocked counter.",
    month = "4",
    pages = "283--294",
    file = "::",
    year = "2008",
    booktitle = "2008 International Conference on Information Processing in Sensor Networks (ipsn 2008)"
}

@article{Eagle2005,
    author = "Eagle, Nathan and Pentland, Alex Sandy",
    doi = "10.1007/s00779-005-0046-3",
    title = "{Reality mining: sensing complex social systems}",
    url = "http://www.springerlink.com/index/10.1007/s00779-005-0046-3",
    abstract = "We introduce a system for sensing complex social systems with data collected from 100 mobile phones over the course of 9 months. We demonstrate the ability to use standard Bluetooth-enabled mobile telephones to measure information access and use in different contexts, recognize social patterns in daily user activity, infer relationships, identify socially significant locations, and model organizational rhythms.",
    issn = "1617-4909",
    number = "4",
    month = "11",
    volume = "10",
    pages = "255--268",
    file = "::",
    year = "2005",
    keywords = "introduced as a useful,metric for quantifying organiza-,mobile phones \ae bluetooth,systems \ae wearable computing,\ae complex social,\ae user modeling",
    journal = "Personal and Ubiquitous Computing"
}

@inproceedings{Eagle2009,
    author = "Eagle, Nathan and de Montjoye, Yves-Alexandre and Bettencourt, Lu\'{\i}s M.A.",
    publisher = "IEEE",
    doi = "10.1109/CSE.2009.91",
    isbn = "978-1-4244-5334-4",
    title = "{Community Computing: Comparisons between Rural and Urban Societies Using Mobile Phone Data}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5284288",
    abstract = "We present a comparative analysis of the behavioral dynamics of rural and urban societies using four years of mobile phone data from all 1.4M subscribers within a small country. We use information from communication logs and top up denominations to characterize attributes such as socioeconomic status and region. We show that rural and urban communities differ dramatically not only in terms of personal network topologies, but also in terms of inferred behavioral characteristics such as travel. We confirm the hypothesis for behavioral adaptation, demonstrating that individuals change their patterns of communication to increase the similarity with their new social environment. To our knowledge, this is the first comprehensive comparison between regional groups of this size.",
    month = "8",
    pages = "144--150",
    file = "::",
    year = "2009",
    booktitle = "2009 International Conference on Computational Science and Engineering"
}

@inproceedings{Eckersley2010,
    author = "Eckersley, Peter and Burns, Jesse",
    url = "https://ipv6.eff.org/files/ccc2010.pdf",
    booktitle = "Chaos Communication Congress",
    year = "2010",
    file = ":home/drt24/Downloads/ccc2010.pdf:pdf",
    title = "{Is the SSLiverse a safe place}"
}

@article{Eckersley2010a,
    author = "Eckersley, Peter",
    doi = "10.1007/978-3-642-14527-8_1",
    isbn = "3642145264",
    title = "{How unique is your web browser?}",
    abstract = "We investigate the degree to which modern web browsers are subject to fingerprinting via the version and con guration information that they will transmit to websites upon request. We implemented one possible ngerprinting algorithm, and collected these fingerprints from a large sample of browsers that visited our test side, panopticlick.eff.org.",
    issn = "03029743",
    pages = "1--18",
    volume = "6205 LNCS",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-14527-8\_1.pdf:pdf",
    year = "2010",
    journal = "PETS, Lecture Notes in Computer Science"
}

@inproceedings{Edwards1997,
    author = "Edwards, W. Keith and Mynatt, Elizabeth D. and Petersen, Karin and Spreitzer, Mike J. and Terry, Douglas B. and Theimer, Marvin M.",
    publisher = "ACM Press",
    doi = "10.1145/263407.263530",
    isbn = "0897918819",
    title = "{Designing and implementing asynchronous collaborative applications with Bayou}",
    url = "http://portal.acm.org/citation.cfm?doid=263407.263530",
    abstract = "Asynchronous collaboration is characterized by the degree of independence collaborators have from one another. In particular, collaborators working asynchronously typically have little need for frequent and fine-grained coordination with one another, and typically do not need to be notified immediately of changes made by others to any shared artifacts they are working with. We present an infrastructure, called Bayou, designed to support the construction of asynchronous collaborative applications. Bayou provides a replicated, weakly-consistent, data storage engine to application writers. The system supports a number of mechanisms for leveraging application semantics; using these mechanisms, applications can implement complex conflict detection and resolution policies, and choose the level of consistency and stability they will see in their databases. We present a number of applications we have built or are building using the Bayou system, and examine how these take advantage of the Bayou architecture.",
    pages = "119--128",
    file = ":auto/homes/drt24/Downloads/p119-edwards.pdf:pdf",
    year = "1997",
    keywords = "Bayou,asynchronous interaction,computer-supported cooperative work,distributed systems",
    booktitle = "UIST"
}

@inproceedings{Edwards1997a,
    author = "Edwards, W. Keith and Mynatt, E.D.",
    publisher = "ACM",
    doi = "10.1145/258549.258710",
    title = "{Timewarp: techniques for autonomous collaboration}",
    url = "http://dl.acm.org/citation.cfm?id=258710",
    abstract = "This paper presents a set of techniques for supporting autonomous collaboration-collaboration where participants work independently for periods, and then join together to integrate their efforts. This paper posits that autonomous collaboration can be well-supported by systems in which the notion of time is made both explicit and editable, so that the parallel but divergent states of a shared artifact are exposed in the interface. We have developed a system, called timewarp, that explores these ideas, and provides support for distribution, awareness, and conflict resolution in an application-independent fashion.",
    pages = "218--225",
    file = ":auto/homes/drt24/Downloads/p218-edwards.pdf:pdf",
    year = "1997",
    keywords = "autonomous,awareness,collaboration,computer-supported cooperative work,conflict detection and resolution,timewarp",
    booktitle = "Proceedings of the SIGCHI conference on Human factors in computing systems"
}

@inproceedings{Edwards2000,
    author = "Edwards, W. Keith and Igarashi, T. and LaMarca, A. and Mynatt, E.D.",
    publisher = "ACM",
    isbn = "1581132123",
    title = "{A temporal model for multi-level undo and redo}",
    url = "http://dl.acm.org/citation.cfm?id=354409",
    abstract = "A number of recent systems have provided rich facilities for manipulating the timelines of applications. Such timelines represent the history of an application’s use in some session, and captures the effects of the user’s interactions with that application. Applications can use timeline manipulation techniques prosaically as a way to provide undo and redo within an application context; more interestingly, they can use these same techniques to make an application’s history directly manipulable in richer ways by users. This paper presents a number of extensions to current techniques for representing and managing application timelines. The first extension captures causal relationships in timelines via a nested transaction mechanism. This extension addresses a common problem in history-based applications, namely, how to represent application state as a set of atomic, incremental operations. The second extension presents a model for “multi-level” time, in which the histories of a set of inter-related artifacts can be represented by both “local” and “global” timelines. This extension allows the histories of related objects in an application to be manipulated independently from one another.",
    pages = "31--40",
    volume = "2",
    file = ":auto/homes/drt24/Downloads/p31-edwards.pdf:pdf",
    year = "2000",
    keywords = "Flatland,Timewarp,history management,redo,timelines,undo",
    booktitle = "Proceedings of the 13th annual ACM symposium on User interface software and technology"
}

@inproceedings{Eeten2011,
    author = "Eeten, Michel Van and Bauer, Johannes M. and Asgharia, Hadi and Tabatabaie, Shirin and Rand, Dave",
    title = "{The role of internet service providers in botnet mitigation an empirical analysis based on spam data}",
    url = "http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1989198",
    abstract = "Botnets – networks of machines infected with malicious software – are widely regarded as a critical security threat. Measures that directly address the owners of the infected machine end users are useful, but have proven insufficient to reduce the overall problem. Recent studies have shifted attention to key intermediaries – most notably, Internet Service Providers (ISPs) – as control points for botnet activity. Surprisingly little empirical information is available to assess the claim that ISPs are an important control point, as well as related claims, for example, that large ISPs are worse cybercitizens than smaller ones. This paper is a first effort to go beyond generalized arguments by dissecting the diversity of ISPs and the number of infected machines in their networks. As most of the current spam is sent through botnets, the origin of spam messages provides us with a proxy for detecting infected machines. Using a global dataset of 138 million unique IP addresses that connected to a spam trap in the period 2005-2008, we have analyzed in detail the geographic patterns, time trends, and differences at the level of countries and ISPs. This data underlines the key position of ISPs as intermediaries. For example, in our dataset just 10 ISPs account for around 30 percent of all unique IP addresses sending spam worldwide; 50 ISPs account for over half of all sources. For the first time, the patterns in infected machines are connected to other data, such as the size of the ISPs and the country in which they are located. Using bivariate and multivariate statistical approaches we investigate empirically the effects of country-level policy measures on the number of unique IP addresses sending spam at the ISP level. The data reveals wide differences between ISPs in the relative number of infected machines, sometimes up to three orders of magnitude. Whereas the overall number of infected machines is largely driven by the size of the user base, we also find limited evidence that public policies to improve cybersecurity have the desired mitigating effects. Our findings confirm some of the claims made in the research literature but refute others.",
    pages = "1--31",
    file = ":home/drt24/Downloads/weis2010\_vaneeten.pdf:pdf",
    year = "2011",
    booktitle = "WEIS"
}

@article{Egele2013,
    author = "Egele, Manuel and Brumley, David and Fratantonio, Yanick and Kruegel, Christopher",
    publisher = "ACM Press",
    doi = "10.1145/2508859.2516693",
    isbn = "9781450324779",
    title = "{An empirical study of cryptographic misuse in android applications}",
    url = "http://dl.acm.org/citation.cfm?doid=2508859.2516693",
    journal = "Proceedings of the 2013 ACM SIGSAC conference on Computer \& communications security - CCS '13",
    year = "2013",
    file = ":home/drt24/Downloads/p73-egele.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "program analysis,software security",
    pages = "73--84"
}

@inproceedings{Egelman2012,
    author = "Egelman, Serge and Bonneau, Joseph and Chiasson, Sonia and Dittrich, David and Schechter, Stuart",
    title = "{It's Not Stealing If You Need It: A Panel on the Ethics of Performing Research Using Public Data of Illicit Origin}",
    url = "http://link.springer.com/content/pdf/10.1007/978-3-642-34638-5_11",
    booktitle = "Financial Cryptography",
    file = ":home/drt24/Downloads/fulltext (10).pdf:pdf",
    year = "2012",
    pages = "124--132"
}

@article{Ellis1999,
    author = "Ellis, Carla Schlatter",
    isbn = "0-7695-0237-7",
    title = "{The Case for Higher-Level Power Management}",
    url = "http://dl.acm.org/citation.cfm?id=822076.822438",
    month = "3",
    year = "1999",
    keywords = "energy consumption,mobile computing,power management",
    pages = "162"
}

@online{Ellis1999a,
    author = "Ellis, C S",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/HOTOS.1999.798394",
    isbn = "0769502377",
    title = "{The case for higher-level power management}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=798394",
    series = "HOTOS '99",
    abstract = "Reducing the energy consumed in the use of computing devices is becoming a major design challenge. While the problem obviously must be addressed with improved low level technology, we claim there is potential value in a higher level perspective, as well. In our approach, the needs of applications serve as the driving force for the development of power management functions in the operating system and of a power based API that allows a partnership between applications and the system in setting energy policy. The development of a PalmPilot application is used as an illustration. We advocate that reducing energy consumption should be raised to first class status among performance goals when software is being designed. In support of this objective, new programming models, measurement tools, and system support mechanisms must be developed. These needs motivate our Milly Watt Project",
    institution = "IEEE",
    year = "1999",
    booktitle = "Proceedings of the Seventh Workshop on Hot Topics in Operating Systems",
    pages = "162--167"
}

@article{Enck2009,
    author = "Enck, W and Ongtang, M and McDaniel, P",
    publisher = "IEEE",
    doi = "10.1109/MSP.2009.26",
    title = "{Understanding Android Security}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4768655",
    abstract = "Google's Android platform is a widely anticipated open source operating system for mobile phones. This article describes Android's security model and attempts to unmask the complexity of secure application development. The authors conclude by identifying lessons and opportunities for future enhancements.",
    issn = "15407993",
    number = "1",
    pages = "50--57",
    volume = "7",
    file = ":home/drt24/Downloads/04768655.pdf:pdf",
    year = "2009",
    keywords = "android,mobile phones,security,smartphones",
    journal = "IEEE Security Privacy Magazine"
}

@article{Enck2009a,
    author = "Enck, William and Ongtang, Machigar and Mcdaniel, Patrick",
    publisher = "ACM Press",
    doi = "10.1145/1653662.1653691",
    isbn = "9781605588940",
    title = "{On lightweight mobile phone application certification}",
    journal = "Security",
    series = "CCS '09",
    abstract = "Users have begun downloading an increasingly large number of mobile phone applications in response to advancements in handsets and wireless networks. The increased number of applications results in a greater chance of installing Trojans and similar malware. In this paper, we propose the Kirin security service for Android, which performs lightweight certification of applications to mitigate malware at install time. Kirin certification uses security rules, which are templates designed to conservatively match undesirable properties in security configuration bundled with applications. We use a variant of security requirements engineering techniques to perform an in-depth security analysis of Android to produce a set of rules that match malware characteristics. In a sample of 311 of the most popular applications downloaded from the official Android Market, Kirin and our rules found 5 applications that implement dangerous functionality and therefore should be installed with extreme caution. Upon close inspection, another five applications asserted dangerous rights, but were within the scope of reasonable functional needs. These results indicate that security configuration bundled with Android applications provides practical means of detecting malware.",
    issn = "15437221",
    pages = "235--245",
    url = "http://portal.acm.org/citation.cfm?doid=1653662.1653691",
    file = ":home/drt24/Downloads/p235-enck.pdf:pdf",
    year = "2009",
    keywords = "a malware,android,described in this paper,described paper,focused revision a,focused revision of a,is a malware,kirin security service,malware,mobile phone security,our previous,similar system described,similar system described in,the kirin security service",
    institution = "ACM"
}

@inproceedings{Enck2010,
    editor = "Arpaci-Dusseau, Remzi H and Chen, Brad",
    author = "Enck, William and Gilbert, Peter and Chun, Byung-Gon and Cox, Landon P and Jung, Jaeyeon and McDaniel, Patrick and Sheth, Anmol N.",
    publisher = "USENIX Association",
    title = "{TaintDroid : An Information-Flow Tracking System for Realtime Privacy Monitoring on Smartphones}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:TaintDroid+:+An+Information-Flow+Tracking+System+for+Realtime+Privacy+Monitoring+on+Smartphones\#0 http://static.usenix.org/events/osdi10/tech/full_papers/Enck.pdf",
    series = "OSDI'10",
    abstract = "Today's smartphone operating systems frequently fail to provide users with adequate control over and visibility into how third-party applications use their private data. We address these shortcomings with TaintDroid, an efficient, system-wide dynamic taint tracking and analysis system capable of simultaneously tracking multiple sources of sensitive data. TaintDroid provides realtime analysis by leveraging Android's virtualized execution environment. TaintDroid incurs only 14\% performance overhead on a CPU-bound micro-benchmark and imposes negligible overhead on interactive third-party applications. Using TaintDroid to monitor the behavior of 30 popular third-party Android applications, we found 68 instances of potential misuse of users' private information across 20 applications. Monitoring sensitive data with TaintDroid provides informed use of third-party applications for phone users and valuable input for smartphone security service firms seeking to identify misbehaving applications.",
    issn = "03601315",
    number = "4",
    pages = "1--6",
    volume = "49",
    file = ":home/drt24/Downloads/Enck.pdf:pdf",
    year = "2010",
    organization = "Tech. Rep. NAS-TR-0120-2010, Network and Security Research Center, Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, USA",
    booktitle = "OSDI"
}

@article{Enck2011,
    editor = "Jajodia, Sushil and Mazumdar, Chandan",
    author = "Enck, William",
    publisher = "Springer Berlin / Heidelberg",
    doi = "10.1007/978-3-642-25560-1_3",
    isbn = "9783642255595",
    title = "{Defending Users Against Smartphone Apps : Techniques and Future Directions}",
    url = "http://www.enck.org/pubs/enck-iciss11.pdf",
    series = "Lecture Notes in Computer Science",
    journal = "ICISS",
    number = "i",
    institution = "North Carolina State University",
    volume = "7093",
    pages = "49--70",
    file = ":home/drt24/Downloads/enck-iciss11.pdf:pdf",
    year = "2011",
    keywords = "smartphone security",
    abstract = "Smartphone security research has become very popular in response to the rapid, worldwide adoption of new platforms such as Android and iOS. Smartphones are characterized by their ability to run third-party applications, and Android and iOS take this concept to the extreme, offering hundreds of thousands of apps through application markets. In response, smartphone security research has focused on protecting users from apps. In this paper, we discuss the current state of smartphone research, including efforts in designing new OS protection mechanisms, as well as performing security analysis of real apps. We offer insight into what works, what has clear limitations, and promising directions for future research."
}

@article{Enck2011a,
    author = "Enck, William and Octeau, Damien and Mcdaniel, Patrick and Chaudhuri, Swarat",
    publisher = "USENIX Association",
    doi = "10.1007/s00256-010-0882-8",
    isbn = "0025601008828",
    title = "{A Study of Android Application Security}",
    url = "http://www.usenix.org/event/sec11/tech/slides/enck.pdf",
    series = "SEC'11",
    journal = "USENIX Security",
    number = "August",
    institution = "Department of Computer Science and Engineering",
    pages = "935--936",
    file = ":home/drt24/Downloads/enck.pdf:pdf",
    year = "2011",
    abstract = "The fluidity of application markets complicate smartphone security. Although recent efforts have shed light on particular security issues, there remains little insight into broader security characteristics of smartphone applications. This paper seeks to better understand smartphone application security by studying 1,100 popular free Android applications. We introduce the ded decompiler, which recovers Android application source code directly from its installation image. We design and execute a horizontal study of smartphone applications based on static analysis of 21 million lines of recovered code. Our analysis uncovered pervasive use/misuse of personal/phone identifiers, and deep penetration of advertising and analytics networks. However, we did not find evidence of malware or exploitable vulnerabilities in the studied applications. We conclude by considering the implications of these preliminary findings and offer directions for future analysis."
}

@article{Enck2011b,
    author = "Enck, William and Octeau, Damien and McDaniel, Patrick and Chaudhuri, Swarat",
    url = "http://dl.acm.org/citation.cfm?id=2028067.2028088",
    title = "{A study of android application security}",
    year = "2011",
    pages = "21",
    month = "8"
}

@online{Encka,
    author = "Enck, William",
    url = "http://www.enck.org/pubs/enck-iciss11.pdf",
    urldate = "10/10/12",
    file = "::",
    title = "{Defending Users Against Smartphone Apps: Techniques and Future Directions}"
}

@article{Engler1995,
    author = "Engler, Dawson R and Kaashoek, M. Frans and {O'Toole Jr}, J and Toole, James O",
    publisher = "ACM",
    isbn = "0897917154",
    title = "{Exokernel: an operating system architecture for application-level resource management}",
    journal = "SIGOPS",
    abstract = "Traditional operating systems limit the performance, flexibility, and functionality of applications by fixing the interface and implemen- tation of operating system abstractions such as interprocess com- munication and virtual memory. The exokernel operating system architecture addresses this problem by providing application-level management of physical resources. In the exokernel architecture, a small kernel securely exports all hardware resources through a low- level interface to untrusted library operating systems. Library op- erating systems use this interface to implement system objects and policies. This separation of resource protection from management allows application-specific customization of traditional operating system abstractions by extending, specializing, or even replacing libraries. We have implemented a prototype exokernel operating system. Measurements show that most primitive kernel operations (such as exception handling and protected control transfer) are ten to 100 times faster than in Ultrix, a mature monolithic UNIX operating sys- tem. In addition, we demonstrate that an exokernel allows applica- tions to control machine resources in ways not possible in traditional operating systems. For instance, virtual memory and interprocess communication abstractions are implemented entirely within an application-level library. Measurements show that application-level virtual memory and interprocess communication primitives are five to 40 times faster than Ultrixs kernel primitives. Compared to state-of-the-art implementations from the literature, the prototype exokernel system is at least five times faster on operations such as exception dispatching and interprocess communication.",
    number = "212",
    volume = "1",
    url = "http://portal.acm.org/citation.cfm?id=224076",
    file = ":auto/homes/drt24/Downloads/p251-engler.pdf:pdf",
    year = "1995",
    pages = "251--266"
}

@book{Engler2005,
    editor = "Abadi, Mart\'{\i}n and Alfaro, Luca",
    author = "Engler, Dawson",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11539452",
    isbn = "978-3-540-28309-6",
    title = "{CONCUR 2005 – Concurrency Theory}",
    url = "http://dl.acm.org/citation.cfm?id=1099332.1099334",
    series = "Lecture Notes in Computer Science",
    year = "2005",
    month = "8",
    volume = "3653",
    address = "Berlin, Heidelberg",
    pages = "1"
}

@article{Eppler2010,
    author = "Eppler, Martin J. and Pfister, Roland a.",
    publisher = "Ieee",
    doi = "10.1109/IV.2010.98",
    isbn = "978-1-4244-7846-0",
    title = "{Drawing Conclusions: Supporting Decision Making through Collaborative Graphic Annotations}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5571225",
    journal = "2010 14th International Conference Information Visualisation",
    month = "7",
    file = "::",
    year = "2010",
    keywords = "annotation,chart,charting,communication quality,decision making,decision quality,decision support,management meetings,sense making,sketching,sketchmark",
    pages = "369--374"
}

@article{Erasmus2012,
    author = "Erasmus, Tyrone",
    journal = "Erasmus",
    year = "2012",
    number = "March",
    file = ":home/drt24/Downloads/bh-eu-12-Erasmus-Heavy-Metal\_Poisoned\_Droid-WP.pdf:pdf",
    title = "{The heavy metal that poisoned the droid}"
}

@inproceedings{Erickson2010,
    author = "Erickson, Varick L and Cerpa, Alberto E",
    isbn = "9781450304580",
    title = "{Occupancy Based Demand Response HVAC Control Strategy}",
    abstract = "Heating, cooling and ventilation accounts for 30\% energy usage and for 50\% of the electricity usage in the United States. Currently, most modern buildings still condition rooms assuming maximum occupancy rather than actual us- age. As a result, rooms are often over-conditioned need- lessly. This paper proposes an HVAC control strategy based on occupancy prediction and real time occupancy monitoring via a sensor network of cameras. This strategy shows 20.0\% potential energy savings while still maintaining ASHRAE building standards.",
    year = "2010",
    mendeley-tags = "Algorithms,Measurement",
    pages = "7--12",
    file = ":home/drt24/Library/papers/BuildSys/Erickson, Cerpa/Erickson, Cerpa - 2010 - Occupancy Based Demand Response HVAC Control Strategy.pdf:pdf",
    address = "Zurich, Switzerland",
    keywords = "Algorithms,Demand Response,Energy Savings,HVAC,Measurement,Occupancy,Ventilation",
    booktitle = "BuildSys"
}

@article{FIPS-186-3,
    title = "{FIPS 186-3: Digital Signature Standard (DSS)}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:FIPS+186-3+Digital+Signature+Standard+(+DSS+)\#0",
    abstract = "This Standard specifies a suite of algorithms that can be used to generate a digital signature. Digital signatures are used to detect unauthorized modifications to data and to authenticate the identity of the signatory. In addition, the recipient of signed data can use a digital signature as evidence in demonstrating to a third party that the signature was, in fact, generated by the claimed signatory. This is known as non-repudiation, since the signatory cannot easily repudiate the signature at a later time.",
    file = ":auto/homes/drt24/Downloads/fips\_186-3.pdf:pdf",
    year = "2009",
    keywords = "Federal Information Processing Standards,computer security,cryptography,digital signatures,public key cryptography",
    journal = "National Institute of Standards and Technology (NIST)"
}

@article{FahadR.Dogar,
    author = "{Fahad R. Dogar}, Peter Steenkiste",
    url = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.189.4904",
    file = "::",
    title = "{Catnap: Exploiting High Bandwidth Wireless Interfaces to Save Energy for Mobile Devices}"
}

@inproceedings{Fahl2012,
    author = {Fahl, Sascha and Harbach, Marian and Muders, Thomas and Smith, Matthew and Baumg\"{a}rtner, Lars and Freisleben, Bernd},
    publisher = "ACM",
    doi = "10.1145/2382196.2382205",
    isbn = "9781450316514",
    title = "{Why Eve and Mallory love Android: an analysis of Android SSL (in)security}",
    url = "http://dl.acm.org/citation.cfm?id=2382205",
    abstract = "Many Android apps have a legitimate need to communicate over the Internet and are then responsible for protecting potentially sensitive data during transit. This paper seeks to better understand the potential security threats posed by benign Android apps that use the SSL/TLS protocols to protect data they transmit. Since the lack of visual security indicators for SSL/TLS usage and the inadequate use of SSL/TLS can be exploited to launch Man-in-the-Middle (MITM) attacks, an analysis of 13,500 popular free apps downloaded from Google’s Play Market is presented. We introduce MalloDroid, a tool to detect potential vulnerability against MITM attacks. Our analysis revealed that 1,074 (8.0\%) of the apps examined contain SSL/TLS code that is potentially vulnerable to MITM attacks. Various forms of SSL/TLS misuse were discovered during a further manual audit of 100 selected apps that allowed us to successfully launch MITM attacks against 41 apps and gather a large variety of sensitive data. Furthermore, an online sur- vey was conducted to evaluate users’ perceptions of certificate warnings and HTTPS visual security indicators in Android’s browser, showing that half of the 754 participating users were not able to correctly judge whether their browser session was protected by SSL/TLS or not. We conclude by considering the implications of these findings and discuss several countermeasures with which these problems could be alleviated.",
    pages = "50--61",
    file = ":home/drt24/Downloads/p50-fahl.pdf:pdf",
    year = "2012",
    keywords = "android,apps,mitma,security,ssl",
    booktitle = "CCS"
}

@book{Fahlman1988,
    author = "Fahlman, S.E.",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.1492\&amp;rep=rep1\&amp;type=pdf",
    publisher = "Citeseer",
    year = "1988",
    file = ":home/drt24/Library/papers/Unknown/Unknown/Unknown - Unknown - quickprop-tr.ps:ps",
    title = "{An empirical study of learning speed in back-propagation networks (quickprop)}"
}

@inproceedings{Falaki2010a,
    author = "Falaki, Hossein and Lymberopoulos, Dimitrios and Mahajan, Ratul and Kandula, Srikanth and Estrin, Deborah",
    publisher = "ACM Press",
    doi = "10.1145/1879141.1879176",
    isbn = "9781450304832",
    title = "{A first look at traffic on smartphones}",
    url = "http://dl.acm.org/citation.cfm?id=1879141.1879176",
    booktitle = "Proceedings of the 10th annual conference on Internet measurement - IMC '10",
    year = "2010",
    month = "11",
    file = "::",
    address = "New York, New York, USA",
    keywords = "power management,smartphone traffic",
    pages = "281"
}

@inproceedings{Falaki2010c,
    author = "Falaki, Hossein and Mahajan, Ratul and Kandula, Srikanth and Lymberopoulos, Dimitrios and Govindan, Ramesh and Estrin, Deborah",
    publisher = "ACM Press",
    doi = "10.1145/1814433.1814453",
    isbn = "9781605589855",
    title = "{Diversity in smartphone usage}",
    url = "http://dl.acm.org/citation.cfm?id=1814433.1814453",
    abstract = "Using detailed traces from 255 users, we conduct a comprehensive study of smartphone use. We characterize intentional user activities -- interactions with the device and the applications used -- and the impact of those activities on network and energy usage. We find immense diversity among users. Along all aspects that we study, users differ by one or more orders of magnitude. For instance, the average number of interactions per day varies from 10 to 200, and the average amount of data received per day varies from 1 to 1000 MB. This level of diversity suggests that mechanisms to improve user experience or energy consumption will be more effective if they learn and adapt to user behavior. We find that qualitative similarities exist among users that facilitate the task of learning user behavior. For instance, the relative application popularity for can be modeled using an exponential distribution, with different distribution parameters for different users. We demonstrate the value of adapting to user behavior in the context of a mechanism to predict future energy drain. The 90th percentile error with adaptation is less than half compared to predictions based on average behavior across users.",
    year = "2010",
    month = "6",
    pages = "179",
    file = "::",
    address = "New York, New York, USA",
    keywords = "smartphone usage,user behavior",
    booktitle = "Proceedings of the 8th international conference on Mobile systems, applications, and services - MobiSys '10"
}

@techreport{Falliere2011,
    author = "Falliere, Nicolas and Murchu, Liam O and Chien, Eric",
    title = "{W32. stuxnet dossier}",
    url = "http://www.h4ckr.us/library/Documents/ICS_Events/Stuxnet Dossier (Symantec) v1.4.pdf",
    booktitle = "White paper, Symantec Corp., Security \ldots",
    number = "February",
    institution = "Symantec",
    volume = "4",
    file = ":home/drt24/Downloads/Stuxnet Dossier (Symantec) v1.4.pdf:pdf",
    year = "2011",
    pages = "1--69"
}

@inproceedings{Fang2010,
    author = "Fang, Lujun and LeFevre, Kristen",
    publisher = "ACM Press",
    doi = "10.1145/1772690.1772727",
    isbn = "9781605587998",
    title = "{Privacy wizards for social networking sites}",
    url = "http://dl.acm.org/citation.cfm?id=1772690.1772727",
    booktitle = "Proceedings of the 19th international conference on World wide web - WWW '10",
    year = "2010",
    month = "4",
    file = "::",
    address = "New York, New York, USA",
    keywords = "active learning,social network privacy,usability",
    pages = "351"
}

@inproceedings{Feeney,
    author = "Feeney, L.M. and Nilsson, M.",
    publisher = "IEEE",
    doi = "10.1109/INFCOM.2001.916651",
    isbn = "0-7803-7016-3",
    title = "{Investigating the energy consumption of a wireless network interface in an ad hoc networking environment}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=916651",
    abstract = "Energy-aware design and evaluation of network protocols requires knowledge of the energy consumption behavior of actual wireless interfaces. But little practical information is available about the energy consumption behavior of well-known wireless network interfaces and device specifications do not provide information in a form that is helpful to protocol developers. This paper describes a series of experiments which obtained detailed measurements of the energy consumption of an IEEE 802.11 wireless network interface operating in an ad hoc networking environment. The data is presented as a collection of linear equations for calculating the energy consumed in sending, receiving and discarding broadcast and point-to-point data packets of various sizes. Some implications for protocol design and evaluation in ad hoc networks are discussed",
    pages = "1548--1557",
    volume = "3",
    file = "::",
    booktitle = "Proceedings IEEE INFOCOM 2001. Conference on Computer Communications. Twentieth Annual Joint Conference of the IEEE Computer and Communications Society (Cat. No.01CH37213)"
}

@article{Feldman2010,
    author = "Feldman, Ariel J and Zeller, William P and Freedman, Michael J. and Felten, Edward W",
    publisher = "USENIX",
    title = "{SPORC : Group Collaboration using Untrusted Cloud Resources}",
    journal = "OSDI",
    abstract = "Cloud-based services are an attractive deployment model for user-facing applications like word processing and calendaring. Unlike desktop applications, cloud ser- vices allowmultiple users to edit shared state concurrently and in real-time, while being scalable, highly available, and globally accessible. Unfortunately, these benefits come at the cost of fully trusting cloud providers with potentially sensitive and important data. To overcome this strict tradeoff, we present SPORC, a generic framework for building a wide variety of collabo- rative applications with untrusted servers. In SPORC, a server observes only encrypted data and cannot deviate from correct execution without being detected. SPORC allows concurrent, low-latency editing of shared state, permits disconnected operation, and supports dynamic access control even in the presence of concurrency. We demonstrate SPORCs flexibility through two prototype applications: a causally-consistent key-value store and a browser-based collaborative text editor. Conceptually, SPORC illustrates the complementary benefits of operational transformation (OT) and fork consistency.The former allows SPORC clients to execute concurrent operations without locking and to resolve any resulting conflicts automatically. The latter prevents a misbehaving server from equivocating about the order of operations unless it is willing to fork clients into disjoint sets. Notably, unlike previous systems, SPORC can auto- matically recover fromsuch malicious forks by leveraging OTs conflict resolution mechanism.",
    issn = "03600300",
    number = "3",
    volume = "34",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:SPORC+:+Group+Collaboration+using+Untrusted+Cloud+Resources\#0",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feldman et al. - 2010 - SPORC Group Collaboration using Untrusted Cloud Resources.pdf:pdf",
    year = "2010",
    pages = "1--14"
}

@article{Felleisen,
    author = "Felleisen, Kathryn E. Gray and Matthias",
    volume = "2007",
    journal = "University of Utah Techreport UUCS-07-013",
    number = "2007",
    title = "{Linguistic Support for Unit Tests}"
}

@article{Felt2011,
    author = "Felt, Adrienne Porter and Finifter, Matthew and Chin, Erika and Hanna, Steve and Wagner, David",
    publisher = "ACM Press",
    doi = "10.1145/2046614.2046618",
    isbn = "9781450310000",
    title = "{A survey of mobile malware in the wild}",
    journal = "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices",
    series = "SPSM '11",
    abstract = "Mobile malware is rapidly becoming a serious threat. In this paper, we survey the current state of mobile malware in the wild. We analyze the incentives behind 46 pieces of iOS, Android, and Symbian malware that spread in the wild from 2009 to 2011. We also use this data set to evalu- ate the effectiveness of techniques for preventing and iden- tifying mobile malware. After observing that 4 pieces of malware use root exploits to mount sophisticated attacks on Android phones, we also examine the incentives that cause non-malicious smartphone tinkerers to publish root exploits and survey the availability of root exploits.",
    pages = "3",
    volume = "55",
    url = "http://dl.acm.org/citation.cfm?doid=2046614.2046618",
    file = ":home/drt24/Downloads/p3-felt.pdf:pdf",
    year = "2011",
    keywords = "malware,mobile devices,smartphones",
    institution = "University of California"
}

@article{Felt2011a,
    author = "Felt, Adrienne Porter and Chin, Erika and Hanna, Steve and Song, Dawn and Wagner, David",
    doi = "10.1145/2046707.2046779",
    isbn = "9781450309486",
    title = "{Android permissions demystified}",
    url = "http://dl.acm.org/citation.cfm?doid=2046707.2046779",
    abstract = "Android provides third-party applications with an extensive API that includes access to phone hardware, settings, and user data. Access to privacy- and security-relevant parts of the API is controlled with an install-time application permis- sion system. We study Android applications to determine whether Android developers follow least privilege with their permission requests. We built Stowaway, a tool that detects overprivilege in compiled Android applications. Stowaway determines the set of API calls that an application uses and then maps those API calls to permissions. We used auto- mated testing tools on the Android API in order to build the permission map that is necessary for detecting overpriv- ilege. We apply Stowaway to a set of 940 applications and find that about one-third are overprivileged. We investigate the causes of overprivilege and find evidence that developers are trying to follow least privilege but sometimes fail due to insufficient API documentation:",
    issn = "09581669",
    pages = "627",
    file = ":home/drt24/Downloads/p627-felt.pdf:pdf",
    year = "2011",
    keywords = "android,least privilege,permissions",
    journal = "Proceedings of the 18th ACM conference on Computer and communications security - CCS '11"
}

@article{Ferreira2011,
    author = "Ferreira, Denzil and Dey, Anind K. and Kostakos, Vassilis",
    isbn = "978-3-642-21725-8",
    title = "{Understanding Human-Smartphone Concerns : A Study of Battery Life}",
    url = "http://dl.acm.org/citation.cfm?id=2021975.2021978",
    abstract = "This paper presents a large, 4-week study of more than 4000 people to assess their smartphone charging habits to identify timeslots suitable for opportunistic data uploading and power intensive operations on such devices, as well as opportunities to provide interventions to support better charging behavior. The paper provides an overview of our study and how it was conducted using an online appstore as a software deployment mechanism, and what battery information was collected. We then describe how people charge their smartphones, the implications on battery life and energy usage, and discuss how to improve users’ experience with battery life.",
    mendeley-tags = "Smartphone,power",
    month = "6",
    pages = "19--33",
    file = "::;::",
    year = "2011",
    keywords = "Smartphone,android,autonomous logging,battery life,large-scale study,power,smartphones",
    journal = "Pervasive Computing"
}

@inproceedings{Field2008,
    author = "Field, Martin and Mary, Saint and Linsey, Julie",
    title = "{Sketch Recognition Algorithms for Comparing Complex and Unpredictable Shapes}",
    abstract = "In an introductory Engineering course with an an- nual enrollment of over 1000 students, a professor has little option but to rely on multiple choice exams for midterms and finals. Furthermore, the teach- ing assistants are too overloaded to give detailed feedback on submitted homework assignments. We introduce Mechanix, a computer-assisted tutoring system for engineering students. Mechanix uses recognition of freehand sketches to provide instant, detailed, and formative feedback as the student pro- gresses through each homework assignment, quiz, or exam. Free sketch recognition techniques allow students to solve free-body diagram and static truss problems as if they were using a pen and paper. The same recognition algorithms enable professors to add new unique problems simply by sketching out the correct answer. Mechanix is able to ease the burden of grading so that instructors can assign more free response questions, which provide a better measure of student progress than multiple choice questions do.",
    pages = "2436--2441",
    file = "::",
    year = "2008",
    keywords = "Special Track on Integrated and Embedded Artificia",
    booktitle = "Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence"
}

@phdthesis{Fielding2000,
    editor = "Taylor, Richard N",
    author = "Fielding, Roy Thomas",
    publisher = "Citeseer",
    school = "University of California, Irvine",
    doi = "10.1.1.91.2433",
    isbn = "0599871180",
    title = "{Architectural Styles and the Design of Network-based Software Architectures}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.9164\&amp;rep=rep1\&amp;type=pdf",
    series = "PhD Dissertation. Dept. of Information and Computer Science",
    abstract = "The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia system. The Web has been iteratively developed over the past ten years through a series of modifications to the standards that define its architecture. In order to identify those aspects of the Web that needed improvement and avoid undesirable modifications, a model for the modern Web architecture was needed to guide its design, definition, and deployment. Software architecture research investigates methods for determining how best to partition a system, how components identify and communicate with each other, how information is communicated, how elements of a system can evolve independently, and how all of the above can be described using formal and informal notations. My work is motivated by the desire to understand and evaluate the architectural design of network-based application software through principled use of architectural constraints, thereby obtaining the functional, performance, and social properties desired of an architecture. An architectural style is a named, coordinated set of architectural constraints. This dissertation defines a framework for understanding software architecture via architectural styles and demonstrates how styles can be used to guide the architectural design of network-based application software. A survey of architectural styles for network-based applications is used to classify styles according to the architectural properties they induce on an architecture for distributed hypermedia. I then introduce the Representational State Transfer (REST) architectural style and describe how REST has been used to guide the design and development of the architecture for the modern Web. REST emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. I describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. Finally, I describe the lessons learned from applying REST to the design of the Hypertext Transfer Protocol and Uniform Resource Identifier standards, and from their subsequent deployment in Web client and server software.",
    number = "2",
    pages = "162",
    volume = "54",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fielding - 2000 - Architectural Styles and the Design of Network-based Software Architectures.pdf:pdf",
    year = "2000",
    booktitle = "Building"
}

@article{Figl2010,
    author = "Figl, Kathrin and Derntl, Michael and Rodriguez, Manuel Caeiro and Botturi, Luca",
    publisher = "Elsevier",
    doi = "10.1016/j.jvlc.2010.08.009",
    title = "{Cognitive effectiveness of visual instructional design languages}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X10000509",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "6",
    month = "12",
    volume = "21",
    file = "::",
    year = "2010",
    keywords = "CoUML,E2ML,PoEML,Visual notations,cognitive effectiveness,instructional design,visual design languages",
    pages = "359--373"
}

@article{Fisher2010,
    author = "Fisher, Danyel and Drucker, Steven M and Fernandez, Roland and Ruble, Scott",
    doi = "10.1109/TVCG.2010.222",
    title = "{Visualizations everywhere: a multiplatform infrastructure for linked visualizations.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/20975154",
    abstract = "In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting JavaScript from within an application and providing a standard data and events interchange. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.",
    issn = "1077-2626",
    number = "6",
    pages = "1157--63",
    volume = "16",
    file = "::",
    year = "2010",
    pmid = "20975154",
    journal = "IEEE transactions on visualization and computer graphics"
}

@article{Flanagan2002,
    author = "Flanagan, Cormac and Leino, K. Rustan M. and Lillibridge, Mark and Nelson, Greg and Saxe, James B. and Stata, Raymie",
    doi = "10.1145/543552.512558",
    isbn = "1-58113-463-0",
    title = "{Extended static checking for Java}",
    url = "http://dl.acm.org/citation.cfm?id=543552.512558",
    journal = "ACM SIGPLAN Notices",
    issn = "03621340",
    number = "5",
    month = "5",
    volume = "37",
    year = "2002",
    keywords = "compile-time program checking",
    pages = "234"
}

@article{Flinn1999,
    author = "Flinn, Jason and Satyanarayanan, M.",
    publisher = "ACM Press",
    doi = "10.1145/319344.319155",
    isbn = "1-58113-140-2",
    title = "{Energy-aware adaptation for mobile applications}",
    url = "http://dl.acm.org/citation.cfm?id=319344.319155 http://portal.acm.org/citation.cfm?id=319344.319155 http://dl.acm.org/citation.cfm?id=319151.319155",
    year = "1999",
    abstract = "In this paper, we demonstrate that a collaborative relationship between the operating system and applications can be used to meet user-specified goals for battery duration. We first show how applications can dynamically modify their behavior to conserve energy. We then show how the Linux operating system can guide such adaptation to yield a battery-life of desired duration. By monitoring energy supply and demand, it is able to select the correct tradeoff between energy conservation and application quality. Our evaluation shows that this approach can meet goals that extend battery life by as much as 30\%.",
    issn = "01635980",
    mendeley-tags = "adaption,energy,odyssey,power,powerscope",
    number = "5",
    month = "12",
    volume = "33",
    pages = "48--63",
    file = "::",
    address = "New York, New York, USA",
    keywords = "adaption,energy,odyssey,power,powerscope",
    journal = "ACM SIGOPS Operating Systems Review"
}

@inproceedings{Flinn1999c,
    author = "Flinn, J. and Satyanarayanan, M.",
    publisher = "IEEE",
    doi = "10.1109/MCSA.1999.749272",
    isbn = "0-7695-0025-0",
    title = "{PowerScope: a tool for profiling the energy usage of mobile applications}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=749272",
    abstract = "We describe the design and implementation of PowerScope, a tool for profiling energy usage by applications. PowerScope maps energy consumption to program structure, in much the same way that CPU profilers map processor cycles to specific processes and procedures. Our approach combines hardware instrumentation to measure current level with kernel software support to perform statistical sampling of system activity. Postprocessing software maps the sample data to program structure and produces a profile of energy usage by process and procedure. Using PowerScope, we have been able to reduce the energy consumption of an adaptive video playing application by 46\%",
    pages = "2--10",
    file = "::",
    year = "1999",
    booktitle = "Proceedings WMCSA'99. Second IEEE Workshop on Mobile Computing Systems and Applications"
}

@inproceedings{Florencio2007,
    author = "Flor\^{e}ncio, Dinei and Herley, Cormac",
    publisher = "ACM",
    doi = "10.1145/1242572.1242661",
    isbn = "9781595936547",
    title = "{A large-scale study of web password habits}",
    url = "http://dl.acm.org/citation.cfm?id=1242661 http://doi.acm.org/10.1145/1242572.1242661",
    booktitle = "Proceedings of the 16th International Conference on World Wide Web",
    year = "2007",
    file = ":home/drt24/Downloads/p657-florencio.pdf:pdf",
    address = "Banff, Alberta, Canada",
    keywords = "authentication,measurements,password",
    pages = "657----666"
}

@article{Florencio2010,
    author = "Florencio, Dinei and Herley, Cormac",
    title = "{Where do security policies come from?}",
    url = "http://dl.acm.org/citation.cfm?id=1837110.1837124",
    abstract = "We examine the password policies of 75 different web- sites. Our goal is understand the enormous diversity of requirements: some will accept simple six-character passwords, while others impose rules of great complex- ity on their users. We compare different features of the sites to find which characteristics are correlated with stronger policies. Our results are surprising: greater security demands do not appear to be a factor. The size of the site, the number of users, the value of the assets protected and the frequency of attacks show no correlation with strength. In fact we find the reverse: some of the largest, most attacked sites with greatest assets allow relatively weak passwords. Instead, we find that those sites that accept advertising, purchase spon- sored links and where the user has a choice show strong inverse correlation with strength. We conclude that the sites with the most restrictive password policies do not have greater security concerns, they are simply better insulated from the consequences of poor usability. Online retailers and sites that sell ad- vertising must compete vigorously for users and traffic. In contrast to government and university sites, poor us- ability is a luxury they cannot afford. This in turn sug- gests that much of the extra strength demanded by the more restrictive policies is superfluous: it causes con- siderable inconvenience for negligible security improve- ment.",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Florencio, Herley - 2010 - Where do security policies come from.pdf:pdf",
    year = "2010",
    journal = "Symposium on Usable Privacy and Security"
}

@online{Forristal2013,
    author = "Forristal, Jeff",
    title = "{Uncovering Android Master Key That Makes 99\% of Devices Vulnerable}",
    url = "https://bluebox.com/technical/uncovering-android-master-key-that-makes-99-of-devices-vulnerable/",
    abstract = "The Bluebox Security research team – Bluebox Labs – recently discovered a vulnerability in Android’s security model that allows a hacker to modify APK code without breaking an application’s cryptographic signature, to turn any legitimate application into a malicious Trojan, completely unnoticed by the app store, the phone, or the end user. The implications are huge! This vulnerability, around at least since the release of Android 1.6 (codename: “Donut” ), could affect any Android phone released in the last 4 years1 – or nearly 900 million devices2– and depending on the type of application, a hacker can exploit the vulnerability for anything from data theft to creation of a mobile botnet. While the risk to the individual and the enterprise is great (a malicious app can access individual data, or gain entry into an enterprise), this risk is compounded when you consider applications developed by the device manufacturers (e.g. HTC, Samsung, Motorola, LG) or third-parties that work in cooperation with the device manufacturer (e.g. Cisco with AnyConnect VPN) – that are granted special elevated privileges within Android – specifically System UID access.",
    year = "2013",
    urldate = "2014-11-11",
    booktitle = "Bluebox security corporate blog"
}

@article{FrankC.EIgler,
    author = "{Frank C. EIgler}, Vara Prasad",
    url = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.1364",
    title = "{Architecture of systemtap: a Linux trace/probe tool}"
}

@article{Frattasi2006,
    author = "Frattasi, S. and Fathi, H. and Fitzek, F.H.P and Prasad, R. and Katz, M.D.",
    doi = "10.1109/MNET.2006.1580917",
    title = "{Defining 4G technology from the user's perspective}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1580917",
    abstract = {The ever-increasing growth of user demand, the limitations of the third generation of wireless mobile communication systems, and the emergence of new mobile broadband technologies on the market have brought researchers and industries to a thorough reflection on the fourth generation. Many prophetic visions have appeared in the literature presenting 4G as the ultimate boundary of wireless mobile communication without any limit to its potential, but in practical terms not giving any design rules and thus any definition of it. In this article we give a pragmatic definition of 4G derived from a new user-centric methodology that considers the user as the "cornerstone" of the design. In this way, we devise fundamental user scenarios that implicitly reveal the key features of 4G, which are then expressed explicitly in a new framework - the "user-centric" system - that describes the various level of interdependency among them. This approach consequently contributes to the identification of the real technical step-up of 4G with respect to 3G. Finally, an example of a potential 4G application is also given in order to demonstrate the validity of the overall methodology},
    issn = "0890-8044",
    number = "1",
    month = "1",
    volume = "20",
    pages = "35--41",
    year = "2006",
    journal = "IEEE Network"
}

@article{Frederick1986,
    author = "Frederick, Peter J.",
    title = "{The Lively Lecture: 8 Variations}",
    journal = "College Teaching",
    mendeley-tags = "teaching",
    number = "2",
    volume = "34",
    file = "::",
    year = "1986",
    keywords = "teaching",
    pages = "43--50"
}

@inproceedings{Freeman2007,
    author = "Freeman, Isaac J and Plimmer, Beryl",
    title = "{Connector Semantics for Sketched Diagram Recognition}",
    abstract = "Comprehensive interpretation of hand-drawn diagrams is a long-standing challenge. Connectors (arrows, edges and lines) are important components of many types of diagram. In this paper we discuss techniques for syntactic and semantic recognition of connectors. Undirected graphs, digraphs and organization charts are presented as exemplars of three broad classes that encompass many types of connected diagram. Generic techniques have been incorporated into the recognition engine of InkKit, an extensible sketch toolkit, thus reducing the development costs for sketch tools.",
    year = "2007",
    volume = "64",
    file = "::",
    address = "Ballarat, Victoria, Australia",
    keywords = "connector semantics,execution,in many of these,progress has been reported,sketch recognition,sketched diagrams",
    booktitle = "Proceedings of the eight Australasian conference on User interface",
    pages = "71--78"
}

@book{Freeman2009,
    author = "Freeman, S and Pryce, N",
    publisher = "Addison-Wesley Professional",
    isbn = "9780321503626",
    title = "{Growing Object-Oriented Software, Guided by Tests}",
    url = "http://portal.acm.org/citation.cfm?id=1655852",
    abstract = {Michael Feathers Test-Driven Development (TDD) is now an established technique for delivering better software faster. TDD is based on a simple idea: Write tests for your code before you write the code itself. However, this "simple" idea takes skill and judgment to do well. Now there's a practical guide to TDD that takes you beyond the basic concepts. Drawing on a decade of experience building real-world systems, two TDD pioneers show how to let tests guide your development and "grow" software that is coherent, reliable, and maintainable. Steve Freeman and Nat Pryce describe the processes they use, the design principles they strive to achieve, and some of the tools that help them get the job done. Through an extended worked example, you'll learn how TDD works at multiple levels, using tests to drive the features and the object-oriented structure of the code, and using Mock Objects to discover and then describe relationships between objects. Along the way, the book systematically addresses challenges that development teams encounter with TDD-from integrating TDD into your processes to testing your most difficult features.},
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freeman, Pryce - 2009 - Growing Object-Oriented Software, Guided by Tests.pdf:pdf",
    year = "2009",
    pages = "384"
}

@inproceedings{Frei2006,
    author = "Frei, Stefan and May, Martin and Fiedler, Ulrich and Plattner, Bernhard",
    publisher = "ACM",
    isbn = "1595934170",
    title = "{Large-scale vulnerability analysis}",
    url = "http://dl.acm.org/citation.cfm?id=1162671",
    abstract = "The security level of networks and systems is determined by the software vulnerabilities of its elements. Defending against large scale attacks requires a quantitative understanding ofthe vulnerability lifecycle. Specifically, one has to understand how exploitation and remediation of vulnerabilities, as well as the distribution of information thereof is handled by industry. In this paper, we examine how vulnerabilities are handled in large-scale, analyzing more than 80,000 security advisories published since 1995. Based on this information,we quantify the performance of the security industry as a whole. We discover trends and discuss their implications. We quantify the gap between exploit and patch availability and provide an analytical representation of our data which lays the foundation for further analysis and risk management",
    month = "9",
    file = ":home/drt24/Downloads/p131-frei.pdf:pdf",
    year = "2006",
    booktitle = "SIGCOMM workshop on Large-scale attack \ldots",
    pages = "131--138"
}

@article{Frei2008,
    author = "Frei, Stefan and Duebendorfer, Thomas and Plattner, Bernhard",
    publisher = "ACM",
    title = "{Firefox (in)security update dynamics exposed}",
    journal = "ACM SIGCOMM Computer Communication Review",
    abstract = "Although there is an increasing trend for attacks against popularWeb browsers, only little is known about the actual patch level of daily used Web browsers on a global scale. We conjecture that users in large part do not actually patch their Web browsers based on recommendations, perceived threats, or any security warnings. Based on HTTP user- agent header information stored in anonymized logs from Google’s web servers, we measured the patch dynamics of about 75\% of the world’s Internet users for over a year. Our focus was on the Web browsers Firefox and Opera. We found that the patch level achieved is mainly determined by the ergonomics and default settings of built-in auto-update mechanisms. Firefox’ auto-update is very effective: most users installed a new version within three days. However, the maximum share of the latest, most secure version never exceeded 80\% for Firefox users and 46\% for Opera users at any day in 2007. This makes about 50 million Firefox users with outdated browsers an easy target for attacks. Our study is the result of the first global scale measurement of the patch dynamics of a popular browser.",
    number = "1",
    volume = "39",
    url = "http://dl.acm.org/citation.cfm?id=1496094",
    file = ":home/drt24/Downloads/p16-frei.pdf:pdf",
    year = "2008",
    pages = "16--22"
}

@article{Frei2008a,
    author = "Frei, Stefan and May, Martin",
    title = "{Putting private and government CERT’s to the test}",
    url = "http://www.techzoom.net/papers/first08_cert_analysis_2008.pdf",
    abstract = "To be able to take notice of newvulnerabilities, business and enterprizes need accurate and validated information from a trusted source. CERT’s and private sector service offerings provide such information through the publication of vulner- ability advisories. The quality, quantity, and disclosure time of such advisories varies considerably between sources. By monitoring relevant security sites on 30-minute intervals for more than 18 months, we collected a unique dataset to com- pare CERT’s and private offerings. In addition, we also col- lected data from well known exploit sites. As an independent research institute, we present an un- biased analysis of the performance of CERT’s and security information providers from the private sector. We show the evolution of the number of disclosures, number of references to CVE, the risk metrics used, and the timeliness of publica- tion over the year, day of week and time of day. Correlat- ing the advisories based on the CVE as a unique vulnera- bility identifier allows us to compare the advisory providers against each other. Further, we compare the advisory data with the rate of exploit publications.We find differences be- tween the advisory providers and offer an interpretation.We revisit the vulnerability lifecycle with respect to our findings and examine their impact in the context of the full disclo- sure debate. We conclude that having multiple independent advisory providers is very important to the security society. Collectively, they serve as an efficient watchdog monitoring the (in)security scene, providing thread information in a us- able format for businesses.",
    file = ":home/drt24/Downloads/first08\_cert\_analysis\_2008.pdf:pdf",
    year = "2008",
    journal = "20th Annual FIRST Conference"
}

@phdthesis{Frei2009,
    author = "Frei, Stefan",
    school = "ETH Zurich",
    isbn = "9781439254097",
    title = "{Security econometrics: The dynamics of (in)security}",
    url = "http://dl.acm.org/citation.cfm?id=1803642",
    abstract = "Global Internet penetration and e-commerce have grown explosively over the past years. Today, information technology has become a backbone of our industry and everyday life. We would intuitively expect such an important technology to be well- monitored and protected. However, no one would dispute that the constant discovery of new vulnerabilities drives the security risks we are constantly exposed to. As risk awareness is an essential factor in human decision making, we are in need of metrics to measure and monitor the risk exposure of our networked economy and society. Research on the economic consequences of cyber attacks has dealt primarily with microanalysis of specific events, technologies or targeted organizations. The measurement of the cumulated number of disclosed vulnerabilities over time is an interesting and often cited indicator of the increasing risk exposure. However, this measure alone is not sufficient for an analysis or understanding of the processes driving risk exposure. Accurate knowledge of the vulnerability discovery-, exploit-, disclosure-, and patch-time (the lifecycle of a vulnerability) allows one to identify different types of risk and to quantify the risk exposure and evolution thereof at global scale. A metric based on the vulnerability lifecycle is vital to better understand the security ecosystem. We build a comprehensive dataset of 30,000 vulnerabilities publicly disclosed since 1996 to reconstruct the vulnerability lifecycle. Based on this data we analyze the risk exposure and evolution thereof from a macroeconomic perspective.",
    number = "18197",
    file = ":home/drt24/Downloads/eth\_dissertation\_stefan\_frei\_2009.pdf:pdf",
    year = "2009",
    keywords = "EGI0806,browser,business,commercial,computer,criminal,cyber,cybercrime,debate,disclosure,discovery,ecosystem,exploit,legal,lifecycle,malware,market,milw0rm,model,patch,plugin,risk,secure,security,software,threat,underground,update,vulnerability,zero-day",
    booktitle = "ETH Zurich"
}

@incollection{Frei2010,
    author = "Frei, Stefan and Schatzmann, Dominik and Plattner, Bernhard and Trammell, Brian",
    chapter = "6",
    publisher = "Springer",
    doi = "10.1007/978-1-4419-6967-5_6",
    isbn = "978-1-4419-6967-5",
    title = "{Modeling the Security Ecosystem -- The Dynamics of (In)Security}",
    url = "http://dx.doi.org/10.1007/978-1-4419-6967-5_6",
    abstract = "The security of information technology and computer networks is effected by a wide variety of actors and processes which together make up a security ecosystem; here we examine this ecosystem, consolidating many aspects of security that have hitherto been discussed only separately. First, we analyze the roles of the major actors within this ecosystem and the processes they participate in, and the the paths vulnerability data take through the ecosystem and the impact of each of these on security risk. Then, based on a quantitative examination of 27,000 vulnerabilities disclosed over the past decade and taken from publicly available data sources, we quantify the systematic gap between exploit and patch availability. We provide the first examination of the impact and the risks associated with this gap on the ecosystem as a whole. Our analysis provides a metric for the success of the responsible disclosure process. We measure the prevalence of the commercial markets for vulnerability information and highlight the role of security information providers (SIP), which function as the free press of the ecosystem.",
    pages = "79--106",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-1-4419-6967-5\_6.pdf:pdf",
    year = "2010",
    booktitle = "Economics of Information Security and Privacy"
}

@article{Freire2008,
    author = "Freire, Juliana and Koop, David and Santos, Emanuele and Silva, Cl",
    publisher = "IEEE Computer Society",
    doi = "10.1109/MCSE.2008.79",
    title = "{Provenance for Computational Tasks: A Survey}",
    url = "http://doi.ieeecomputersociety.org/plugins/dl/doi/10.1109/MCSE.2008.79 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4488060",
    journal = "Computing in Science \& Engineering",
    issn = "1521-9615",
    number = "3",
    month = "5",
    volume = "10",
    file = "::",
    year = "2008",
    pages = "11--21"
}

@article{Frew2008,
    author = "Frew, James and Metzger, Dominic and Slaughter, Peter",
    publisher = "Wiley Online Library",
    title = "{Automatic capture and reconstruction of computational provenance}",
    url = "http://onlinelibrary.wiley.com/doi/10.1002/cpe.1247/full",
    journal = "Concurrency and Computation: Practice and Experience",
    number = "5",
    volume = "20",
    file = "::",
    year = "2008",
    keywords = "es3,instrumentation,lineage,passive,provenance,transparency",
    pages = "485--496"
}

@book{Froehlich2007a,
    author = "Froehlich, Jon and Chen, Mike Y. and Consolvo, Sunny and Harrison, Beverly and Landay, James A.",
    publisher = "ACM Press",
    doi = "10.1145/1247660.1247670",
    isbn = "9781595936141",
    title = "{MyExperience: a system for in situ tracing and capturing of user feedback on mobile phones}",
    url = "http://dl.acm.org/citation.cfm?id=1247660.1247670",
    abstract = "This paper presents MyExperience, a system for capturing both objective and subjective in situ data on mobile computing activities. MyExperience combines the following two techniques: 1) passive logging of device usage, user context, and environmental sensor readings, and 2) active context-triggered user experience sampling to collect in situ, subjective user feedback. MyExperience currently runs on mobile phones and supports logging of more than 140 event types, including: 1) device usage such as communication, application usage, and media capture, 2) user context such as calendar appointments, and 3) environmental sensing such as Bluetooth and GPS. In addition, user experience sampling can be targeted to moments of interest by triggering off sensor readings. We present several case studies of field deployments on people's personal phones to demonstrate how MyExperience can be used effectively to understand how people use and experience mobile technology.",
    year = "2007",
    month = "6",
    pages = "57",
    file = "::",
    address = "New York, New York, USA",
    keywords = "SmartPhones,context-aware systems,experience sampling method (ESM),field studies,in situ evaluation,mobile computing,toolkit,usage logging,user surveys,user-centered design",
    booktitle = "Proceedings of the 5th international conference on Mobile systems, applications and services - MobiSys '07"
}

@inproceedings{GaborKusperGergelyKovasznaiWolfgangSchreinerGaborGuta2010,
    author = "{Gabor Kusper, Gergely Kovasznai, Wolfgang Schreiner, Gabor Guta}, Janos Sztrik",
    booktitle = "8th international conference on applied informatics",
    year = "2010",
    title = "{A small survey of Java specification languages}"
}

@article{Galak2010,
    author = "Galak, Jeff and Nelson, Leif D.",
    publisher = "Elsevier Inc.",
    doi = "10.1016/j.jesp.2010.08.002",
    title = "{The virtues of opaque prose: How lay beliefs about fluency influence perceptions of quality}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S0022103110001745",
    abstract = "Instructors tell their students to write clearly. This prescription meshes with our intuition, wins confirmation in scores of books on writing, and finds empirical confirmation in research on perceptual fluency: People like content that is easy to process. Nevertheless, in some circumstances people expect content to be difficult, and ease might be interpreted as a lack of quality. We investigate this possibility by asking people to judge the quality of written text which varies in fluency (through the manipulation of font and facial feedback). Across three studies, disfluent content was judged to be of higher quality when it was thought to come from a source focused on conveying information than one designed to maximize enjoyment.",
    issn = "00221031",
    number = "1",
    month = "1",
    volume = "47",
    pages = "250--253",
    file = ":home/drt24/Downloads/1-s2.0-S0022103110001745-main.pdf:pdf",
    year = "2010",
    keywords = "Fluency,Meta-cognition,Reading,Writing",
    journal = "Journal of Experimental Social Psychology"
}

@article{Galak2011,
    author = "Galak, Jeff and Nelson, Leif D.",
    publisher = "Elsevier Inc.",
    doi = "10.1016/j.jesp.2010.08.002",
    title = "{The virtues of opaque prose: How lay beliefs about fluency influence perceptions of quality}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S0022103110001745",
    abstract = "Instructors tell their students to write clearly. This prescription meshes with our intuition, wins confirmation in scores of books on writing, and finds empirical confirmation in research on perceptual fluency: People like content that is easy to process. Nevertheless, in some circumstances people expect content to be difficult, and ease might be interpreted as a lack of quality. We investigate this possibility by asking people to judge the quality of written text which varies in fluency (through the manipulation of font and facial feedback). Across three studies, disfluent content was judged to be of higher quality when it was thought to come from a source focused on conveying information than one designed to maximize enjoyment.",
    issn = "00221031",
    number = "1",
    month = "1",
    volume = "47",
    pages = "250--253",
    file = ":home/drt24/Downloads/1-s2.0-S0022103110001745-main.pdf:pdf",
    year = "2011",
    keywords = "Fluency,Meta-cognition,Reading,Writing",
    journal = "Journal of Experimental Social Psychology"
}

@inproceedings{Ganti2010,
    author = "Ganti, Raghu K. and Pham, Nam and Ahmadi, Hossein and Nangia, Saurabh and Abdelzaher, Tarek F.",
    isbn = "9781605589855",
    title = "{GreenGPS: A participatory sensing fuel-efficient maps application}",
    url = "http://dl.acm.org/citation.cfm?id=1814450",
    booktitle = "Proceedings of the 8th international conference on Mobile systems, applications, and services (MobiSys2010)",
    file = "::",
    year = "2010",
    keywords = "green gps,green navigation,model,participatory sensing"
}

@inproceedings{Gao2009,
    author = "Gao, Ge and Whitehouse, Kamin",
    isbn = "9781605588247",
    title = "{The Self-Programming Thermostat : Optimizing Setback Schedules based on Home Occupancy Patterns}",
    abstract = "Programmable thermostats offer large potential energy savings without sacrificing comfort, but only if setback schedules are defined correctly. We present the concept of a self-programming thermostat that automatically creates an optimal setback schedule by sensing the occupancy statistics of a home. The system monitors occupancy using simple sensors in the home, similar to those already used in typi- cal security systems, and the user defines the desired balance between energy and comfort using a single, intuitive knob. Our preliminary results show that this approach can reduce heating and cooling demand by up to 15\% over the default setback schedule recommended by EnergyStar.",
    mendeley-tags = "Design,Economics,Experimentation,Human Factors",
    file = ":home/drt24/Library/papers/BuildSys/Gao, Whitehouse/Gao, Whitehouse - 2009 - The Self-Programming Thermostat Optimizing Setback Schedules based on Home Occupancy Patterns.pdf:pdf",
    year = "2009",
    keywords = "Design,Economics,Experimentation,Human Factors,building energy,home monitoring,mostats,programmable ther-,wireless sensor networks",
    booktitle = "BuildSys"
}

@article{Garlan2009,
    author = "Garlan, D and Allen, R and Ockerbloom, J",
    publisher = "IEEE Computer Society Press",
    doi = "10.1109/MS.2009.86",
    title = "{Architectural Mismatch: Why Reuse Is Still So Hard}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5076461",
    abstract = {In this article, David Garlan, Robert Allen, and John Ockerbloom reflect on the state of architectural mismatch, a term they coined in their 1995 IEEE Software article, "Architectural Mismatch: Why Reuse Is So Hard." Although the nature of software systems has changed dramatically since the earlier article was published, the challenge of architectural mismatch remains an important concern for the software engineering field.},
    issn = "07407459",
    number = "4",
    pages = "66--69",
    volume = "26",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garlan, Allen, Ockerbloom - 2009 - Architectural Mismatch Why Reuse Is Still So Hard.pdf:pdf",
    year = "2009",
    keywords = "architecture mismatch,component based systems,software architecture,software engineering",
    journal = "IEEE Software"
}

@article{Gascon2011,
    author = "Gascon, Hugo and Orfila, Agustin and Blasco, Jorge",
    publisher = "Elsevier Ltd",
    doi = "10.1016/j.cose.2011.08.010",
    title = "{Analysis of update delays in signature-based network intrusion detection systems}",
    url = "http://dx.doi.org/10.1016/j.cose.2011.08.010 http://www.sciencedirect.com/science/article/pii/S0167404811001106",
    abstract = "Network Intrusion Detection Systems (NIDS) play a fundamental role on security policy deployment and help organizations in protecting their assets from network attacks. Signature-based NIDS rely on a set of known patterns to match malicious traffic. Accord- ingly, they are unable to detect a specific attack until a specific signature for the corre- sponding vulnerability is created, tested, released and deployed. Although vital, the delay in the updating process of these systems has not been studied in depth. This paper pres- ents a comprehensive statistical analysis of this delay in relation to the vulnerability disclosure time, the updates of vulnerability detection systems (VDS), the software patching releases and the publication of exploits. The widely deployed NIDS Snort and its detection signatures release dates have been used. Results show that signature updates are typically available later than software patching releases. Moreover, Snort rules are generally released within the first 100 days from the vulnerability disclosure and most of the times exploits and the corresponding NIDS rules are published with little difference. Implications of these results are drawn in the context of security policy definition. This study can be easily kept up to date due to the methodology used.",
    issn = "0167-4048",
    number = "8",
    pages = "613--624",
    volume = "30",
    file = ":home/drt24/Downloads/1-s2.0-S0167404811001106-main.pdf:pdf",
    year = "2011",
    journal = "Computers \& Security"
}

@article{Gates2009,
    author = "Gates, Alan F and Natkovich, Olga and Chopra, Shubham and Kamath, Pradeep and Narayanamurthy, Shravan M and Olston, Christopher and Reed, Benjamin and Srinivasan, Santhosh and Srivastava, Utkarsh",
    publisher = "VLDB Endowment",
    isbn = "0000000000000",
    title = "{Building a High-Level Dataflow System on top of Map-Reduce : The Pig Experience}",
    url = "http://portal.acm.org/citation.cfm?id=1687568",
    abstract = "Increasingly, organizations capture, transform and analyze enormous data sets. Prominent examples include internet companies and e-science. The Map-Reduce scalable dataflow paradigm has become popular for these applications. Its simple, explicit dataflow programming model is favored by some over the traditional high-level declarative approach: SQL. On the other hand, the extreme simplicity of Map-Reduce leads to much low-level hacking to deal with the many-step, branching dataflows that arise in practice. Moreover, users must repeatedly code standard operations such as join by hand. These practices waste time, introduce bugs, harm readability, and impede optimizations. Pig is a high-level dataflow system that aims at a sweet spot between SQL and Map-Reduce. Pig offers SQL-style high-level data manipulation constructs, which can be assembled in an explicit dataflow and interleaved with custom Map- and Reduce-style functions or executables. Pig programs are compiled into sequences of Map-Reduce jobs, and executed in the Hadoop Map-Reduce environment. Both Pig and Hadoop are open-source projects administered by the Apache Software Foundation. This paper describes the challenges we faced in developing Pig, and reports performance comparisons between Pig execution and raw Map-Reduce execution.",
    issn = "21508097",
    number = "2",
    pages = "1414--1425",
    volume = "2",
    file = ":home/drt24/Downloads/p1414-gates.pdf:pdf",
    year = "2009",
    journal = "Proceedings of the VLDB Endowment"
}

@article{Gentry2002,
    author = "Gentry, Craig and Szydlo, Mike",
    doi = "10.1007/3-540-46035-7_20",
    isbn = "978-3-540-43553-2",
    title = "{Cryptanalysis of the revised NTRU signature scheme}",
    url = "http://link.springer.com/chapter/10.1007/3-540-46035-7_20",
    abstract = "In this paper, we describe a three-stage attack against Revised NSS, an NTRU-based signature scheme proposed at the Eurocrypt 2001 conference as an enhancement of the (broken) proceedings version of the scheme. The first stage, which typically uses a transcript of only 4 signatures, effectively cuts the key length in half while completely avoiding the intended hard lattice problem. After an empirically fast second stage, the third stage of the attack combines lattice-based and congruence-based methods in a novel way to recover the private key in polynomial time. This cryptanalysis shows that a passive adversary observing only a few valid signatures can recover the signer’s entire private key. We also briefly address the security of NTRUSign, another NTRU-based signature scheme that was recently proposed at the rump session of Asiacrypt 2001. As we explain, some of our attacks on Revised NSS may be extended to NTRUSign, but a much longer transcript is necessary. We also indicate how the security of NTRUSign is based on the hardness of several problems, not solely on the hardness of the usual NTRU lattice problem.",
    pages = "299--320",
    volume = "2332",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F3-540-46035-7\_20.pdf:pdf",
    year = "2002",
    keywords = "cryptanalysis,cyclotomic integer,duction,galois,lattice re-,nss,ntru,ntrusign,orthogonal lattice,signature scheme",
    journal = "Advances in Cryptology—EUROCRYPT 2002"
}

@inproceedings{Gentry2009,
    author = "Gentry, Craig",
    isbn = "9781605585062",
    title = "{Fully Homomorphic Encryption Using Ideal Lattices}",
    abstract = "We propose a fully homomorphic encryption scheme – i.e., a scheme that allows one to evaluate circuits over encrypted data without being able to decrypt. Our solution comes in three steps. First, we provide a general result – that, to construct an encryption scheme that permits evaluation of arbitrary circuits, it suffices to construct an encryption scheme that can evaluate (slightly augmented versions of) its own decryption circuit; we call a scheme that can evaluate its (augmented) decryption circuit bootstrappable. Next, we describe a public key encryption scheme using ideal lattices that is almost bootstrappable. Lattice-based cryptosystems typically have decryption algorithms with low circuit complexity, often dominated by an inner product computation that is in NC1. Also, ideal lattices provide both additive and multiplicative homomorphisms (modulo a public-key ideal in a polynomial ring that is represented as a lattice), as needed to evaluate general circuits. Unfortunately, our initial scheme is not quite bootstrap- pable – i.e., the depth that the scheme can correctly evalu- ate can be logarithmic in the lattice dimension, just like the depth of the decryption circuit, but the latter is greater than the former. In the final step, we show how to modify the scheme to reduce the depth of the decryption circuit, and thereby obtain a bootstrappable encryption scheme, with- out reducing the depth that the scheme can evaluate. Ab- stractly, we accomplish this by enabling the encrypter to start the decryption process, leaving less work for the de- crypter, much like the server leaves less work for the de- crypter in a server-aided cryptosystem.",
    pages = "169--178",
    file = ":auto/homes/drt24/Downloads/p169-gentry.pdf:pdf",
    year = "2009",
    keywords = "Algorithms,Design,Public key cryptosystems,Security,Theory",
    booktitle = "STOC"
}

@article{Georgiev2014,
    author = "Georgiev, Martin and Jana, Suman and Shmatikov, Vitaly",
    publisher = "Internet Society",
    doi = "10.14722/ndss.2014.23323",
    isbn = "1891562355",
    title = "{Breaking and Fixing Origin-Based Access Control in Hybrid Web/Mobile Application Frameworks}",
    url = "http://www.cs.utexas.edu/users/shmat/shmat_ndss14nofrak.pdf",
    abstract = "Hybrid mobile applications (apps) combine the features of Web applications and “native” mobile apps. Like Web applications, they are implemented in portable, platform- independent languages such as HTML and JavaScript. Like native apps, they have direct access to local device resources—file system, location, camera, contacts, etc. Hybrid apps are typically developed using hybrid application frameworks such as PhoneGap. The purpose of the framework is twofold. First, it provides an embedded Web browser (for example,WebView on Android) that executes the app’sWeb code. Second, it supplies “bridges” that allow Web code to escape the browser and access local resources on the device. We analyze the software stack created by hybrid frameworks and demonstrate that it does not properly compose the access- control policies governing Web code and local code, respectively. Web code is governed by the same origin policy, whereas local code is governed by the access-control policy of the operating system (for example, user-granted permissions in Android). The bridges added by the framework to the browser have the same local access rights as the entire application, but are not correctly protected by the same origin policy. This opens the door to fracking attacks, which allow foreign-origin Web content included into a hybrid app (e.g., ads confined in iframes) to drill through the layers and directly access device resources. Fracking vulnerabilities are generic: they affect all hybrid frameworks, all embedded Web browsers, all bridge mechanisms, and all platforms on which these frameworks are deployed. We study the prevalence of fracking vulnerabilities in free Android apps based on the PhoneGap framework. Each vul- nerability exposes sensitive local resources—the ability to read and write contacts list, local files, etc.—to dozens of potentially maliciousWeb domains.We also analyze the defenses deployed by hybrid frameworks to prevent resource access by foreign-origin Web content and explain why they are ineffectual. We then present NOFRAK, a capability-based defense against fracking attacks. NOFRAK is platform-independent, compatible with any framework and embedded browser, requires no changes to the code of the existing hybrid apps, and does not break their advertising-supported business model. I.",
    file = ":home/drt24/Downloads/shmat\_ndss14nofrak (1).pdf:pdf",
    year = "2014",
    journal = "NDSS"
}

@inproceedings{Gersch2012,
    author = "Gersch, Joe and Massey, Dan",
    title = "{Reverse-DNS Naming Convention for CIDR Address Blocks}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Gersch.pdf http://conferences.npl.co.uk/satin/presentations/satin2012slides-Massey.pdf",
    abstract = "Reverse DNS is the inverse naming technique that maps an IPv4 or IPv6 address to a domain name. The current reverse DNS naming method is used to specify a complete IP address. Currently, it cannot be used to handle address ranges. For example, there is no formal mechanism for specifying a reverse DNS name for the block of addresses specified by the IPv4 prefix 129.82.0.0/16. Defining such a reverse-DNS naming convention would be useful for a number of applications. These include applications for secure BGP routing, applications that need host-information for a device owning a complete IPv6 address block, and others. There are various subtleties, advantages and disadvantages that emerge when trying to define an optimal naming technique. The remainder of this paper illustrates these issues and concludes with a recommended reverse-DNS naming convention.",
    pages = "1--12",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Massey.pdf:pdf;:auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Gersch.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@article{Ghemawat2003,
    author = "Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak",
    doi = "10.1145/1165389.945450",
    isbn = "1581137575",
    title = "{The Google file system}",
    url = "http://portal.acm.org/citation.cfm?doid=1165389.945450",
    abstract = "We have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use.",
    issn = "01635980",
    number = "5",
    month = "12",
    volume = "37",
    pages = "29",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghemawat, Gobioff, Leung - 2003 - The Google file system.pdf:pdf",
    year = "2003",
    keywords = "clustered storage,data storage,fault tolerance,scalability",
    journal = "ACM SIGOPS Operating Systems Review"
}

@inproceedings{Ghinita2009,
    author = "Ghinita, Gabriel and Damiani, Maria Luisa and Silvestri, Claudio and Bertino, Elisa",
    publisher = "ACM",
    doi = "10.1145/1653771.1653807",
    isbn = "9781605586496",
    title = "{Preventing Velocity ­ based Linkage Attacks in Location ­ Aware Applications Categories and Subject Descriptors}",
    url = "http://dl.acm.org/citation.cfm?id=1653807",
    abstract = "Mobile devices with positioning capabilities allow users to partic- ipate in novel and exciting location-based applications. For in- stance, users may track the whereabouts of their acquaintances in location-aware social networking applications, e.g., GoogleLati- tude. Furthermore, users can request information about landmarks in their proximity. Such scenarios require users to report their co- ordinates to other parties, which may not be fully trusted. Report- ing precise locations may result in serious privacy violations, such as disclosure of lifestyle details, sexual orientation, etc. A typical approach to preserve location privacy is to generate a cloaking re- gion �CR) that encloses the user position. However, if locations are continuously reported, an attacker can correlate CRs from multiple timestamps to accurately pinpoint the user position within a CR. In this work, we protect against linkage attacks that infer exact locations based on prior knowledge about maximum user velocity. Assume user u who reports two consecutive cloaked regions Aand B. We consider two distinct protection scenarios: in the first case, the attacker does not have information about the sensitive locations on the map, and the objective is to ensure that u can reach some point in B from any point in A. In the second case, the attacker knows the placement of sensitive locations, and the objective is to ensure that u can reach any point inB from any point inA. We pro- pose spatial and temporal cloaking transformations to preserve user privacy, and we show experimentally that privacy can be achieved without significant quality of service deterioration.",
    year = "2009",
    pages = "246--255",
    file = ":home/drt24/Downloads/p246-ghinita.pdf:pdf",
    address = "Seattle",
    keywords = "all or part of,is granted without fee,location privacy,location-aware social networks,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for",
    booktitle = "GIS"
}

@book{Giannakopoulou2012,
    editor = "Giannakopoulou, Dimitra and M\'{e}ry, Dominique",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-32759-9",
    isbn = "978-3-642-32758-2",
    title = "{FM 2012: Formal Methods}",
    url = "http://www.springerlink.com/content/r302qp342755755q/",
    series = "Lecture Notes in Computer Science",
    year = "2012",
    volume = "7436",
    address = "Berlin, Heidelberg"
}

@article{Giereth2008,
    author = "Giereth, Mark and Ertl, Thomas",
    publisher = "Ieee",
    doi = "10.1109/IV.2008.36",
    isbn = "978-0-7695-3268-4",
    title = "{Design Patterns for Rapid Visualization Prototyping}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4578006",
    journal = "2008 12th International Conference Information Visualisation",
    month = "7",
    file = "::",
    year = "2008",
    pages = "569--574"
}

@inproceedings{Girardello2010,
    author = "Girardello, Andrea and Michahelles, Florian",
    publisher = "ACM Press",
    doi = "10.1145/1851600.1851698",
    isbn = "9781605588353",
    title = "{AppAware: which mobile applications are hot?}",
    url = "http://dl.acm.org/citation.cfm?id=1851600.1851698",
    abstract = "Today most mobile operating systems provide users with an application portal where they can search for applications published by third-party developers. However, finding new apps is not an easy task and requires either to know what to look for or to go through an endless list of applications. In this paper we present work in progress of a platform that allows its users to discover mobile applications in a serendipitous manner. AppAware is a mobile application that captures and shares installations, updates, and removals of Android programs in real time. Accordingly, AppAware allows its users to see what applications are being installed right now or around their position by other people, thus introducing a new way of interaction with application portals and other mobile users.",
    year = "2010",
    month = "9",
    pages = "431",
    file = "::",
    address = "New York, New York, USA",
    keywords = "AppAware,android,application portal,applications,market,mobile,social network",
    booktitle = "Proceedings of the 12th international conference on Human computer interaction with mobile devices and services - MobileHCI '10"
}

@article{Gkantsidis2006,
    author = "Gkantsidis, Christos and Karagiannis, Thomas and Vojnovi\'{c}, Milan",
    doi = "10.1145/1151659.1159961",
    isbn = "1595933085",
    title = "{Planet scale software updates}",
    abstract = "Fast and effective distribution of software updates (a.k.a. patches) to millions of Internet users has evolved into a critical task over the last years. In this paper, we characterize “Windows Update”, one of the largest update services in the world, with the aim to draw general guidelines on how to best design and architect a fast and effective planet-scale patch dissemination system. To this end, we analyze an extensive set of data traces collected over the period of a year, consisting of billions of queries from over 300 million computers. Based on empirical observations and analytical results, we identify interesting properties of today’s update traffic and user behavior. Building on this analysis, we consider alternative patch delivery strategies such as caching and peer-to-peer and evaluate their performance. We identify key factors that determine the effectiveness of these schemes in reducing the server workload and the network traffic, and in speeding-up the patch delivery. Most of our findings are invariant properties induced by either user behavior or architectural characteristics of today’s Internet, and thus apply to the general problem of Internet-wide dissemination of software updates.",
    issn = "01464833",
    pages = "423",
    volume = "36",
    file = ":home/drt24/Downloads/p423-gkantsidis.pdf:pdf",
    year = "2006",
    keywords = "caching,peer-to-peer,software updates",
    journal = "ACM SIGCOMM Computer Communication Review"
}

@inproceedings{Glendenning2011,
    author = "Glendenning, Lisa and Beschastnikh, Ivan and Krishnamurthy, Arvind and Anderson, Thomas",
    publisher = "ACM Press",
    doi = "10.1145/2043556.2043559",
    isbn = "9781450309776",
    title = "{Scalable consistency in Scatter}",
    url = "http://dl.acm.org/citation.cfm?doid=2043556.2043559",
    abstract = "Distributed storage systems often trade off strong semantics for improved scalability. This paper describes the design, implementation, and evaluation of Scatter, a scalable and consistent distributed key-value storage system. Scatter adopts the highly decentralized and self-organizing structure of scalable peer-to-peer systems, while preserving linearizable consistency even under adverse circumstances. Our prototype implementation demonstrates that even with very short node lifetimes, it is possible to build a scalable and consistent system with practical performance.",
    year = "2011",
    pages = "15",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glendenning et al. - 2011 - Scalable consistency in Scatter.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "consistency,distributed systems,distributed transactions,fault tolerance,paxos,scalability,storage",
    booktitle = "SOSP"
}

@article{Gold1967a,
    author = "Gold, R.",
    doi = "10.1109/TIT.1967.1054048",
    title = "{Optimal binary sequences for spread spectrum multiplexing (Corresp.)}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1054048",
    abstract = "First Page of the Article",
    issn = "0018-9448",
    number = "4",
    month = "10",
    volume = "13",
    pages = "619--621",
    file = "::",
    year = "1967",
    journal = "IEEE Transactions on Information Theory"
}

@article{Goldberg1996,
    author = "Goldberg, Ian and Wagner, David",
    title = "{Randomness and the netscape browser}",
    url = "http://www.hit.bme.hu/~buttyan/courses/BMEVIHIM132/abib/03-prng/Goldberg96.pdf",
    abstract = "As the World Wide Web gains broad public appeal, companies are becoming interested in using the Web not just to advertise, but also to take orders for their merchandise and services. Since ordering a product online requires the customer to transmit payment information (such as a credit-card number) from a client program to the company's server program through the Internet, there's need for cryptographic protection. By encrypting payment information before transmitting it, a customer can ensure that no one except the company from which he is purchasing can decode that sensitive data. Netscape Communications has been at the forefront of the effort to inte-grate cryptographic techniques into Web servers and browsers. Netscape's Web browser supports the Secure Sockets Layer (SSL), a cryptographic protocol developed by Netscape to provide secure Internet transactions. Given the popularity of Netscape's browser and the widespread use of its cryptographic protocol on the Internet, we decided to study Netscape's SSL implementation in detail. Our study revealed serious flaws in Netscape's implementation of SSL that make it relatively easy for an eavesdropper to decode the encrypted communications. Although Netscape has fixed these problems in a new version of their browser (as of this writing, Netscape 2.0 beta1 and Netscape Navigator 1.22 Security Update are available), these weaknesses provide several lessons for people interested in producing or purchasing secure software.",
    file = ":home/drt24/Downloads/Goldberg96.pdf:pdf",
    year = "1996",
    journal = "Dr Dobb's Journal"
}

@article{Golle2009,
    editor = "Tokuda, Hideyuki and Beigl, Michael and Friday, Adrian and Brush, A J Bernheim and Tobe, Yoshito",
    author = "Golle, Philippe and Partridge, Kurt",
    publisher = "Springer-Verlag",
    doi = "10.1007/978-3-642-01516-8",
    isbn = "9783642015151",
    title = "{On the Anonymity of Home/Work Location Pairs}",
    url = "http://dx.doi.org/10.1007/978-3-642-01516-8_26",
    series = "Lecture Notes in Computer Science",
    abstract = "Many applications benefit from user location data, but lo- cation data raises privacy concerns. Anonymization can protect privacy, but identities can sometimes be inferred from supposedly anonymous data. This paper studies a new attack on the anonymity of location data. We show that if the approximate locations of an individuals home and workplace can both be deduced from a location trace, then the median size of the individuals anonymity set in the U.S. working population is 1, 21 and 34,980, for locations known at the granularity of a census block, census track and county respectively. The location data of people who live and work in different regions can be re-identified even more easily. Our results show that the threat of re-identification for location data is much greater when the individuals home and work locations can both be deduced from the data. To preserve anonymity, we offer guidance for obfuscating location traces before they are disclosed.",
    pages = "390--397",
    volume = "5538",
    file = ":auto/homes/drt24/Downloads/fulltext (7).pdf:pdf",
    year = "2009",
    journal = "Pervasive Computing"
}

@inproceedings{Gong1990,
    author = "Gong, Li and Needham, Roger M.",
    publisher = "IEEE",
    doi = "10.1109/RISP.1990.63854",
    title = "{Reasoning about belief in cryptographic protocols}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=63854",
    abstract = "Analysis methods for cryptographic proto- cols have often focused on information leakage rather than on seeing whether a protocol meets its goals. Many protocols, however, fall far short of meeting their goals, sometimes for quite subtle reasons. We introduce a mech- anism for reasoning about belief as a systematic way to understand the working of cryptographic protocols. Our mechanism captures more features of such protocols than that given in a recent work, to which our proposals are a substantial extension.",
    year = "1990",
    pages = "234--248",
    file = ":auto/homes/drt24/Downloads/00063854.pdf:pdf",
    address = "Oakland, California",
    keywords = "BAN logic,GNY logic,authentication,cryptography,formal methods",
    booktitle = "IEEE Symposium on Research in Security and Privacy"
}

@inproceedings{Gong1997,
    author = "Gong, Li and Mueller, Marianne and Prafullchandra, Hemma and Schemers, Roland",
    title = "{Going Beyond the Sandbox : An Overview of the New Security Architecture in the Java Development Kit 1.2}",
    abstract = "This paper describes the new security architectur e that has been implemented as part of JDK 1.2 the forthc oming JavaTM Development Kit. In going beyond the sandbox se curity model in the original release of Java, JDK1.2 provides fine grained access control via an easily configur able security policy. Moreover JDK1.2 introduces the concept of protection domain and a few related security primitives that help to make the underlying protection mechanism more robust.",
    number = "December",
    file = ":auto/homes/drt24/Downloads/j9a.pdf:pdf",
    year = "1997",
    booktitle = "USENIX Symposium on Internet Technologies and Systems"
}

@article{Gonzalez2008,
    author = "Gonz\'{a}lez, Marta C and Hidalgo, C\'{e}sar A and Barab\'{a}si, Albert-L\'{a}szl\'{o}",
    doi = "10.1038/nature06958",
    title = "{Understanding individual human mobility patterns}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/18528393",
    abstract = "Despite their importance for urban planning, traffic forecasting and the spread of biological and mobile viruses, our understanding of the basic laws governing human motion remains limited owing to the lack of tools to monitor the time-resolved location of individuals. Here we study the trajectory of 100,000 anonymized mobile phone users whose position is tracked for a six-month period. We find that, in contrast with the random trajectories predicted by the prevailing L\'{e}vy flight and random walk models, human trajectories show a high degree of temporal and spatial regularity, each individual being characterized by a time-independent characteristic travel distance and a significant probability to return to a few highly frequented locations. After correcting for differences in travel distances and the inherent anisotropy of each trajectory, the individual travel patterns collapse into a single spatial probability distribution, indicating that, despite the diversity of their travel history, humans follow simple reproducible patterns. This inherent similarity in travel patterns could impact all phenomena driven by human mobility, from epidemic prevention to emergency response, urban planning and agent-based modelling.",
    issn = "1476-4687",
    mendeley-tags = "mobility",
    number = "7196",
    month = "6",
    volume = "453",
    pages = "779--82",
    file = "::",
    year = "2008",
    keywords = "Cellular Phone,Cellular Phone: statistics \& numerical data,Disaster Planning,Geographic Information Systems,Humans,Locomotion,Models,Probability,Statistical,Travel,Travel: statistics \& numerical data,mobility",
    pmid = "18528393",
    journal = "Nature"
}

@techreport{Gonzalez2013,
    author = "Gonzalez, Robin and Locasto, Michael E",
    title = "{Classifying the Data Semantics of Patches}",
    abstract = "Patching software remains a key defensive technique for mitigating flaws and vulnerabilities. Patches, however, entail complications that are hard to predict. Patches can be incomplete or incorrect, thereby not fully addressing the targeted flaw or introducing new bugs and unintended behavior. System administrators and owners are often at a loss to assess the risk that applying a patch might carry. Without a lengthy evaluation, they cannot predict how the patch will behave in or affect their environment. Such obstacles often prevent the use of hot patching or dynamic software updating. One major obstacle to hot patching arises from the desynchronization of existing data with the patch’s new code semantics. This paper adopts a machine learning approach to assist this kind of prediction: whether the patch contains elements that are likely to cause problems if the patch is applied to the running system. We drive this automated assessment (based on a Support Vector Machine) via an analysis of the control and data modification operations in the patch. Our SVM classifies a set of 25 unlabeled patches with 92\% accuracy. As a baseline, it also classifies its testing set of 50 patches (blindly, without labels) with 84\% accuracy.",
    pages = "1--34",
    file = ":home/drt24/Downloads/gonzalez-cpsc-2013-1047-14.pdf:pdf",
    year = "2013",
    institution = "University of Calgary"
}

@article{Grace2012,
    author = "Grace, Michael and Zhou, Yajin and Wang, Zhi and Jiang, Xuxian",
    title = "{Systematic detection of capability leaks in stock Android smartphones}",
    url = "http://www4.ncsu.edu/~zwang15/files/NDSS12_Woodpecker.pdf",
    abstract = "Recent years have witnessed a meteoric increase in the adoption of smartphones. To manage information and features on such phones, Android provides a permission-based security model that requires each application to explicitly request permissions before it can be installed to run. In this paper, we analyze eight popular Android smartphones and discover that the stock phone images do not properly enforce the permission model. Several privileged permissions are unsafely exposed to other applications which do not need to request them for the actual use. To identify these leaked permissions or capabilities, we have developed a tool called Woodpecker. Our results with eight phone images show that among 13 privileged permissions examined so far, 11 were leaked, with individual phones leaking up to eight permissions. By exploiting them, an untrusted application can manage to wipe out the user data, send out SMS messages, or record user conversation on the affected phones – all without asking for any permission.",
    file = ":home/drt24/Downloads/NDSS12\_Woodpecker.pdf:pdf",
    year = "2012",
    journal = "Network and Distributed System Security Symposium (NDSS)"
}

@inproceedings{Grace2012a,
    author = "Grace, Michael and Zhou, Yajin and Zhang, Qiang and Zou, Shihong and Jiang, Xuxian",
    doi = "10.1145/2307636.2307663",
    isbn = "9781450313018",
    title = "{RiskRanker: Scalable and Accurate Zero-day Android Malware Detection}",
    abstract = "Smartphone sales have recently experienced explosive growth. Their popularity also encourages malware authors to pene- trate various mobile marketplaces with malicious applica- tions (or apps). These malicious apps hide in the sheer number of other normal apps, which makes their detection challenging. Existing mobile anti-virus software are inadequate in their reactive nature by relying on known malware samples for signature extraction. In this paper, we propose a proactive scheme to spot zero-day Android malware. Without relying on malware samples and their signatures, our scheme is motivated to assess potential security risks posed by these untrusted apps. Specifically, we have developed an automated system called RiskRanker to scalably analyze whether a particular app exhibits dangerous behavior (e.g., launching a root exploit or sending background SMS mes- sages). The output is then used to produce a prioritized list of reduced apps that merit further investigation. When applied to examine 118,318 total apps collected from var- ious Android markets over September and October 2011, our system takes less than four days to process all of them and effectively reports 3,281 risky apps. Among these re- ported apps, we successfully uncovered 718 malware samples (in 29 families) and 322 of them are zero-day (in 11 fami- lies). These results demonstrate the efficacy and scalability of RiskRanker to police Android markets of all stripes.",
    pages = "281--293",
    file = ":home/drt24/Downloads/p281-grace.pdf:pdf",
    year = "2012",
    keywords = "android,malware,riskranker",
    booktitle = "Mobisys"
}

@article{Grace2012b,
    author = "Grace, Michael and Zhou, Yajin and Wang, Zhi and Jiang, Xuxian and Drive, Oval",
    publisher = "NDSS",
    title = "{Systematic Detection of Capability Leaks in Stock Android Smartphones}",
    url = "http://handysmarkt.com/gehen/http://www.csc.ncsu.edu/faculty/jiang/pubs/NDSS12_WOODPECKER.pdf",
    abstract = "Recent years have witnessed a meteoric increase in the adoption of smartphones. To manage information and fea- tures on such phones, Android provides a permission-based security model that requires each application to explicitly request permissions before it can be installed to run. In this paper, we analyze eight popular Android smartphones and discover that the stock phone images do not properly enforce the permission model. Several privileged permis- sions are unsafely exposed to other applications which do not need to request them for the actual use. To identify these leaked permissions or capabilities, we have developed a tool called Woodpecker. Our results with eight phone im- ages show that among 13 privileged permissions examined so far, 11 were leaked, with individual phones leaking up to eight permissions. By exploiting them, an untrusted ap- plication can manage to wipe out the user data, send out SMS messages, or record user conversation on the affected phones all without asking for any permission.",
    year = "2012",
    journal = "North"
}

@inproceedings{Grace2012c,
    author = "Grace, MC and Zhou, Wu and Jiang, X and Sadeghi, AR",
    publisher = "ACM",
    doi = "10.1145/2185448.2185464",
    isbn = "9781450312653",
    title = "{Unsafe exposure analysis of mobile in-app advertisements}",
    url = "http://dl.acm.org/citation.cfm?id=2185464",
    abstract = {In recent years, there has been explosive growth in smartphone sales, which is accompanied with the availability of a huge number of smartphone applications (or simply apps). End users or consumers are attracted by the many interesting features offered by these devices and the associated apps. The developers of these apps are also benefited by the prospect of financial compensation, either by selling their apps directly or by embedding one of the many ad libraries available on smartphone platforms. In this paper, we focus on potential privacy and security risks posed by these embedded or in-app advertisement libraries (henceforth "ad libraries," for brevity). To this end, we study the popular Android platform and collect 100,000 apps from the official Android Market in March-May, 2011. Among these apps, we identify 100 representative in-app ad libraries (embedded in 52.1\% of them) and further develop a system called AdRisk to systematically identify potential risks. In particular, we first decouple the embedded ad libraries from host apps and then apply our system to statically examine the ad libraries, ranging from whether they will upload privacy-sensitive information to remote (ad) servers or whether they will download untrusted code from remote servers. Our results show that most existing ad libraries collect private information: some of them may be used for legitimate targeting purposes (i.e., the user's location) while others are hard to justify by invasively collecting the information such as the user's call logs, phone number, browser bookmarks, or even the list of installed apps on the phone. Moreover, additional ones go a step further by making use of an unsafe mechanism to directly fetch and run code from the Internet, which immediately leads to serious security risks. Our investigation indicates the symbiotic relationship between embedded ad libraries and host apps is one main reason behind these exposed risks. These results clearly show the need for better regulating the way ad libraries are integrated in Android apps.},
    year = "2012",
    number = "Section 2",
    pages = "101--112",
    volume = "067",
    file = ":home/drt24/Downloads/p101-grace.pdf:pdf",
    address = "Tucson, Arizona, USA",
    keywords = "in-app advertisement,privacy,smartphone",
    booktitle = "WiSec"
}

@article{Grace2012d,
    author = "Grace, Michael C and Zhou, Wu and Jiang, Xuxian and Sadeghi, Ahmad-Reza",
    doi = "10.1145/2185448.2185464",
    isbn = "978-1-4503-1265-3",
    title = "{Unsafe exposure analysis of mobile in-app advertisements}",
    url = "http://doi.acm.org/10.1145/2185448.2185464",
    abstract = {In recent years, there has been explosive growth in smartphone sales, which is accompanied with the availability of a huge number of smartphone applications (or simply apps). End users or consumers are attracted by the many interesting features offered by these devices and the associated apps. The developers of these apps are also benefited by the prospect of financial compensation, either by selling their apps directly or by embedding one of the many ad libraries available on smartphone platforms. In this paper, we focus on potential privacy and security risks posed by these embedded or in-app advertisement libraries (henceforth "ad libraries," for brevity). To this end, we study the popular Android platform and collect 100,000 apps from the official Android Market in March-May, 2011. Among these apps, we identify 100 representative in-app ad libraries (embedded in 52.1\% of them) and further develop a system called AdRisk to systematically identify potential risks. In particular, we first decouple the embedded ad libraries from host apps and then apply our system to statically examine the ad libraries, ranging from whether they will upload privacy-sensitive information to remote (ad) servers or whether they will download untrusted code from remote servers. Our results show that most existing ad libraries collect private information: some of them may be used for legitimate targeting purposes (i.e., the user's location) while others are hard to justify by invasively collecting the information such as the user's call logs, phone number, browser bookmarks, or even the list of installed apps on the phone. Moreover, additional ones go a step further by making use of an unsafe mechanism to directly fetch and run code from the Internet, which immediately leads to serious security risks. Our investigation indicates the symbiotic relationship between embedded ad libraries and host apps is one main reason behind these exposed risks. These results clearly show the need for better regulating the way ad libraries are integrated in Android apps.},
    number = "Section 2",
    pages = "101--112",
    volume = "067",
    file = ":home/drt24/Downloads/week2b.pdf:pdf",
    year = "2012",
    keywords = "in-app advertisement,privacy,smartphone",
    journal = "Proc. 5th ACM conference on Security and Privacy in Wireless and Mobile Networks"
}

@inproceedings{Graham1982,
    author = "Graham, Susan L. and Kessler, Peter B. and Mckusick, Marshall K.",
    publisher = "ACM Press",
    doi = "10.1145/800230.806987",
    isbn = "0897910745",
    title = "{Gprof}",
    url = "http://dl.acm.org/citation.cfm?id=800230.806987",
    booktitle = "Proceedings of the 1982 SIGPLAN symposium on Compiler construction - SIGPLAN '82",
    issn = "0362-1340",
    year = "1982",
    number = "6",
    month = "6",
    volume = "17",
    file = "::",
    address = "New York, New York, USA",
    pages = "120--126"
}

@article{Grammel2010,
    author = "Grammel, Lars and Tory, Melanie and Storey, Margaret-Anne",
    title = "{How Information Visualisation Novices Construct Visualisations}",
    journal = "Visualisation and Computer Graphics",
    number = "6",
    volume = "16",
    file = "::",
    year = "2010",
    pages = "943--952"
}

@inproceedings{Greenwald2006,
    author = "Greenwald, Michael B and Khanna, Sanjeev and Kunal, Keshav and Pierce, Benjamin C and Schmitt, Alan",
    doi = "10.1007/11864219_19",
    title = "{Agreeing to Agree : Conflict Resolution for Optimistically Replicated Data}",
    abstract = "Current techniques for reconciling disconnected changes to optimistically replicated data often use version vectors or related mech- anisms to track causal histories. This allows the system to tell whether the value at one replica dominates another or whether the two replicas are in conflict. However, current algorithms do not provide entirely sat- isfactory ways of repairing conflicts. The usual approach is to introduce fresh events into the causal history, even in situations where the causally independent values at the two replicas are actually equal. In some sce- narios these events may later conflict with each other or with further updates, slowing or even preventing convergence of the whole system. To address this issue, we enrich the set of possible actions at a replica to include a notion of explicit conflict resolution between existing events, where the user at a replica declares that one set of events dominates another, or that a set of events are equivalent. We precisely specify the behavior of this refined replication framework from a user’s point of view and show that, if communication is assumed to be “reciprocal” (with pairs of replicas exchanging information about their current states), then this specification can be implemented by an algorithm with the property that the information stored at any replica and the sizes of the messages sent between replicas are bounded by a polynomial function of the number of replicas in the system.",
    pages = "1--15",
    file = ":auto/homes/drt24/Downloads/fulltext (1).pdf:pdf",
    year = "2006",
    booktitle = "DISC"
}

@techreport{Greskam2004,
    author = "Greskam, Brian",
    title = "{Linux Whole-System Proﬁling Study}",
    url = "http://iacoma.cs.uiuc.edu/~greskamp/pdfs/423.pdf",
    mendeley-tags = "OS Profiling",
    year = "2004",
    keywords = "OS Profiling",
    pages = "9"
}

@online{Griffiths2012,
    author = "Griffiths, Chris",
    url = "http://conferences.npl.co.uk/satin/presentations/satin2012slides-Griffiths.pdf",
    booktitle = "SATIN",
    year = "2012",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Griffiths.pdf:pdf",
    title = "{DNSSEC at Comcast}"
}

@article{Guha2011a,
    author = "Guha, Saikat and Cheng, Bin and Francis, Paul",
    title = "{Privad : Practical Privacy in Online Advertising}",
    url = "http://www.usenix.org/events/nsdi11/tech/full_papers/Guha.pdf",
    abstract = "Online advertising is a major economic force in the In- ternet today, funding a wide variety of websites and ser- vices. Todays deployments, however, erode privacy and degrade performance as browsers wait for ad networks to deliver ads. This paper presents Privad, an online ad- vertising system designed to be faster and more private than existing systems while filling the practical market needs of targeted advertising: ads shown in web pages; targeting based on keywords, demographics, and inter- ests; ranking based on auctions; view and click account- ing; and defense against click-fraud. Privad occupies a point in the design space that strikes a balance between privacy and practical considerations. This paper presents the design of Privad, and analyzes the pros and cons of various design decisions. It provides an informal anal- ysis of the privacy properties of Privad. Based on mi- crobenchmarks and traces from a production advertising platform, it shows that Privad scales to present-day needs while simultaneously improving users browsing experi- ence and lowering infrastructure costs for the ad network. Finally, it reports on our implementation of Privad and deployment of over two thousand clients.",
    mendeley-tags = "adverts,mobile:privacy",
    file = "::",
    year = "2011",
    keywords = "adverts,mobile:privacy",
    journal = "NSDI"
}

@inproceedings{Guinard2009,
    author = "Guinard, Antony and Gibney, Alan Mc and Pesch, Dirk",
    isbn = "9781605588247",
    title = "{A Wireless Sensor Network Design Tool to Support Building Energy Management}",
    abstract = "The physical location of sensor nodes strongly influences the performance of the network from the perspective of accurate data sensing and reliable communication. Therefore deployment planning can be regarded as an essential stepping stone to producing a viable network infrastructure. The research presented in this paper aims to assist the deployment of a Building Management System relying on wireless sensors and actuators. This is accomplished by the development of a WSN design and optimization software tool to support designers and system integrators when undertaking the difficult task of WSN deployment for building energy management.",
    mendeley-tags = "Design,Theory",
    pages = "25--30",
    file = ":home/drt24/Library/papers/BuildSys/Guinard, Gibney, Pesch/Guinard, Gibney, Pesch - 2009 - A Wireless Sensor Network Design Tool to Support Building Energy Management.pdf:pdf",
    year = "2009",
    keywords = "Building Management System,Design,Heterogeneous Wireless Network Infrastructure,Industry Foundation Classes,Theory,Wireless Sensor Network Design",
    booktitle = "BuildSys"
}

@inproceedings{Gun2011,
    author = {G\"{u}n, Emin and Willem, Sirer and Patrick, De Bruijn and Shieh, Alan and Walsh, Kevin and Williams, Dan and Schneider, Fred B},
    isbn = "9781450309776",
    title = "{Logical Attestation : An Authorization Architecture for Trustworthy Computing}",
    abstract = "This paper describes the design and implementation of a newoperating systemauthorization architecture to support trustworthy computing. Called logical attestation, this architecture provides a sound framework for reasoning about run time behavior of applications. Logical attestation is based on attributable, unforgeable statements about programproperties, expressed in a logic. These statements are suitable formechanical processing, proof construction, and verification; they can serve as credentials, support authorization based on expressive authorization policies, and enable remote principals to trust software components without restricting the local user’s choice of binary implementations. We have implemented logical attestation in a new operating system called the Nexus. The Nexus executes natively on x86 platforms equipped with secure coprocessors. It supports both native Linux applications and uses logical attestation to support new trustworthy-computing applications. When deployed on a trustworthy cloud-computing stack, logical attestation is efficient, achieves high- performance, and can run applications that provide qualitative guarantees not possible with existing modes of attestation.",
    year = "2011",
    file = ":auto/homes/drt24/Downloads/18-sirer-online.pdf:pdf",
    address = "Cascais, Portugal",
    keywords = "Credentials-Based Authorization,Logic,Trusted Platform Module",
    booktitle = "SOSP"
}

@article{Gupta2001,
    author = "Gupta, Indranil and Chandra, Tushar D. and Goldszmidt, Germ\'{a}n S.",
    publisher = "ACM Press",
    doi = "10.1145/383962.384010",
    isbn = "1581133839",
    title = "{On scalable and efficient distributed failure detectors}",
    url = "http://portal.acm.org/citation.cfm?doid=383962.384010",
    abstract = "Process groups in distributed applications and services rely on failure detectors to detect process failures completely, and as quickly, accurately, and scalably as possible, even in the face of unreliable message deliveries. In this paper, we look at quantifying the optimal scalability, in terms of network load, (in messages per second, with messages having a size limit) of distributed, complete failure detectors as a function of application-specified requirements. These requirements are 1) quick failure detection by some non- faulty process, and 2) accuracy of failure detection. We assume a crash-recovery (non-Byzantine) failure model, and a network model that is probabilistically unreliable (w.r.t. message deliveries and process failures). First, we characterize, under certain independence assumptions, the opti- mum worst-case network load imposed by any failure detector that achieves an application's requirements. We then discuss why traditional heartbeating schemes are inherently unscalable according to the optimal load. We also present a randomized, distributed, failure detector algorithm that imposes an equal expected load per group member. This protocol satisfies the application defined constraints of completeness and accuracy, and speed of detection on an average. It imposes a network load that differs from the optimal by a sub-optimality factor that is much lower than that for traditional distributed heartbeating schemes. Moreover, this sub-optimality factor does not vary with group size (for large groups).",
    year = "2001",
    pages = "170--179",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta, Chandra, Goldszmidt - 2001 - On scalable and efficient distributed failure detectors.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "Accuracy,Distributed systems,Efficiency,Failure detectors,Scalability",
    journal = "Proceedings of the twentieth annual ACM symposium on Principles of distributed computing - PODC '01"
}

@inproceedings{Hall1992,
    author = "Hall, Robert J.",
    publisher = "ACM Press",
    doi = "10.1145/143062.143147",
    isbn = "0897915046",
    title = "{Call path profiling}",
    url = "http://dl.acm.org/citation.cfm?id=143062.143147",
    booktitle = "Proceedings of the 14th international conference on Software engineering - ICSE '92",
    year = "1992",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    pages = "296--306"
}

@article{Hall2011,
    author = "Hall, Chris and Anderson, Ross and Clayton, Richard and Ouzounis, Evangelos and Trimintzios, Panagiotis",
    title = "{Resilience of the Internet Interconnection Ecosystem}",
    url = "http://weis2011.econinfosec.org/papers/Resilience of the Internet Interconnection Ecosystem.pdf",
    abstract = "In 2010 the European Network and Information Security Agency (ENISA) launched a study to investigate the resilience of the Internet’s inter- connection system and come up with policy recommendations. A large num- ber of stakeholders were contacted, and their expertise has been reflected in the study. The formal outcome of the study was the publication by ENISA in early 2011 of a detailed technical report, ‘Inter-X: Resilience of the Internet Interconnection Ecosystem’. This paper presents a much abridged version of the ENISA report. In it, we present a summary of the problems that the Internet faces in keeping its interconnection system resilient, along with the recommendations proposed to policy makers.",
    pages = "1--32",
    file = ":auto/homes/drt24/Downloads/weisresilience.pdf:pdf",
    year = "2011",
    journal = "European Network and Information Security Agency"
}

@article{Hammond2003,
    author = "Hammond, Tracy and Davis, Randall",
    title = "{LADDER : A Language to Describe Drawing , Display , and Editing in Sketch Recognition}",
    journal = "IJCAI",
    number = "Figure 1",
    file = "::",
    year = "2003",
    pages = "461--467"
}

@phdthesis{Hammond2007,
    author = "Hammond, Tracy Anne",
    booktitle = "Thesis",
    year = "2007",
    file = "::",
    title = "{LADDER : A Perceptually-based Language to Simplify Sketch Recognition User Interface Development by}"
}

@article{Hammond2007a,
    author = "Hammond, Tracy",
    publisher = "Ieee",
    doi = "10.1109/FIE.2007.4417930",
    isbn = "978-1-4244-1083-5",
    title = "{Enabling instructors to develop sketch recognition applications for the classroom}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4417930",
    journal = "37Th Annual Frontiers in Education Conference - Global Engineering: Knowledge Without Borders, Opportunities Without Passports",
    issn = "0190-5848",
    month = "10",
    file = "::",
    year = "2007",
    pages = "S3J--11--S3J--16"
}

@article{Han2013,
    author = "Han, Jin and Kywe, Su Mon and Yan, Qiang and Bao, Feng and Deng, Robert and Gao, Debin and Li, Yingjiu and Zhou, Jianying",
    title = "{Launching generic attacks on ios with approved third-party applications}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-38980-1_17",
    abstract = "iOS is Apple’s mobile operating system, which is used on iPhone, iPad and iPod touch. Any third-party applications developed for iOS devices are required to go through Apple’s application vetting pro- cess and appear on the official iTunes App Store upon approval.When an application is downloaded from the store and installed on an iOS device, it is given a limited set of privileges, which are enforced by iOS applica- tion sandbox. Although details of the vetting process and the sandbox are kept as black box by Apple, it was generally believed that these iOS security mechanisms are effective in defending against malwares. In this paper, we propose a generic attack vector that enables third- party applications to launch attacks on non-jailbroken iOS devices. Fol- lowing this generic attack mechanism, we are able to construct multiple proof-of-concept attacks, such as cracking device PIN and taking snap- shots without user’s awareness. Our applications embedded with the at- tack codes have passed Apple’s vetting process and work as intended on non-jailbroken devices. Our proof-of-concept attacks have shown that Apple’s vetting process and iOS sandbox have weaknesses which can be exploited by third-party applications. We further provide corresponding mitigation strategies for both vetting and sandbox mechanisms, in order to defend against the proposed attack vector.",
    pages = "272--289",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F978-3-642-38980-1\_17.pdf:pdf",
    year = "2013",
    journal = "ANCS"
}

@article{Hao2007,
    author = "Hao, Feng",
    doi = "10.1007/978-3-540-77156-2_16",
    isbn = "978-3-540-77155-5",
    title = "{Combining Crypto with Biometrics : A New Human-Security Interface (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/978-3-540-77156-2_16",
    abstract = "I present my research on combining cryptography and iris biometrics. This is work with Ross Anderson and John Daugman. It is a short talk so I will leave out the technical detail. The motivation of the research is to incorporate advanced biometric authentication features into cryptography. We find that cryptography lacks the involvement of a human factor. In authentication, you would use a password or a token, but there is no real human factor involved. We studied the iris biometric because it is one of the most reliable biometrics discovered so far. There are however certain issues with the iris biometric. First, it is fuzzy. Second, its storage is quite controversial for privacy reasons. And third, it cannot be kept secret by its very nature. These limitations apply to biometrics in general.",
    pages = "133--138",
    volume = "4631",
    file = ":home/drt24/Downloads/10.1007\_978-3-540-77156-2\_16.pdf:pdf",
    year = "2007",
    journal = "Security Protocols"
}

@article{Hao2011,
    author = "Hao, Feng and Ryan, Peter Y A",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-25867-1_16",
    title = "{How to Sync with Alice}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-25867-1_16",
    abstract = "This paper explains the sync problem and compares solutions in Firefox 4 and Chrome 10. The sync problem studies how to securely synchronize data across different computers. Google has added a built-in sync function in Chrome 10, which uses a user-defined pass- word to encrypt bookmarks, history, cached passwords etc. However, due to the low-entropy of passwords, the encryption is inherently weak – anyone with access to the ciphertext can easily uncover the key (and hence disclose the plaintext). Mozilla used to have a very similar sync solution in Firefox 3.5, but since Firefox 4 it has made a complete change of how sync works in the browser. The new solution is based on a security protocol called J-PAKE, which is a balanced Password Authenticated Key Exchange (PAKE) protocol. To our best knowledge, this is the first large-scale deployment of the PAKE technology. Since PAKE does not require a PKI, it has compelling advantages than PKI-based schemes such as SSL/TLS in many applications. However, in the past decade, deploying PAKE has been greatly hampered by the patent and other issues. With the rise of patent-free solutions such as J-PAKE and also that the EKE patent will soon expire in October, 2011, we believe the PAKE technology will be more widely adopted in the near future.",
    pages = "170--178",
    volume = "7114",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-25867-1\_16.pdf:pdf",
    year = "2011",
    journal = "Security Protocols XIX"
}

@article{Hao2011a,
    author = "Hao, Feng",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-25867-1_17",
    isbn = "978-3-642-25866-4",
    title = "{How to Sync with Alice (Transcript of Discussion)}",
    abstract = "This talk is about How to Sync with Alice. It is joint work with Peter Ryan. Life used to be simple; you have only one desktop computer. Then you have laptop, which is more convenient, and is becoming inexpensive. In the past five years you’ve seen the rise of smartphones, and tablets. So the computer has been evolving. It used to be bulky, and fixed at a permanent location, but now it is mobile and can be anywhere. A person commonly owns more than one computer. Back to the theme of this workshop, Alice Doesn’t Live Here Anymore. First, who is Alice? Alice could be a PC, a smartphone, or a tablet, or anything with a chip. Her location is not important, because she can be anywhere. Identity is not important whether it is PC, laptop, or mobile phone. The device is only a platform for you to access Internet. With the cloud computing you no longer store data on the laptop; you store data in the cloud.",
    pages = "179--188",
    volume = "7114",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-25867-1\_17.pdf:pdf",
    year = "2011",
    journal = "Security Protocols XIX"
}

@article{Hao2011b,
    author = "Hao, Feng",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-22137-8_24",
    isbn = "978-3-642-22136-1",
    title = "{Password Authenticated Key Exchange by Juggling (Transcript of Discussion)}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-22137-8_24",
    abstract = "In today’s presentation I am going to describe a password authenticated key exchange protocol. This problem is one of the central problems in cryptography. The solution to this problem has a wide range of practical applications.",
    pages = "172--179",
    volume = "6615",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-22137-8\_24.pdf:pdf",
    year = "2011",
    journal = "Security Protocols"
}

@article{Hao2011c,
    author = "Hao, Feng and Ryan, Peter Y.A.",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-22137-8_23",
    isbn = "978-3-642-22136-1",
    title = "{Password authenticated key exchange by juggling}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-22137-8_23",
    abstract = "Password-Authenticated Key Exchange (PAKE) studies how to establish secure communication between two remote parties solely based on their shared password, without requiring a Public Key Infrastructure (PKI). Despite extensive research in the past decade, this problem remains unsolved. Patent has been one of the biggest brakes in deploying PAKE solutions in practice. Besides, even for the patented schemes like EKE and SPEKE, their security is only heuristic; researchers have reported some subtle but worrying security issues. In this paper, we propose to tackle this problem using an approach different from all past solutions. Our protocol, Password Authenticated Key Exchange by Juggling (J-PAKE), achieves mutual authentication in two steps: first, two parties send ephemeral public keys to each other; second, they encrypt the shared password by juggling the public keys in a verifiable way. The first use of such a juggling technique was seen in solving the Dining Cryptographers problem in 2006. Here, we apply it to solve the PAKE problem, and show that the protocol is zero-knowledge as it reveals nothing except one-bit information: whether the supplied passwords at two sides are the same. With clear advantages in security, our scheme has comparable efficiency to the EKE and SPEKE protocols.",
    pages = "159--171",
    volume = "6615",
    file = ":home/drt24/Downloads/10.1007\_978-3-642-22137-8\_23.pdf:pdf",
    year = "2011",
    keywords = "eke,key,password-authenticated key exchange,speke",
    journal = "Security Protocols"
}

@article{Harel1988,
    author = "Harel, David",
    doi = "10.1145/42411.42414",
    title = "{On visual formalisms}",
    url = "http://portal.acm.org/citation.cfm?doid=42411.42414",
    abstract = "The higraph, a general kind of diagramming object, forms a visual formalism of topological nature. Higraphs are suited for a wide array of applications to databases, knowledge representation, and, most notably, the behavioral specification of complex concurrent systems using the higraph-based language of statecharts.",
    issn = "00010782",
    number = "5",
    month = "5",
    volume = "31",
    pages = "514--530",
    file = "::",
    year = "1988",
    journal = "Communications of the ACM"
}

@article{Harman,
    author = "Harman, Mark and Mcminn, Phil and Souza, Jerffeson Teixeira De and Yoo, Shin",
    abstract = "The aim of Search Based Software Engineering (SBSE) research is to move software engineering problems from human-based search to machine-based search, using a variety of techniques from the metaheuristic search, operations research and evolutionary computation paradigms. The idea is to exploit humans’ creativity and machines’ tenacity and reliability, rather than requiring humans to perform the more tedious, error prone and thereby costly aspects of the engineering process. SBSE can also provide insights and decision support. This tutorial will present the reader with a step-by-step guide to the application of SBSE techniques to Software Engineering. It assumes neither previous knowledge nor experience with Search Based Optimisation. The intention is that the tutorial will cover sufficient material to allow the reader to become productive in successfully applying search based optimisation to a chosen Software Engineering problem of interest.",
    journal = "Search",
    file = ":auto/homes/drt24/Downloads/searchbasedSWEng.pdf:pdf",
    title = "{Search Based Software Engineering : Techniques , Taxonomy , Tutorial}"
}

@inproceedings{Harter2011,
    author = "Harter, Tyler and Dragga, Chris and Vaughn, Michael and Arpaci-Dusseau, Andrea C. and Arpaci-Dusseau, Remzi H.",
    publisher = "ACM Press",
    doi = "10.1145/2043556.2043564",
    isbn = "9781450309776",
    title = "{A file is not a file}",
    url = "http://dl.acm.org/citation.cfm?id=2043556.2043564",
    booktitle = "Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles - SOSP '11",
    year = "2011",
    month = "10",
    file = "::",
    address = "New York, New York, USA",
    pages = "71"
}

@inproceedings{Hay2009,
    author = "Hay, Simon and Rice, Andrew C.",
    publisher = "ACM Press",
    doi = "10.1145/1810279.1810283",
    isbn = "9781605588247",
    title = "{The case for apportionment}",
    url = "http://portal.acm.org/citation.cfm?doid=1810279.1810283",
    abstract = "Apportioning the total energy consumption of a building or organisation to individual users may provide incentives to make reductions. We explore howsensor systems installed in many buildings today can be used to apportion energy con- sumption between users. We investigate the differences be- tween a number of possible policies to evaluate the case for apportionment based on energy and usage data collected over the course of a year. We also study the additional possibili- ties offered by more fine-grained data with reference to case studies for specific shared resources, and discuss the poten- tial and challenges for future sensor systems in this area.",
    year = "2009",
    mendeley-tags = "Economics,Measurement",
    pages = "13",
    file = ":home/drt24/Library/papers/BuildSys/Hay, Rice/Hay, Rice - 2009 - The case for apportionment.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "Economics,Measurement,personal energy meter",
    booktitle = "BuildSys"
}

@inproceedings{Hay2009a,
    author = "Hay, Simon",
    abstract = "Every day each of us consumes a significant amount of en- ergy, both directly through transportation, heating and use of appliances, and indirectly from our needs for the production of food, manufacture of goods and provision of services. I envisage a personal energy meter which can record and apportion an individual’s energy usage in order to provide baseline information and incentives for reducing the environ- mental impact of our lives. Contextual information will be crucial for apportioning the use and energy costs of shared resources. In order to obtain this it will be necessary to develop low cost, low infrastructure location systems that can be deployed on a truly global scale.",
    year = "2009",
    booktitle = "Pervasive",
    file = ":home/drt24/Library/papers/Pervasive/Hay/Hay - 2009 - A Global Personal Energy Meter.pdf:pdf",
    title = "{A Global Personal Energy Meter}"
}

@article{Hay2009b,
    author = "Hay, Simon and Harle, Robert",
    publisher = "Springer",
    doi = "10.1007/978-3-642-01721-6_8",
    title = "{Bluetooth Tracking without Discoverability}",
    url = "http://www.springerlink.com/index/h6p4104852184rj8.pdf",
    abstract = "Outdoor location-based services are now prevalent due to advances in mobile technology and GPS. Indoors, however, even coarse location remains unavailable. Bluetooth has been identified as a potential location technology that mobile consumer devices already support, easing deployment and maintenance. However, Bluetooth tracking systems to date have relied on the Bluetooth inquiry mode to constantly scan for devices. This process is very slow and can be a security and privacy risk. In this paper we investigate an alternative: connection-based tracking. This permits tracking of a previously identified handset within a field of fixed base stations. Proximity is determined by creating and monitoring low-level Bluetooth connections that do not require authorisation. We investigate the properties of the low-level connections both theoretically and in practice, and show how to construct a building-wide tracking system based on this technique. We conclude that the technique is a viable alternative to inquiry-based Bluetooth tracking.",
    pages = "120--137",
    file = ":home/drt24/Downloads/bluetoothtracking.pdf:pdf",
    year = "2009",
    journal = "Location and Context Awareness"
}

@inproceedings{Hay2010,
    author = "Hay, Simon and Rice, Andrew C. and Hopper, Andy",
    title = "{Personal energy metering}",
    abstract = "Every day each of us consumes a significant amount of energy, both directly through trans- portation, heating and use of appliances, and indirectly from our needs for the production of food, manufacture of goods and provision of services. As part of the wider Computing for the Future of the Planet framework [5], we are investigating a personal energy meter which can record and apportion an individuals energy us- age in order to supply baseline information and incentives for reducing the environmental im- pact of our lives [6]. It could provide a mecha- nismto raise awareness of our consumption and help us reduce our impact. This would depend on a global sensor network and poses a number of challenges: new sensor systems are required both to account for the energy used and to de- termine the identity and activities of users.",
    pages = "3--4",
    file = ":home/drt24/Library/papers/CompSust/Hay, Rice, Hopper/Hay, Rice, Hopper - 2010 - Personal energy metering.pdf:pdf",
    year = "2010",
    booktitle = "CompSust"
}

@article{Hayashi2012,
    author = "Hayashi, Eiji and Riva, Oriana and Strauss, Karin and Brush, A J Bernheim and Schechter, Stuart",
    doi = "10.1145/2335356.2335359",
    title = "{Goldilocks and the two mobile devices: going beyond all-or-nothing access to a device's applications}",
    url = "http://dl.acm.org/citation.cfm?id=2335359 http://cups.cs.cmu.edu/soups/2012/proceedings/a2_Hayashi.pdf",
    abstract = "Most mobile phones and tablets support only two access control device states: locked and unlocked. We investigated how well all- or-nothing device access control meets the need of users by interviewing 20 participants who had both a smartphone and tablet. We find all-or-nothing device access control to be a remarkably poor fit with users’ preferences. On both phones and tablets, participants wanted roughly half their applications to be available even when their device was locked and half protected by authentication. We also solicited participants’ interest in new access control mechanisms designed specifically to facilitate device sharing. Fourteen participants out of 20 preferred these controls to existing security locks alone. Finally, we gauged participants’ interest in using face and voice biometrics to authenticate to their mobile phone and tablets; participants were surprisingly receptive to biometrics, given that they were also aware of security and reliability limitations.",
    file = ":home/drt24/Downloads/a2\_Hayashi.pdf:pdf",
    year = "2012",
    journal = "SOUPS"
}

@article{Hayden2012,
    author = "Hayden, Erika Check",
    doi = "10.1038/486312a",
    title = "{Informed consent: a broken contract.}",
    url = "http://www.nature.com/news/informed-consent-a-broken-contract-1.10862",
    abstract = "As researchers find more uses for data, informed consent has become a source of confusion. Something has to change.",
    issn = "1476-4687",
    number = "7403",
    month = "6",
    volume = "486",
    pages = "312--4",
    file = "::",
    year = "2012",
    keywords = "Consent Forms,Consent Forms: ethics,Consent Forms: standards,Databases,Genetic,Genetic Testing,Genetic Testing: ethics,Humans,Informed Consent,Informed Consent: ethics,Informed Consent: standards,Parkinson Disease,Parkinson Disease: genetics,Patents as Topic,Patient Advocacy",
    pmid = "22722173",
    journal = "Nature"
}

@article{Heer,
    author = "Heer, Jeffrey and Agrawala, Maneesh",
    journal = "Information Visualization",
    file = "::",
    title = "{Design Considerations for Collaborative Visual Analytics}"
}

@article{Heer2006,
    author = "Heer, Jeffrey and Agrawala, Maneesh",
    doi = "10.1109/TVCG.2006.178",
    title = "{Software design patterns for information visualization.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/17080809",
    abstract = "Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication.",
    issn = "1077-2626",
    number = "5",
    pages = "853--60",
    volume = "12",
    file = "::",
    year = "2006",
    keywords = "Algorithms,Computer Graphics,Database Management Systems,Databases, Factual,Information Storage and Retrieval,Information Storage and Retrieval: methods,Software,Software Design,User-Computer Interface",
    pmid = "17080809",
    journal = "IEEE transactions on visualization and computer graphics"
}

@article{Heer2007,
    author = "Heer, Jeffrey and Vi\'{e}gas, Fernanda B and Wattenberg, Martin",
    isbn = "9781595935939",
    title = "{Voyagers and Voyeurs : Supporting Asynchronous Collaborative Information Visualization}",
    abstract = "This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us, a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.",
    file = "::",
    year = "2007",
    journal = "SIGCHI conference on Human factors in computing systems"
}

@article{Heer2010,
    author = "Heer, Jeffrey and Bostock, Michael",
    doi = "10.1109/TVCG.2010.144",
    title = "{Declarative language design for interactive visualization.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/20975153",
    abstract = "We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.",
    issn = "1077-2626",
    number = "6",
    pages = "1149--56",
    volume = "16",
    file = "::",
    year = "2010",
    pmid = "20975153",
    journal = "IEEE transactions on visualization and computer graphics"
}

@inproceedings{Heninger2012,
    author = "Heninger, Nadia and Durumeric, Zakir and Wustrow, Eric and Halderman, J. Alex",
    publisher = "USENIX",
    title = "{Mining your Ps and Qs: detection of widespread weak keys in network devices}",
    url = "https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final228.pdf",
    booktitle = "Proceedings of the 21st conference on Security symposium",
    file = ":home/drt24/Downloads/sec12-final228.pdf:pdf",
    year = "2012"
}

@inproceedings{Henze2010,
    author = "Henze, Niels and Poppinga, Benjamin and Boll, Susanne",
    publisher = "ACM Press",
    doi = "10.1145/1868914.1869002",
    isbn = "9781605589343",
    title = "{Experiments in the Wild: Public Evaluation of Off-Screen Visualizations in the Android Market}",
    url = "http://dl.acm.org/citation.cfm?id=1868914.1869002",
    booktitle = "Proceedings of the 6th Nordic Conference on Human-Computer Interaction Extending Boundaries - NordiCHI '10",
    year = "2010",
    month = "10",
    file = "::",
    address = "New York, New York, USA",
    keywords = "Android Market,experiment,game,map navigation,off-screen",
    pages = "675"
}

@inproceedings{Hergenroder2012,
    author = "Hergenroder, Anton and Furthmuller, Jochen",
    publisher = "IEEE",
    doi = "10.1109/ICC.2012.6364942",
    isbn = "978-1-4577-2053-6",
    title = "{On energy measurement methods in wireless networks}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6364942",
    abstract = "Measuring the energy consumption of a communication device is necessary in order to develop energy-aware and energy-efficient protocols and applications. There exist various approaches to determine the energy consumption of a device. This paper gives a structured overview on the state of the art of energy measurement and provides a detailed analysis of the advantages and drawbacks of each technique. An improved understanding of how energy measurement can actually be accomplished allows to choose the right measurement technique according to a particular purpose and leverages the development and improvement of energy-aware and energy-efficient protocols and applications.",
    month = "6",
    pages = "6268--6272",
    file = "::",
    year = "2012",
    booktitle = "2012 IEEE International Conference on Communications (ICC)"
}

@article{Herlihy1990,
    author = "Herlihy, Maurice P. and Wing, Jeannette M",
    publisher = "ACM",
    doi = "10.1145/78969.78972",
    title = "{Linearizability: a correctness condition for concurrent objects}",
    url = "http://portal.acm.org/citation.cfm?doid=78969.78972",
    abstract = "A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.",
    issn = "01640925",
    number = "3",
    pages = "463--492",
    volume = "12",
    file = ":auto/homes/drt24/Downloads/p463-herlihy.pdf:pdf",
    year = "1990",
    keywords = "Theory,concurrrency,correctness,linearizability,multi-processing,phrases,serializability,shared memory,specification,verification",
    journal = "ACM Transactions on Programming Languages and Systems"
}

@article{Herlihy1991,
    author = "Herlihy, Maurice P. and Corporation, Digital Equipment",
    publisher = "ACM",
    doi = "10.1145/114005.102808",
    title = "{Wait-free synchronization}",
    url = "http://portal.acm.org/citation.cfm?doid=114005.102808",
    abstract = "A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes. The problem of constructing a wait-free implementation of one data object from another lies at the heart of much recent work in concurrent algorithms, concurrent data structures, and multiprocessor architectures. First, we introduce a simple and general technique, based on reduction to a concensus protocol, for proving statements of the form, there is no wait-free implementation of X by Y. We derive a hierarchy of objects such that no object at one level has a wait-free implementation in terms of objects at lower levels. In particular, we show that atomic read/write registers, which have been the focus of much recent attention, are at the bottom of the hierarchy: thay cannot be used to construct wait-free implementations of many simple and familiar data types. Moreover, classical synchronization primitives such astest\&set and fetch\&add, while more powerful than read and write, are also computationally weak, as are the standard message-passing primitives. Second, nevertheless, we show that there do exist simple universal objects from which one can construct a wait-free implementation of any sequential object.",
    issn = "01640925",
    number = "1",
    pages = "124--149",
    volume = "13",
    file = ":auto/homes/drt24/Downloads/p124-herlihy.pdf:pdf",
    year = "1991",
    journal = "ACM Transactions on Programming Languages and Systems"
}

@inproceedings{Hicks2010,
    author = "Hicks, John and Ramanathan, Nithya and Kim, Donnie and Monibi, Mohamad and Selsky, Joshua and Hansen, Mark and Estrin, Deborah",
    publisher = "ACM Press",
    doi = "10.1145/1921081.1921087",
    isbn = "9781605589893",
    title = "{AndWellness}",
    url = "http://dl.acm.org/citation.cfm?id=1921081.1921087",
    booktitle = "Wireless Health 2010 on - WH '10",
    year = "2010",
    month = "10",
    address = "New York, New York, USA",
    keywords = "experience sampling method (ESM),in situ data collection,mobile computing,system architecture,wireless health monitoring",
    pages = "34"
}

@inproceedings{Higgins2012,
    author = "Higgins, Brett D. and Flinn, Jason and Giuli, T. J. and Noble, Brian and Peplin, Christopher and Watson, David",
    publisher = "ACM Press",
    doi = "10.1145/2307636.2307651",
    isbn = "9781450313018",
    title = "{Informed mobile prefetching}",
    url = "http://dl.acm.org/citation.cfm?id=2307636.2307651",
    abstract = "Prefetching is a double-edged sword. It can hide the latency of data transfers over poor and intermittently connected wireless networks, but the costs of prefetching in terms of increased energy and cellular data usage are potentially substantial, particularly for data prefetched incorrectly. Weighing the costs and benefits of prefetching is complex, and consequently most mobile applications employ simple but sub-optimal strategies. Rather than leave the job to applications, we argue that the underlying mobile system should provide explicit prefetching support. Our prototype, IMP, presents a simple interface that hides the complexity of the prefetching decision. IMP uses a cost-benefit analysis to decide when to prefetch data. It employs goal-directed adaptation to try to minimize application response time while meeting budgets for battery lifetime and cellular data usage. IMP opportunistically uses available networks while ensuring that prefetches do not degrade network performance for foreground activity. It tracks hit rates for past prefetches and accounts for network-specific costs in order to dynamically adapt its prefetching strategy to both the network conditions and the accuracy of application prefetch disclosures. Experiments with email and news reader applications show that IMP provides predictable usage of budgeted resources, while lowering application response time compared to the oblivious strategies used by current applications.",
    year = "2012",
    month = "6",
    pages = "155",
    file = "::",
    address = "New York, New York, USA",
    keywords = "adaptation,budgeted resources,mobile prefetching",
    booktitle = "Proceedings of the 10th international conference on Mobile systems, applications, and services - MobiSys '12"
}

@article{Ho2006,
    author = "Ho, Alex and Fetterman, Michael and Clark, Christopher and Warfield, Andrew and Hand, Steven",
    doi = "10.1145/1218063.1217939",
    isbn = "1-59593-322-0",
    title = "{Practical taint-based protection using demand emulation}",
    url = "http://dl.acm.org/citation.cfm?id=1218063.1217939",
    journal = "ACM SIGOPS Operating Systems Review",
    issn = "01635980",
    number = "4",
    month = "10",
    volume = "40",
    file = "::",
    year = "2006",
    keywords = "QEMU,Xen,demand emulation,emulation,false tainting,tainting,virtual machine,virtualization",
    pages = "29"
}

@inproceedings{Hobarth2011,
    author = {H\"{o}barth, Sebastian and Mayrhofer, Rene},
    title = "{A framework for on-device privilege escalation exploit execution on Android}",
    url = "http://mail1.gibraltar.at/downloads/publications/IWSSI2011-Android-Exploit-Framework.pdf http://www.mayrhofer.eu.org/downloads/publications/IWSSI2011-Android-Exploit-Framework.pdf",
    abstract = "Exploits on mobile phones can be used for various reasons; a benign one may be to achieve system-level access on a device that was locked by the manufacturer or service provider (also known as ‘jailbreaking’ or ‘rooting’), while potentially malicious reasons are manifold. Independently of the use case however, a specific exploit is not sufficient to achieve the desired access rights. Typically, exploits provide temporary privilege escalation immediately after their execution. To provide additional access to applications, permanent privilege escalation is required – in the benign case, including secure access control for the user to decide which (parts of) applications are granted elevated access. In this paper, we present a framework that can use arbitrary temporary exploits on Android devices to achieve permanent ‘root’ capabilities for select (parts of) applications.",
    month = "6",
    file = ":home/drt24/Downloads/IWSSI2011-Android-Exploit-Framework.pdf:pdf",
    year = "2011",
    booktitle = "Proceedings of IWSSI/SPMU"
}

@techreport{Hoffman2006,
    author = "Hoffman, P. (VPN Consortium) and Harris, S (University of Michigan)",
    title = "{The Tao of IETF: A Novice’s Guide to the Internet Engineering Task Force}",
    url = "http://tools.ietf.org/pdf/rfc4677",
    abstract = "This document describes the inner workings of IETF meetings and Working Groups, discusses organizations related to the IETF, and introduces the standards process. It is not a formal IETF process document but instead an informational overview.",
    pages = "1--51",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffman, Harris - 2006 - The Tao of IETF A Novice’s Guide to the Internet Engineering Task Force.pdf:pdf",
    year = "2006",
    institution = "IETF: Network Working Group"
}

@techreport{Hoffman2006a,
    author = "Hoffman, P (VPN Consortium) and Harris, S (University of Michigan)",
    title = "{The Tao of IETF: A Novice’s Guide to the Internet Engineering Task Force}",
    url = "http://tools.ietf.org/pdf/rfc4677",
    abstract = "This document describes the inner workings of IETF meetings and Working Groups, discusses organizations related to the IETF, and introduces the standards process. It is not a formal IETF process document but instead an informational overview.",
    pages = "1--51",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffman, Harris - 2006 - The Tao of IETF A Novice’s Guide to the Internet Engineering Task Force.pdf:pdf",
    year = "2006",
    institution = "IETF: Network Working Group"
}

@techreport{Hoffman2012,
    author = "Hoffman, P. (VPN Consortium) and Schlyter, J. (Kirei AB)",
    title = "{The DNS-Based Authentication of Named Entities (DANE) Protocol for Transport Layer Security (TLS) draft-ietf-dane-protocol-18}",
    abstract = "Encrypted communication on the Internet often uses Transport Level Security (TLS), which depends on third parties to certify the keys used. This document improves on that situation by enabling the administrator of a domain name to certify the keys used in that domain’s TLS servers. This requires matching improvements in TLS client software, but no change in TLS server software.",
    pages = "1--33",
    file = ":auto/homes/drt24/Downloads/draft-ietf-dane-protocol-18.pdf:pdf",
    year = "2012",
    institution = "IETF"
}

@inproceedings{Hoffmann2010,
    author = "Hoffmann, Henry and Eastep, Jonathan and Santambrogio, Marco D. and Miller, Jason E. and Agarwal, Anant",
    publisher = "ACM Press",
    doi = "10.1145/1809049.1809065",
    isbn = "9781450300742",
    title = "{Application heartbeats}",
    url = "http://dl.acm.org/citation.cfm?id=1809049.1809065",
    abstract = "The rise of multicore computing has greatly increased system complexity and created an additional burden for software developers. This burden is especially troublesome when it comes to optimizing software on modern computing systems. Autonomic or adaptive computing has been proposed as one method to help application programmers handle this complexity. In an autonomic computing environment, system services monitor applications and automatically adapt their behavior to increase the performance of the applications they support. Unfortunately, applications often run as performance black-boxes and adaptive services must infer application performance from low-level information or rely on system-specific ad hoc methods. This paper proposes a standard framework, Application Heartbeats, which applications can use to communicate both their current and target performance and which autonomic services can use to query these values. The Application Heartbeats framework is designed around the well-known idea of a heartbeat. At important points in the program, the application registers a heartbeat. In addition, the interface allows applications to express their performance in terms of a desired heart rate and/or a desired latency between specially tagged heartbeats. Thus, the interface provides a standard method for an application to directly communicate its performance and goals while allowing autonomic services access to this information. Thus, Heartbeat-enabled applications are no longer performance black-boxes. This paper presents the Applications Heartbeats interface, characterizes two reference implementations (one suitable for clusters and one for multicore), and illustrates the use of Heartbeats with several examples of systems adapting behavior based on feedback from heartbeats.",
    year = "2010",
    month = "6",
    pages = "79",
    file = "::",
    address = "New York, New York, USA",
    keywords = "adaptive computing,self-tuning systems",
    booktitle = "Proceeding of the 7th international conference on Autonomic computing - ICAC '10"
}

@article{Hoffstein2003,
    author = "Hoffstein, Jeffrey and Howgrave-Graham, Nick and Pipher, Jill and Silverman, Joseph H. and Whyte, William",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-36563-X_9",
    isbn = "978-3-540-00847-7",
    title = "{NTRUSign: Digital signatures using the NTRU lattice}",
    url = "http://link.springer.com/chapter/10.1007/3-540-36563-X_9",
    abstract = "In this paper we introduce NTRUSign, an ew family of signature schemes based on solving the approximate closest vector problem (appr-CVP) in NTRU-type lattices. We explore the properties of general appr-CVP based signature schemes (e.g. GGH) and show that they are not immune to transcript attacks even in the random oracle model. We then introduce the idea of using carefully chosen perturbations to limit the information that is obtainable from an analysis of a large signature transcript. In the case of NTRUSign this can be achieved while maintaining attractive efficiency properties.",
    pages = "122--140",
    volume = "2612",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F3-540-36563-X\_9.pdf:pdf",
    year = "2003",
    journal = "Topics in cryptology— CT-RSA"
}

@article{Hopper2008,
    editor = "Guthrie, P and Juma, C and {H Sillem}",
    author = "Hopper, Andy and Rice, Andrew C.",
    publisher = "The Royal Society",
    title = "{Computing for the future of the planet.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/18672457",
    journal = "Philosophical Transactions of the Royal Society - Series A: Mathematical, Physical and Engineering Sciences",
    number = "1881",
    institution = "Computer Laboratory, University of Cambridge, 15 J J Thomson Avenue, Cambridge, UK.",
    volume = "366",
    pages = "3685--3697",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hopper, Rice - 2008 - Computing for the future of the planet.pdf:pdf",
    year = "2008",
    keywords = "computer assisted,computer communication networks,computer communication networks trends,conservation natural resources,earth (planet),microcomputers,microcomputers trends,signal processing,software,user computer interface",
    pmid = "18672457",
    abstract = "Digital technology is becoming an indispensable and crucial component of our lives, society and the environment. We present a framework for computing in the context of problems facing the planet. The framework has a number of goals: an optimal digital infrastructure, sensing and optimizing with a global world model, reliably predicting and reacting to our environment and providing digital alternatives to physical activities. This paper describes our vision in which data centres can scale power consumption in line with performance, run closer to the wire with reduced redundancy and behave as a 'virtual battery' dynamically using spare, or otherwise unusable, generation capacity from renewable sources. On a broader scale, we consider how global sensing might allow us to optimize our daily activities and lives. We highlight the issues and dilemmas inherent in the deployment of global sensing infrastructure and work towards our challenge of a personal energy meter as a tool for informing decisions and providing impetus for reducing the ecological footprint of our society."
}

@inproceedings{Hornyack2011,
    author = "Hornyack, Peter and Han, Seungyeop and Jung, Jaeyeon and Schechter, Stuart and Wetherall, David",
    publisher = "ACM Press",
    doi = "10.1145/2046707.2046780",
    isbn = "9781450309486",
    title = "{These aren't the droids you're looking for: retrofitting android to protect data from imperious applications}",
    url = "http://research.microsoft.com/apps/pubs/default.aspx?id=149596",
    series = "CCS '11",
    abstract = "We examine two privacy controls for Android smartphones that empower users to run permission-hungry applications while protecting private data from being exfiltrated: (1) covertly substituting shadow data in place of data that the user wants to keep private, and (2) blocking network transmissions that contain data the user made available to the application for on-device use only. We retrofit the Android operating system to implement these two controls for use with unmodified applications. A key challenge of imposing shadowing and exfiltration blocking on existing applications is that these controls could cause side effects that interfere with user-desired functionality. To measure the impact of side effects, we develop an automated testing methodology that records screenshots of application executions both with and without privacy controls, then automatically highlights the visual differences between the different executions. We evaluate our privacy controls on 50 applications from the Android Market, selected from those that were both popular and permission-hungry. We find that our privacy controls can successfully reduce the effective permissions of the application without causing side effects for 66\% of the tested applications. The remaining 34\% of applications implemented user-desired functionality that required violating the privacy requirements our controls were designed to enforce; there was an unavoidable choice between privacy and user-desired functionality.",
    pages = "639--652",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornyack, Schechter - Unknown - “ These Aren ’ t the Droids You ’ re Looking For ” Retrofitting Android to Protect Data from Imperious Applications Categories and Subject Descriptors(2).pdf:pdf",
    year = "2011",
    organization = "Microsoft Research",
    booktitle = "Proceedings of the 18th ACM conference on Computer and communications security"
}

@inproceedings{Hornyack2011a,
    author = "Hornyack, Peter and Han, Seungyeop and Jung, Jaeyeon and Schechter, Stuart and Wetherall, David",
    publisher = "ACM Press",
    doi = "10.1145/2046707.2046780",
    isbn = "9781450309486",
    title = "{These aren't the droids you're looking for: retrofitting android to protect data from imperious applications}",
    url = "http://dl.acm.org/citation.cfm?id=2046707.2046780",
    booktitle = "Proceedings of the 18th ACM conference on Computer and communications security - CCS '11",
    year = "2011",
    month = "10",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornyack, Schechter - Unknown - “ These Aren ’ t the Droids You ’ re Looking For ” Retrofitting Android to Protect Data from Imperious Applications Categories and Subject Descriptors(2).pdf:pdf",
    address = "New York, New York, USA",
    keywords = "android,privacy,smartphone",
    pages = "639"
}

@inproceedings{Housel1996,
    author = "Housel, Barron C. and Lindquist, David B.",
    publisher = "ACM Press",
    doi = "10.1145/236387.236416",
    isbn = "089791872X",
    title = "{WebExpress: a system for optimizing Web browsing in a wireless environment}",
    url = "http://dl.acm.org/citation.cfm?id=236387.236416",
    abstract = "This paper describes software technology that makes it possible to run Internet World Wide Web applications in wide area wireless netwurks. Web technology in conjunction with today’s mobile devices (e.g., laptops, notebooks, pemonal digital ass\&ants) and the emerging wireless technologies (e.g., packet radio, CDPD) offer the potential for unprecedented access to data and applications by mobile workers. Yet, the limited bandwidth, high latency, high cost, and poor reliability of today’s wireless wide-area networks greatly inhibits (even to the point of being unfeasible) supporting WebExpress Web applications over wireless networks. significantly reduces user cost and response time of wireless wmmunicatiuns by intercepting the HTTP data stream and performing various optimizations including: file caching, forms diffmcing. protocol reduction, and the elimination of re\&mdant HTTP header transmission. This paper describes these optimizations and presents some experiment results.",
    year = "1996",
    month = "11",
    pages = "108--116",
    file = "::",
    address = "New York, New York, USA",
    booktitle = "Proceedings of the 2nd annual international conference on Mobile computing and networking - MobiCom '96"
}

@inproceedings{Howard1993,
    author = "Howard, John H",
    publisher = "IEEE",
    doi = "10.1109/WWOS.1993.348172",
    title = "{Using reconciliation to share files between occasionally connected computers}",
    abstract = "Future large distributed systems will be made by interconnecting highly autonomous subsystems, rather than by building ever more elaborate complexes which attempt to provide a single system image transparent to the user. The work described here explores the implications of this in the context of file sharing using occasional reconciliation.",
    pages = "56 -- 60",
    file = ":auto/homes/drt24/Downloads/00348172.pdf:pdf",
    year = "1993",
    booktitle = "Workstation Operating Systems, 1993"
}

@article{Howgrave-Graham2001,
    author = "Howgrave-Graham, NA and Smart, NP",
    publisher = "Kluwer Academic Publishers",
    doi = "10.1023/A:1011214926272",
    title = "{Lattice attacks on digital signature schemes}",
    url = "http://link.springer.com/article/10.1023/A:1011214926272",
    abstract = "We describe a lattice attack on the Digital Signature Algorithm (DSA) when used to sign many messages, mi, under the assumption that a proportion of the bits of each of the associated ephemeral keys, yi, can be recovered by alternative techniques.",
    number = "3",
    pages = "283--290",
    volume = "23",
    file = ":home/drt24/Downloads/art\%3A10.1023\%2FA\%3A1011214926272.pdf:pdf",
    year = "2001",
    keywords = "digital signatures,lattices",
    journal = "Designs, Codes and Cryptography"
}

@article{Hu,
    author = "Hu, Y. Charlie",
    title = "{Understanding the Impact of Wireless Signal Strength on Smartphone Battery Drain}"
}

@inproceedings{Huang2012,
    author = "Huang, Junxian and Qian, Feng and Gerber, Alexandre and Mao, Z. Morley and Sen, Subhabrata and Spatscheck, Oliver",
    publisher = "ACM Press",
    doi = "10.1145/2307636.2307658",
    isbn = "9781450313018",
    title = "{A close examination of performance and power characteristics of 4G LTE networks}",
    url = "http://dl.acm.org/citation.cfm?id=2307636.2307658",
    booktitle = "Proceedings of the 10th international conference on Mobile systems, applications, and services - MobiSys '12",
    year = "2012",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    keywords = "3g,4g,4gtest,energy saving,lte,network model simulation,power model simulation",
    pages = "225"
}

@article{Huffman1952,
    author = "Huffman, David",
    doi = "10.1109/JRPROC.1952.273898",
    title = "{A Method for the Construction of Minimum-Redundancy Codes}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4051119",
    abstract = "An optimum method of coding an ensemble of messages consisting of a finite number of members is developed. A minimum-redundancy code is one constructed in such a way that the average number of coding digits per message is minimized.",
    issn = "0096-8390",
    number = "9",
    month = "9",
    volume = "40",
    pages = "1098--1101",
    year = "1952",
    journal = "Proceedings of the IRE"
}

@article{Hundhausen2004a,
    author = "Hundhausen, Christopher D.",
    title = "{Using End User Visualization Environments to Mediate Conversations : A ‘ Communicative Dimensions ’ Framework}",
    journal = "Visual Languages and Computing",
    number = "509",
    file = "::",
    year = "2004"
}

@article{Hundhausen2007,
    author = "Hundhausen, C and Brown, J",
    doi = "10.1016/j.jvlc.2006.03.002",
    title = "{What You See Is What You Code: A “live” algorithm development and visualization environment for novice learners}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X06000140",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "1",
    month = "2",
    volume = "18",
    file = "::",
    year = "2007",
    pages = "22--47"
}

@inproceedings{Hundt2011,
    author = "Hundt, Robert",
    title = "{Loop Recognition in C++/Java/Go/Scala}",
    url = "http://research.google.com/pubs/pub37122.html",
    abstract = "In this experience report we encode a well speciﬁed, compact benchmark in four programming languages, namely C++, Java, Go, and Scala. The implementations each use the languages’ idiomatic container classes, looping constructs, and memory/object allocation schemes. It does not attempt to exploit speciﬁc language and runtime features to achieve maximum performance. This approach allows an almost fair comparison of language features, code complexity, compilers and compile time, binary sizes, runtimes, and memory footprint. While the benchmark itself is simple and compact, it employs many language features, in particular, higher-level data structures (lists, maps, lists and arrays of sets and lists), a few algorithms (union/ﬁnd, dfs / deep recursion, and loop recognition based on Tarjan), iterations over collection types, some object oriented features, and interesting memory allocation patterns. We do not explore any aspects of multi-threading, or higher level type mechanisms, which vary greatly between the languages. The benchmark points to very large differences in all examined dimensions of the language implementations. After publication of the benchmark internally at Google, several engineers produced highly optimized versions of the benchmark. While this whole effort is an anectodal comparison only, the benchmark and subsequent tuning effort might be indicatie of typical performance pain points in the respective languages.",
    file = "::",
    year = "2011",
    booktitle = "Proceedings of Scala Days 2011"
}

@inproceedings{Hunt2010,
    author = "Hunt, Patrick and Konar, Mahadev and Junqueira, Flavio P and Reed, Benjamin",
    publisher = "USENIX Association",
    title = "{ZooKeeper: wait-free coordination for internet-scale systems}",
    url = "http://dl.acm.org/citation.cfm?id=1855840.1855851",
    series = "USENIXATC'10",
    abstract = "In this paper, we describe ZooKeeper, a service for co- ordinating processes of distributed applications. Since ZooKeeper is part of critical infrastructure, ZooKeeper aims to provide a simple and high performance kernel for building more complex coordination primitives at the client. It incorporates elements from group messaging, shared registers, and distributed lock services in a repli- cated, centralized service. The interface exposed by ZooKeeper has the wait-free aspects of shared registers with an event-driven mechanism similar to cache invalidations of distributed file systems to provide a simple, yet powerful coordination service. The ZooKeeper interface enables a high-performance service implementation. In addition to the wait-free property, ZooKeeper provides a per client guarantee of FIFO execution of requests and linearizability for all re- quests that change the ZooKeeper state. These design decisions enable the implementation of a high performance processing pipeline with read requests being satisfied by local servers. We show for the target workloads, 2:1 to 100:1 read to write ratio, that ZooKeeper can handle tens to hundreds of thousands of transactions per second. This performance allows ZooKeeper to be used exten- sively by client applications.",
    pages = "11",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hunt et al. - 2010 - ZooKeeper wait-free coordination for internet-scale systems.pdf:pdf",
    year = "2010",
    booktitle = "Proceedings of the 2010 USENIX conference on USENIX annual technical conference"
}

@article{Ince2012,
    author = "Ince, Darrel C and Hatton, Leslie and Graham-Cumming, John",
    publisher = "Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.",
    shorttitle = "Nature",
    title = "{The case for open computer programs.}",
    journal = "Nature",
    abstract = "Scientific communication relies on evidence that cannot be entirely included in publications, but the rise of computational science has added a new layer of inaccessibility. Although it is now accepted that data should be made available on request, the current regulations regarding the availability of software are inconsistent. We argue that, with some exceptions, anything less than the release of source programs is intolerable for results that depend on computation. The vagaries of hardware, software and natural language will always ensure that exact reproducibility remains uncertain, but withholding code increases the chances that efforts to reproduce results will fail.",
    issn = "1476-4687",
    number = "7386",
    month = "2",
    volume = "482",
    url = "http://dx.doi.org/10.1038/nature10836",
    year = "2012",
    pages = "485--8"
}

@article{Ioannidou2009,
    author = "Ioannidou, Andri and Repenning, Alexander and Webb, David C.",
    publisher = "Elsevier",
    doi = "10.1016/j.jvlc.2009.04.001",
    title = "{AgentCubes: Incremental 3D end-user development}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X09000238",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "4",
    month = "8",
    volume = "20",
    file = "::",
    year = "2009",
    keywords = "Computational thinking,End-user development,Game design,IT fluency,Incremental 3D,Visual programming",
    pages = "236--251"
}

@inproceedings{Ion2011,
    author = "Ion, Iulia and Sachdeva, Niharika and Kumaraguru, Ponnurangam and Capkun, Srdjan",
    doi = "10.1145/2078827.2078845",
    title = "{Home is safer than the cloud!: privacy concerns for consumer cloud storage}",
    url = "http://dl.acm.org/citation.cfm?id=2078845",
    abstract = "Several studies ranked security and privacy to be major areas of concern and impediments of cloud adoption for companies, but none have looked into end-users’ attitudes and practices. Not much is known about consumers’ privacy beliefs and expectations for cloud storage, such as webmail, document and photo sharing platforms, or about users’ awareness of contractual terms and conditions. We conducted 36 in-depth interviews in Switzerland and India (two countries with different privacy perceptions and expecta- tions); and followed up with an online survey with 402 participants in both countries. We study users’ privacy atti- tudes and beliefs regarding their use of cloud storage systems. Our results show that privacy requirements for con- sumer cloud storage differ from those of companies. Users are less concerned about some issues, such as guaranteed deletion of data, country of storage and storage outsourcing, but are uncertain about using cloud storage. Our results further show that end-users consider the Internet intrinsically insecure and prefer local storage for sensitive data over cloud storage. However, users desire better security and are ready to pay for services that provide strong privacy guarantees. Participants had misconceptions about the rights and guarantees their cloud storage providers offers. For example, users believed that their provider is liable in case of data loss, does not have the right to view and modify user data, and cannot disable user accounts. Finally, our results show that cultural differences greatly influence user attitudes and beliefs, such as their willingness to store sensitive data in the cloud and their acceptance that law enforcement agencies monitor user accounts. We believe that these observations can help in improving users privacy in cloud storage systems.",
    file = ":home/drt24/Downloads/iion-cloud-2011.pdf:pdf",
    year = "2011",
    keywords = "cloud storage,copies of all or,copyright is held by,cross-cultural,for personal or classroom,or hard,owner,part of this work,permission to make digital,social factors,the author,usability,use is granted",
    booktitle = "SOUPS"
}

@inproceedings{Isard2007,
    author = "Isard, Michael and Budiu, Mihai and Yu, Yuan and Birrell, Andrew and Fetterly, Dennis",
    doi = "10.1145/1272996.1273005",
    isbn = "978-1-59593-636-3",
    title = "{Dryad: distributed data-parallel programs from sequential building blocks}",
    url = "http://dl.acm.org/citation.cfm?id=1272996.1273005",
    abstract = {Dryad is a general-purpose distributed execution engine for coarse-grain data-parallel applications. A Dryad application combines computational "vertices" with communication "channels" to form a dataflow graph. Dryad runs the application by executing the vertices of this graph on a set of available computers, communicating as appropriate through flies, TCP pipes, and shared-memory FIFOs. The vertices provided by the application developer are quite simple and are usually written as sequential programs with no thread creation or locking. Concurrency arises from Dryad scheduling vertices to run simultaneously on multiple computers, or on multiple CPU cores within a computer. The application can discover the size and placement of data at run time, and modify the graph as the computation progresses to make efficient use of the available resources. Dryad is designed to scale from powerful multi-core single computers, through small clusters of computers, to data centers with thousands of computers. The Dryad execution engine handles all the difficult problems of creating a large distributed, concurrent application: scheduling the use of computers and their CPUs, recovering from communication or computer failures, and transporting data between vertices.},
    issn = "0163-5980",
    number = "3",
    month = "3",
    volume = "41",
    pages = "59--59--72--72",
    file = "::",
    year = "2007",
    keywords = "cluster computing,concurrency,dataflow,distributed programming",
    booktitle = "ACM SIGOPS Operating Systems Review"
}

@article{J.Burke,
    author = "{J. Burke}, D. Estrin",
    title = "{Participatory sensing}",
    url = "http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.3024",
    abstract = "This paper introduces the concept of participatory sensing, which tasks everyday mobile devices, such as cellular phones, to form interactive, participatory sensor networks that enable public and professional users to gather, analyze and share local knowledge. An initial architecture to enhance data credibility, quality, privacy and ‘shareability ’ in such networks is described, as well as a campaign application model that encompasses participation at personal, social and urban scales. Example applications are outlined in four areas: urban planning, public health, cultural identity and creative expression, and natural resource management. Keywords Participatory sensing, urban sensing, network-attested context, community-based participatory research, mobile handsets, urban planning, natural resource management, public health, cultural identity.",
    mendeley-tags = "pervasive computing",
    file = "::",
    keywords = "pervasive computing"
}

@article{Jablon1996,
    author = "Jablon, David P.",
    doi = "10.1145/242896.242897",
    title = "{Strong password-only authenticated key exchange}",
    url = "http://portal.acm.org/citation.cfm?doid=242896.242897",
    journal = "ACM SIGCOMM Computer Communication Review",
    issn = "01464833",
    number = "5",
    month = "10",
    volume = "26",
    file = ":home/drt24/Downloads/p5-jablon.pdf:pdf",
    year = "1996",
    pages = "5--26"
}

@article{Jacobi2010,
    author = "Jacobi, Ian",
    publisher = "Springer",
    doi = "10.1007/978-3-642-17819-1_29",
    title = "{Data Provenance in Distributed Propagator Networks}",
    url = "http://www.springerlink.com/index/P1M3354055770667.pdf",
    journal = "Provenance and Annotation of Data and Processes",
    file = "::",
    year = "2010",
    pages = "260--264"
}

@unpublished{Jakobsson2011,
    author = "Jakobsson, Markus and Akavipat, Ruj",
    keywords = "error correction,fastword,handset,mobile,password",
    abstract = "We describe and analyze a variant of the traditional password scheme. This is designed to take advantage of standard error-correcting methods of the types used to facilitate text entry on handsets. We call the new approach fast- words to emphasize their primary feature compared to regular passwords. Compared with passwords, fastwords are approximately twice as fast to enter on mobile keyboards, and approximately three times as fast on full-size keyboards. This is supported by user studies reported on herein. Furthermore, these user studies show that fastwords also have considerably greater entropy than passwords, and that their recall rates are dramatically higher than that of passwords and PINs. The new structure permits a memory jogging technique in which a portion of the fastword is revealed to a user who has forgotten it. We show that this results in boosted re- call rates, while maintaining a security above that of traditional passwords. We also introduce the notion of equivalence classes – whether based on semantics or pronunciation – and describe uses, including voice-based authentication. The new technology does not need any client-side modification.",
    year = "2011",
    file = ":auto/homes/drt24/Downloads/fastwords.pdf:pdf",
    title = "{Rethinking Passwords to Adapt to Constrained Keyboards}"
}

@inproceedings{Jeannot,
    author = "Jeannot, E. and Knutsson, B.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/HPDC.2002.1029938",
    isbn = "0-7695-1686-6",
    title = "{Adaptive online data compression}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1029938",
    abstract = "Quickly transmitting large datasets in the context of distributed computing on wide area networks can be achieved by compressing data before transmission, However such an approach is not efficient when dealing with higher speed networks. Indeed, the time to compress a large file and to send it is greater than the time to send the uncompressed file. In this paper we explore and enhance an algorithm that allows us to overlap communications with compression and to automatically adapt the compression effort to currently available network and processor resources.",
    pages = "379--388",
    booktitle = "Proceedings 11th IEEE International Symposium on High Performance Distributed Computing"
}

@inproceedings{Jia2013,
    author = "Jia, Limin and Aljuraidan, Jassim and Fragkaki, Elli and Bauer, Lujo and Stroucken, Michael and Fukushima, Kazuhide and Kiyomoto, Shinsaku and Miyake, Yutaka",
    title = "{Run-Time Enforcement of Information-Flow Properties (Extended Abstract)}",
    abstract = "Recent years have seen a dramatic increase in the number and importance of mobile devices. The security properties that these devices provide to their applications, however, are inadequate to protect against many undesired behaviors. A broad class of such behaviors is violations of simple information- flow properties. This paper proposes an enforcement systemthat permitsAndroid applications to be concisely annotated with information-flow policies, which the system enforces at run time. Information-flow constraints are enforced both between applications and between components within applications, aiding developers in implementing least privilege. We model our enforcement system in detail using a process calculus, and use the model to prove noninterference. Our system and model have a number of useful and novel features, including support for Android’s single- and multiple-instance components, floating labels, declassification and endorsement capabilities, and support for legacy applications. We have developed a prototype of our system on Android 4.0.4 and tested it on a Nexus S phone, verifying that it can enforce practically useful policies that can be implemented with minimal modification to off-the-shelf applications.",
    pages = "775--792",
    file = ":home/drt24/Downloads/10.1007-978-3-642-40203-6\_43.pdf:pdf",
    year = "2013",
    booktitle = "Computer Security–ESORICS 2013"
}

@inproceedings{Jiang2010,
    author = "Jiang, Xiaofan and Dawson-haggerty, Stephen and Culler, David",
    doi = "10.1145/1791212.1791261",
    isbn = "9781605589886",
    title = "{Poster Abstract : sMAP – Simple Monitoring and Actuation Profile}",
    url = "http://dl.acm.org/citation.cfm?id=1791261",
    abstract = "We present the architecture, specification, and implemen- tations of a simple monitoring and action profile (sMAP), optimized for sensors, meters, and actuators in building en- vironments. Our architecture is built on HTTP/REST and uses JSON as the object format for interoperability. We implement sMAP on a variety of resource monitors and ac- tuators inside a commercial building, including mote-based wireless sensors and meters running IPv6/6LowPAN, Mod- bus based panel meters, and external data sources. We show that sMAP is widely implementable and efficient, and our API and schema definitions are expressive and concise. We demonstrate that our architecture is well suited for resource constrained devices using compressed JSON and proxies.",
    year = "2010",
    pages = "374--375",
    file = ":auto/homes/drt24/Downloads/p374-jiang.pdf:pdf",
    address = "Stockholm, Sweeden",
    keywords = "building,energy,sensor networks,wireless",
    booktitle = "IPSN"
}

@inproceedings{Joh2011,
    author = "Joh, HyunChul and Malaiya, Yashwant K.",
    title = "{Defining and assessing quantitative security risk measures using vulnerability lifecycle and cvss metrics}",
    url = "http://www.cs.colostate.edu/~malaiya/p/johrisk11.pdf",
    abstract = "Known vulnerabilities which have been discov- ered but not patched represents a security risk which can lead to considerable financial damage or loss of reputation. They include vulnerabilities that have either no patches available or for which patches are applied after some delay. Exploitation is even possible before public disclosure of a vulnerability. This paper formally defines risk measures and examines possible approaches for assessing risk using actu- al data. We explore the use of CVSS vulnerability metrics which are publically available and are being used for rank- ing vulnerabilities. Then, a general stochastic risk evalua- tion approach is proposed which considers the vulnerability lifecycle starting with discovery. A conditional risk measure and assessment approach is also presented when only known vulnerabilities are considered. The proposed ap- proach bridges formal risk theory with industrial approach- es currently being used, allowing IT risk assessment in an organization, and a comparison of potential alternatives for optimizing remediation. These actual data driven methods will assist managers with software selection and patch ap- plication decisions in quantitative manner.",
    number = "1",
    file = ":home/drt24/Downloads/johrisk11.pdf:pdf",
    year = "2011",
    keywords = "CVSS,Security vulnerabilities,Software Risk Evaluation,Vulnerability lifecycle",
    booktitle = "international conference on security and management (SAM)",
    pages = "10--16"
}

@inproceedings{Johansson,
    author = "Johansson, A. and Suri, N.",
    publisher = "IEEE",
    doi = "10.1109/DSN.2005.45",
    isbn = "0-7695-2282-3",
    title = "{Error Propagation Profiling of Operating Systems}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1467783",
    abstract = "An operating system (OS) constitutes a fundamental software (SW) component of a computing system. The robustness of its operations, or lack thereof, strongly influences the robustness of the entire system. Targeting enhancement of robustness at the OS level via use of add-on SW wrappers, this paper presents an error propagation profiling framework that assists in a) systematic identification and location of design and operational vulnerabilities, and b) quantification of their potential impact. Focusing on data (value) errors occurring in OS drivers, a set of measures is presented that aids a designer to locate such vulnerabilities, either on an OS service (system call) basis or a per driver basis. A case study and associated experimental process, using Windows CE .Net, is presented outlining the utility of our proposed approach.",
    pages = "86--95",
    booktitle = "2005 International Conference on Dependable Systems and Networks (DSN'05)"
}

@article{Joukov2006,
    author = "Joukov, Nikolai and Traeger, Avishay and Iyer, Rakesh and Wright, Charles P. and Zadok, Erez",
    isbn = "1-931971-47-1",
    title = "{Operating system profiling via latency analysis}",
    url = "http://dl.acm.org/citation.cfm?id=1298455.1298465",
    month = "11",
    file = "::",
    year = "2006",
    pages = "89--102"
}

@techreport{Ju2006,
    author = "Ju, Wendy and Neeley, Lawrence and Winograd, Terry and Leifer, Larry",
    title = "{Thinking with Erasable Ink : Ad-hoc Whiteboard Use in Collaborative Design}",
    abstract = "Our work uses interactive workspace capture technology to investigate the hows and whys of whiteboard use in collaborative design environments. By showing excerpts from data collected in two collaborative design settings, we describe how collaborators use whiteboards in an opportunistic, task-oriented fashion. We illustrate the patterns collaborators follow in their interactions with the whiteboard and each other. We demonstrate that sketches generated in these ad-hoc design sessions ground real-time discussion, but seldom convey much information after the fact. These findings are analyzed to help us reexamine our approaches towards computer-supported collaborative design activity outside of the formal meeting environment.",
    volume = "560",
    file = "::",
    year = "2006",
    booktitle = "Analysis"
}

@article{Juang1990,
    author = "Juang, B.H. and Rabiner, L.R.",
    publisher = "IEEE",
    title = "{The segmental K-means algorithm for estimating parameters of hidden Markov models}",
    journal = "Acoustics, Speech and Signal Processing, IEEE Transactions on",
    abstract = "Statistical analysis techniques using hidden Markov models have found widespread use in many problem areas. This cor- respondence discusses and documents a parameter estimation algo- rithm for data sequence modeling involving hidden Markov models. The algorithm which we call the segmental K-means method uses the state-optimized joint likelihood for the observation data and the un- derlying Markovian state sequence as the objective function for esti- mation. We prove the convergence of the algorithm and compare it with the traditional Baum-Welch reestimation method. We also point out the increased flexibility this algorithm offers in the general speech modeling framework.",
    number = "9",
    volume = "38",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=60082",
    file = ":home/drt24/Library/papers/Electrical Engineering/Raghuveer et al/Raghuveer et al. - 1990 - ,a(\&) (3).pdf:pdf",
    year = "1990",
    pages = "1639--1641"
}

@inproceedings{Jurdak2010,
    author = "Jurdak, Raja and Corke, Peter and Dharman, Dhinesh and Salagnac, Guillaume",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1869990",
    isbn = "9781450303446",
    title = "{Adaptive GPS duty cycling and radio ranging for energy-efficient localization}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1869990",
    abstract = "This paper addresses the tradeoff between energy consumption and localization performance in a mobile sensor network application. The focus is on augmenting GPS location with more energy-efficient location sensors to bound position estimate uncertainty in order to prolong node lifetime. We use empirical GPS and radio contact data from a large-scale animal tracking deployment to model node mobility, GPS and radio performance. These models are used to explore duty cycling strategies for maintaining position uncertainty within specified bounds. We then explore the benefits of using short-range radio contact logging alongside GPS as an energy-inexpensive means of lowering uncertainty while the GPS is off, and we propose a versatile contact logging strategy that relies on RSSI ranging and GPS lock back-offs for reducing the node energy consumption relative to GPS duty cycling. Results show that our strategy can cut the node energy consumption by half while meeting application-specific positioning criteria.",
    year = "2010",
    mendeley-tags = "energy,gps,power,ttff",
    month = "11",
    pages = "57",
    file = "::",
    address = "New York, New York, USA",
    keywords = "energy,gps,power,ttff",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10"
}

@misc{Kara2004,
    author = "Kara, Levent Burak and Stahovich, Thomas F",
    booktitle = "ACM Symposium on User Interface Software and Technology",
    year = "2004",
    isbn = "1581139578",
    file = "::",
    title = "{Hierarchical Parsing and Recognition of Hand-Sketched Diagrams}"
}

@techreport{Karger1974,
    author = "Karger, P.A.",
    url = "http://oai.dtic.mil/oai/oai?verb=getRecord\&amp;metadataPrefix=html\&amp;identifier=ADA001120 http://csrc.nist.gov/publications/history/karg74.pdf",
    year = "1974",
    institution = "DTIC Document",
    file = ":auto/homes/drt24/Downloads/karg74.pdf:pdf",
    title = "{Multics Security Evaluation Volume II. Vulnerability Analysis.}"
}

@inproceedings{Karger1997,
    author = "Karger, David R. and Lehman, E. and Leighton, T. and Panigrahy, R. and Levine, M. and Lewin, D.",
    publisher = "ACM",
    title = "{Consistent Hashing and Random Trees : Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web}",
    url = "http://portal.acm.org/citation.cfm?id=258660",
    abstract = "Wedescribe a family of caching protocols for distrib-uted networks that can be used to decrease or eliminate the occurrence of hot spots in the network. Our protocols are particularly designed for use with very large networks such as the Internet, where delays caused by hot spots can be severe, and where it is not feasible for every server to have complete information about the current state of the entire network. The protocols are easy to implement using existing net- work protocols such as TCP/fF’,and require very little overhead. The protocols work with local control, make efficient use of exist- ing resources, and scale gracefully as the network grows. Our caching protocols are based on a special kind of hashing that we call consistent hashing. Roughly speaking, a consistent hash function is one which changes nr.inimaflyas the range of the function changes. Through the development of good consistent hash functions, we are able to develop caching protocols which do not require users to have a current or even consistent view of the network. We believe that consistent hash functions may eventually prove to be useful in other applications such as distributed name servers and/or quorum systems.",
    pages = "654--663",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karger et al. - 1997 - Consistent Hashing and Random Trees Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web.pdf:pdf",
    year = "1997",
    booktitle = "Proceedings of the twenty-ninth annual ACM symposium on Theory of computing"
}

@misc{Kasurinen2008,
    author = "Kasurinen, Jussi and Purmonen, Mika and Nikula, Uolevi",
    title = "{A Study of Visualization in Introductory Programming}",
    abstract = "The teaching of fundamental programming skills is a field that extensively uses different kinds of tools to enhance learning experience. These tools come in several sizes, offering wide range of different equipment or approaches to the teaching of introductory programming curricula. At the same time, computer sciences, and programming courses in particular, suffer from high drop-out rates and falling student grades. Students lose interest on programming because of several complex models and structures have to be learned before anything visually impressive can be created. This problem is intensified by the new multimedia environments like games and applets, whereas command line programs and data algorithms have lost impact and are not considered interesting. So can visualization tools be used to increase the student motivation and create motivational tasks to promote interest towards programming? This paper describes a project to enhance student motivation and interest towards programming in the introductory programming course by applying visualization tool to lecture demonstrations and to the course assignments. We present the results from the course and observed student reactions to introduction of a visualization application. Finally we discuss the impact of the visual demonstrations and project assignments from the motivational point of view, and present future improvement plans and observations based on the results of the development project and course outcome.",
    number = "Lancaster 2008",
    file = "::",
    year = "2008",
    keywords = "a,d,learning to program pop-ii,novices pop-iii,pop-i,visualization",
    booktitle = "Psychology of Programming Languages Interest Group"
}

@book{Katz2008,
    author = "Katz, Jonathan and Lindell, Yehuda",
    publisher = "Chapman \& Hall/CRC",
    year = "2008",
    isbn = "1-58488-551-3",
    pages = "i--xvii, 1--534",
    title = "{Introduction to Modern Cryptography}"
}

@inproceedings{Kelley2009,
    author = "Kelley, Patrick Gage and Bresee, Joanna and Cranor, Lorrie Faith and Reeder, Robert W.",
    publisher = "ACM Press",
    doi = "10.1145/1572532.1572538",
    isbn = "9781605587363",
    title = {{A "nutrition label" for privacy}},
    url = "http://dl.acm.org/citation.cfm?id=1572532.1572538",
    booktitle = "Proceedings of the 5th Symposium on Usable Privacy and Security - SOUPS '09",
    year = "2009",
    month = "7",
    file = "::",
    address = "New York, New York, USA",
    keywords = "P3P,information design,labeling,nutrition label,policy,privacy,user interface",
    pages = "1"
}

@inproceedings{Kermarrec2001,
    author = "Kermarrec, Anne-Marie and Rowstron, Antony and Shapiro, Marc and Druschel, Peter",
    publisher = "ACM Press",
    doi = "10.1145/383962.384020",
    isbn = "1581133839",
    title = "{The IceCube approach to the reconciliation of divergent replicas}",
    url = "http://portal.acm.org/citation.cfm?doid=383962.384020",
    abstract = "We describe a novel approach to log-based reconciliation called IceCube. It is general and is parameterised by appli- cation and object semantics. IceCube considers more flex- ible orderings and is designed to ease the burden of recon- ciliation on the application programmers. IceCube captures the static and dynamic reconciliation constraints between all pairs of actions, proposes schedules that satisfy the static constraints, and validates them against the dynamic con- straints. Preliminary experience indicates that strong static constraints successfully contain the potential combinatorial explosion of the simulation stage. With weaker static constraints, the system still finds good solutions in a reasonable time.",
    pages = "210--218",
    file = ":auto/homes/drt24/Downloads/p210-kermarrec.pdf:pdf",
    year = "2001",
    organization = "ACM SIGACT-SIGOPS",
    booktitle = "Proceedings of the twentieth annual ACM symposium on Principles of distributed computing PODC 01"
}

@article{Keshav2007,
    author = "Keshav, S.",
    doi = "10.1145/1273445.1273458",
    title = "{How to read a paper}",
    url = "http://dl.acm.org/citation.cfm?id=1273445.1273458",
    abstract = "Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.",
    issn = "01464833",
    mendeley-tags = "general,reading,research,research skills,surveying",
    number = "3",
    month = "7",
    volume = "37",
    pages = "83",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keshav - 2007 - How to read a paper.pdf:pdf",
    year = "2007",
    keywords = "general,hints,paper,reading,research,research skills,surveying",
    journal = "ACM SIGCOMM Computer Communication Review"
}

@inproceedings{Khanna2007,
    editor = "Arvind, V and Prasad, Sanjiva",
    author = "Khanna, Sanjeev and Kunal, Keshav and Pierce, Benjamin C",
    publisher = "Springer",
    title = "{A Formal Investigation of Diff3}",
    url = "http://www.springerlink.com/index/r8861106501830w7/",
    series = "Lecture Notes in Computer Science",
    abstract = "The diff3 algorithm is widely considered the gold standard formerginguncoordinatedchanges to list-structureddata suchas text files. Surprisingly, its fundamental properties have never been studied in depth. We offer a simple, abstract presentation of the diff3 algorithm and investigate its behavior. Despite abundant anecdotal evidence that peo- ple find diff3’s behavior intuitive and predictable in practice, charac- terizing its good properties turns out to be rather delicate: a number of seemingly natural intuitions are incorrect in general. Our main result is a careful analysis of the intuition that edits to “well-separated” regions of the same document are guaranteed never to conflict.",
    number = "1",
    volume = "4855",
    file = ":auto/homes/drt24/Downloads/fulltext (2).pdf:pdf",
    year = "2007",
    booktitle = "FSTTCS",
    pages = "1----12"
}

@article{Kim2008,
    author = "Kim, SungYe and Maciejewski, Ross and Ostmo, Karl and Delp, Edward J and Collins, Timothy F and Ebert, David S",
    doi = "10.1057/palgrave.ivs.9500168",
    title = "{Mobile analytics for emergency response and training}",
    url = "http://ivi.sagepub.com/lookup/doi/10.1057/palgrave.ivs.9500168",
    journal = "Information Visualization",
    issn = "1473-8716",
    number = "1",
    month = "2",
    volume = "7",
    file = "::",
    year = "2008",
    keywords = "emergency response,mobile visualization,visual analytics",
    pages = "77--88"
}

@inproceedings{Kim2009,
    author = "Kim, Younghun and Schmid, Thomas and Srivastava, Mani B. and Wang, Yan",
    publisher = "ACM Press",
    doi = "10.1145/1810279.1810281",
    isbn = "9781605588247",
    title = "{Challenges in resource monitoring for residential spaces}",
    url = "http://portal.acm.org/citation.cfm?doid=1810279.1810281",
    abstract = "Buildings consume approximately 73\% of the total elec- trical energy, and 12\% of the potable water resources in the United States. Even a moderate reduction in this sector re- sults in significant monetary and resource savings. Fine- grained resource monitoring is regarded as one technology that could help consumers and building owners to under- stand, and thus reduce, their resource waste. In this paper, we discuss challenges emerging from these fine grained re- source monitoring systems through an empirical study of long-term monitoring data of a residential space. We col- lected synchronouswater and electricity usage over 3 months from a single family house. Using a matched filter mecha- nism we detect several water and electrical events happening in the house, showing that with simple mathematical tools, these data traces reveal already a lot of information about the consumption patterns. We further discuss challenges in fine grained load monitoring using the main power meter, advo- cating that synchronous water and power traces help to dis- ambiguate several power consumers. In addition, our analy- sis revealed interesting privacy implications while monitor- ing a household’s resource consumption at high time resolu- tion, a problem that could easily hamper the successful adap- tation of these technologies.",
    year = "2009",
    mendeley-tags = "Experimentation,Human Factors,Measurement",
    pages = "1",
    file = ":home/drt24/Library/papers/BuildSys/Kim et al/Kim et al. - 2009 - Challenges in resource monitoring for residential spaces.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "Experimentation,Human Factors,Measurement,energy efficient homes,resource monitoring,sustain-",
    booktitle = "BuildSys"
}

@inproceedings{Kim2010,
    author = "Kim, Donnie H. and Kim, Younghun and Estrin, Deborah and Srivastava, Mani B.",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1869989",
    isbn = "9781450303446",
    title = "{SensLoc: sensing everyday places and paths using less energy}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1869989",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10",
    year = "2010",
    mendeley-tags = "cell,energy,gps,power,tracking,wifi",
    month = "11",
    file = "::",
    address = "New York, New York, USA",
    keywords = "cell,energy,energy-efficient tracking,gps,power,semantic location context,tracking,wifi",
    pages = "43"
}

@inproceedings{Kim2010a,
    author = "Kim, Donnie H. and Kim, Younghun and Estrin, Deborah and Srivastava, Mani B.",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1869989",
    isbn = "9781450303446",
    title = "{SensLoc: sensing everyday places and paths using less energy}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1869989",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10",
    year = "2010",
    mendeley-tags = "cell,energy,gps,power,tracking,wifi",
    month = "11",
    file = "::",
    address = "New York, New York, USA",
    keywords = "cell,energy,energy-efficient tracking,gps,power,semantic location context,tracking,wifi",
    pages = "43"
}

@book{Kim2011,
    editor = "Kim, Tai-hoon and Adeli, Hojjat and Robles, Rosslin John and Balitanas, Maricel",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-23312-8",
    isbn = "978-3-642-23311-1",
    title = "{Advanced Communication and Networking}",
    url = "http://www.springerlink.com/content/u850975645522v64/",
    series = "Communications in Computer and Information Science",
    year = "2011",
    volume = "199",
    address = "Berlin, Heidelberg"
}

@online{King2007,
    author = "King, Frank H.",
    url = "http://www.cl.cam.ac.uk/teaching/0708/Probabilty/",
    booktitle = "Course notes",
    title = "{Probability}",
    year = "2008",
    month = "1"
}

@article{Kinshumann2011,
    author = "Kinshumann, Kinshuman and Glerum, Kirk and Greenberg, Steve and Aul, Gabriel and Orgovan, Vince and Nichols, Greg and Grant, David and Loihle, Gretchen and Hunt, Galen",
    doi = "10.1145/1965724",
    isbn = "9781605587523",
    title = "{Debugging in the (very) large: Ten years of implementation and experience}",
    url = "http://uwashington.worldcat.org.offcampus.lib.washington.edu/title/debugging-in-the-very-large-ten-years-of-implementation-and-experience/oclc/741645407\&referer=brief_results",
    abstract = "Windows Error Reporting (WER) is a distributed system that automates the processing of error reports coming from an installed base of a billion machines. WER has collected billions of error reports in 10 years of operation. It collects error data automatically and classifies errors into buckets, which are used to prioritize developer effort and report fixes to users. WER uses a progressive approach to data collec- tion, which minimizes overhead for most reports yet allows developers to collect detailed information when needed. WER takes advantage of its scale to use error statistics as a tool in debugging; this allows developers to isolate bugs that cannot be found at smaller scale. WER has been designed for efficient operation at large scale: one pair of database servers records all the errors that occur on all Windows computers worldwide.",
    issn = "0001-0782",
    pages = "111 -- 116",
    volume = "54",
    file = ":home/drt24/Downloads/p103-glerum.pdf:pdf",
    year = "2011",
    keywords = "Large-Scale Systems,Software Quality,bucketing,classifying,error reports,labeling,minidump,statistics-based debugging",
    journal = "Communications of the ACM"
}

@article{Kjaergaard2007,
    author = "Kj\ae rgaard, M.",
    publisher = "Springer",
    title = "{A taxonomy for radio location fingerprinting}",
    url = "http://www.springerlink.com/index/58X7555373U7P510.pdf",
    journal = "Location-and Context-Awareness",
    file = "::",
    year = "2007",
    pages = "139--156"
}

@inproceedings{Klein2009,
    author = "Klein, Gerwin and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon and Elphinstone, Kevin and Heiser, Gernot and Andronick, June and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal",
    publisher = "ACM Press",
    doi = "10.1145/1629575.1629596",
    isbn = "9781605587523",
    title = "{seL4}",
    url = "http://dl.acm.org/citation.cfm?id=1629575.1629596",
    booktitle = "Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles - SOSP '09",
    year = "2009",
    month = "10",
    address = "New York, New York, USA",
    keywords = "isabelle/hol,l4,microkernel,sel4",
    pages = "207"
}

@inproceedings{Knupfer,
    author = "Knupfer, A. and Nagel, W.E.",
    publisher = "IEEE",
    doi = "10.1109/ICPP.2005.28",
    isbn = "0-7695-2380-3",
    title = "{Construction and Compression of Complete Call Graphs for Post-Mortem Program Trace Analysis}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=1488612",
    abstract = "Compressed complete call graphs (cCCGs) are a newly developed memory data structure for event based program traces. The most important advantage over linear lists or arrays traditionally used is the ability to apply lossy or lossless data compression. The compression scheme is completely transparent with respect to read access decompression is not required. This approach is a new way to cope with todays challenges when analyzing enormous amounts of trace data. The article focuses on CCG construction and compression, querying and evaluation are briefly covered.",
    pages = "165--172",
    booktitle = "2005 International Conference on Parallel Processing (ICPP'05)"
}

@book{KnuthTAOCP1,
    author = "Knuth, Donald E.",
    publisher = "Addison-Wesley",
    isbn = "0-201-89683-4",
    title = "{The Art of Computer Programming -- Volume 1 -- Fundamental Algorithms}",
    edition = "Third Edit",
    year = "1998",
    pages = "i--xx, 1--650"
}

@book{KnuthTAOCP2,
    author = "Knuth, Donald E.",
    publisher = "Addison-Wesley",
    isbn = "0-201-89684-2",
    title = "{The Art of Computer Programming -- Volume 2 -- Seminumerical Algorithms}",
    edition = "Third Edit",
    year = "1998",
    pages = "i--xiv, 1--762"
}

@article{Koblitz2005,
    author = "Koblitz, Neal and Menezes, Alfred",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11586821_2",
    isbn = "978-3-540-30276-6",
    title = "{Pairing-based cryptography at high security levels}",
    url = "http://link.springer.com/chapter/10.1007/11586821_2",
    abstract = "In recent years cryptographic protocols based on the Weil and Tate pairings on elliptic curves have attracted much attention. A notable success in this area was the elegant solution by Boneh and Franklin [8] of the problem of efficient identity-based encryption. At the same time, the security standards for public key cryptosystems are expected to increase, so that in the future they will be capable of providing security equivalent to 128-, 192-, or 256-bit AES keys. In this paper we examine the implications of heightened security needs for pairing-based cryptosystems. We first describe three different reasons why high-security users might have concerns about the long-term viability of these systems. However, in our view none of the risks inherent in pairing-based systems are sufficiently serious to warrant pulling them from the shelves. We next discuss two families of elliptic curves E for use in pairing-based cryptosystems. The first has the property that the pairing takes values in the prime field \$\backslash mathbb\{F\}\_p\$ over which the curve is defined; the second family consists of supersingular curves with embedding degree k = 2. Finally, we examine the efficiency of the Weil pairing as opposed to the Tate pairing and compare a range of choices of embedding degree k, including k = 1 and k = 24.",
    pages = "13--36",
    volume = "3796",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F11586821\_2.pdf:pdf",
    year = "2005",
    journal = "Lecture notes in Computer Science: Cryptography and Coding"
}

@techreport{Kolkman2013,
    author = "Kolkman, O. and Mekking, W. and Gieben, R.",
    title = "{DNSSEC Operational Practices, Version 2}",
    abstract = "This document describes a set of practices for operating the DNS with security extensions (DNSSEC). The target audience is zone administrators deploying DNSSEC. The document discusses operational aspects of using keys and signatures in the DNS. It discusses issues of key generation, key storage, signature generation, key rollover, and related policies. This document obsoletes RFC 4641 as it covers more operational ground and gives more up-to-date requirements with respect to key sizes and the DNSSEC operations.",
    pages = "1--83",
    volume = "4641",
    file = ":home/drt24/Downloads/draft-ietf-dnsop-rfc4641bis-13.pdf:pdf",
    year = "2013",
    institution = "IETF"
}

@article{Krintz2006,
    author = "Krintz, C. and Sucu, S.",
    doi = "10.1109/TPDS.2006.3",
    title = "{Adaptive on-the-fly compression}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1549812",
    abstract = "We present a system called the adaptive compression environment (ACE) that automatically and transparently applies compression (on-the-fly) to a communication stream to improve network transfer performance. ACE uses a series of estimation techniques to make short-term forecasts of compressed and uncompressed transfer time at the 32 Kb block level. ACE considers underlying networking technology, available resource performance, and data characteristics as part of its estimations to determine which compression algorithm to apply (if any). Our empirical evaluation shows that, on average, ACE improves transfer performance given changing network types and performance characteristics by 8 to 93 percent over using the popular compression techniques that we studied (Bzip, Zlib, LZO, and no compression) alone.",
    issn = "1045-9219",
    number = "1",
    month = "1",
    volume = "17",
    pages = "15--24",
    year = "2006",
    journal = "IEEE Transactions on Parallel and Distributed Systems"
}

@article{Krumm2006,
    editor = "Dourish, Paul and Friday, Adrian",
    author = "Krumm, John and Horvitz, Eric and Dourish, Paul and Friday, Adrian",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11853565",
    isbn = "978-3-540-39634-5",
    title = "{Predestination: Inferring Destinations from Partial Trajectories}",
    url = "http://www.springerlink.com/content/c5w327n534083656/",
    series = "Lecture Notes in Computer Science",
    abstract = "We describe a method called Predestination that uses a history of a driver’s destinations, along with data about driving behaviors, to predict where a driver is going as a trip progresses. Driving behaviors include types of destinations, driving efficiency, and trip times. Beyond considering previously visited destinations, Predestination leverages an open-world modeling methodology that considers the likelihood of users visiting previously unobserved locations based on trends in the data and on the background properties of locations. This allows our algorithm to smoothly transition between “out of the box” with no training data to more fully trained with increasing numbers of observations. Multiple components of the analysis are fused via Bayesian inference to produce a probabilistic map of destinations. Our algorithm was trained and tested on hold-out data drawn from a database of GPS driving data gathered from 169 different subjects who drove 7,335 different trips.",
    year = "2006",
    pages = "243--260",
    volume = "4206",
    file = "::",
    address = "Berlin, Heidelberg",
    journal = "UbiComp 2006: Ubiquitous Computing"
}

@article{Krumm2007,
    author = "Krumm, John",
    chapter = "8",
    publisher = "Springer",
    doi = "10.1007/978-3-540-72037-9_8",
    isbn = "9783540720362",
    title = "{Inference Attacks on Location Tracks}",
    url = "http://www.springerlink.com/index/TG64551RW2716103.pdf",
    series = "Lecture Notes in Computer Science",
    abstract = "Abstract. Although the privacy threats and countermeasures associated with location data are well known, there has not been a thorough experiment to assess the effectiveness of either. We examine location data gathered from volunteer subjects to quantify how well four different algorithms can identify the subjects home locations and then their identities using a freely available, programmable Web search engine. Our procedure can identify at least a small fraction of the subjects and a larger fraction of their home addresses. We then apply three different obscuration countermeasures designed to foil the privacy attacks: spatial cloaking, noise, and rounding. We show how much obscuration is necessary to maintain the privacy of all the subjects.",
    number = "Pervasive",
    pages = "127--143",
    volume = "10",
    file = ":auto/homes/drt24/Downloads/fulltext (6).pdf:pdf",
    year = "2007",
    keywords = "inference attack,location,location tracks,privacy",
    journal = "Pervasive Computing"
}

@inproceedings{Kutar2002,
    author = "Kutar, Maria and Britton, Carol and Barker, Trevor and Kutar, M S and Britton, C",
    title = "{A Comparison of Empirical Study and Cognitive Dimensions Analysis in the Evaluation of UML Diagrams}",
    abstract = "It is important that all those who use representations of a system during the development process can clearly understand the representations that are used. Research has shown that structure plays an important role in whether a diagrammatic representation may be readily understood. In this paper we present the results of a study where two different approaches were taken to the evaluation of two notations which form part of the UML diagram toolkit: sequence diagrams and collaboration diagrams. First, a theoretical investigation was carried out using the cognitive dimensions framework. Second, an empirical study was carried out to investigate user understanding of such diagrams. The results of the two studies did not concur, with the theoretical approach supporting the original hypothesis that structure is an important factor in diagram comprehension, but the study providing no evidence to support this.",
    number = "June",
    file = "::",
    year = "2002",
    keywords = "a,b,c,choice of methodology pop-ii,cognitive,d,dimensions pop-iii,individual differences pop-iii,object-oriented design,pop-i,specification languages pop-iv",
    booktitle = "Psychology of Programming Languages Interest Group"
}

@article{Kwok1997,
    author = "Kwok, T Y and Yeung, D Y",
    doi = "10.1109/72.572102",
    title = "{Constructive algorithms for structure learning in feedforward neural networks for regression problems.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/18255666",
    abstract = "In this survey paper, we review the constructive algorithms for structure learning in feedforward neural networks for regression problems. The basic idea is to start with a small network, then add hidden units and weights incrementally until a satisfactory solution is found. By formulating the whole problem as a state-space search, we first describe the general issues in constructive algorithms, with special emphasis on the search strategy. A taxonomy, based on the differences in the state transition mapping, the training algorithm, and the network architecture, is then presented.",
    issn = "1045-9227",
    number = "3",
    month = "1",
    volume = "8",
    pages = "630--45",
    file = ":home/drt24/Library/papers/IEEE transactions on neural networks a publication of the IEEE Neural Networks Council/Kwok, Yeung/Kwok, Yeung - 1997 - Constructive algorithms for structure learning in feedforward neural networks for regression problems.pdf:pdf",
    year = "1997",
    pmid = "18255666",
    journal = "IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council"
}

@article{Lally2010,
    author = "Lally, P and {Van Jaarsveld}, Chm and Potts, Hww and Wardle, J",
    publisher = "JOHN WILEY \& SONS LTD",
    title = "{How are habits formed: Modelling habit formation in the real world}",
    journal = "European Journal of Social Psychology",
    abstract = "To investigate the process of habit formation in everyday life, 96 volunteers chose an eating, drinking or activity behaviour to carry out daily in the same context (for example 'after breakfast') for 12 weeks. They completed the self-report habit index (SRHI) each day and recorded whether they carried out the behaviour. The majority (82) of participants provided sufficient data for analysis, and increases in automaticity (calculated with a sub-set of SRHI items) were examined over the study period. Nonlinear regressions fitted an asymptotic curve to each individual's automaticity scores over the 84 days. The model fitted for 62 individuals, of whom 39 showed a good fit. Performing the behaviour more consistently was associated with better model fit. The time it took participants to reach 95\% of their asymptote of automaticity ranged from 18 to 254 days; indicating considerable variation in how long it takes people to reach their limit of automaticity and highlighting that it can take a very long time. Missing one opportunity to perform the behaviour did not materially affect the habit formation process. With repetition of a behaviour in a consistent context, automaticity increases following an asymptotic curve which can be modelled at the individual level. Copyright (C) 2009 John Wiley \& Sons, Ltd.",
    number = "June 2009",
    volume = "1009",
    url = "http://discovery.ucl.ac.uk/16751/",
    file = "::",
    year = "2010",
    keywords = "consumption,fruit,intention behavior relationship,physical activity,planned behavior,strength",
    pages = "998--1009"
}

@article{Lamport1978,
    author = "Lamport, Leslie",
    doi = "10.1145/359545.359563",
    title = "{Time, clocks, and the ordering of events in a distributed system}",
    url = "http://portal.acm.org/citation.cfm?doid=359545.359563",
    abstract = "The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.",
    issn = "00010782",
    number = "7",
    month = "7",
    volume = "21",
    pages = "558--565",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamport - 1978 - Time, clocks, and the ordering of events in a distributed system.pdf:pdf",
    year = "1978",
    keywords = "clock synchronization,computer networks,distributed systems,multiprocess systems",
    journal = "Communications of the ACM"
}

@article{Lamport1978a,
    author = "Lamport, Leslie",
    doi = "10.1016/0376-5075(78)90045-4",
    title = "{The Implementation of Reliable Distributed Multiprocess Systems}",
    url = "http://dx.doi.org/10.1016/0376-5075(78)90045-4",
    abstract = {A method is described for implementing any system by a network of processes so it continues to function properly despite the failure or malfunction of individual processes and communication arcs; where "malfunction" means doing something incorrectly, and "failure" means doing nothing. The system is defined in terms of a sequential "user machine", and a precise correctness condition for the implementation of this user machine is given. An algorithm to implement the user machine in the absence of malfunctioning, and a rigorous proof of its correctness, are given for a network of three processes with perfect clocks. The generalization to an arbitrary network of processes with imperfect clocks is described. It is briefly indicated how malfunctioning can be handled by adding redundant checking to the implementation and including error detection and correction mechanisms in the user machine.},
    issn = "03765075",
    number = "2",
    pages = "95--114",
    volume = "2",
    file = ":auto/homes/drt24/Downloads/science.pdf:pdf",
    year = "1978",
    keywords = "computer networks,distributed computation,reliable synchronization,system specification",
    journal = "Computer Networks"
}

@techreport{Lamport1979,
    author = "Lamport, Leslie",
    title = "{Constructing digital signatures from a one-way function}",
    url = "http://research.microsoft.com/en-US/um/people/Lamport/pubs/dig-sig.pdf",
    number = "October",
    institution = "SRI International",
    file = ":home/drt24/Downloads/dig-sig.pdf:pdf",
    year = "1979",
    pages = "1--7"
}

@article{Lamport1998a,
    author = "Lamport, Leslie",
    publisher = "ACM",
    doi = "10.1145/279227.279229",
    isbn = "0203509307",
    title = "{The part-time parliament}",
    url = "http://portal.acm.org/citation.cfm?doid=279227.279229",
    abstract = "Recent archaeological discoveries on the island of Paxos reveal that the parliament functioned despite the peripatetic propensity of its part-time legislators. The legislators maintained consistent copies of the parliamentary record, despite their frequent forays from the chamber and the forgetfulness of their messengers. The Paxon parliament's protocol provides a new way of implementing the state machine approach to the design of distributed systems.",
    issn = "07342071",
    number = "2",
    month = "5",
    volume = "16",
    pages = "133--169",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lamport - 1998 - The part-time parliament.pdf:pdf",
    year = "1998",
    journal = "ACM Transactions on Computer Systems"
}

@article{Lampson1973,
    author = "Lampson, Butler W. (Xerox Palo Alto Research Center)",
    title = "{A note on the confinement problem}",
    url = "http://dl.acm.org/citation.cfm?id=362389",
    abstract = "This note explores the problem of confining a program during its execution so that it cannot transmit information to any other program except its caller. A set of examples attempts to stake out the boundaries of the problem. Necessary conditions for a solution are stated and informally justified",
    pages = "613--615",
    volume = "10",
    file = ":auto/homes/drt24/Downloads/Acrobat.pdf:pdf",
    year = "1973",
    keywords = "and phrases,confinement,leakage of data,privacy,proprietary program,protection,security",
    journal = "Communications of the ACM"
}

@article{Lange2011,
    author = "Lange, Matthias and Liebergeld, Steffen and Warg, Alexander and Peter, Michael",
    publisher = "ACM",
    isbn = "9781450310000",
    title = "{L4Android : A Generic Operating System Framework for Secure Smartphones Chair of Operating Systems}",
    url = "http://www.matze-lange.de/presentation/papers/spsm03-lange.pdf",
    abstract = "Smartphones became many peoples primary means of com- munication. Emerging applications such as Near Field Com- munication require new levels of security that cannot be en- forced by current smartphone operating systems. Therefore vendors resort to hardware extensions that have limitations in flexibility and increase the bill of materials. In this work we present a generic operating system framework that does away with the need for such hardware extensions. We encap- sulate the original smartphone operating system in a virtual machine. Our framework allows for highly secure applica- tions to run side-by-side with the virtual machine. It is based on a state-of-the-art microkernel that ensures isola- tion between the virtual machine and secure applications. We evaluate our framework by sketching how it can be used to solve four problems in current smartphone security.",
    pages = "39--50",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lange et al. - 2011 - L4Android A Generic Operating System Framework for Secure Smartphones Chair of Operating Systems.pdf:pdf",
    year = "2011",
    keywords = "ization,near field communication,secure operating systems,smartphones,system virtual",
    journal = "Components"
}

@inproceedings{Lange2011a,
    author = "Lange, Matthias and Liebergeld, Steffen and Lackorzynski, Adam and Warg, Alexander and Peter, Michael",
    isbn = "9781450310000",
    title = "{L4Android : A Generic Operating System Framework for Secure Smartphones}",
    abstract = "Smartphones became many people’s primary means of com- munication. Emerging applications such as Near Field Communication require new levels of security that cannot be en- forced by current smartphone operating systems. Therefore vendors resort to hardware extensions that have limitations in flexibility and increase the bill of materials. In this work we present a generic operating system framework that does away with the need for such hardware extensions. We encapsulate the original smartphone operating system in a virtual machine. Our framework allows for highly secure applications to run side-by-side with the virtual machine. It is based on a state-of-the-art microkernel that ensures isolation between the virtual machine and secure applications. We evaluate our framework by sketching how it can be used to solve four problems in current smartphone security.",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lange et al. - 2011 - L4Android A Generic Operating System Framework for Secure Smartphones Chair of Operating Systems.pdf:pdf",
    year = "2011",
    keywords = "near field communication,secure operating systems,smartphones,system virtualization",
    booktitle = "SPSM"
}

@article{Langheinrich2001a,
    editor = "Abowd, Gregory D and Brumitt, Barry and Shafer, Steven A",
    author = "Langheinrich, Marc",
    chapter = "23",
    publisher = "Springer",
    doi = "10.1007/3-540-45427-6_23",
    isbn = "3540426140",
    title = "{Privacy by Design - Principles of Privacy-Aware Ubiquitous Systems}",
    journal = "Ubicomp 2001 Ubiquitous Computing",
    series = "LNCS",
    abstract = "This paper tries to serve as an introductory reading to privacy issues in the field of ubiquitous computing. It develops six principles for guiding system design, based on a set of fair information practices common in most privacy legislation in use today: notice, choice and consent, proximity and locality, anonymity and pseudonymity, security, and access and recourse. A brief look at the history of privacy protection, its legal status, and its expected utility is provided as a background.",
    issn = "03029743",
    number = "2201",
    pages = "273--291",
    volume = "2201",
    url = "http://www.springerlink.com/index/y9reah898fcuc2n8.pdf",
    file = "::",
    year = "2001",
    institution = "ETH Zurich 8092 Zurich Switzerland"
}

@article{Langner2011,
    author = "Langner, R",
    publisher = "IEEE",
    doi = "10.1109/MSP.2011.67",
    title = "{Stuxnet: Dissecting a cyberwarfare weapon}",
    journal = "Security \& Privacy, IEEE",
    abstract = "Last year marked a turning point in the history of cybersecurity-the arrival of the first cyber warfare weapon ever, known as Stuxnet. Not only was Stuxnet much more complex than any other piece of malware seen before, it also followed a completely new approach that's no longer aligned with conven tional confidentiality, integrity, and availability thinking. Contrary to initial belief, Stuxnet wasn't about industrial espionage: it didn't steal, manipulate, or erase information. Rather, Stuxnet's goal was to physically destroy a military target-not just metaphorically, but literally. Let's see how this was done.",
    number = "3",
    volume = "9",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5772960",
    file = ":home/drt24/Downloads/05772960.pdf:pdf",
    year = "2011",
    pages = "49--51"
}

@techreport{Langner2013,
    author = "Langner, Ralph",
    abstract = "This document summarizes the most comprehensive research on the Stuxnet malware so far: It combines results from reverse engineering the attack code with intelligence on the design of the attacked plant and background information on the attacked uranium enrichment process. It looks at the attack vectors of the two different payloads contained in the malware and especially provides an analysis of the bigger and much more complex payload that was designed to damage centrifuge rotors by overpressure. With both attack vectors viewed in context, conclusions are drawn about the reasoning behind a radical change of tactics between the complex earlier attack and the comparatively simple later attack that tried to manipulate centrifuge rotor speeds. It is reasoned that between 2008 and 2009 the creators of Stuxnet realized that they were on to something much bigger than to delay the Iranian nuclear program: History’s first field experiment in cyber- physical weapon technology. This may explain why in the course of the campaign against Natanz, OPSEC was lossened to the extent that one can speculate that the attackers really were no longer ultimately concerned about being detected or not but rather pushing the envelope. Another section of this paper is dedicated to the discussion of several popular misconceptions about Stuxnet, most importantly how difficult it would be to use Stuxnet as a blueprint for cyber-physical attacks against critical infrastructure of the United States and their allies. It is pointed out that offensive cyber forces around the world will certainly learn from history’s first true cyber weapon, and it is further explained why nation state resources are not required to launch cyber-physical attacks. It is also explained why conventional infosec wisdom and deterrence does not sufficiently protect against Stuxnet-inspired copycat attacks. The last section of the paper provides a wealth of plant floor footage that allows for a better understanding of the attack, and it also closes a gap in the research literature on the Iranian nuclear program that so far focused on individual centrifuges rather than on higher-level assemblies such as cascades and cascade units. In addition, intelligence is provided on the instrumentation and control that is a crucial point in understanding Iran’s approach to uranium enrichment. There is only one reason why we publish this analysis: To help asset owners and governments protect against sophisticated cyber-physical attacks as they will almost definitely occur in the wake of Stuxnet. Public discussion of the subject and corporate strategies on how to deal with it clearly indicate widespread misunderstanding of the attack and its details, not to mention a misunderstanding of how to secure industrial control systems in general. For example, post-Stuxnet mitigation strategies like emphasizing the use of air gaps, anti-virus, and security patches are all indications of a failure to understand how the attack actually worked. By publishing this paper we hope to change this unsatisfactory situation and stimulate a broad discussion on proper mitigation strategies that don’t miss the mark.",
    year = "2013",
    number = "November",
    file = ":home/drt24/Downloads/To-kill-a-centrifuge.pdf:pdf",
    title = "{To Kill a Centrifuge - A Technical Analysis of What Stuxnet’s Creators Tried to Achieve}"
}

@article{Langner2013a,
    author = "Langner, Ralph",
    year = "2013",
    number = "November",
    file = ":home/drt24/Downloads/To-kill-a-centrifuge.pdf:pdf",
    title = "{To Kill a Centrifuge - A Technical Analysis of what Stuxnet's Creators Tried to Achieve}"
}

@techreport{Laurie2013,
    author = "Laurie, Ben and Langley, Adam and Kasper, Emilia",
    title = "{RFC6962: Certificate Transparency}",
    url = "http://www.hjp.at/doc/rfc/rfc6962.html",
    abstract = "This document describes an experimental protocol for publicly logging the existence of Transport Layer Security (TLS) certificates as they are issued or observed, in a manner that allows anyone to audit certificate authority (CA) activity and notice the issuance of suspect certificates as well as to audit the certificate logs themselves. The intent is that eventually clients would refuse to honor certificates that do not appear in a log, effectively forcing CAs to add all issued certificates to the logs. Logs are network services that implement the protocol operations for submissions and queries that are defined in this document.",
    institution = "IETF",
    year = "2013",
    month = "6",
    pages = "1--27"
}

@article{Law2008,
    author = "Law, Amdahl and Hill, Mark D and Marty, Michael R",
    title = "{Amdahl’s Law in the Multicore Era}",
    year = "2008",
    number = "July",
    file = "::",
    pages = "33--38"
}

@inproceedings{Lawall2010,
    author = "Lawall, Julia and Laurie, Ben and Hansen, Ren\'{e} Rydhof and Palix, Nicolas and Muller, Gilles",
    doi = "10.1109/EDCC.2010.31",
    title = "{Finding error handling bugs in OpenSSL using Coccinelle}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5474182",
    abstract = "OpenSSL is a library providing various functionalities relating to secure network communication. Detecting and fixing bugs in OpenSSL code is thus essential, particularly when such bugs can lead to malicious attacks. In previous work, we have proposed a methodology for finding API usage protocols in Linux kernel code using the program matching and transformation engine Coccinelle. In this work, we report on our experience in applying this methodology to OpenSSL, focusing on API usage protocols related to error handling. We have detected over 30 bugs in a recent OpenSSL snapshot, and in many cases it was possible to correct the bugs automatically. Our patches correcting these bugs have been accepted by the OpenSSL developers. This work furthermore confirms the applicability of our methodology to user-level code.",
    pages = "191--196",
    file = ":home/drt24/Downloads/edcc10.pdf:pdf",
    year = "2010",
    keywords = "API usage protocols,Coccinelle transformation engine,Communication system security,Computer bugs,Computer networks,Kernel,Libraries,Linux,OpenSSL,Pattern matching,Protocols,Search engines,Sockets,application program interfaces,error handling bugs,program matching,secure sockets layer,security of data",
    booktitle = "Dependable Computing Conference (EDCC)"
}

@inproceedings{Ledlie2005,
    author = "Ledlie, Jonathan and Holland, D.A.",
    publisher = "IEEE",
    doi = "10.1109/ICDE.2005.270",
    isbn = "0-7695-2657-8",
    title = "{Provenance-Aware Sensor Data Storage}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1647801 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1647801",
    booktitle = "21st International Conference on Data Engineering Workshops (ICDEW'05)",
    file = "::",
    year = "2005",
    pages = "1189--1189"
}

@article{Lee2001,
    author = "Lee, Byong G. and {Hari Narayanan}, N. and Chang, Kai H.",
    publisher = "Elsevier",
    title = "{An integrated approach to distributed version management and role-based access control in computer supported collaborative writing}",
    journal = "Journal of Systems and Software",
    abstract = "Tools to support computer supported collaborative writing (CSCWriting) allow multiple distributed users to collaborate over a wide area network on constructing a shared document. Prior research on computer supported collaborative work (CSCW) in general has predominantly focused on synchronous collaboration. Network latency becomes a bottleneck in maintaining shared artifacts during synchronous collaboration. Besides, to enable truly cooperative work asynchronous modes need to be supported as well, so that mobile users can switch between synchronous and asynchronous modes while they disconnect and reconnect to the network. These two considerations motivated the development of a distributed version control system for CSCWriting described in this paper. The most important contribution of our work is the proposal of an activity identification (AID) tag as the fundamental mechanism to support distributed management of multiple versions of a document. The AID tag facilitates the design and implementation of an integrated approach that includes differencing, merging and role-based access control at different levels of granularity, maintaining and visualizing the version structure, and group awareness of document status and operations. The AID tag leads to simple and effective differencing and merging schemes. Its unique address scheme eliminates the need for large storage capacity for version maintenance. Role-based access control can be implemented by associating the access right table and role assignment capabilities with the AID tag. Information for providing group awareness of the changing document is available from the AID tag. In addition, since the system maintains a user-browsable version structure of the evolving document that incorporates AID tag information, any user collaborating in the authoring of a document can easily visualize the historical evolution and current context of the document.",
    number = "2",
    volume = "59",
    url = "http://www.sciencedirect.com/science/article/pii/S0164121201000139",
    file = ":auto/homes/drt24/Downloads/science (1).pdf:pdf",
    year = "2001",
    pages = "119--134"
}

@inproceedings{Lee2012,
    author = "Lee, Young-Seol and Cho, Sung-Bae",
    publisher = "IEEE",
    doi = "10.1109/ICDCSW.2012.47",
    isbn = "978-1-4673-1423-7",
    title = "{An Efficient Energy Management System for Android Phone Using Bayesian Networks}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6258142",
    abstract = "Many applications on smart phones have been developed for a user's convenience. They are using various sensors such as accelerometer, proximity, light and orientation sensors for context-awareness. Energy-efficient battery management systems become more important to support the sensors on a mobile phone because recent applications consume a large amount of energy for diverse functionalities. This paper proposes a context-aware battery management system which infers a user's situation and controls unnecessary functionalities using embedded sensors on a mobile phone. The proposed system uses probabilistic models to infer a user's situation and minimizes the cost of probability calculation according to the change of context. In order to show the feasibility of the proposed method, we conducted the evaluation with a real dataset collected from mobile device.",
    month = "6",
    year = "2012",
    booktitle = "2012 32nd International Conference on Distributed Computing Systems Workshops",
    pages = "102--107"
}

@inproceedings{Lerner2013,
    author = "Lerner, Benjamin S. and Elberty, Liam and Poole, Neal and Krishnamurthi, Shriram",
    publisher = "Springer",
    title = "{Verifying Web Browser Extensions' Compliance with Private-Browsing Mode}",
    url = "http://cs.brown.edu/~sk/Publications/Papers/Published/lepk-verif-ext-pbm/paper.pdf",
    abstract = "Modern web browsers implement a private browsing mode that is intended to leave behind no traces of a user’s browsing activity on their computer. This feature is in direct tension with support for extensions, which can silently void this guarantee. We create a static type system to analyze JavaScript extensions for observation of private browsing mode. Using this type system, extension authors and app stores can convince themselves of an extension’s safety for private browsing mode. In addition, some extensions intentionally violate the private browsing guarantee; our type system accommodates this with a small annotation overhead, proportional to the degree of violation. These annotations let code auditors narrow their focus to a small fraction of the extension’s codebase. We have retrofitted type annotations to Firefox’s apis and to a sample of actively used Firefox extensions. We used the type system to verify several extensions as safe, find actual bugs in several others (most of which have been confirmed by their authors), and find dubious behavior in the rest. Firefox 20, released April 2, 2013, implements a finer-grained private browsing mode; we sketch both the new challenges in this implementation and how our approach can handle them.",
    file = ":home/drt24/Downloads/paper.pdf:pdf",
    year = "2013",
    booktitle = "Computer Security–ESORICS 2013"
}

@inproceedings{Li2004,
    author = "Li, Jinyuan and Krohn, Maxwell and Mazi, David and Shasha, Dennis",
    title = "{Secure Untrusted Data Repository (SUNDR)}",
    url = "http://static.usenix.org/publications/library/proceedings/osdi04/tech/full_papers/li_j/li_j.pdf",
    abstract = "SUNDR is a network file system designed to store data securely on untrusted servers. SUNDR lets clients detect any attempts at unauthorized file modification by malicious server operators or users. SUNDRs protocol achieves a property called fork consistency, which guar- antees that clients can detect any integrity or consistency failures as long as they see each others file modifications. An implementation is described that performs compara- bly with NFS (sometimes better and sometimes worse), while offering significantly stronger security.",
    pages = "121--136",
    file = ":auto/homes/drt24/Downloads/li\_j.pdf:pdf",
    year = "2004",
    booktitle = "OSDI"
}

@inproceedings{Li2007,
    author = "Li, Jinyuan and Mazi\`{e}res, David",
    publisher = "USENIX",
    title = "{Beyond one-third faulty replicas in Byzantine fault tolerant systems}",
    url = "http://www.usenix.org/event/nsdi07/tech/full_papers/li/li_html/",
    abstract = "Byzantine fault tolerant systems behave correctly when no more than f out of 3f+1 replicas fail. When there are more than f failures, traditional BFT protocols make no guarantees whatsoever. Malicious replicas can make clients accept arbitrary results, and the system behavior is totally unspecified. However, there is a large spectrum between complete correctness and arbitrary failure that traditional BFT systems ignore. This paper argues that we can and should bound the system behavior beyond f failures. We present BFT2F, an extension to the well-known Castro-Liskov PBFT algorithm [6], to explore the design space beyond f failures. Specifically, BFT2F has the same liveness and consistency guarantees as PBFT when no more than f replicas fail; with more than f but no more than 2f failures, BFT2F prohibits malicious servers from making up operations that clients have never issued and restricts malicious servers to only certain kinds of consistency violations. Evaluations of a prototype implementation show that the additional guarantees of BFT2F come at the cost of only a slight performance degradation compared to PBFT.",
    pages = "131--144",
    file = ":home/drt24/Downloads/fork\_byzantine.pdf:pdf",
    year = "2007",
    booktitle = "NSDI"
}

@inproceedings{Li2013,
    author = "Li, Jingwei and Chen, Xiaofeng and Jia, Chunfu and Ma, Jianfeng and Lou, Wenjing",
    publisher = "Springer",
    title = "{Fine-Grained Access Control System Based on Outsourced Attribute-Based Encryption}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-40203-6_33",
    abstract = "As cloud computing becomes prevalent, more and more sensitive data is being centralized into the cloud for sharing, which brings forth new challenges for outsourced data security and privacy. Attribute-based encryption (ABE) is a promising cryptographic primitive, which has been widely applied to design fine-grained access control system recently. However, ABE is being criticized for its high scheme overhead as the computational cost grows with the complexity of the access formula. This disadvantage becomes more serious for mobile devices because they have constrained computing resources. Aiming at tackling the challenge above, we present a generic and efficient solution to implement attribute-based access control system by introducing secure outsourcing techniques into ABE. More precisely, two cloud service providers (CSPs), namely key generation-cloud service provider (KG-CSP) and decryption-cloud service provider (D-CSP) are introduced to perform the outsourced key-issuing and decryption on behalf of attribute authority and users respectively. In order to outsource heavy computation to both CSPs without private information leakage, we formulize an underlying primitive called outsourced ABE (OABE) and propose several constructions with outsourced decryption and key-issuing. Finally, extensive experiment demonstrates that with the help of KG-CSP and D-CSP, efficient key-issuing and decryption are achieved in our constructions.",
    file = ":home/drt24/Downloads/ESORICS13\_Li.pdf:pdf",
    year = "2013",
    booktitle = "Computer Security–ESORICS 2013"
}

@article{Li2013a,
    author = "Li, Qing and Clark, Greg",
    doi = "10.1109/MSP.2013.15",
    isbn = "1540-7993 VO - 11",
    title = "{Mobile security: A look ahead}",
    abstract = "Fueled by widespread adoption of employee-owned devices in the workplace and the explosion of mobile applications, mobile device security is under heavy debate in both the academic and industry security communities. Businesses and government agencies are struggling to find some sense of control at a time when employee-owned devices now access some of the most sensitive data in an organization. Various approaches and solutions have been proposed, ranging from device-based intrusion detection systems, execution isolation through application sandboxing and bare metal hypervisors, ontology-based firewalls, behavior-based detection, to cloud-based protection through the use of VPN technology. The challenge of heterogeneous hardware and software platforms, such as iOS vs. Android OS, adds yet another layer of complexity to creating a comprehensive solution. The authors provide an overview of the current threats based on data collected from observing the interaction of 75 million users with the Internet. Extrapolating this data gives an insight into what threats wait on the horizon.",
    issn = "15407993",
    number = "February",
    pages = "78--81",
    volume = "11",
    file = ":home/drt24/Downloads/06427812.pdf:pdf",
    year = "2013",
    keywords = "cloud-based defense,malware,mobile device security",
    journal = "IEEE Security and Privacy"
}

@article{Lieng2012,
    author = "Lieng, Henrik and Dodgson, Neil A",
    doi = "10.2312/COMPAESTH/COMPAESTH12/081-087",
    title = "{Random Discrete Colour Sampling}",
    abstract = "Apparently-random distributions of colours in a discrete setting have been used by many artists and craftsmen in the past century. Manual colourisation is a tedious and difficult process. Automatic colourisation, on the other hand, tends not to not look ‘random’ to a human, as randomly-generated clusters and patterns stimulate human perception and break the appearance of randomness. We propose an algorithm that minimises these apparent patterns, making the distribution of colours look as if they have been distributed randomly by a human. We show that our approach is superior to current solutions, especially for small numbers of colours. Our algorithm is easily extendible to non-regular patterns in any coordinate system.",
    file = ":home/drt24/Downloads/E2-paper(1).pdf:pdf;:home/drt24/Downloads/p81-lieng.pdf:pdf",
    year = "2012",
    journal = "CAe"
}

@inproceedings{Lim2011,
    author = "Lim, Hyeontaek and Fan, Bin and Andersen, DG",
    doi = "10.1145/2043556.2043558",
    isbn = "9781450309776",
    title = "{SILT: A memory-efficient, high-performance key-value store}",
    url = "http://dl.acm.org/citation.cfm?id=2043558",
    abstract = "SILT (Small Index Large Table) is a memory-efficient, high-performance key-value store system based on flash storage that scales to serve billions of key-value items on a single node. It requires only 0.7 bytes of DRAM per entry and retrieves key/value pairs using on average 1.01 flash reads each. SILT combines new algorithmic and systems techniques to balance the use of memory, storage, and computation. Our contributions include: (1) the design of three basic key-value stores each with a different emphasis on memory-efficiency and write-friendliness; (2) synthesis of the basic key-value stores to build a SILT key-value store system; and (3) an analytical model for tuning system parameters carefully to meet the needs of different workloads. SILT requires one to two orders of magnitude less memory to provide comparable throughput to current high-performance key-value systems on a commodity desktop system with flash storage.",
    file = ":auto/homes/drt24/Downloads/01-lim-online.pdf:pdf",
    year = "2011",
    keywords = "Algorithms,design,flash,measurement,memory efficiency,performance",
    booktitle = "SOSP"
}

@inproceedings{Lin2010b,
    author = "Lin, Kaisen and Kansal, Aman and Lymberopoulos, Dimitrios and Zhao, Feng",
    publisher = "ACM Press",
    doi = "10.1145/1814433.1814462",
    isbn = "9781605589855",
    title = "{Energy-accuracy trade-off for continuous mobile device location}",
    url = "http://dl.acm.org/citation.cfm?id=1814433.1814462",
    booktitle = "Proceedings of the 8th international conference on Mobile systems, applications, and services - MobiSys '10",
    year = "2010",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    keywords = "GPS energy,continuous location,location-based applications",
    pages = "285"
}

@inproceedings{Lin2012,
    author = "Lin, Jialiu and Sadeh, Norman and Amini, Shahriyar and Lindqvist, Janne and Hong, Jason I. and Zhang, Joy",
    publisher = "ACM Press",
    doi = "10.1145/2370216.2370290",
    isbn = "9781450312240",
    title = "{Expectation and purpose}",
    url = "http://dl.acm.org/citation.cfm?id=2370216.2370290",
    booktitle = "Proceedings of the 2012 ACM Conference on Ubiquitous Computing - UbiComp '12",
    year = "2012",
    month = "9",
    file = "::",
    address = "New York, New York, USA",
    keywords = "Android permissions,crowdsourcing,mental model,mobile app,privacy as expectations,privacy summary",
    pages = "501"
}

@inproceedings{Linnap2011,
    author = "Linnap, Mattias and Rice, Andrew C.",
    title = "{Energy Limits in Location Tracking}",
    abstract = "Continuous location tracking records a mobile device’s po- sition for days, months or years without any user interaction to mark movement periods. GPS consumes a significant fraction of power in lo- cation tracking, and various methods for increasing energy-efficiency by GPS scheduling have been proposed in previous work. By deriving and validating an energy-optimal GPS schedule, we show that the minimal energy requirement for continuous tracking by any GPS-based method at 30 metre accuracy is 10mW.We developed and validated a detailed GPS energy model for Android smartphones that captures context-dependent variation in time-to-first-fix, and show that power consumption cannot be easily attributed to individual hardware components. We evaluate GPS scheduling methods on a continuous 14-day sensor trace, and high- light the importance of optimising power consumption during periods of inactivity.",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Linnap, Rice - 2011 - Energy Limits in Location Tracking.pdf:pdf;:auto/homes/drt24/Downloads/optimalenergy (1).pdf:pdf",
    year = "2011",
    keywords = "energy-efficiency,gps,location tracking,mobile devices",
    booktitle = "MobiSys"
}

@inproceedings{Liskov1991,
    author = "Liskov, Barbara H. and Ghemawat, Sanjay and Gruber, Robert E. and Johnson, Paul and Shrira, Liuba",
    publisher = "ACM",
    doi = "10.1145/121132.121169",
    isbn = "0897914473",
    title = "{Replication in the harp file system}",
    url = "http://dx.doi.org/10.1145/121132.121169",
    abstract = "This paper describes the design and implementation of the Harp file system. Harp is a replicated Unix file system accessible via the VFS interface. It provides highly available and reliable storage for files and guarantees that file operations are executed atomically in spite of concurrency and failures. It uses a novel variation of the primary copy replication technique that provides good performance because it allows us to trade disk accesses for network communication. Harp is intended to be used within a file service in a distributed network; in our current implementation, it is accessed via NFS. Preliminary performance results indicate that Harp provides equal or better response time and system capacity than an unreplicated implementation of NFS that uses Unix files directly.",
    issn = "01635980",
    number = "5",
    pages = "226--238",
    volume = "25",
    file = ":auto/homes/drt24/Downloads/p226-liskov.pdf:pdf",
    year = "1991",
    booktitle = "SOSP"
}

@article{Liu,
    author = "Liu, YD",
    url = "http://sensorlab.cs.dartmouth.edu/NSFPervasiveComputingAtScale/pdf/1569390837.pdf",
    journal = "sensorlab.cs.dartmouth.edu",
    file = "::",
    title = "{Energy-Aware Programming in Pervasive Computing}"
}

@inproceedings{Liu2012,
    author = "Liu, Lri and Zhang, Xinwen and Yan, Guanhua and Chen, Songqing",
    title = "{Chrome extensions: Threat analysis and countermeasures}",
    url = "http://profsandhu.com/zhang/pub/ndss12-chrome.pdf",
    abstract = "The widely popular browser extensions now become one of the most commonly used malware attack vectors. The Google Chrome browser, which implements the principles of least privileges and privilege separation by design, of- fers a strong security mechanism to protect malicious web- sites from damaging the whole browser system via exten- sions. In this study, we however reveal that Chrome’s ex- tension security model is not a panacea for all possible at- tacks with browser extensions. Through a series of prac- tical bot-based attacks that can be performed even under typical settings, we demonstrate that malicious Chrome ex- tensions pose serious threats, including both information dispersion and harvesting, to browsers. We further con- duct an in-depth analysis of Chrome’s extension security model, and conclude that its vulnerabilities are rooted from the violation of the principles of least privileges and privi- lege separation. Following these principles, we propose a set of countermeasures that enforce the policies of micro- privilege management and differentiating DOM elements. Using a prototype developed on the latest Chrome browser, we show that they can effectively mitigate the threats posed by malicious Chrome extensions with little effect on normal browsing experience.",
    file = ":home/drt24/Downloads/ndss12-chrome.pdf:pdf",
    year = "2012",
    booktitle = "Network and Distributed System Security Symposium"
}

@inproceedings{Lloyd2011,
    author = "Lloyd, Wyatt and Freedman, Michael J. and Kaminsky, Michael and Andersen, David G.",
    isbn = "9781450309776",
    title = "{Don't settle for eventual: scalable causal consistency for wide-area storage with COPS}",
    url = "http://dl.acm.org/citation.cfm?id=2043593",
    abstract = "Geo-replicated, distributed data stores that support complex online applications, such as social net- works, must provide an “always-on” experience where operations always complete with low latency. Today’s systems often sacrifice strong consistency to achieve these goals, exposing inconsistencies to their clients and necessitating complex application logic. In this paper, we identify and define a consistency model—causal consistency with convergent conflict handling, or causal+—that is the strongest achieved under these constraints. We present the design and implementation of COPS, a key-value store that delivers this consistency model across the wide-area. A key contribution of COPS is its scalability, which can enforce causal dependencies between keys stored across an entire cluster, rather than a single server like previous systems. The central approach in COPS is tracking and explicitly checking whether causal dependencies between keys are satisfied in the local cluster before exposing writes. Further, in COPS-GT, we introduce get transactions in order to obtain a consistent view of multiple keys without locking or blocking. Our evaluation shows that COPS completes operations in less than a millisecond, provides throughput similar to previous systems when using one server per cluster, and scales well as we increase the number of servers in each cluster. It also shows that COPS-GT provides similar latency, throughput, and scaling to COPS for common workloads.",
    file = ":auto/homes/drt24/Downloads/28-lloyd-online.pdf:pdf",
    year = "2011",
    keywords = "ALPS systems,Key-value storage,causal+ consistency,read transactions,scalable wide-area replication",
    booktitle = "SOSP"
}

@unpublished{Loh2007,
    author = {L\"{o}h, Andres and Swierstra, Wouter and Leijen, Daan},
    publisher = "Citeseer",
    doi = "10.1.1.129.5867",
    title = "{A principled approach to version control}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.5867\&amp;rep=rep1\&amp;type=pdf",
    abstract = "Version control systems are essential for managing the distributed development of large software projects. We present a formal model for reasoning about version control. In particular, we give a general definition of patch. Patches abstract over the data on which they operate, making our framework equally suited for version control of everything from highly-structured XML files to blobs of bits. We model repositories as a multiset of patches. The mathematical definitions of patches and repositories enable us to reason about complicated issues such as conflicts and conflict resolution.",
    number = "Section 2",
    file = ":auto/homes/drt24/Downloads/10.1.1.129.5867.pdf:pdf",
    year = "2007"
}

@online{Lowinder2012,
    author = {L\"{o}winder, Anne-Marie Eklund},
    url = "http://conferences.npl.co.uk/satin/presentations/satin2012slides-EklundLowinder.pdf",
    booktitle = "SATIN",
    year = "2012",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-EklundLowinder.pdf:pdf",
    title = "{Step by step DNSSEC deployment in . se}"
}

@article{Lu2009,
    author = "Lu, Hong and Pan, Wei and Lane, Nicholas D and Choudhury, Tanzeem and Campbell, Andrew T",
    publisher = "ACM",
    title = "{SoundSense: scalable sound sensing for people-centric applications on mobile phones}",
    url = "http://portal.acm.org/citation.cfm?id=1555834",
    abstract = "Top end mobile phones include a number of specialized (e.g., accelerometer, compass, GPS) and general purpose sensors (e.g., microphone, camera) that enable new people-centric sensing applications. Perhaps the most ubiquitous and unexploited sensor on mobile phones is the microphone - a powerful sensor that is capable of making sophisticated inferences about human activity, location, and social events from sound. In this paper, we exploit this untapped sensor not in the context of human communications but as an enabler of new sensing applications. We propose SoundSense, a scalable framework for modeling sound events on mobile phones. SoundSense is implemented on the Apple iPhone and represents the first general purpose sound sensing system specifically designed to work on resource limited phones. The architecture and algorithms are designed for scalability and Soundsense uses a combination of supervised and unsupervised learning techniques to classify both general sound types (e.g., music, voice) and discover novel sound events specific to individual users. The system runs solely on the mobile phone with no back-end interactions. Through implementation and evaluation of two proof of concept people-centric sensing applications, we demostrate that SoundSense is capable of recognizing meaningful sound events that occur in users' everyday lives.",
    pages = "13",
    file = "::",
    year = "2009",
    keywords = "audio processing,mobile phones,people centric sensing,sound classification,urban sensing",
    journal = "Proceedings of the MobiSys Conference"
}

@inproceedings{Lu2010,
    author = "Lu, Hong and Yang, Jun and Liu, Zhigang and Lane, Nicholas D. and Choudhury, Tanzeem and Campbell, Andrew T.",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1869992",
    isbn = "9781450303446",
    title = "{The Jigsaw continuous sensing engine for mobile phone applications}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1869992",
    abstract = "Supporting continuous sensing applications on mobile phones is challenging because of the resource demands of long-term sensing, inference and communication algorithms. We present the design, implementation and evaluation of the Jigsaw continuous sensing engine, which balances the performance needs of the application and the resource demands of continuous sensing on the phone. Jigsaw comprises a set of sensing pipelines for the accelerometer, microphone and GPS sensors, which are built in a plug and play manner to support: i) resilient accelerometer data processing, which allows inferences to be robust to different phone hardware, orientation and body positions; ii) smart admission control and on-demand processing for the microphone and accelerometer data, which adaptively throttles the depth and sophistication of sensing pipelines when the input data is low quality or uninformative; and iii) adaptive pipeline processing, which judiciously triggers power hungry pipeline stages (e.g., sampling the GPS) taking into account the mobility and behavioral patterns of the user to drive down energy costs. We implement and evaluate Jigsaw on the Nokia N95 and the Apple iPhone, two popular smartphone platforms, to demonstrate its capability to recognize user activities and perform long term GPS tracking in an energy-efficient manner.",
    year = "2010",
    mendeley-tags = "energy,gps,mobile,power,sensing",
    month = "11",
    pages = "71",
    file = "::",
    address = "New York, New York, USA",
    keywords = "activity recognition,energy,gps,machine learning,mobile,mobile phone sensing,power,power management,sensing",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10"
}

@inproceedings{Lu2010a,
    author = "Lu, Jiakang and Sookoor, Tamim and Srinivasan, Vijay and Gao, Ge and Holben, Brian and Stankovic, John and Field, Eric and Whitehouse, Kamin",
    publisher = "ACM Press",
    doi = "10.1145/1869983.1870005",
    isbn = "9781450303446",
    title = "{The smart thermostat: using occupancy sensors to save energy in homes}",
    url = "http://dl.acm.org/citation.cfm?id=1869983.1870005",
    abstract = "Heating, ventilation and cooling (HVAC) is the largest source of residential energy consumption. In this paper, we demonstrate how to use cheap and simple sensing technology to automatically sense occupancy and sleep patterns in a home, and how to use these patterns to save energy by automatically turning off the home's HVAC system. We call this approach the smart thermostat. We evaluate this approach by deploying sensors in 8 homes and comparing the expected energy usage of our algorithm against existing approaches. We demonstrate that our approach will achieve a 28\% energy saving on average, at a cost of approximately \$25 in sensors. In comparison, a commercially-available baseline approach that uses similar sensors saves only 6.8\% energy on average, and actually increases energy consumption in 4 of the 8 households.",
    year = "2010",
    mendeley-tags = "energy,home,simulation,thermostat",
    month = "11",
    pages = "211",
    file = "::",
    address = "New York, New York, USA",
    keywords = "building energy,energy,home,home monitoring,programmable thermostats,simulation,thermostat,wireless sensor networks",
    booktitle = "Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems - SenSys '10"
}

@inproceedings{Luo2011,
    author = "Luo, Tongbo and Hao, Hao and Du, Wenliang and Wang, Yifei and Yin, Heng",
    isbn = "9781450306720",
    title = "{Attacks on WebView in the Android System}",
    abstract = "WebView is an essential component in both Android and iOS platforms, enabling smartphone and tablet apps to embed a simple but powerful browser inside them. To achieve a bet- ter interaction between apps and their embedded“browsers”, WebView provides a number of APIs, allowing code in apps to invoke and be invoked by the JavaScript code within the web pages, intercept their events, and modify those events. Using these features, apps can become customized “browsers” for their intended web applications. Currently, in the Android market, 86 percent of the top 20 most down- loaded apps in 10 diverse categories use WebView. The design ofWebView changes the landscape of theWeb, especially from the security perspective. Two essential pieces of the Web’s security infrastructure are weakened if Web- View and its APIs are used: the Trusted Computing Base (TCB) at the client side, and the sandbox protection im- plemented by browsers. As results, many attacks can be launched either against apps or by them. The objective of this paper is to present these attacks, analyze their funda- mental causes, and discuss potential solutions.",
    pages = "343----352",
    file = ":home/drt24/Downloads/p343-luo.pdf:pdf",
    year = "2011",
    booktitle = "ACSAC"
}

@article{Lyle2010,
    author = "Lyle, John",
    title = "{Trusted computing and provenance: Better together}",
    url = "http://portal.acm.org/citation.cfm?id=1855796",
    journal = "Workshop on Theory and Practice of Provenance",
    file = "::",
    year = "2010"
}

@book{Lyons2011,
    editor = "Lyons, Kent and Hightower, Jeffrey and Huang, Elaine M.",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-21726-5",
    isbn = "978-3-642-21725-8",
    title = "{Pervasive Computing}",
    url = "http://www.springerlink.com/index/10.1007/978-3-642-21726-5 http://www.springerlink.com/content/n2t1257557j50716/",
    series = "Lecture Notes in Computer Science",
    year = "2011",
    volume = "6696",
    address = "Berlin, Heidelberg"
}

@online{MWRLabs2013,
    author = "Labs, MWR",
    url = "https://labs.mwrinfosecurity.com/blog/2013/09/24/webview-addjavascriptinterface-remote-code-execution/",
    urldate = "2014-12-19",
    year = "2013",
    title = "{WebView addJavascriptInterface Remote Code Execution}"
}

@misc{Mackinlay1986,
    author = "Mackinlay, J. D.",
    year = "1986",
    file = "::",
    title = "{Automating the Design of Graphical Presentations of Relational Information}"
}

@article{Mackinlay2007,
    author = "Mackinlay, Jock and Hanrahan, Pat and Stolte, Chris",
    doi = "10.1109/TVCG.2007.70594",
    title = "{Show me: automatic presentation for visual analysis.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/17968057",
    abstract = "This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.",
    issn = "1077-2626",
    number = "6",
    pages = "1137--44",
    volume = "13",
    file = "::",
    year = "2007",
    keywords = "Computer Graphics,Expert Systems,Information Storage and Retrieval,Information Storage and Retrieval: methods,Programming Languages,Software,Software Design,User-Computer Interface",
    pmid = "17968057",
    journal = "IEEE transactions on visualization and computer graphics"
}

@article{Madhavapeddy2005,
    author = "Madhavapeddy, Anil and Sharp, Richard and Scott, David and Tse, Alastair",
    doi = "10.1109/MPRV.2005.50",
    title = "{Audio networking: the forgotten wireless technology}",
    journal = "Pervasive Computing",
    abstract = "In this article, we'll review various modulation schemes we've worked with previously, covering how to transfer data to nearby smart phones as well as usability and security issues. We'll consider audio networking as a mechanism for introducing data packets into ongoing mobile phone calls. We'll also discuss some real-world problems reported with telephone conferencing and apply audio-networking techniques to them in a case study application.",
    month = "7",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1495392",
    file = ":home/drt24/Downloads/01495392.pdf:pdf",
    year = "2005",
    pages = "55--60"
}

@phdthesis{Madhavapeddy2006,
    author = "Madhavapeddy, Anil",
    publisher = "PhD thesis, University of Cambridge",
    school = "University of Cambridge, Computer Laboratory",
    title = "{Creating high-performance statically type-safe network applications}",
    url = "http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-775.pdf",
    abstract = "A typical Internet server finds itself in the middle of a virtual battleground, under constant threat from worms, viruses and other malware seeking to subvert the original intentions of the programmer. In particular, critical Internet servers such as OpenSSH, BIND and Sendmail have had numerous security issues ranging from low-level buffer overflows to subtle protocol logic errors. These problems have cost billions of dollars as the growth of the Internet exposes increasing numbers of computers to electronic malware. Despite the decades of research on techniques such as model-checking, type-safety and other forms of formal analysis, the vast majority of server implementations continue to be written unsafely and informally in C/C++. In this dissertation we propose an architecture for constructing newimplementations of stan- dard Internet protocols which integrates mature formal methods not currently used in deployed servers: (i) static type systems from theMLfamily of functional languages; (ii) model checking to verify safety properties exhaustively about aspects of the servers; and (iii) generative meta- programming to express high-level constraints for the domain-specific tasks of packet parsing and constructing non-deterministic state machines. Our architecture—dubbed MELANGE—is based on Objective Caml and contributes two domain-specific languages: (i) the Meta Packet Language (MPL), a data description language used to describe the wire format of a protocol and output statically type-safe code to handle network traffic using high-level functional data structures; and (ii) the Statecall Policy Language (SPL) for constructing non-deterministic finite state automata which are embedded into applications and dynamically enforced, or translated into PROMELA and statically model-checked. Our research emphasises the importance of delivering efficient, portable code which is feasi- ble to deploy across the Internet. We implemented two complex protocols—SSH and DNS—to verify our claims, and our evaluation shows that they perform faster than their standard coun- terparts OpenSSH and BIND, in addition to providing static guarantees against some classes of errors that are currently a major source of security problems.",
    number = "775",
    file = ":auto/homes/drt24/Downloads/UCAM-CL-TR-775.pdf:pdf",
    year = "2006"
}

@article{Madhavapeddy2010,
    author = "Madhavapeddy, Anil and Mortier, Richard and Sohan, Ripduman and Gazagnaire, Thomas and Hand, Steven and Deegan, Tim and McAuley, D and Crowcroft, Jon",
    publisher = "USENIX Association",
    title = "{Turning Down the LAMP : Software Specialisation for the Cloud}",
    url = "http://portal.acm.org/citation.cfm?id=1863114",
    abstract = "The wide availability of cloud computing offers an unprecedented opportunity to rethink how we construct applications. The cloud is currently mostly used to package up existing software stacks and operating systems (e.g. LAMP) for scaling out websites. We instead view the cloud as a stable hardware platform, and present a programming framework which permits applications to be constructed to run directly on top of it without intervening software layers. Our prototype (dubbed Mirage) is unashamedly academic; it extends the Objective Caml language with storage extensions and a custom run-time to emit binaries that execute as a guest operating system under Xen. Mirage applications exhibit significant performance speedups for I/O and memory handling versus the same code running under Linux/Xen. Our results can be generalised to offer insight into improving more commonly used languages such as PHP, Python and Ruby, and we discuss lessons learnt and future directions.",
    pages = "7",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madhavapeddy et al. - 2010 - Turning Down the LAMP Software Specialisation for the Cloud.pdf:pdf",
    year = "2010",
    journal = "on Hot topics in cloud"
}

@online{Madhavapeddy2012,
    author = "Madhavapeddy, Anil",
    title = "{Signposts: Trusted effectful internet names}",
    url = "http://conferences.npl.co.uk/satin/presentations/satin2012slides-Madhavapeddy.pdf",
    booktitle = "SATIN",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Madhavapeddy.pdf:pdf",
    year = "2012",
    pages = "1--44"
}

@inproceedings{Madhavapeddy2013,
    author = "Madhavapeddy, Anil and Mortier, Richard and Rotsos, Charalampos",
    isbn = "9781450318709",
    title = "{Unikernels: Library Operating Systems for the Cloud}",
    url = "http://anil.recoil.org/papers/2013-asplos-mirage.pdf",
    abstract = "We present unikernels, a new approach to deploying cloud services via applications written in high-level source code. Unikernels are single-purpose appliances that are compile-time specialised into standalone kernels, and sealed against modification when deployed to a cloud platform. In return they offer significant reduction in image sizes, improved efficiency and security, and should reduce operational costs. Our Mirage prototype compiles OCaml code into unikernels that run on commodity clouds and offer an order of magnitude reduction in code size without significant performance penalty. The architecture combines static type-safety with a single address-space layout that can be made immutable via a hypervisor extension. Mirage contributes a suite of type-safe protocol libraries, and our results demonstrate that the hypervisor is a platform that overcomes the hardware compatibility issues that have made past library operating systems impractical to deploy in the real-world.",
    year = "2013",
    file = ":home/drt24/Downloads/2013-asplos-mirage.pdf:pdf",
    address = "Houston, Texas",
    booktitle = "ASPLOS"
}

@article{Mahajan2010,
    author = "Mahajan, Prince and Setty, Srinath and Lee, Sangmin and Clement, Allen and Alvisi, Lorenzo and Dahlin, Mike and Walfish, Michael",
    publisher = "USENIX Association",
    title = "{Depot : Cloud storage with minimal trust Why untrusted storage ?}",
    url = "http://www.usenix.org/event/osdi10/tech/full_papers/Mahajan.pdf",
    abstract = "The paper describes the design, implementation, and evaluation of Depot, a cloud storage system that minimizes trust assumptions. Depot tolerates buggy or malicious behavior by any number of clients or servers, yet it provides safety and liveness guarantees to correct clients. Depot provides these guarantees using a two-layer architecture. First, Depot ensures that the updates observed by correct nodes are consistently ordered under Fork-Join-Causal consistency (FJC). FJC is a slight weakening of causal consistency that can be both safe and live despite faulty nodes. Second, Depot implements protocols that use this consistent ordering of updates to provide other desirable consistency, staleness, durability, and recovery properties. Our evaluation suggests that the costs of these guarantees are modest and that Depot can tolerate faults and maintain good availability, latency, overhead, and staleness even when significant faults occur.",
    pages = "1--12",
    file = ":auto/homes/drt24/Downloads/Mahajan.pdf:pdf",
    year = "2010",
    journal = "OSDI"
}

@article{Maisonneuve2009,
    editor = "Athanasiadis, Ioannis N and Mitkas, Pericles A and Rizzoli, Andrea E and Gmez, Jorge Marx",
    author = "Maisonneuve, Nicolas and Stevens, Matthias and Niessen, Maria E and Steels, Luc",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-540-88351-7_16",
    isbn = "9783540883517",
    title = "{NoiseTube: Measuring and mapping noise pollution with mobile phones}",
    journal = "Information Technologies in Environmental Engineering",
    series = "Environmental Science and Engineering",
    abstract = "In this paper we present a new approach for the assessment of noise pollution involving the general public. The goal of this project is to turn GPS-equipped mobile phones into noise sensors that enable citizens to measure their personal exposure to noise in their everyday environment. Thus each user can contribute by sharing their geo-localised measurements and further personal annotation to produce a collective noise map.",
    issn = "18635520",
    number = "May",
    pages = "215--228",
    volume = "4",
    url = "http://prog.vub.ac.be/Publications/2009/vub-prog-tr-09-08.pdf",
    file = "::",
    year = "2009",
    institution = "Springer Berlin Heidelberg"
}

@article{Major2011,
    author = "Major, Louis and Kyriacou, Theocharis and Brereton, Pearl",
    isbn = "9788461474233",
    title = "{Simulated Robotic Agents as Tools to Teach Introductary Programming}",
    journal = "Computing",
    mendeley-tags = "End-User Programming",
    number = "March",
    file = "::",
    year = "2011",
    keywords = "End-User Programming,computing,innovation,learning,mapping study,novices,programming,robotics,robots,systematic literature review,teaching",
    pages = "3837--3846"
}

@inproceedings{Manner2010,
    author = {Manner, Jukka and Luoma, Marko and Ott, J\"{o}rg and H\"{a}m\"{a}l\"{a}inen, Jyri},
    publisher = "ACM Press",
    doi = "10.1145/1791314.1791325",
    isbn = "9781450300421",
    title = "{Mobile networks unplugged}",
    url = "http://portal.acm.org/citation.cfm?id=1791314.1791325",
    booktitle = "Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking - e-Energy '10",
    year = "2010",
    mendeley-tags = "energy,mobile,network,power",
    month = "4",
    file = "::",
    address = "New York, New York, USA",
    keywords = "2G,3G,LTE,energy,energy consumption,energy efficiency,mobile,mobile networks,network,power,renewable energy",
    pages = "71"
}

@inproceedings{Manweiler2011,
    author = "Manweiler, Justin and Choudhury, Romit Roy",
    isbn = "9781450306430",
    title = "{Avoiding the Rush Hours : WiFi Energy Management via Traffic Isolation}",
    abstract = "WiFi continues to be a prime source of energy consumption in mobile devices. This paper observes that, despite a rich body of research in WiFi energy management, there is room for improvement. Our key finding is that WiFi energy optimiza- tions have conventionally been designed with a single AP in mind. However, network contention among different APs can dramatically increase a client’s energy consumption. Each client may have to keep awake for long durations before its own AP gets a chance to send packets to it. As the AP density increases in the vicinity, the waiting time inflates, resulting in a proportional decrease in battery life. We design SleepWell, a system that achieves energy efficiency by evading network contention. The APs regulate the sleep- ing window of their clients in a way that different APs are active/inactive during non-overlapping time windows. The solution is analogous to the common wisdom of going late to office and coming back late, thereby avoiding the rush hours. We implement SleepWell on a testbed of 8 Laptops and 9 An- droid phones, and evaluate it over a wide variety of scenarios and traffic patterns (YouTube, Pandora, FTP, Internet radio, and mixed). Results show a median gain of up to 2x when WiFi links are strong; when links are weak and the network density is high, the gains can be even more. We believe Sleep- Well is a desirable upgrade toWiFi systems, especially in light of increasingWiFi density.",
    mendeley-tags = "Algorithms,Design,Experimentation,Measurement",
    file = ":home/drt24/Library/papers/MobiSys/Manweiler, Choudhury/Manweiler, Choudhury - 2011 - Avoiding the Rush Hours WiFi Energy Management via Traffic Isolation.pdf:pdf",
    year = "2011",
    keywords = "802.11,AP,Algorithms,Beacon,Contention,Design,Experimentation,Measurement,PSM,Scheduling,WLAN",
    booktitle = "MobiSys"
}

@inproceedings{Marchiori2010,
    author = "Marchiori, Alan and Han, Qi",
    isbn = "9781450304580",
    title = "{Distributed Wireless Control for Building Energy Management ∗}",
    abstract = "Automated building energy management systems are es- sential to enabling the development of mass-market, low- energy buildings. In existing and future buildings, the im- pacts of occupant behaviors contribute significantly to the total energy efficiency. As building technologies and materi- als improve, the relative impact of behavioral factors is more significant. We propose a general framework where building systems can share information in order to optimize perfor- mance. To be successful, such a system must be respon- sive, intuitive, robust, and scalable. As a first step toward achieving these goals, we present a prototype distributed control system for building energy management that uses wireless sensor network-class nodes. Using protocol inde- pendent multicast, sensors and controllers are allowed to ef- ficiently share information in a distributed peer-to-peer fash- ion. Our prototype system achieved an energy savings of 7.1\% - 14.6\% by implementing a relatively simple control policy. Based on the results of this this work we have identi- fied three key areas for future work.",
    mendeley-tags = "Design,Experimentation,Performance",
    pages = "37--42",
    file = ":home/drt24/Library/papers/BuildSys/Marchiori, Han/Marchiori, Han - 2010 - Distributed Wireless Control for Building Energy Management ∗.pdf:pdf",
    year = "2010",
    keywords = "Design,Distributed Wireless Control,Experimentation,Multicast,Peer-to-Peer,Performance",
    booktitle = "BuildSys"
}

@inproceedings{Marconato2012,
    author = "Marconato, Geraldine Vache and Nicomette, Vincent and Ka\^{a}niche, Mohamed",
    publisher = "IEEE",
    doi = "10.1109/CRISIS.2012.6378954",
    isbn = "9781467330893",
    title = "{Security-related vulnerability life cycle analysis}",
    abstract = "This paper deals with the characterization of security-related vulnerabilities based on public data reported in the Open Source Vulnerability Database. We focus on the analysis of vulnerability life cycle events corresponding to the vulnerability discovery, the vulnerability disclosure, the patch release, and the exploit availability. We study the distribution of the time between these events considering different operating systems (Windows, Unix, Mobile OS), and different attributes such as the vulnerability impact on confidentiality, integrity or availability, the access vector reflecting how the vulnerability is exploited, and the complexity of the exploit. The results obtained highlight some interesting trends and behaviours, concerning, e.g. the time between the disclosure of a vulnerability and the availability of a patch or of the exploit, that are sometimes specific to the considered operating system or the vulnerability attributes. The results are also aimed at providing useful inputs to security risk assessment and modelling studies.",
    file = ":home/drt24/Downloads/06378954.pdf:pdf",
    year = "2012",
    booktitle = "7th International Conference on Risks and Security of Internet and Systems, CRiSIS 2012"
}

@article{Masry1997,
    author = "Masry, E. and Fan, Jianqing",
    publisher = "Wiley Online Library",
    title = "{Local polynomial estimation of regression functions for mixing processes}",
    url = "http://onlinelibrary.wiley.com/doi/10.1111/1467-9469.00056/abstract",
    journal = "Scandinavian Journal of Statistics",
    number = "2",
    volume = "24",
    file = ":home/drt24/Library/papers/Unknown/Unknown/Unknown - Unknown - timereg.ps:ps",
    year = "1997",
    keywords = "Asymptotic normality,local polynomial fitting,mixing processes",
    pages = "165--179"
}

@inproceedings{Massacci2010,
    author = "Massacci, Fabio and Nguyen, Viet Hung",
    publisher = "ACM",
    isbn = "9781450303408",
    title = "{Which is the right source for vulnerability studies? An empirical analysis on Mozilla Firefox}",
    url = "http://dl.acm.org/citation.cfm?id=1853925",
    abstract = "Recent years have seen a trend towards the notion of quanti- tative security assessment and the use of empirical methods to analyze or predict vulnerable components. Many papers focused on vulnerability discovery models based upon either a public vulnerability databases (e.g., CVE, NVD), or ven- dor ones (e.g.,MFSA). Some combine these databases. Most of these works address a knowledge problem: can we under- stand the empirical causes of vulnerabilities? Can we predict them? Still, if the data sources do not completely capture the phenomenon we are interested in predicting, then our predictor might be optimal with respect to the data we have but unsatisfactory in practice. In our work, we focus on a more fundamental question: the quality of vulnerability database. We provide an an- alytical comparison of different security metric papers and the relative data sources. We also show, based on exper- imental data for Mozilla Firefox, how using different data sources might lead to completely different results.",
    year = "2010",
    month = "9",
    file = ":home/drt24/Downloads/a4-massacci.pdf:pdf",
    address = "Bolzano-Bozen, Italy",
    booktitle = "MetriSec"
}

@book{Maurice1968,
    author = "Wilkes, Maurice V.",
    year = "1968",
    edition = "2",
    title = "{Time-sharing computer systems}",
    isbn = "0356024261",
    publisher = "MacDonald \& Co."
}

@book{Maurice1975,
    author = "Wilkes, Maurice V.",
    publisher = "Elsevier Science Inc",
    year = "1975",
    isbn = "0444195254",
    title = "{Time Sharing Computer Systems}"
}

@inproceedings{Mazieres2002,
    author = "Mazi\`{e}res, David and Shasha, Dennis",
    publisher = "ACM",
    doi = "10.1145/571825.571840",
    isbn = "1581134851",
    title = "{Building secure file systems out of Byzantine storage}",
    url = "http://dl.acm.org/citation.cfm?id=571840",
    abstract = "This paper shows how to implement a trusted network file system on an untrusted server. While cryptographic storage techniques exist that allow users to keep data secret from untrusted servers, this work concentrates on the detection of tampering attacks and stale data. Ideally, users of an untrusted storage server would immediately and unconditionally notice any misbehavior on the part of the server. This ideal is unfortunately not achievable. However, we define a notion of data integrity called fork consistency in which, if the server delays just one user from seeing even a single change by another, the two users will never again see one another's changes---a failure easily detectable with on-line communication. We give a practical protocol for a multi-user network file system called SUNDR, and prove that SUNDR offers fork consistency whether or not the server obeys the protocol.",
    year = "2002",
    month = "7",
    pages = "108--117",
    file = ":home/drt24/Downloads/p108-mazieres.pdf:pdf",
    address = "Monterey, California",
    booktitle = "Principles of distributed computing (PODC)"
}

@article{McCartney1999a,
    author = "McCartney, T",
    doi = "10.1006/jvlc.1999.0116",
    title = "{End-User Visualization and Manipulation of Distributed Aggregate Data}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X99901167",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "3",
    month = "6",
    volume = "10",
    file = "::",
    year = "1999",
    pages = "193--213"
}

@inproceedings{McCullough2011,
    author = "McCullough, John C. and Agarwal, Yuvraj and Chandrashekar, Jaideep and Kuppuswamy, Sathyanarayan and Snoeren, Alex C. and Gupta, Rajesh K.",
    title = "{Evaluating the effectiveness of model-based power characterization}",
    url = "http://dl.acm.org/citation.cfm?id=2002181.2002193",
    abstract = "Accurate power characterization is important in computing platforms for several reasons ranging from poweraware adaptation to power provisioning. Power characterization is typically obtained through either direct measurements enabled by physical instrumentation or modeling based on hardware performance counters. We show, however, that linear-regression based modeling techniques commonly used in the literature work well only in restricted settings. These techniques frequently exhibit high prediction error in modern computing platforms due to inherent complexities such as multiple cores, hidden device states, and large dynamic power components. Using a comprehensive measurement framework and an extensive set of benchmarks, we consider several more advanced modeling techniques and observe limited improvement. Our quantitative demonstration of the limitations of a variety of modeling techniques highlights the challenges posed by rising hardware complexity and variability and, thus, motivates the need for increased direct measurement of power consumption.",
    month = "6",
    file = "::",
    year = "2011",
    booktitle = "Proceedings of the 2011 USENIX conference on USENIX annual technical conference",
    pages = "12"
}

@inproceedings{McDaniel2010,
    author = "McDaniel, P. and Butler, Kevin and McLaughlin, S. and Sion, R. and Zadok, E. and Winslett, M.",
    publisher = "USENIX Association",
    title = "{Towards a secure and efficient system for end-to-end provenance}",
    url = "http://dl.acm.org/citation.cfm?id=1855797",
    booktitle = "Proceedings of the 2nd conference on Theory and practice of provenance",
    file = "::",
    year = "2010",
    pages = "2--2"
}

@article{McIntyre1997,
    author = "McIntyre, Michael",
    title = "{Lucidity and Science - I: Writing skills and the pattern perception hypothesis}",
    journal = "Interdisciplinary Science Review",
    number = "3",
    volume = "22",
    year = "1997",
    keywords = "lucidity,perception,writing",
    pages = "199--216"
}

@article{McMillan2010,
    editor = {Flor\'{e}en, Patrik and Kr\"{u}ger, Antonio and Spasojevic, Mirjana},
    author = {McMillan, Donald and Morrison, Alistair and Brown, Owain and Hall, Malcolm and Chalmers, Matthew and Flor\'{e}en, Patrik and Kr\"{u}ger, Antonio and Spasojevic, Mirjana},
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/978-3-642-12654-3",
    isbn = "978-3-642-12653-6",
    title = "{Further into the Wild: Running Worldwide Trials of Mobile Systems}",
    url = "http://www.springerlink.com/content/r42qt78526318686/",
    series = "Lecture Notes in Computer Science",
    abstract = "Many studies of ubiquitous computing systems involve deploying a system to a group of users who will be studied through direct observation, interviews and the gathering of system log data. However, such studies are often limited in the number of participants and duration of the trial, particularly if the researchers are providing the participants with hardware. Apple’s App Store and similar application repositories have become popular with smartphone users, yet few ubiquitous computing studies have yet utilised these distribution mechanisms. We describe our experiences of running a very large scale trial where such a distribution model is used to recruit thousands of users for a mobile system trial that can be run continuously with no constrained end date. We explain how we conducted such a trial, covering issues such as data logging and interviewing users based in several different continents. Benefits and potential shortcomings of running a trial in this way are discussed and we offer guidance on ways to help manage a large and disparate user-base using in-application feedback measures and web-based social networking applications. We describe how, through these methods, we were able to further the development of a piece of ubiquitous computing software through user-informed design on a mass scale.",
    year = "2010",
    pages = "210--227",
    volume = "6030",
    file = "::",
    address = "Berlin, Heidelberg",
    journal = "Pervasive Computing"
}

@article{McNab2009,
    author = "McNab, Neil and Bryan, Anthony",
    isbn = "9781605587233",
    title = "{An implementation of the Linux software repository model for other operating systems}",
    url = "http://portal.acm.org/citation.cfm?id=1656437.1656445",
    journal = "HotSWUp '09: Proceedings of the 2nd International Workshop on Hot Topics in Software Upgrades",
    file = ":home/drt24/Downloads/a6-mcnab.pdf:pdf",
    year = "2009",
    keywords = "detection,packages,repository,upgrade",
    pages = "3--8"
}

@article{Melnik2010,
    author = "Melnik, Sergey and Gubarev, Andrey and Long, Jing Jing and Romer, Geoffrey and Shivakumar, Shiva and Tolton, Matt and Vassilakis, Theo",
    publisher = "VLDB Endowment",
    title = "{Dremel : Interactive Analysis of Web-Scale Datasets}",
    url = "http://portal.acm.org/citation.cfm?id=1920886",
    journal = "Proceedings of the VLDB Endowment",
    issn = "21508097",
    number = "1-2",
    institution = "Google",
    volume = "3",
    pages = "330--339",
    file = "::",
    year = "2010",
    abstract = "Dremel is a scalable, interactive ad-hoc query system for analy- sis of read-only nested data. By combining multi-level execution trees and columnar data layout, it is capable of running aggrega- tion queries over trillion-row tables in seconds. The system scales to thousands of CPUs and petabytes of data, and has thousands of users at Google. In this paper, we describe the architecture and implementation of Dremel, and explain how it complements MapReduce-based computing. We present a novel columnar stor- age representation for nested records and discuss experiments on few-thousand node instances of the system"
}

@inproceedings{Merkle1988,
    author = "Merkle, Ralph",
    publisher = "Springer",
    doi = "10.1007/3-540-48184-2_32",
    title = "{A digital signature based on a conventional encryption function}",
    url = "http://www.springerlink.com/index/q865hwxq73ex1am9.pdf",
    abstract = "A new digital signature based only on a conventional encryption function (such as DES) is described which is as secure as the underlying encryption function -- the security does not depend on the difficulty of factoring and the high computational costs of modular arithmetic are avoided. The signature system can sign an unlimited number of messages, and the signature size increases logarithmically as a function of the number of messages signed. Signature size in a ‘typical’ sys- tem might range from a few hundred bytes to a few kilobytes, and generation of a signature might require a few hundred to a few thousand computations of the underlying conventional encryption function.",
    pages = "369--378",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merkle - 1988 - A digital signature based on a conventional encryption function.pdf:pdf",
    year = "1987",
    booktitle = "Advances in Cryptology"
}

@article{Message2008,
    author = "Message, Robin and Mycroft, Alan",
    doi = "10.1016/j.entcs.2008.04.096",
    title = "{Controlling Control Flow in Web Applications}",
    url = "http://dx.doi.org/10.1016/j.entcs.2008.04.096",
    abstract = "Control flow is often key problem in current web applications. For example, using the back button gives a POSTDATA error, using multiple windows books the wrong hotel, and sending a link to a friend does not work. Previous solutions used continuations as a model for user interaction. However continuations are insufficient as a model of all web interactions. We believe the protocol and browsers themselves are insufficiently powerful to represent the control flow desired in a web application. Our solution is to extend the protocol and browser sufficiently that these problems can be avoided. We seek to be agnostic about how web applications are written and instead recognise that many of the problems stem from underlying weaknesses in the protocol. As an example, the application ought to be able to inform the browser that pressing back on a payment confirmation page is not allowed. Instead, the cached page can be displayed in a read-only, archive fashion to the user, or a new page can be shown instead which is consistent with the global state. We discuss how some of these ideas may be implemented within the existing HTTP/1.1 protocol; and what modest extensions to the protocol would enable full implementation. We also discuss the interaction with Web 2.0 and the security and privacy implications of our extensions.",
    issn = "15710661",
    number = "3",
    month = "5",
    volume = "200",
    pages = "119--131",
    year = "2008",
    keywords = "ajax,browser,continuations,control flow,navigation,protocol,state,web application",
    journal = "Electronic Notes in Theoretical Computer Science"
}

@inproceedings{Mettler2010,
    author = "Mettler, Adrian and Wagner, Daniel and Close, Tyler",
    title = "{Joe-E: A security-oriented subset of Java}",
    url = "http://www.eecs.berkeley.edu/~daw/papers/joe-e-ndss10.pdf",
    abstract = "We present Joe-E, a language designed to support the development of secure software systems. Joe-E is a subset of Java that makes it easier to architect and implement programs with strong security properties that can be checked during a security review. It enables programmers to apply the principle of least privilege to their programs; implement application-specific reference monitors that cannot be bypassed; introduce and use domain-specific security abstractions; safely execute and interact with untrusted code; and build secure, extensible systems. Joe-E demonstrates how it is possible to achieve the strong security properties of an object-capability language while retaining the fea- tures and feel of a mainstream object-oriented language. Additionally, we present ways in which Java’s static type safety complements object-capability analysis and permits additional security properties to be verified statically, com- pared with previous object-capability languages which rely on runtime checks. In this paper, we describe the design and implementation of Joe-E and its advantages for secu- rity and auditability over standard Java. We demonstrate how Joe-E can be used to develop systems with novel secu- rity properties that would be difficult or impossible to en- sure otherwise, including a web application platform that provides transparent, transactional object persistence and can safely host multiple mutually-distrustful applications in a single JVM.",
    file = ":auto/homes/drt24/Downloads/joe-e-ndss10.pdf:pdf",
    year = "2010",
    booktitle = "Network and Distributed System Security Symposium (NDSS)"
}

@inproceedings{MichaelCohenHaitaoSteveZhuSenemEzgiEmgin2011,
    author = "{Michael Cohen, Haitao Steve Zhu, Senem Ezgi Emgin}, Yu David Liu",
    year = "2011",
    title = "{Energy Types}"
}

@techreport{Miller2011,
    author = "Miller, Matt and Burrell, Tim and Howard, Michael",
    year = "2011",
    title = "{Mitigating software vulnerabilities}"
}

@inproceedings{Minsky2002,
    author = "Minsky, Y and Trachtenberg, A",
    title = "{Scalable set reconciliation}",
    url = "https://gnunet.org/sites/default/files/practical.pdf",
    abstract = "We consider the problem of efficiently reconciling two similar sets held by different hosts. This problem is motivated by the problem of data exchange in a gossip protocol, but also has other applications including synchronisation of PDA databases and maintenance of routing tables in the face of host failures. Previous results have presented algorithms for set reconcilation that are nearly optimal in terms of communication complexity, but have computational complexity that is cubic in the number of differences. We present and analyze a novel algorithm that has expected computational and communication complexity that is linear in the number of differences between the sets being reconciled. We also provide experimental results from an implementation of this algorithm.",
    year = "2002",
    month = "10",
    file = ":home/drt24/Downloads/BUTR2002-01.ps:ps",
    address = "Monticello",
    booktitle = "40th Annual Allerton Conference on Communication, Control and Computing"
}

@article{Minsky2003,
    author = "Minsky, Yaron and Trachtenberg, Ari and Zippel, Richard",
    isbn = "4962000101",
    title = "{Set reconciliation with nearly optimal communication complexity}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1226606",
    abstract = "We consider the problem of efficiently reconciling two similar sets held by different hosts while minimizing the communication complexity, which we call the set reconciliation problem. We describe an approach to set reconciliation based on a polynomial encoding of sets. The resulting protocols exhibit tractable computational complexity and nearly optimal communication complexity when the sets being reconciled are sparse. Also, these protocols can be adapted to work over a broadcast channel, allowing many clients to reconcile with one host based on a single broadcast, even if each client is missing a different subset.",
    number = "9",
    pages = "2213--2218",
    volume = "49",
    file = ":home/drt24/Downloads/ieee-it3-web.pdf:pdf;:home/drt24/Downloads/01226606.pdf:pdf",
    year = "2003",
    keywords = "Data consistency,gossip/epidemic protocols,interactive computation,reconciliation",
    journal = "IEEE International Symposium on Information Theory"
}

@unpublished{Mitra,
    author = "Mitra, Sabyasachi and Ransbotham, Sam",
    keywords = "Diffusion of Innovation,Information Disclosure,Information Security,Negative Innovation,Software Vulnerability",
    abstract = "With the nearly instantaneous dissemination of information in the modern era, policies regarding the disclosure of sensitive information have become the focus of significant discussion in several contexts. The fundamental debate centers on tradeoffs inherent in disclosing information that society needs, but that can also be used for nefarious purposes. Using information security as a research context, our empirical study examines the adoption of software vulnerabilities by a population of attackers. We compare attacks based on software vulnerabilities disclosed through full disclosure and limited disclosure mechanisms. We find that full disclosure accelerates the diffusion of attacks, increases the penetration of attacks within the target population, and increases the risk of first attack after the vulnerability is reported. Interestingly, the effect of full disclosure is greater during periods when there are more overall vulnerabilities reported, indicating that attackers may strategically focus on busy periods when the effort of security professionals is spread across many vulnerabilities. Although the aggregate volume of attacks remains unaffected by full disclosure, attacks occur earlier in the life cycle of the vulnerability. Building off our theoretical insights, we discuss the implications of our findings in more general contexts. Keywords:",
    file = ":home/drt24/Downloads/Ransbotham.pdf:pdf",
    title = "{The Disclosure and Diffusion of Security Information}"
}

@online{Mobarhan,
    author = "Mobarhan, Masoumeh Alsadat Haghighi",
    url = "http://publications.lib.chalmers.se/publication/136115",
    language = "en",
    file = "::",
    title = "{Formal Specification of Selected Android Core Applications and Library Functions}"
}

@inproceedings{Molina-Markham2010,
    author = "Molina-Markham, Andres and Shenoy, Prashant and Fu, Kevin and Cecchet, Emmanuel and Irwin, David E.",
    isbn = "9781450304580",
    title = "{Private Memoirs of a Smart Meter}",
    abstract = "Household smart meters that measure power consumption in real-time at fine granularities are the foundation of a future smart electricity grid. However, the widespread deployment of smart meters has serious privacy implications since they inadvertently leak detailed information about household ac- tivities. In this paper, we show that even without a priori knowledge of household activities or prior training, it is possible to extract complex usage patterns from smart meter data using off-the-shelf statistical methods. Our analysis uses two months of data from three homes, which we instrumented to log aggregate household power consumption every second. With the data from our small-scale deployment, we demon- strate the potential for power consumption patterns to reveal a range of information, such as how many people are in the home, sleeping routines, eating routines, etc. We then sketch out the design of a privacy-enhancing smart meter architec- ture that allows an electric utility to achieve its net metering goals without compromising the privacy of its customers.",
    mendeley-tags = "Design,Measurement,Security,Standardization",
    file = ":home/drt24/Library/papers/BuildSys/Molina-Markham et al/Molina-Markham et al. - 2010 - Private Memoirs of a Smart Meter.pdf:pdf",
    year = "2010",
    keywords = "Design,Measurement,Security,Standardization,privacy,security,smart grid,smart meters",
    booktitle = "BuildSys"
}

@article{Moreau,
    author = "Moreau, Luc and Tan, Hock Kim",
    url = "http://www.libsearch.com/view/2132815",
    abstract = "The problem of protecting mobile code from both denial-of-service and state tampering attacks by malicious hosts are not well addressed in existing techniques for mobile code security. We propose a possible approach based on extending an existing mobile code security technique: cryptographic tracing. This is achieved through the introduction of a trusted third party, the verification server, which undertakes the verification of execution traces on behalf of the agent owner. The interaction between the verification servers and host platforms in the new protocol is outlined. Security properties of the protocol are verified by modelling the system in CSP and checking the resulting state transitions using the model checker FDR. Limitations of this approach to verification are then briefly discussed.",
    title = "{Extending Execution Tracing for Mobile Code$\backslash$nSecurity}"
}

@article{Morris1979,
    author = "Morris, Robert and Thompson, Ken",
    publisher = "ACM",
    doi = "10.1145/359168.359172",
    title = "{Password security: A case history}",
    journal = "Communications of the ACM",
    abstract = "This paper describes the history of the design of the password security scheme on a remotely accessed time-sharing system. The present design was the result of countering observed attempts to penetrate the system. The result is a compromise between extreme security and ease of use.",
    number = "11",
    volume = "22",
    url = "http://dl.acm.org/citation.cfm?id=359172",
    file = ":auto/homes/drt24/Downloads/passwd.ps:ps",
    year = "1979",
    pages = "594--597"
}

@article{Morris1979a,
    author = "Morris, Robert and Thompson, Ken",
    title = "{Password security: A case history}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.8377",
    journal = "COMMUNICATIONS OF THE ACM",
    number = "11",
    volume = "22",
    file = "::",
    year = "1979",
    pages = "594 -- 597"
}

@article{MorrisJr1973,
    author = "{Morris Jr}, James.H.",
    publisher = "ACM",
    title = "{Protection in programming languages}",
    journal = "Communications of the ACM",
    abstract = "Linguistic mechanisms which can be used to protect one subprogram from another's malfunctioning are described. Function-producing functions and various type-tagging schemes are considered. An attempt is made to distinguish between access limitation and authentication.",
    number = "1",
    volume = "16",
    url = "http://dl.acm.org/citation.cfm?id=361937",
    file = ":auto/homes/drt24/Downloads/morris73.pdf:pdf",
    year = "1973",
    keywords = "access,access keys,and phrases,authentication,control,environments,protection,seals,secrecy,trademarks,types",
    pages = "15--21"
}

@article{Mowery2012,
    author = "Mowery, Keaton and Shacham, Hovav",
    title = "{Pixel Perfect : Fingerprinting Canvas in HTML5}",
    abstract = "Tying the browser more closely to operating system func- tionality and system hardware means that websites have more access to these resources, and that browser behavior varies depending on the behavior of these resources. We propose a new system fingerprint, inspired by the observation above: render text and WebGL scenes to a <canvas> element, then examine the pixels produced. The new fingerprint is consistent, high-entropy, orthogonal to other fingerprints, transparent to the user, and readily obtainable.",
    pages = "1--12",
    file = ":home/drt24/Downloads/canvas.pdf:pdf",
    year = "2012",
    journal = "Web 2.0 Security \& Privacy 20 (W2SP)"
}

@inproceedings{Muniswamy-Reddy2006,
    author = "Muniswamy-Reddy, K.K. and Holland, D.A. and Braun, Uri and Seltzer, Margo",
    title = "{Provenance-aware storage systems}",
    url = "http://www.usenix.org/events/usenix06/tech/full_papers/muniswamy-reddy/muniswamy-reddy_html/",
    booktitle = "Proceedings of the 2006 USENIX Annual Technical Conference",
    file = "::",
    year = "2006",
    pages = "43--56"
}

@online{Muniswamy-Reddy2008,
    author = "Muniswamy-Reddy, Kiran-Kumar and Holland, Stephen",
    url = "http://www.eecs.harvard.edu/~syrah/node/198",
    year = "2008",
    file = "::",
    title = "{Layering in Provenance-Aware Storage Systems}"
}

@inproceedings{Muniswamy-Reddy2009,
    author = "Muniswamy-Reddy, K.K. and Braun, Uri and Holland, D.A. and Macko, Peter and Maclean, Diana and Margo, Daniel and Seltzer, Margo and Smogor, Robin",
    publisher = "USENIX Association",
    title = "{Layering in provenance systems}",
    url = "http://dl.acm.org/citation.cfm?id=1855817",
    booktitle = "Proceedings of the 2009 conference on USENIX Annual technical conference",
    file = "::",
    year = "2009",
    pages = "10--10"
}

@article{Muniswamy-Reddy2009a,
    author = "Muniswamy-Reddy, K.K. and Holland, D.A.",
    publisher = "ACM",
    doi = "10.1145/1629080.1629083",
    title = "{Causality-based versioning}",
    url = "http://portal.acm.org/citation.cfm?doid=1629080.1629083 http://dl.acm.org/citation.cfm?id=1629083",
    journal = "ACM Transactions on Storage (TOS)",
    issn = "15533077",
    number = "4",
    month = "12",
    volume = "5",
    file = "::",
    year = "2009",
    pages = "13"
}

@article{Muniswamy-Reddy2009c,
    author = "Muniswamy-Reddy, Kiran-Kumar and Braun, Uri and Holland, David A. and Macko, Peter and Maclean, Diana and Margo, Daniel and Seltzer, Margo and Smogor, Robin",
    url = "http://dl.acm.org/citation.cfm?id=1855807.1855817",
    title = "{Layering in provenance systems}",
    year = "2009",
    pages = "10",
    month = "6"
}

@article{Murdoch2010,
    author = "Murdoch, Steven J. and Anderson, Ross",
    publisher = "Springer",
    doi = "10.1007/978-3-642-14577-3_27",
    title = "{Verified by Visa and MasterCard SecureCode: or, how not to design authentication}",
    journal = "Financial Cryptography and Data Security",
    abstract = "Banks worldwide are starting to authenticate online card transactions using the ‘3-D Secure’ protocol, which is branded as Veri- fied by Visa and MasterCard SecureCode. This has been partly driven by the sharp increase in online fraud that followed the deployment of EMV smart cards for cardholder-present payments in Europe and else- where. 3-D Secure has so far escaped academic scrutiny; yet it might be a textbook example of how not to design an authentication protocol. It ignores good design principles and has significant vulnerabilities, some of which are already being exploited. Also, it provides a fascinating les- son in security economics. While other single sign-on schemes such as OpenID, InfoCard and Liberty came up with decent technology they got the economics wrong, and their schemes have not been adopted. 3-D Se- cure has lousy technology, but got the economics right (at least for banks and merchants); it now boasts hundreds of millions of accounts.We sug- gest a path towards more robust authentication that is technologically sound and where the economics would work for banks, merchants and customers – given a gentle regulatory nudge.",
    number = "January",
    url = "http://www.springerlink.com/index/C6638483R55018TX.pdf",
    file = ":home/drt24/Library/papers/Area/Murdoch, Anderson/Murdoch, Anderson - 2010 - Verified by Visa and MasterCard SecureCode or , How Not to Design Authentication.pdf:pdf",
    year = "2010",
    pages = "336--342"
}

@article{Murdoch2011,
    author = "Murdoch, Stephen J",
    publisher = "Springer",
    doi = "10.1007/978-3-642-22137-8_13",
    isbn = "978-3-642-22136-1",
    title = "{Hardened Stateless Session Cookies}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-22137-8_13",
    abstract = "Stateless session cookies allow web applications to alter their behaviour based on user preferences and access rights, without maintain- ing server-side state for each session. This is desirable because it reduces the impact of denial of service attacks and eases database replication issues in load-balanced environments. The security of existing session cookie proposals depends on the server protecting the secrecy of a sym- metric MAC key, which for engineering reasons is usually stored in a database, and thus at risk of accidental leakage or disclosure via appli- cation vulnerabilities. In this paper we show that by including a salted iterated hash of the user password in the database, and its pre-image in a session cookie, an attacker with read access to the server is unable to spoof an authenticated session. Even with knowledge of the server’s MAC key the attacker needs a user’s password, which is not stored on the server, to create a valid cookie. By extending an existing session cookie scheme, we maintain all the previous security guarantees, but also pre- serve security under partial compromise.",
    number = "April",
    pages = "93--101",
    volume = "6615",
    file = ":home/drt24/Downloads/protocols08cookies.pdf:pdf",
    year = "2011",
    journal = "Security Protocols XVI"
}

@inproceedings{Murmuria2012,
    author = "Murmuria, Rahul and Medsger, Jeffrey and Stavrou, Angelos and Voas, Jeffrey M.",
    publisher = "IEEE",
    doi = "10.1109/SERE.2012.19",
    isbn = "978-1-4673-2067-2",
    title = "{Mobile Application and Device Power Usage Measurements}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true\&arnumber=6258304\&contentType=Conference+Publications",
    abstract = "Reducing power consumption has become a crucial design tenet for both mobile and other small computing devices that are not constantly connected to a power source. However, unlike devices that have a limited and predefined set of functionality, recent mobile smart phone devices have a very rich set of components and can handle multiple general purpose programs that are not a-priori known or profiled. In this paper, we present a general methodology for collecting measurements and modelling power usage on smart phones. Our goal is to characterize the device subsystems and perform accurate power measurements. We implemented a system that effectively accounts for the power usage of all of the primary hardware subsystems on the phone: CPU, display, graphics, GPS, audio, microphone, and Wi-Fi. To achieve that, we make use of the per-subsystem time shares reported by the operating system's power-management module. We present the models capability to further calculate the power consumption of individual applications given measurements, and also the feasibility of our model to operate in real-time and without significant impact in the power footprint of the devices we monitor.",
    month = "6",
    year = "2012",
    booktitle = "2012 IEEE Sixth International Conference on Software Security and Reliability",
    pages = "147--156"
}

@inproceedings{Murray2010,
    author = "Murray, Derek G. and Hand, Steven",
    title = "{Scripting the cloud with skywriting}",
    url = "http://dl.acm.org/citation.cfm?id=1863103.1863115",
    abstract = "Recent distributed computing frameworks--such as MapReduce, Hadoop and Dryad--have made it simple to exploit multiple machines in a compute cloud. However, these frameworks use coordination languages that are insufficiently expressive for many classes of computation, including iterative and recursive algorithms. To address this problem, and generalise previous approaches, we introduce Skywriting: a Turing-powerful, purely-functional script language for describing distributed computations. In this paper, we introduce the main features of Skywriting, and outline our novel cooperative task farming execution engine.",
    month = "6",
    file = "::",
    year = "2010",
    booktitle = "HotCloud'10 Proceedings of the 2nd USENIX conference on Hot topics in cloud computing",
    pages = "12"
}

@article{Muthitacharoen2002,
    author = "Muthitacharoen, Athicha and Morris, Robert",
    doi = "10.1145/1060289.1060293",
    title = "{Ivy: A read/write peer-to-peer file system}",
    url = "http://dl.acm.org/citation.cfm?id=844132",
    abstract = "Ivy is a multi-user read/write peer-to-peer file system. Ivy has no centralized or dedicated components, and it provides useful integrity properties without requiring users to fully trust either the underlying peer-to-peer-storage system or the other users of the file system.An Ivy file system consists solely of a set of logs, one log per participant. Ivy stores its logs in the DHash distributed hash table. Each participant finds data by consulting all logs, but performs modifications by appending only to its own log. This arrangement allows Ivy to maintain meta-data consistency without locking. Ivy users can choose which other logs to trust, an appropriate arrangement in a semi-open peer-to-peer system.Ivy presents applications with a conventional file system interface. When the underlying network is fully connected, Ivy provides NFS-like semantics, such as close-to-open consistency. Ivy detects conflicting modifications made during a partition, and provides relevant version information to application-specific conflict resolvers. Performance measurements on a wide-area network show that Ivy is two to three times slower than NFS.",
    pages = "31--44",
    file = ":home/drt24/Downloads/ivy.pdf:pdf",
    year = "2002",
    journal = "Operating Systems Review (SIGOPS)"
}

@article{Mycroft2009,
    author = "Mycroft, Kathryn E. Gray and Alan",
    volume = "5503",
    journal = "Fundamental Approaches To Software Engineering",
    year = "2009",
    pages = "186--200",
    title = "{Logical Testing: Hoare-style Specification Meets Executable Validation}"
}

@inproceedings{Myers1997,
    author = "Myers, Andrew C. and Liskov, Barbara H.",
    publisher = "ACM",
    title = "{A decentralized model for information flow control}",
    url = "http://dl.acm.org/citation.cfm?id=266669",
    abstract = "This paper presents a newmodel for controlling information flow in systems with mutual distrust and decentralized au- thority. The model allows users to share information with distrusted code (e.g., downloaded applets), yet still control howthat code disseminates the shared information to others. The model improves on existing multilevel security models by allowing users to declassify information in a decentralized way, and by improving support for fine-grained data sharing. The paper also shows how static program analysis can be used to certify proper information flows in this model and to avoid most run-time information flow checks.",
    number = "5",
    volume = "31",
    file = ":auto/homes/drt24/Downloads/iflow-sosp97.pdf:pdf",
    year = "1997",
    booktitle = "SIGOPS",
    pages = "129--142"
}

@article{Naccache2001,
    editor = "Frankel, Yair",
    author = "Naccache, David and Stern, Jacques",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/3-540-45472-1_9",
    title = "{Signing on a Postcard}",
    abstract = "We investigate the problem of signing short messages using a scheme that minimizes the total length of the original message and the appended signature. This line of research was motivated by several postal services interested by stamping machines capable of producing digital signatures. Although several message recovery schemes exist, their security is questionable. This paper proposes variants of DSA and ECDSA allowing partial recovery: the signature is appended to a truncated message and the discarded bytes are recovered by the verification algorithm. Still, the signature authenticates the whole message. Our scheme has some form of provable security, based on the random oracle model. Using further optimizations we can lower the scheme’s overhead to 26 bytes for a 2-80 security level, compared to forty bytes for DSA or ECDSA and 128 bytes 1024-bit RSA.",
    pages = "121--135",
    volume = "1962",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F3-540-45472-1\_9.pdf:pdf",
    year = "2001",
    journal = "Lecture Notes in Computer Science:Financial Cryptography"
}

@techreport{Nachenberg,
    author = "Nachenberg, Carey",
    url = "http://www.symantec.com/content/en/us/enterprise/white_papers/b-mobile-device-security_WP.en-us.pdf",
    abstract = "The mass-adoption of both consumer and managed mobile devices in the enterprise has increased employee productivity but has also exposed the enterprise to new security risks. The latest mobile plat- forms were designed with security in mind—both teams of engineers attempted to build security features directly into the operating sys- tem to limit attacks from the outset. However, as the paper discusses, while these security provisions raise the bar, they may be insufficient to protect the enterprise assets that regularly find their way onto de- vices. Finally, complicating the security picture is the fact that virtu- ally all of today’s mobile devices operate in an ecosystem, much of it not controlled by the enterprise—they connect and synchronize out-of- the-box with third-party cloud services and computers whose security posture is potentially unknown and outside of the enterprise’s control.",
    file = ":home/drt24/Downloads/b-mobile-device-security\_WP.en-us.pdf:pdf;::",
    title = "{Examining the security approaches employed in Apple’s iOS and Google’s Android}"
}

@article{Nadji2011,
    author = "Nadji, Yacin and Giffin, Jonathon and Traynor, Patrick",
    publisher = "ACM Press",
    doi = "10.1145/2076732.2076791",
    isbn = "9781450306720",
    title = "{Automated remote repair for mobile malware}",
    url = "http://dl.acm.org/citation.cfm?id=2076791",
    series = "ACSAC '11",
    abstract = "Mobile application markets currently serve as the main line of defense against malicious applications. While marketplace revocations have successfully removed the few overtly malicious applications installed on mobile devices, the anticipated coming flood of mobile malware mandates the need for mechanisms that can respond faster than manual intervention. In this paper, we propose an infrastructure that automatically identifies and responds to malicious mobile applications based on their network behavior. We design and implement a prototype, Airmid, that uses cooperation between in-network sensors and smart devices to identify the provenance of malicious traffic. We then develop sample malicious mobile applications exceeding the capabilities of malware recently discovered in the wild, demonstrate the ease with which they can evade current detection techniques, and then use Airmid to show a range of automated recovery responses ranging from on-device firewalling to application removal.",
    pages = "1--6",
    file = ":home/drt24/Downloads/repair11.pdf:pdf",
    year = "2011",
    journal = "Proceedings of the 27th Annual Computer"
}

@article{Nair2008,
    author = "Nair, Srijith K. and Simpson, Patrick N.D. and Crispo, Bruno and Tanenbaum, Andrew S.",
    doi = "10.1016/j.entcs.2007.10.010",
    title = "{A Virtual Machine Based Information Flow Control System for Policy Enforcement}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1571066108000455",
    journal = "Electronic Notes in Theoretical Computer Science",
    issn = "15710661",
    number = "1",
    month = "2",
    volume = "197",
    file = ":home/drt24/Downloads/1-s2.0-S1571066108000455-main.pdf:pdf",
    year = "2008",
    keywords = "information flow,policy enforcement,run-time monitoring",
    pages = "3--16"
}

@techreport{Nair2008a,
    author = "Nair, Srijith K and Simpson, Patrick N D and Crispo, Bruno and Tanenbaum, Andrew S",
    title = "{Trishul : A Policy Enforcement Architecture for Java Virtual Machines}",
    url = "http://srijith.net/publications/techreports/Trishul-IR-CS-45.pdf",
    abstract = "The standard Java execution environment provides only primitive support for specifying and enforcing access control policies both at the stack and method call level as well as the higher application level. The current implementation also falls short of providing a secure execution environment for Java applications because of its inability to trace information flow within the environment. In this paper we present the design and implementation of Trishul, a modular information flow control based policy enforcement framework for the Java VirtualMachine. A flexible and powerful language to implement Trishul’s policy decision en- gine is also presented. Performance measurements show that though the prototype implementation does incur overhead, they are within usable limits.",
    pages = "1----27",
    file = ":home/drt24/Downloads/Trishul-IR-CS-45.pdf:pdf",
    year = "2008",
    institution = "Department of Computer Science, Vrije Universiteit"
}

@inproceedings{Nakamoto,
    author = "Nakamoto, Satoshi",
    title = "{Bitcoin: a peer-to-peer electronic cash system}"
}

@article{Narayanan2013,
    author = "Narayanan, Arvind",
    title = "{What Happened to the Crypto Dream?, Part 1}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6493328",
    journal = "Security \& Privacy, IEEE",
    number = "April",
    file = ":home/drt24/Downloads/crypto-dream-part1.pdf:pdf",
    year = "2013",
    pages = "2--3"
}

@article{Narayanan2013a,
    author = "Narayanan, Arvind",
    title = "{What Happened to the Crypto Dream?, Part 2}",
    url = "http://randomwalker.info/publications/crypto-dream-part1.pdf",
    journal = "Security \& Privacy, IEEE",
    file = ":home/drt24/Downloads/crypto-dream-part2.pdf:pdf",
    year = "2013",
    pages = "2--5"
}

@inproceedings{Naudziuniene2011,
    author = "Naudziuniene, Daiva and Botincan, Matko and Distefano, Dino and Dodds, Mike and Grigore, Radu and Parkinson, Matthew J.",
    publisher = "ACM Press",
    doi = "10.1145/2025113.2025182",
    isbn = "9781450304436",
    title = "{jStar-eclipse}",
    url = "http://dl.acm.org/citation.cfm?id=2025113.2025182",
    booktitle = "Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering - SIGSOFT/FSE '11",
    year = "2011",
    month = "9",
    address = "New York, New York, USA",
    keywords = "automated verification,eclipse,java,separation logic",
    pages = "428"
}

@article{Nauman2010,
    author = "Nauman, Mohammad and Khan, Sohail and Zhang, Xinwen",
    publisher = "ACM Press",
    doi = "10.1145/1755688.1755732",
    isbn = "9781605589367",
    title = "{Apex : Extending Android Permission Model and Enforcement with User-defined Runtime Constraints}",
    url = "http://portal.acm.org/citation.cfm?id=1755732",
    series = "ASIACCS '10",
    abstract = "Android is the first mass-produced consumer-market open source mobile platform that allows developers to easily create applications and users to readily install them. However, giving users the ability to install third-party applications poses serious security concerns. While the existing security mechanism in Android allows a mobile phone user to see which resources an application requires, she has no choice but to allow access to all the requested permissions if she wishes to use the applications. There is no way of granting some permissions and denying others. Moreover, there is no way of restricting the usage of resources based on runtime constraints such as the location of the device or the number of times a resource has been previously used. In this paper, we present Apex - a policy enforcement framework for Android that allows a user to selectively grant permissions to applications as well as impose constraints on the usage of resources. We also describe an extended package installer that allows the user to set these constraints through an easy-to-use interface. Our enforcement framework is implemented through a minimal change to the existing Android code base and is backward compatible with the current security mechanism.",
    number = "c",
    pages = "328--332",
    file = ":home/drt24/Downloads/p328-nauman.pdf:pdf",
    year = "2010",
    keywords = "android,constraints,mobile platforms,policy framework",
    journal = "Information Systems Journal"
}

@article{Neamtiu2011,
    author = "Neamtiu, Iulian and Dumitra??, Tudor",
    doi = "10.1109/MESOCA.2011.6049037",
    isbn = "9781457706479",
    title = "{Cloud software upgrades: Challenges and opportunities}",
    abstract = "The fast evolution pace for cloud computing software is on a collision course with our growing reliance on cloud computing. On one hand, cloud software must have the agility to evolve rapidly, in order to remain competitive; on the other hand, more and more critical services become dependent on the cloud and demand high availability through firm Service Level Agreements (SLAs) for cloud infrastructures. This race between the needs to increase both the cloud upgrade frequency and the service availability is unsustainable. In this paper we highlight challenges and opportunities for upgrades in the cloud. We survey the release histories of several cloud applications to analyze their evolution pace, and we discuss the shortcomings with current cloud upgrade mechanisms. We outline several solutions for sustaining this evolution while improving availability, by focusing on the novel characteristics of cloud computing. By discussing several promising directions for realizing this vision, we propose a research agenda for the future of software upgrades in the cloud.",
    file = ":home/drt24/Downloads/06049037.pdf:pdf",
    year = "2011",
    journal = "2011 International Workshop on the Maintenance and Evolution of Service-Oriented and Cloud-Based Systems, MESOCA 2011"
}

@article{Needham1978,
    author = "Needham, Roger M. and Schroeder, Michael D.",
    doi = "10.1145/359657.359659",
    title = "{Using encryption for authentication in large networks of computers}",
    url = "http://portal.acm.org/citation.cfm?doid=359657.359659",
    journal = "Communications of the ACM",
    issn = "00010782",
    number = "12",
    month = "12",
    volume = "21",
    file = ":auto/homes/drt24/Downloads/needham.pdf:pdf",
    year = "1978",
    keywords = "3,31,35,4,81,and phrases,authentication,cr categories,cryptosystems,data encryption standard,encryption,networks,protocols,public-key,security",
    pages = "993--999"
}

@article{Nikiforakis2013,
    author = "Nikiforakis, Nick and Kapravelos, Alexandros",
    title = "{Cookieless monster: Exploring the ecosystem of web-based device fingerprinting}",
    url = "http://seclab.cs.ucsb.edu/media/uploads/papers/sp2013_cookieless.pdf",
    abstract = "The web has become an essential part of our society and is currently the main medium of information delivery. Billions of users browse the web on a daily basis, and there are single websites that have reached over one billion user accounts. In this environment, the ability to track users and their online habits can be very lucrative for advertising companies, yet very intrusive for the privacy of users. In this paper, we examine how web-based device fingerprint- ing currently works on the Internet. By analyzing the code of three popular browser-fingerprinting code providers, we reveal the techniques that allow websites to track users without the need of client-side identifiers. Among these techniques, we show how current commercial fingerprinting approaches use questionable practices, such as the circumvention of HTTP proxies to discover a user’s real IP address and the installation of intrusive browser plugins. At the same time, we show how fragile the browser ecosystem is against fingerprinting through the use of novel browser- identifying techniques.With so many different vendors involved in browser development, we demonstrate how one can use diversions in the browsers’ implementation to distinguish successfully not only the browser-family, but also specific major and minor versions. Browser extensions that help users spoof the user-agent of their browsers are also evaluated. We show that current commercial approaches can bypass the extensions, and, in addition, take advantage of their shortcomings by using them as additional fingerprinting features.",
    file = ":home/drt24/Downloads/download (1).pdf:pdf",
    year = "2013",
    journal = "IEEE Symposium on Security and Privacy"
}

@techreport{Nissen2003,
    author = "Nissen, Steffen",
    title = "{Implementation of a Fast Artificial Neural Network Library ( fann )}",
    abstract = "This report describes the implementation of a fast artificial neural network library in ANSI C called fann. The library implements multilayer feedforward networks with support for both fully connected and sparse connected net- works. Fann offers support for execution in fixed point arithmetic to allow for fast execution on systems with no floating point processor. To overcome the problems of integer overflow, the library calculates a position of the decimal point after training and guarantees that integer overflow can not occur with this decimal point. The library is designed to be fast, versatile and easy to use. Several bench- marks have been executed to test the performance of the library. The results show that the fann library is significantly faster than other libraries on systems without a floating point processor, while the performance was comparable to other highly optimized libraries on systems with a floating point processor.",
    institution = "Department of Computer Science University of Copenhagen (DIKU)",
    file = ":home/drt24/Library/papers/Training/Nissen/Nissen - 2003 - Implementation of a Fast Artificial Neural Network Library ( fann ).pdf:pdf",
    year = "2003",
    keywords = "ann,ansi c,artificial neural network,fixed point arithmetic,performance engineering",
    booktitle = "Training"
}

@article{Noto2008,
    author = "Noto, Keith and Craven, Mark",
    title = "{Learning Hidden Markov Models for Regression using Path Aggregation.}",
    journal = "Uncertainty in artificial intelligence : proceedings of the ... conference. Conference on Uncertainty in Artificial Intelligence",
    abstract = "We consider the task of learning mappings from sequential data to real-valued responses. We present and evaluate an approach to learning a type of hidden Markov model (HMM) for regression. The learning process involves inferring the structure and parameters of a conventional HMM, while simultaneously learning a regression model that maps features that characterize paths through the model to continuous responses. Our results, in both synthetic and biological domains, demonstrate the value of jointly learning the two components of our approach.",
    issn = "1525-3384",
    month = "7",
    volume = "2008",
    url = "http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3141580\&tool=pmcentrez\&rendertype=abstract",
    file = ":home/drt24/Library/papers/Uncertainty in artificial intelligence proceedings of the ... conference. Conference on Uncertainty in Artificial Intelligence/Noto, Craven/Noto, Craven - 2008 - Learning Hidden Markov Models for Regression using Path Aggregation.pdf:pdf",
    year = "2008",
    pages = "444--451"
}

@article{Nurmi2009,
    author = "Nurmi, Daniel and Wolski, Rich and Grzegorczyk, Chris and Obertelli, Graziano and Soman, Sunil and Youseff, Lamia and Zagorodnov, Dmitrii",
    publisher = "Ieee",
    doi = "10.1109/CCGRID.2009.93",
    isbn = "978-1-4244-3935-5",
    title = "{The Eucalyptus Open-Source Cloud-Computing System}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5071863",
    journal = "2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid",
    file = ":auto/homes/drt24/Downloads/3622a124.pdf:pdf",
    year = "2009",
    pages = "124--131"
}

@article{Nyberg1996,
    author = "Nyberg, Kaisa and Rueppel, Rainer A.",
    doi = "10.1007/BF00125076",
    title = "{Message recovery for signature schemes based on the discrete logarithm problem}",
    url = "http://link.springer.com/10.1007/BF00125076",
    abstract = "The new signature scheme presented by the authors in [13] is the first signature scheme based on the discrete logarithm problem that gives message recovery. The purpose of this paper is to show that the message recovery feature is independent of the choice of the signature equation and that all ElGamal-type schemes have variants giving message recovery. For each of the six basic ElGamal-type signature equations five variants are presented with different properties regarding message recovery, length of commitment and strong equivalence. Moreover, the six basic signature schemes have different properties regarding security and implementation. It turns out that the scheme proposed in [13] is the only inversionless scheme whereas the message recovery variant of the DSA requires computing of inverses in both generation and verification of signatures. In general, message recovery variants can be given for ElGamal-type signature schemes over any group with large cyclic subgroup as the multiplicative group of GF(2 n ) or elliptic curve over a finite field. The present paper also shows how to integrate the DLP-based message recovery schemes with secret session key establishment and ElGamal encryption. In particular, it is shown that with DLP-based schemes the same functionality as with RSA can be obtained. However, the schemes are not as elegant as RSA in the sense that the signature (verification) function cannot at the same time be used as the decipherment (encipherment) function.",
    issn = "0925-1022",
    number = "1-2",
    month = "1",
    volume = "7",
    pages = "61--81",
    file = ":home/drt24/Downloads/art\%3A10.1007\%2FBF00125076.pdf:pdf",
    year = "1996",
    journal = "Designs, Codes and Cryptography"
}

@article{Oki1988,
    author = "Oki, Brian M and Liskov, Barbara H.",
    publisher = "ACM",
    doi = "10.1145/62546.62549",
    isbn = "0897912772",
    title = "{Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems}",
    url = "http://portal.acm.org/citation.cfm?id=62546.62549\&coll=portal\&dl=ACM\&type=series\&idx=SERIES391\&part=series\&WantType=Proceedings\&title=PODC\&CFID=107360185\&CFTOKEN=53116535",
    abstract = "One of the potential benefits of distributed systems is their use in providing highly-available services that are likely to be usable when needed. Availabilay is achieved through replication. By having inore than one copy of information, a service continues to be usable even when some copies are inaccessible, for example, because of a crash of the computer where a copy was stored. This paper presents a new replication algorithm that has desirable performance properties. Our approach is based on the primary copy technique. Computations run at a primary. which notifies its backups of what it has done. If the primary crashes, the backups are reorganized, and one of the backups becomes the new primary. Our method works in a general network with both node crashes and partitions. Replication causes little delay in user computations and little information is lost in a reorganization; we use a special kind of timestamp called a viewstamp to detect lost information",
    pages = "8--17",
    volume = "62",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oki, Liskov - 1988 - Viewstamped Replication A New Primary Copy Method to Support Highly-Available Distributed Systems.pdf:pdf",
    year = "1988",
    journal = "PODC 88 Proceedings of the seventh annual ACM Symposium on Principles of distributed computing"
}

@techreport{Oliner2013,
    author = "Oliner, Adam J and Iyer, Anand P and Stoica, Ion and Lagerspetz, Eemil and Tarkoma, Sasu",
    abstract = "We aim to detect and diagnose energy anomalies, abnor- mally heavy battery use. This paper describes a collaborative black-box method, and an implementation called Carat, for performing such diagnosis on mobile devices. A client app sends intermittent, coarse-grained measurements to a server, which identifies correlations between higher expected en- ergy use and client properties like the running apps, device model, and operating system. The analysis quantifies the er- ror and confidence associated with a diagnosis, suggests ac- tions the user could take to improve battery life, and projects the amount of improvement. Carat detected all anomalies in a controlled experiment and, during a deployment to a com- munity of more than 340,000 devices, identified thousands of energy anomalies in the wild. On average, a Carat user’s battery life increased by 10\% after 10 days.",
    year = "2013",
    file = "::",
    title = "{Carat: Collaborative Energy Diagnosis for Mobile Devices}"
}

@inproceedings{Oliveira2011,
    author = "de Oliveira, Rodrigo and Karatzoglou, Alexandros and {Concejero Cerezo}, Pedro and {Armenta Lopez de Vicu\~{n}a}, Ana and Oliver, Nuria",
    publisher = "ACM Press",
    doi = "10.1145/1979742.1979920",
    isbn = "9781450302685",
    title = "{Towards a psychographic user model from mobile phone usage}",
    url = "http://dl.acm.org/citation.cfm?id=1979742.1979920",
    booktitle = "Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems - CHI EA '11",
    year = "2011",
    month = "5",
    file = "::",
    address = "New York, New York, USA",
    keywords = "big five,call detail record,five factor model,personality,psychographics,user modeling",
    pages = "2191"
}

@article{Oliver2009,
    author = "Oliver, Earl",
    doi = "10.1145/1508285.1508292",
    title = "{A survey of platforms for mobile networks research}",
    url = "http://portal.acm.org/citation.cfm?id=1508285.1508292 http://portal.acm.org/citation.cfm?doid=1508285.1508292",
    abstract = "The use of smartphones is growing at an unprecedented rate and is projected to soon pass laptops as consumers' mobile platform of choice. The proliferation of these devices has created new opportunities for mobile researchers; however, when faced with hundreds of devices across nearly a dozen development platforms, selecting the ideal platform is often met with unanswered questions. In this paper I consider desirable characteristics of mobile platforms necessary for mobile networks research. Based on these characteristics, I assess five smartphone platforms: Android (Linux), BlackBerry, iPhone (Mac OS X), Symbian, and Windows Mobile. This survey is current as of December 2008. A living version of this survey is available at: http://blizzard.cs.uwaterloo.ca/eaoliver/platforms/.",
    issn = "15591662",
    mendeley-tags = "mobile",
    number = "4",
    month = "2",
    volume = "12",
    pages = "56",
    file = "::",
    year = "2009",
    keywords = "mobile",
    journal = "ACM SIGMOBILE Mobile Computing and Communications Review"
}

@article{Oliver2009b,
    author = "Oliver, Earl",
    doi = "10.1145/1508285.1508292",
    title = "{A survey of platforms for mobile networks research}",
    url = "http://dl.acm.org/citation.cfm?id=1508285.1508292",
    journal = "ACM SIGMOBILE Mobile Computing and Communications Review",
    issn = "15591662",
    number = "4",
    month = "2",
    volume = "12",
    file = "::",
    year = "2009",
    pages = "56"
}

@article{Oliver2009c,
    author = "Oliver, Earl",
    doi = "10.1145/1508285.1508292",
    title = "{A survey of platforms for mobile networks research}",
    url = "http://dl.acm.org/citation.cfm?id=1508285.1508292",
    journal = "ACM SIGMOBILE Mobile Computing and Communications Review",
    issn = "15591662",
    number = "4",
    month = "2",
    volume = "12",
    file = "::",
    year = "2009",
    pages = "56"
}

@inproceedings{Oliver2010,
    author = "Oliver, Earl",
    publisher = "ACM Press",
    doi = "10.1145/1834616.1834623",
    isbn = "9781450301770",
    title = "{The challenges in large-scale smartphone user studies}",
    url = "http://dl.acm.org/citation.cfm?id=1834616.1834623",
    abstract = "We present preliminary results of a large-scale smartphone user study that examines how users interact with and consume energy on their personal mobile devices. Our dataset consists of over one millennium of user interaction traces from over 17300 BlackBerry users. Despite the scale and detail of the dataset, there are many research questions that it cannot answer; further user studies are therefore needed. We detail our insight into the major challenges in conducting a large-scale user study on BlackBerry devices.",
    year = "2010",
    month = "6",
    pages = "1",
    file = "::",
    address = "New York, New York, USA",
    booktitle = "Proceedings of the 2nd ACM International Workshop on Hot Topics in Planet-scale Measurement - HotPlanet '10"
}

@inproceedings{Oliver2011,
    author = "Oliver, Earl A. and Keshav, Srinivasan",
    publisher = "ACM Press",
    doi = "10.1145/2030112.2030159",
    isbn = "9781450306300",
    title = "{An empirical approach to smartphone energy level prediction}",
    url = "http://dl.acm.org/citation.cfm?id=2030112.2030159",
    abstract = "We conduct a large-scale user study to measure the energy consumption characteristics of 20,100 BlackBerry smartphone users. Our dataset is several orders of magnitude larger than any previous work. We use this dataset to build the Energy Emulation Toolkit (EET) that allows developers to evaluate the energy consumption requirements of their applications against real users' energy traces. The EET computes the successful execution rate of energy-intensive applications across all users, specific devices, and specific smartphone user types. We also consider active adaptation to energy constraints. By classifying smartphone users based on their charging characteristics we demonstrate that energy level can be predicted within 72\% accuracy a full day in advance, and through an Energy Management Oracle energy intensive applications can adapt their execution to achieve a near optimal successful execution rate.",
    year = "2011",
    month = "9",
    pages = "345",
    file = "::",
    address = "New York, New York, USA",
    keywords = "energy,energy emulation toolkit,energy management oracle,smartphone,user study",
    booktitle = "Proceedings of the 13th international conference on Ubiquitous computing - UbiComp '11"
}

@article{Oppen1983,
    author = "Oppen, Derek C and Dalal, Yogen K",
    publisher = "ACM",
    doi = "10.1145/357436.357439",
    title = "{The Clearinghouse: A Decentralized Agent for Locating Named Objects in a Distributed Environment}",
    url = "http://doi.acm.org/10.1145/357436.357439",
    abstract = {The problem of naming and locating objects in a distributed environment is considered, and the clearinghouse, a decentralized agent for supporting the naming of these "network-visible" objects, is described. The objects "known" to the clearinghouse are of many types and include workstations, file servers, print servers, mail servers, clearinghouse servers, and human user. All objects known to the clearinghouse are named using the same convention, and the clearinghouse provides information about objects in a uniform fashion, regardless of their type. The clearinghouse also supports aliases. The clearinghouse binds a name to a set of properties of various types. For instance, the name of a user may be associated with the location of his local workstation, mailbox, and nonlocation information such as password and comments. The clearinghouse is decentralized and replicated. That is, instead of one global clearinghouse server, there are many local clearinghouse servers, each storing a copy of a portion of the global database. The totality of services supplied by these clearinghouse servers is called "the clearinghouse." Decentralization and replication increase efficiency, security, and reliability. A request to the clearinghouse to bind a name to its set of properties may originate anywhere in the system and be directed to any clearinghouse server. A clearinghouse client need not be concerned with the question of which clearinghouse server actually contains the binding--the clearinghouse stub in the client in conjunction with distributed clearinghouse servers automatically fmds the mapping ff it exists. Updates to the various copies of a mapping may occur asynchronously and be interleaved with requests for bindings of names to properties; updates to the various copies are not treated as indivisible transactions. Any resulting inconsistency between the various copies is only transient: the clearinghouse automatically arbitrates between conflicting updates to restore consistency. Categories and Subject Descriptors: C.2.3 [Computer-Communlcation Networks]: Ne},
    issn = "10468188",
    number = "3",
    pages = "230--253",
    volume = "1",
    file = ":auto/homes/drt24/Downloads/p230-oppen.pdf:pdf",
    year = "1983",
    keywords = "Clearinghouse,binding,internetwork,locations,names,network-visible objects",
    journal = "ACM TOOIS"
}

@inproceedings{Orchard2012,
    author = "Orchard, Dominic and Mycroft, Alan",
    year = "2012",
    title = "{A notation for comonads}"
}

@inproceedings{Osterweil2012,
    editor = "Clayton, Richard",
    author = "Osterweil, Eric and Kaliski, Burt and Larson, Matt and Mcpherson, Danny",
    publisher = "NPL",
    title = "{Reducing the X.509 Attack Surface with DNSSEC's DANE}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Osterweil.pdf http://conferences.npl.co.uk/satin/presentations/satin2012slides-Osterweil.pdf",
    abstract = "For the last decade, perhaps the most commonly used type of end-user security has been the HTTP Secure (HTTPS) protocol employed by web browsers (which runs over the Secure Sockets Layer, SSL or its successor, TLS). In HTTPS, any service (such as a website) may create its own cryptographic certificate to secure its communication channel, and clients use this certificate to verify data from, and transmit data to the server. This model has helped to secure online banking transactions, eCommerce websites, social networking websites, and more. However, two inherent complications to this approach are that clients must have a secure way to learn the authentic certificate for each website before they begin using this protocol, and they must be able to determine if they can trust the named entity that the certificate belongs to. These complications are conflated in today’s security model, which is based on a list of prespecified trusted X.509 Certificate Authorities (CAs) that every client must know a priori, and a very ad-hoc approach to determining which of this list of CAs will vouch for any keys discovered. In this paper we first outline some of the fundamental problems that exist with today’s CA model, problems that arise from its conflation of the two inherent complications, and some of the implications and attack vectors that these problems present to the security of this model’s users. Then we introduce some of the relative benefits that can be gained from a new approach being standardized in the IETF called DNS- based Authentication of Named Entities (DANE), in which certificate credentials are verified by DNSSEC-enabled zones, rather than the CA model used today. We illustrate that the DNSSEC-verification model reduces the attack surface that users currently inherit, and show that this model opens avenues that have previously remained elusive (such as a usable S/MIME verification infrastructure).",
    month = "3",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Osterweil.pdf:pdf;:auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Osterweil.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@article{Ouyang2009,
    author = "Ouyang, Tom Y and Davis, Randall",
    journal = "In Proceedings of the nternational Joint Conference on Artificial Intelligence",
    year = "2009",
    file = "::",
    title = "{A Visual Approach to Sketched Symbol Recognition}"
}

@article{Ouyang2009a,
    author = "Ouyang, Tom Y and Davis, Randall",
    journal = "In Advances in Neural Information Processing Systems",
    year = "2009",
    pages = "1--9",
    file = "::",
    title = "{Learning from Neighboring Strokes : Combining Appearance and Context for Multi-Domain Sketch Recognition}"
}

@inproceedings{Pandita2013,
    author = "Pandita, Rahul and Xiao, Xusheng and Yang, Wei and Enck, William and Xie, Tao",
    publisher = "USENIX",
    isbn = "9781931971034",
    title = "{WHYPER : Towards Automating Risk Assessment of Mobile Applications W HYPER : Towards Automating Risk Assessment of Mobile Applications}",
    url = "https://www.usenix.org/conference/usenixsecurity13/technical-sessions/presentation/pandita",
    abstract = "Application markets such as Apple’s App Store and Google’s Play Store have played an important role in the popularity of smartphones and mobile devices. However, keeping malware out of application markets is an ongoing challenge. While recent work has developed various techniques to determine what applications do, no work has provided a technical approach to answer, what do users expect? In this paper, we present the first step in addressing this challenge. Specifically, we focus on permissions for a given application and examine whether the application description provides any indication for why the application needs a permission. We present WHYPER, a framework using Natural Language Processing (NLP) techniques to identify sentences that describe the need for a given permission in an application description. WHYPER achieves an average precision of 82.8\%, and an average recall of 81.5\% for three permissions (address book, calendar, and record audio) that protect frequently used security and privacy sensitive resources. These results demonstrate great promise in using NLP techniques to bridge the semantic gap between user expectations and application functionality, further aiding the risk assessment of mobile applications.",
    year = "2013",
    month = "8",
    pages = "527--542",
    file = ":home/drt24/Downloads/12324-sec13-paper\_pandita.pdf:pdf",
    address = "Washington, D.C.",
    booktitle = "22nd USENIX Security Symposium"
}

@article{Park2008,
    author = "Park, Unkyu and Heidemann, John",
    publisher = "Springer",
    doi = "10.1007/978-3-540-89965-5_28",
    title = "{Provenance in sensornet republishing}",
    url = "http://www.springerlink.com/index/q6k7p0150119j877.pdf",
    journal = "Provenance and Annotation of Data and Processes",
    file = "::",
    year = "2008",
    pages = "280--292"
}

@inproceedings{Parno2006,
    author = "Parno, Bryan and Kuo, Cynthia and Perrig, Adrian",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11889663_1",
    isbn = "978-3-540-46255-2",
    title = "{Phoolproof phishing prevention}",
    url = "http://link.springer.com/chapter/10.1007/11889663_1",
    abstract = "Phishing, or web spoofing, is a growing problem: the Anti-Phishing Working Group (APWG) received almost 14,000 unique phishing reports in August 2005, a 56\% jump over the number of reports in December 2004 [3]. For financial institutions, phishing is a particularly insidious problem, since trust forms the foundation for customer relationships, and phishing attacks undermine confidence in an institution. Phishing attacks succeed by exploiting a user’s inability to distinguish legitimate sites from spoofed sites. Most prior research focuses on assisting the user in making this distinction; however, users must make the right security decision every time. Unfortunately, humans are ill-suited for performing the security checks necessary for secure site identification, and a single mistake may result in a total compromise of the user’s online account. Fundamentally, users should be authenticated using information that they cannot readily reveal to malicious parties. Placing less reliance on the user during the authentication process will enhance security and eliminate many forms of fraud. We propose using a trusted device to perform mutual authentication that eliminates reliance on perfect user behavior, thwarts Man-in-the-Middle attacks after setup, and protects a user’s account even in the presence of keyloggers and most forms of spyware.We demonstrate the practicality of our system with a prototype implementation.",
    pages = "1--19",
    file = ":home/drt24/Downloads/10.1007\_11889663\_1.pdf:pdf",
    year = "2006",
    keywords = "fraud prevention,identity theft,phishing and social engineering,secure banking and financial,web services",
    booktitle = "Financial Cryptography and Data Security"
}

@inproceedings{Patel2006,
    editor = "Dourish, Paul and Friday, Adrian",
    author = "Patel, Shwetak and Kientz, Julie and Hayes, Gillian and Bhat, Sooraj and Abowd, Gregory and Dourish, Paul and Friday, Adrian",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11853565",
    isbn = "978-3-540-39634-5",
    title = "{Farther Than You May Think: An Empirical Investigation of the Proximity of Users to Their Mobile Phones}",
    url = "http://www.springerlink.com/content/20958531r2541355/",
    series = "Lecture Notes in Computer Science",
    abstract = "Implicit in much research and application development for mobile phones is the assumption that the mobile phone is a suitable proxy for its owner’s location. We report an in-depth empirical investigation of this assumption in which we measured proximity of the phone to its owner over several weeks of continual observation. Our findings, summarizing results over 16 different subjects of a variety of ages and occupations, establish baseline statistics for the proximity relationship in a typical US metropolitan market. Supplemental interviews help us to establish reasons why the phone and owner are separated, leading to guidelines for developing mobile phone applications that can be smart with respect to the proximity assumption. We show it is possible to predict the proximity relationship with 86\% confidence using simple parameters of the phone, such as current cell ID, current date and time, signal status, charger status and ring/vibrate mode.",
    year = "2006",
    pages = "123--140",
    volume = "4206",
    file = "::",
    address = "Berlin, Heidelberg",
    booktitle = "Ubicomp 2006"
}

@inproceedings{Pathak2011a,
    author = "Pathak, Abhinav and Hu, Y. Charlie and Zhang, Ming and Bahl, Paramvir and Wang, Yi-Min",
    publisher = "ACM Press",
    doi = "10.1145/1966445.1966460",
    isbn = "9781450306348",
    title = "{Fine-grained power modeling for smartphones using system call tracing}",
    url = "http://dl.acm.org/citation.cfm?id=1966445.1966460 http://www.mendeley.com/share/viewDocument/webLibrary/3177171_4400652735:/1329994947/762966cab800ab80b9d13a2634543023a741f2fc/",
    booktitle = "Proceedings of the sixth conference on Computer systems - EuroSys '11",
    year = "2011",
    month = "4",
    file = "::;::",
    address = "New York, New York, USA",
    keywords = "energy,mobile,smartphone",
    pages = "153"
}

@inproceedings{Pathak2012,
    author = "Pathak, Abhinav and Hu, Y. Charlie and Zhang, Ming",
    publisher = "ACM Press",
    doi = "10.1145/2168836.2168841",
    isbn = "9781450312233",
    title = "{Where is the energy spent inside my app?}",
    url = "http://dl.acm.org/citation.cfm?id=2168836.2168841",
    booktitle = "Proceedings of the 7th ACM european conference on Computer Systems - EuroSys '12",
    year = "2012",
    month = "4",
    file = "::",
    address = "New York, New York, USA",
    keywords = "Eprof,energy,mobile,smartphones",
    pages = "29"
}

@inproceedings{Pathak2012a,
    author = "Pathak, Abhinav and Jindal, Abhilash and Hu, Y. Charlie and Midkiff, Samuel P.",
    publisher = "ACM Press",
    doi = "10.1145/2307636.2307661",
    isbn = "9781450313018",
    title = "{What is keeping my phone awake?}",
    url = "http://dl.acm.org/citation.cfm?id=2307636.2307661",
    booktitle = "Proceedings of the 10th international conference on Mobile systems, applications, and services - MobiSys '12",
    year = "2012",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    keywords = "energy,energy-bug,mobile,nosleep-bug,smartphones",
    pages = "267"
}

@article{Pattath2006a,
    author = "Pattath, Avin and Bue, Brian and Jang, Yun and Ebert, David and Zhong, Xuan and Ault, Aaron and Coyle, Edward",
    publisher = "Ieee",
    doi = "10.1109/VAST.2006.261434",
    isbn = "1-4244-0591-2",
    title = "{Interactive Visualization and Analysis of Network and Sensor Data on Mobile Devices}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4035751",
    journal = "2006 IEEE Symposium On Visual Analytics And Technology",
    mendeley-tags = "Data Visualisation",
    month = "10",
    file = "::",
    year = "2006",
    keywords = "Data Visualisation,mobile visualization,network visualization,visual an-",
    pages = "83--90"
}

@inproceedings{Paul2010,
    author = "Paul, Kolin and Kundu, Tapas Kumar",
    publisher = "IEEE",
    doi = "10.1109/CIT.2010.416",
    isbn = "978-1-4244-7547-6",
    title = "{Android on Mobile Devices: An Energy Perspective}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5578292",
    abstract = "Mobile devices and embedded devices need more processing power but energy consumption should be less to save battery power. Open Handset Alliance (OHA) hosting members like Google, Motorola, HTC etc released an open source platform Android for mobile devices. Android is also used in netbook and embedded platform. Android runs on top of linux kernel with a custom JVM set on top of it. Android uses new power management framework to save power in mobile devices. Android developers are allowed to build only JAVA applications. Google tries to make Android as energy efficient as possible to save battery power in mobile devices. In this work, we present benefits of using Android in low power embedded devices. We compared Android JAVA performance with popular Sun embedded JVM running on top of Angstrom linux. Our work shows that Android provides better VM designs but consumes more energy due to lack of dynamic compiler in Dalvik JVM. The implication is that, Android can become more energy efficient by implementing an optimized dynamic compiler in Dalvik JVM.",
    mendeley-tags = "android,java,jit,jvm,mobile,power",
    month = "6",
    pages = "2421--2426",
    file = "::",
    year = "2010",
    keywords = "android,java,jit,jvm,mobile,power",
    booktitle = "2010 10th IEEE International Conference on Computer and Information Technology"
}

@inproceedings{Paul2010c,
    author = "Paul, Kolin and Kundu, Tapas Kumar",
    publisher = "IEEE",
    doi = "10.1109/CIT.2010.416",
    isbn = "978-1-4244-7547-6",
    title = "{Android on Mobile Devices: An Energy Perspective}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5578292",
    abstract = "Mobile devices and embedded devices need more processing power but energy consumption should be less to save battery power. Open Handset Alliance (OHA) hosting members like Google, Motorola, HTC etc released an open source platform Android for mobile devices. Android is also used in netbook and embedded platform. Android runs on top of linux kernel with a custom JVM set on top of it. Android uses new power management framework to save power in mobile devices. Android developers are allowed to build only JAVA applications. Google tries to make Android as energy efficient as possible to save battery power in mobile devices. In this work, we present benefits of using Android in low power embedded devices. We compared Android JAVA performance with popular Sun embedded JVM running on top of Angstrom linux. Our work shows that Android provides better VM designs but consumes more energy due to lack of dynamic compiler in Dalvik JVM. The implication is that, Android can become more energy efficient by implementing an optimized dynamic compiler in Dalvik JVM.",
    month = "6",
    year = "2010",
    booktitle = "2010 10th IEEE International Conference on Computer and Information Technology",
    pages = "2421--2426"
}

@article{Paulson1999,
    author = "Paulson, Lawrence C.",
    publisher = "ACM",
    doi = "10.1145/322510.322530",
    title = "{Inductive analysis of the Internet protocol TLS}",
    url = "http://portal.acm.org/citation.cfm?doid=322510.322530",
    abstract = "Internet browsers use security protocols to protect sensitive messages. An inductive analysis of TLS (a descendant of SSL 3.0) has been performed using the theorem prover Isabelle. Proofs are based on higher-order logic and make no assumptions concerning beliefs of finiteness. All the obvious security goals can be proved; session resumption appears to be secure even if old session keys are compromised. The proofs suggest minor changes to simplify the analysis. TLS, even at an abstract level, is much more complicated than most protocols verified by researchers. Session keys are negotiated rather than distributed, and the protocol has many optional parts. Netherless, the resources needed to verify TLS are modest: six man-weeks of effort and three minutes of processor time.",
    issn = "10949224",
    number = "3",
    month = "8",
    volume = "2",
    pages = "332--351",
    file = ":home/drt24/Downloads/p332-paulson.pdf:pdf",
    year = "1999",
    journal = "ACM Transactions on Information and System Security"
}

@article{Pauw2001,
    author = "Pauw, Wim De and Jensen, Erik and Mitchell, Nick and Sevitsky, Gary and Vlissides, John M. and Yang, Jeaha",
    isbn = "3-540-43323-6",
    title = "{Visualizing the Execution of Java Programs}",
    url = "http://dl.acm.org/citation.cfm?id=647382.724791",
    month = "5",
    year = "2001",
    pages = "151--162"
}

@article{Pauw2001a,
    author = "Pauw, Wim De and Jensen, Erik and Mitchell, Nick and Sevitsky, Gary and Vlissides, John M. and Yang, Jeaha",
    url = "http://dl.acm.org/citation.cfm?id=647382.724791",
    title = "{Visualizing the Execution of Java Programs}",
    year = "2001",
    pages = "151--162",
    month = "5"
}

@article{Pearce2012,
    author = "Pearce, Paul and Felt, Adrienne Porter and Wagner, David",
    doi = "10.1145/2414456.2414498",
    isbn = "9781450313032",
    title = "{AdDroid: Privilege Separation for Applications and Advertisers in Android}",
    abstract = "Name: AdDroid",
    file = ":home/drt24/Downloads/p71-pearce.pdf:pdf",
    year = "2012",
    journal = "ACM Symposium on Information, Computer and Communication Security (ASIACCS)"
}

@online{PearsonSiani,
    author = "{Pearson Siani} and {Shen Yun}",
    url = "http://www.hpl.hp.com/techreports/2010/HPL-2010-74.pdf",
    urldate = "05/10/12",
    file = "::",
    title = "{Context-Aware Privacy Design Pattern Selection}"
}

@article{Peek2006,
    author = "Peek, Daniel",
    title = "{EnsemBlue: Integrating distributed storage and consumer electronics}",
    url = "http://dl.acm.org/citation.cfm?id=1298477",
    abstract = "EnsemBlue is a distributed file system for personal mul- timedia that incorporates both general-purpose comput- ers and consumer electronic devices (CEDs). Ensem- Blue leverages the capabilities of a few general-purpose computers to make CEDs first class clients of the file system. It supports namespace diversity by translating between its distributed namespace and the local names- paces of CEDs. It supports extensibility through persis- tent queries, a robust event notification mechanism that leverages the underlying cache consistency protocols of the file system. Finally, it allows mobile clients to self- organize and share data through device ensembles. Our results show that these features impose little overhead, yet they enable the integration of emerging platforms such as digital cameras, MP3 players, and DVRs.",
    pages = "219--232",
    file = ":auto/homes/drt24/Downloads/p219-peek.pdf:pdf",
    year = "2006",
    journal = "Proceedings of the 7th symposium on Operating"
}

@online{Percival2009,
    author = "Percival, Colin",
    title = "{Stronger key derivation via sequential memory-hard functions}",
    url = "http://www.unixhowto.de/docs/87_scrypt.pdf",
    abstract = "We introduce the concepts of memory-hard algorithms and sequential memory-hard functions, and argue that in order for key derivation functions to be maximally secure against attacks using custom hardware, they should be constructed from sequential memory-hard functions. We present a family of key derivation functions which, under the random oracle model of cryptographic hash functions, are provably sequential memory-hard, and a variation which appears to be marginally stronger at the expense of lacking provable strength. Finally, we provide some estimates of the cost of performing brute force attacks on a variety of password strengths and key derivation functions.",
    month = "5",
    file = ":home/drt24/Downloads/scrypt.pdf:pdf",
    year = "2009",
    urldate = "2014-01-07",
    booktitle = "BSDCan",
    pages = "1--16"
}

@inproceedings{Perrucci2009,
    author = "Perrucci, Gian Paolo and Fitzek, Frank H.P. and Sasso, Giovanni and Kellerer, Wolfgang and Widmer, Jorg",
    publisher = "IEEE",
    doi = "10.1109/EW.2009.5357972",
    isbn = "978-1-4244-5935-3",
    title = "{On the impact of 2G and 3G network usage for mobile phones' battery life}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5357972",
    abstract = "Over the last years mobile phones had a remarkable evolution. From a simple device for voice communication, it became a full blown multimedia device with multiple features and appealing services. In parallel with the introduction of novel services, mobile devices became more and more energy-hungry reducing the operational time for the user. To extend the battery life of mobile phones is one of the top priorities for mobile phones' manufacturers. This paper presents results of power and energy consumption measurements conducted on mobile phones for 2G and 3G networks. The services under investigation were text messaging, voice and data. The paper reports larger energy consumption in 3G networks for text messaging and voice services than energy consumption in 2G networks. On the other side the 3G networks become more energy friendly when large volumes of data have to be downloaded. The results imply that mobile phones should switch the network in dependency of the service used to save the maximum amount of energy. As this handover consumes energy, we include its analysis in our measurements.",
    month = "5",
    pages = "255--259",
    file = "::",
    year = "2009",
    booktitle = "2009 European Wireless Conference"
}

@techreport{Pescatore2001,
    author = "Pescatore, John",
    title = "{Nimda Worm Shows You Can't Always Patch Fast Enough}",
    url = "https://www.gartner.com/doc/340962 https://archive.today/tdhfu",
    abstract = "Nimda bundles several known exploits against Internet Information Server and other Microsoft software. Enterprises with Web applications should start to investigate less-vulnerable Web server products.",
    file = ":home/drt24/Downloads/nimdawormgartner.pdf:pdf",
    year = "2001",
    institution = "Gartner"
}

@inproceedings{Petersen1997a,
    author = "Petersen, Karin and Spreitzer, Mike J. and Terry, Douglas B. and Theimer, Marvin M. and Demers, Alan J.",
    publisher = "ACM",
    doi = "10.1145/269005.266711",
    isbn = "0897919165",
    title = "{Flexible Update Propagation for Weakly Consistent Replication}",
    url = "http://portal.acm.org/citation.cfm?doid=269005.266711",
    abstract = "Bayou’s anti-entropy protocol for update propagation between weakly consistent storage replicas is based on pair-wise communication, the propagation of write operations, and a set of ordering and closure. constraints on the propagation of the writes. The simplicity of the design makes the protocol very flexible, thereby providing support for diverse networking environments and usage scenarios. It accommodates a variety of policies for when and where to propagate updates. It operates over diverse network topologies, including low-bandwidth links. It is incremental. It enables replica convergence, and updates can be propagated using floppy disks and similar transportable media. Moreover, the protocol handles replica creation and retirement in a light-weight manner. Each of these features is enabled by only one or two of the protocol’s design choices, and can be independently incorporated in other systems. This paper presents the anti-entropy protocol in detail, describing the design decisions and resulting features",
    issn = "01635980",
    number = "5",
    pages = "288--301",
    volume = "31",
    file = ":home/drt24/Downloads/p288-petersen.pdf:pdf",
    year = "1997",
    organization = "ACM SIGOPS",
    booktitle = "SOSP"
}

@techreport{Pierce2004,
    author = "Pierce, Benjamin C and Vouillon, J\'{e}r\^{o}me",
    publisher = "Citeseer",
    institution = "Department of Computer and Information Science, University of Pennsylvania",
    title = "{What’s in Unison? A formal specification and reference implementation of a file synchronizer}",
    url = "http://repository.upenn.edu/cgi/viewcontent.cgi?article=1045\&amp;context=cis_reports",
    abstract = "A file synchronizer is a tool that reconciles disconnected modifications to a replicated directory structure. Trustworthy synchronizers are difficult to build, since they must deal correctly with both the semantic complexities of file systems and the unpredictable failure modes arising from distributed operation. On the other hand, synchronizers are often packaged as stand-alone, user-level utilities, whose intended behavior is relatively easy to isolate from the other functions of the system. This combination of subtlety and isolability makes file synchronizers attractive candidates for precise mathematical specification. We present here a detailed specification of a particular file synchronizer called Unison, sketch an idealized reference implementation of our specification, and discuss the relation between our idealized implementation and the actual code base.",
    month = "2",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierce, Vouillon - 2004 - What’s in Unison A formal specification and reference implementation of a file synchronizer.pdf:pdf",
    year = "2004",
    booktitle = "Department of Computer and Information Science University of Pennsylvania",
    pages = "1--32"
}

@article{Pike2005,
    author = "Pike, Rob and Dorward, Sean and Griesemer, Robert and Quinlan, Sean",
    publisher = "IOS Press",
    title = "{Interpreting the data: Parallel analysis with Sawzall}",
    journal = "Scientific Programming",
    abstract = "Very large data sets often have a flat but regular structure and span multiple disks and machines. Examples include telephone call records, network logs, and web document repositories. These large data sets are not amenable to study using traditional database techniques, if only because they can be too large to fit in a single relational database. On the other hand, many of the analyses done on them can be expressed using simple, easily distributed computations: filtering, aggregation, extraction of statistics, and so on. We present a system for automating such analyses. A filtering phase, in which a query is expressed using a new procedural programming language, emits data to an aggregation phase. Both phases are distributed over hundreds or even thousands of computers. The results are then collated and saved to a file. The design - including the separation into two phases, the form of the programming language, and the properties of the aggregators - exploits the parallelism inherent in having data and computation distributed across many machines.",
    issn = "10589244",
    number = "4",
    volume = "13",
    url = "http://iospress.metapress.com/index/99vjkgkae3jkvu9t.pdf",
    file = ":auto/homes/drt24/Downloads/Pike2005InterpretingthedataParallelanalysiswithSawzall.pdf:pdf",
    year = "2005",
    pages = "1--33"
}

@article{Pintsov2001,
    author = "Pintsov, LA and Vanstone, SA",
    doi = "10.1007/3-540-45472-1_8",
    title = "{Postal revenue collection in the digital age}",
    url = "http://link.springer.com/chapter/10.1007/3-540-45472-1_8",
    abstract = "In recent years postal revenue collection underwent a major transformation due to widespread transition to digital methods of communication. This transition directly a.ected not only telecommunications which form an integral part of the postal revenue collection but also, and in a much more profound way, postage evidencing. Traditional postage evidencing remained unchanged for several dozens years until the introduction of digital printing which drastically changed all its security related aspects and considerations. This paper defines conceptual foundations of the postal revenue collection system (which is simultaneously a payment system for mailers), fundamental requirements imposed by the nature of hardcopy-based communication and suggests what the authors believe to be an optimal solution for public key-based postage evidencing founded on elliptic-curve cryptography.",
    pages = "105--120",
    volume = "1962",
    file = ":home/drt24/Downloads/chp\%3A10.1007\%2F3-540-45472-1\_8.pdf:pdf",
    year = "2001",
    journal = "Lecture Notes in Computer Science:Financial Cryptography"
}

@article{Pironti2011,
    author = "Pironti, Alfredo and Pozza, Davide",
    title = "{Automated Formal Methods for Security Protocol Engineering}",
    url = "http://alfredo.pironti.eu/research/sites/default/files/cssigi11.pdf",
    abstract = "Designing and implementing security protocols are known to be error-prone tasks. Recent research progress in the field of formal methods applied to security protocols has enabled the use of these techniques in practice. The objective of this chapter is to give a circumstantial account of the state-of-the- art reached in this field, showing how formal methods can help in improving quality. Since automation is a key factor for the acceptability of these techniques in the engineering practice, the chapter focuses on automated techniques and illustrates in particular how high-level protocol models in the Dolev-Yao style can be automatically analyzed and how it is possible to automatically enforce formal correspondence between an abstract high-level model and an implementation.",
    file = ":auto/homes/drt24/Downloads/cssigi11.pdf:pdf",
    year = "2011",
    journal = "Security Standards, Practices and"
}

@article{Plimmer,
    author = "Plimmer, Beryl and Apperley, Mark",
    keywords = "design tools,pen-based computing,sketching",
    journal = "Most",
    file = "::",
    title = "{From Sketch to Blueprint : supporting the creative design process .}"
}

@inproceedings{Popa2011,
    author = "Popa, Raluca Ada and Redfield, Catherine M S and Zeldovich, Nickolai and Balakrishnan, Hari",
    publisher = "ACM",
    doi = "10.1145/2043556.2043566",
    isbn = "9781450309776",
    title = "{CryptDB : Protecting Confidentiality with Encrypted Query Processing}",
    abstract = "Online applications are vulnerable to theft of sensitive information because adversaries can exploit software bugs to gain access to private data, and because curious or malicious administrators may capture and leak data. CryptDB is a system that provides practical and provable confidentiality in the face of these attacks for applica- tions backed by SQL databases. It works by executing SQL queries over encrypted data using a collection of efficient SQL-aware en- cryption schemes. CryptDB can also chain encryption keys to user passwords, so that a data item can be decrypted only by using the password of one of the users with access to that data. As a result, a database administrator never gets access to decrypted data, and even if all servers are compromised, an adversary cannot decrypt the data of any user who is not logged in. An analysis of a trace of 126 million SQL queries from a production MySQL server shows that CryptDB can support operations over encrypted data for 99.5\% of the 128,840 columns seen in the trace. Our evaluation shows that CryptDB has low overhead, reducing throughput by 14.5\% for phpBB, a web forum application, and by 26\% for queries from TPC- C, compared to unmodifiedMySQL. Chaining encryption keys to user passwords requires 11–13 unique schema annotations to secure more than 20 sensitive fields and 2–7 lines of source code changes for three multi-user web applications.",
    year = "2011",
    file = ":auto/homes/drt24/Downloads/raluca-cryptdb.pdf:pdf",
    address = "New York, NY, USA",
    keywords = "Database Administration,Security,integrity,protection",
    booktitle = "SOSP"
}

@article{Poppinga2011,
    author = "Poppinga, Benjamin and Henze, Niels",
    abstract = "Experiments are a corner stone of HCI research. Mobile dis- tribution channels such as Apple’s App Store and Google’s Android Market have created the opportunity to bring ex- periments to the end user. Hardly any experience exists how to conduct such experiments successfully. This article re- ports about five experiments that we conducted by publish- ing Apps in the Android Market. The Apps are freely avail- able and have been installed more than 30,000 times. The outcomes of the experiments range from failure to valuable insights. Based on these outcomes we identified factors that account for the success of experiments using mobile appli- cation stores. When generalizing findings it must be consid- ered that smartphone users are a non-representative sample of the world’s population. Most participants can be obtained by informing users about the study when the App had been started for the first time. Because Apps are often used for a short time only, data should be collected as early as possible. To collect valuable qualitative feedback other channels than user comments and email have to be used. Finally, the inter- pretation of collected data has to consider unpredicted usage patterns to provide valid conclusions.",
    year = "2011",
    file = "::",
    title = "{My App is an Experiment : Experience from User Studies in Mobile App Stores}"
}

@techreport{Postel1997,
    author = "Postel, J and Reynolds, J",
    title = "{Instructions to RFC Authors}",
    mendeley-tags = "INF,RFC",
    pages = "1--21",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Postel, Reynolds - 1997 - Instructions to RFC Authors.pdf:pdf",
    year = "1997",
    keywords = "INF,RFC",
    institution = "Network Working Group"
}

@inproceedings{Qian2011,
    author = "Qian, Feng and Wang, Zhaoguang and Gerber, Alexandre and Mao, Zhuoqing and Sen, Subhabrata and Spatscheck, Oliver",
    publisher = "ACM Press",
    doi = "10.1145/1999995.2000026",
    isbn = "9781450306430",
    title = "{Profiling resource usage for mobile applications}",
    url = "http://dl.acm.org/citation.cfm?id=1999995.2000026",
    abstract = "Despite the popularity of mobile applications, their performance and energy bottlenecks remain hidden due to a lack of visibility into the resource-constrained mobile execution environment with potentially complex interaction with the application behavior. We design and implement ARO, the mobile Application Resource Optimizer, the first tool that efficiently and accurately exposes the cross-layer interaction among various layers including radio resource channel state, transport layer, application layer, and the user interaction layer to enable the discovery of inefficient resource usage for smartphone applications. To realize this, ARO provides three key novel analyses: (i) accurate inference of lower-layer radio resource control states, (ii) quantification of the resource impact of application traffic patterns, and (iii) detection of energy and radio resource bottlenecks by jointly analyzing cross-layer information. We have implemented ARO and demonstrated its benefit on several essential categories of popular Android applications to detect radio resource and energy inefficiencies, such as unacceptably high (46\%) energy overhead of periodic audience measurements and inefficient content prefetching behavior.",
    year = "2011",
    month = "6",
    pages = "321",
    file = "::",
    address = "New York, New York, USA",
    keywords = "3G networks,UMTS,crosslayer analysis,radio resource optimization,rrc state machine,smartphone applications",
    booktitle = "Proceedings of the 9th international conference on Mobile systems, applications, and services - MobiSys '11"
}

@inproceedings{Qian2012,
    author = "Qian, Feng and Quah, Kee Shen and Huang, Junxian and Erman, Jeffrey and Gerber, Alexandre and Mao, Zhuoqing and Sen, Subhabrata and Spatscheck, Oliver",
    publisher = "ACM Press",
    doi = "10.1145/2307636.2307649",
    isbn = "9781450313018",
    title = "{Web caching on smartphones}",
    url = "http://dl.acm.org/citation.cfm?id=2307636.2307649",
    booktitle = "Proceedings of the 10th international conference on Mobile systems, applications, and services - MobiSys '12",
    year = "2012",
    month = "6",
    file = "::",
    address = "New York, New York, USA",
    keywords = "cellular networks,http caching,redundancy elimination,redundant traffic,smartphone applications",
    pages = "127"
}

@inproceedings{Qian2012a,
    author = "Qian, Feng and Quah, Kee Shen and Huang, Junxian and Erman, Jeffrey and Gerber, Alexandre and Mao, Zhuoqing and Sen, Subhabrata and Spatscheck, Oliver",
    publisher = "ACM Press",
    doi = "10.1145/2307636.2307649",
    isbn = "9781450313018",
    title = "{Web caching on smartphones}",
    url = "http://dl.acm.org/citation.cfm?id=2307636.2307649",
    booktitle = "Proceedings of the 10th international conference on Mobile systems, applications, and services - MobiSys '12",
    year = "2012",
    month = "6",
    address = "New York, New York, USA",
    keywords = "cellular networks,http caching,redundancy elimination,redundant traffic,smartphone applications",
    pages = "127"
}

@inproceedings{Quinn2011,
    author = "Quinn, Alexander J. and Bederson, Benjamin B.",
    publisher = "ACM Press",
    title = "{Human computation}",
    url = "http://dl.acm.org/citation.cfm?id=1978942.1979148 http://portal.acm.org/citation.cfm?doid=1978942.1979148",
    abstract = {The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal "holes" in the existing work as opportunities for new research. Since human computation is often confused with "crowdsourcing" and other terms, we explore the position of human computation with respect to these related topics.},
    year = "2011",
    month = "5",
    pages = "1403",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quinn, Bederson - 2011 - Human computation(2).pdf:pdf",
    address = "New York, New York, USA",
    keywords = "crowdsourcing,data mining,human computation,literature review,social computing,survey,taxonomy",
    booktitle = "Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11"
}

@inproceedings{Quinn2011a,
    author = "Quinn, Alexander J. and Bederson, Benjamin B.",
    publisher = "ACM Press",
    doi = "10.1145/1978942.1979148",
    isbn = "9781450302289",
    title = "{Human computation}",
    url = "http://dl.acm.org/citation.cfm?id=1978942.1979148 http://portal.acm.org/citation.cfm?doid=1978942.1979148",
    abstract = {The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal "holes" in the existing work as opportunities for new research. Since human computation is often confused with "crowdsourcing" and other terms, we explore the position of human computation with respect to these related topics.},
    year = "2011",
    mendeley-tags = "crowdsourcing,general,humansensing,research",
    month = "5",
    pages = "1403",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quinn, Bederson - 2011 - Human computation(2).pdf:pdf",
    address = "New York, New York, USA",
    keywords = "crowdsourcing,data mining,general,human computation,humansensing,literature review,research,social computing,survey,taxonomy",
    booktitle = "Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11"
}

@techreport{RFC2629,
    author = "Rose, M",
    title = "{Writing I-Ds and RFCs using XML}",
    abstract = "This memo presents a technique for using XML (Extensible Markup Language) as a source format for documents in the Internet-Drafts (I-Ds) and Request for Comments (RFC) series.",
    pages = "1--32",
    file = ":auto/homes/drt24/Downloads/rfc2629.pdf:pdf",
    year = "1999",
    institution = "IETF"
}

@techreport{RFC4033,
    author = "Arends, Roy and Austein, Rob and Larson, Matt and Massey, Dan and Rose, Scott",
    title = "{DNS Security Introduction and Requirements (RFC 4033)}",
    url = "http://tools.ietf.org/html/rfc4033",
    abstract = "The Domain Name System Security Extensions (DNSSEC) add data origin authentication and data integrity to the Domain Name System. This document introduces these extensions and describes their capabilities and limitations. This document also discusses the services that the DNS security extensions do and do not provide. Last, this document describes the interrelationships between the documents that collectively describe DNSSEC.",
    pages = "1--22",
    file = ":auto/homes/drt24/Downloads/rfc4033.pdf:pdf",
    year = "2005",
    institution = "IEFT: Network Working Group"
}

@techreport{RFC4255,
    author = "Schlyter, J (OpenSSH) and Griffin, W (SPARTA)",
    title = "{Using DNS to Securely Publish Secure Shell (SSH) Key Fingerprints (rfc4255)}",
    url = "http://tools.ietf.org/pdf/rfc4255",
    abstract = "This document describes a method of verifying Secure Shell (SSH) host keys using Domain Name System Security (DNSSEC). The document defines a new DNS resource record that contains a standard SSH key fingerprint.",
    pages = "1--10",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schlyter, Griffin - 2006 - Using DNS to Securely Publish Secure Shell (SSH) Key Fingerprints (rfc4255).pdf:pdf",
    year = "2006",
    keywords = "DNS,DNSSEC,SSH,authentication,fingerprint,keys",
    institution = "The Internet Society - Network Working Group"
}

@techreport{RFC6394,
    author = "Barnes, R",
    title = "{Use Cases and Requirements for DNS-based Authentication of Named Entities (DANE)}",
    url = "http://ebook.tools.ietf.org/html/rfc6394",
    abstract = "Many current applications use the certificate-based authentication features in Transport Layer Security (TLS) to allow clients to verify that a connected server properly represents a desired domain name. Typically, this authentication has been based on PKIX certificate chains rooted in well-known certificate authorities (CAs), but additional information can be provided via the DNS itself. This document describes a set of use cases in which the DNS and DNS Security Extensions (DNSSEC) could be used to make assertions that support the TLS authentication process. The main focus of this document is TLS server authentication, but it also covers TLS client authentication for applications where TLS clients are identified by domain names.",
    pages = "1--12",
    file = ":auto/homes/drt24/Downloads/rfc6394.txt.pdf:pdf",
    year = "2011",
    institution = "IETF"
}

@article{RICE2006,
    author = "RICE, A and HARLE, R and BERESFORD, A",
    title = "{Analysing fundamental properties of marker-based vision system designs}",
    url = "http://dx.doi.org/10.1016/j.pmcj.2006.07.006",
    abstract = "This paper investigates fundamental properties of marker-based vision (MBV) systems. We present a theoretical analysis of the performance of basic tag designs which is extended through simulation to investigate the effects of different processing algorithms. Real-world data are processed and related to the simulated results. Image processing is performed using Cantag, an open-source software toolkit for building marker-based vision (MBV) systems that can identify and accurately locate printed markers in three dimensions. Cantag supports multiple fiducial shapes, payload types, data sizes and image processing algorithms in one framework. This paper explores the design space of tags within the Cantag system, and describes the design parameters and performance characteristics which an application writer can use to select the best tag system for any given scenario.",
    issn = "15741192",
    number = "4",
    month = "11",
    volume = "2",
    pages = "453--471",
    year = "2006",
    keywords = "computer vision,fiducial tag design",
    journal = "Pervasive and Mobile Computing"
}

@techreport{Rabin1979,
    author = "Rabin, Michael O.",
    title = "{Digitalized signatures and public-key functions as intractable as factorization}",
    url = "http://dl.acm.org/citation.cfm?id=889813 http://publications.csail.mit.edu/lcs/pubs/pdf/MIT-LCS-TR-212.pdf",
    abstract = "We introduce a new class of public-key functions involving a number n = p.q having two large prime factors. As usual, the key n is public, while p and q are the private key used by the issuer for production of signatures and function inversion. These functions can be used for all the applications involving public-key functions proposed by Diffie and Hellman [ 2 ], including digitalized signatures.",
    month = "1",
    file = ":home/drt24/Downloads/MIT-LCS-TR-212.pdf:pdf",
    year = "1979",
    institution = "Massachusetts Institute of Technology - Laboratory for Computer Science"
}

@article{Radia1993,
    author = "Radia, Sanjay and Pachl, Jan",
    doi = "10.1109/88.242448",
    title = "{The per-process view of naming and remote execution}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=242448",
    abstract = "The per-process approach lets each process create its own private view of naming, instead of relying solely on the system's naming tree as in the per-system approach. The result is a flexible naming environment for distributed systems, especially for remote execution",
    issn = "10636552",
    number = "3",
    volume = "1",
    file = ":home/drt24/Downloads/00242448.pdf:pdf",
    year = "1993",
    journal = "IEEE Parallel Distributed Technology Systems Applications"
}

@inproceedings{Rahmati2007,
    author = "Rahmati, Ahmad and Qian, Angela and Zhong, Lin",
    publisher = "ACM Press",
    doi = "10.1145/1377999.1378017",
    isbn = "9781595938626",
    title = "{Understanding human-battery interaction on mobile phones}",
    url = "http://dl.acm.org/citation.cfm?id=1377999.1378017",
    booktitle = "Proceedings of the 9th international conference on Human computer interaction with mobile devices and services - MobileHCI '07",
    year = "2007",
    month = "9",
    file = "::",
    address = "New York, New York, USA",
    keywords = "batteries,human-battery interaction,mobile phones,power management",
    pages = "265--272"
}

@article{Rahmati2009,
    author = "Rahmati, Ahmad and Zhong, Lin",
    doi = "10.1016/j.pmcj.2008.08.003",
    title = "{Human–battery interaction on mobile phones}",
    url = "http://dx.doi.org/10.1016/j.pmcj.2008.08.003",
    abstract = "Mobile phone users have to deal with limited battery lifetime through a reciprocal process we call human–battery interaction. We conducted three user studies in order to understand human–battery interaction and discover the problems in existing designs that prevent users from effectively dealing with the limited battery lifetime. The studies include a large-scale international survey, two long-term field trials including quantitative battery logging and qualitative inquiries, and structured interviews with twenty additional mobile phone users. We evaluated various aspects of human–battery interaction, including charging behavior, battery indicators, user interfaces for power-saving settings, user knowledge, and user reaction. We find that mobile phone users can be categorized into two types regarding human–battery interaction and often have inadequate knowledge regarding phone power characteristics. We provide qualitative and quantitative evidence that problems in state-of-the-art user interfaces have led to under-utilized power-saving settings, under-utilized battery energy, and dissatisfied users. Our findings provide insights into improving mobile phone design for users to effectively deal with the limited battery lifetime. Our work is the first to systematically address human–battery interaction on mobile phones and is complementary to the extensive research on energy-efficient design for a longer battery lifetime.",
    issn = "15741192",
    number = "5",
    month = "10",
    volume = "5",
    pages = "465--477",
    file = "::",
    year = "2009",
    keywords = "batteries,human–battery interaction,mobile phones,power management",
    journal = "Pervasive and Mobile Computing"
}

@inproceedings{Rahmati2010,
    author = "Rahmati, Ahmad and Zhong, Lin and Vasudevan, Venu and Wickramasuriya, Jehan and Stewart, Daniel",
    publisher = "ACM Press",
    doi = "10.1145/1734583.1734603",
    isbn = "9781450300056",
    title = "{Enabling pervasive mobile applications with the FM radio broadcast data system}",
    url = "http://dl.acm.org/citation.cfm?id=1734583.1734603",
    booktitle = "Proceedings of the Eleventh Workshop on Mobile Computing Systems \& Applications - HotMobile '10",
    year = "2010",
    month = "2",
    file = "::",
    address = "New York, New York, USA",
    pages = "78"
}

@inproceedings{Ram2009,
    author = "Ram, Kaushik Kumar and Santos, Jose Renato and Turner, Yoshio and Cox, Alan L. and Rixner, Scott",
    publisher = "ACM Press",
    doi = "10.1145/1508293.1508303",
    isbn = "9781605583754",
    title = "{Achieving 10 Gb/s using safe and transparent network interface virtualization}",
    url = "http://dl.acm.org/citation.cfm?id=1508293.1508303",
    booktitle = "Proceedings of the 2009 ACM SIGPLAN/SIGOPS international conference on Virtual execution environments - VEE '09",
    year = "2009",
    month = "3",
    address = "New York, New York, USA",
    keywords = "device drivers,i/o,networking,performance analysis,virtual machine,virtualization",
    pages = "61"
}

@inproceedings{Ramasubramanian2004,
    author = "Ramasubramanian, Venugopalan and Sirer, Emin Gun",
    publisher = "USENIX Association",
    title = "{Beehive : O ( 1 ) Lookup Performance for Power-Law Query Distributions in Peer-to-Peer Overlays}",
    abstract = "Structured peer-to-peer hash tables provide decentral- ization, self-organization, failure-resilience, and good worst-case lookup performance for applications, but suf- fer from high latencies (O(logN)) in the average case. Such high latencies prohibit them from being used in many relevant, demanding applications such as DNS. In this paper, we present a proactive replication frame- work that can provide constant lookup performance for common Zipf-like query distributions. This framework is based around a closed-form optimal solution that achieves O(1) lookup performance with low storage re- quirements, bandwidth overhead and network load. Sim- ulations show that this replication framework can re- alistically achieve good latencies, outperform passive caching, and adapt efficiently to sudden changes in ob- ject popularity, also known as flash crowds. This frame- work provides a feasible substrate for high-performance, low-latency applications, such as peer-to-peer domain name service.",
    number = "1",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramasubramanian, Sirer - 2004 - Beehive O ( 1 ) Lookup Performance for Power-Law Query Distributions in Peer-to-Peer Overlays.pdf:pdf",
    year = "2004",
    booktitle = "Symposium on Networked Systems Design and Implementation"
}

@online{Rasmussen2012,
    author = "Rasmussen, Rod",
    url = "http://conferences.npl.co.uk/satin/presentations/satin2012slides-Rasmussen.pdf",
    booktitle = "SATIN",
    year = "2012",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Rasmussen.pdf:pdf",
    title = "{Using the DNS as a Hammer The Good, the Bad and the Ugly}"
}

@inproceedings{Rastogi2013,
    author = "Rastogi, Vaibhav and Chen, Yan and Jiang, Xuxian",
    publisher = "ACM",
    doi = "10.1145/2484313.2484355",
    isbn = "978-1-4503-1767-2",
    title = "{DroidChameleon: evaluating Android Anti-malware against Transformation Attacks}",
    url = "https://www.eecs.northwestern.edu/docs/techreports/2013_TR/NU-EECS-13-01.pdf",
    abstract = "Mobile malware threats (e.g., on Android) have recently become a real concern. In this paper, we evaluate the state-of-the-art commercial mobile anti-malware products for Android and test how resistant they are against various common obfuscation techniques (even with known malware). Such an evaluation is important for not only measuring the available defense against mobile malware threats but also proposing effective, next-generation solutions. We developed DroidChameleon, a systematic framework with various transformation techniques, and used it for our study. Our results on ten popular commercial anti-malware applications for Android are worrisome: none of these tools is resistant against common malware transformation techniques. Moreover, a majority of them can be trivially defeated by applying slight transformation over known malware with little effort for malware authors. Finally, in the light of our results, we propose possible remedies for improving the current state of malware detection on mobile devices.",
    number = "March",
    pages = "329--334",
    file = ":home/drt24/Downloads/droidchameleon\_nu\_eecs\_13\_01.pdf:pdf",
    year = "2013",
    booktitle = "Proceedings of the 8th ACM SIGSAC symposium on Information, computer and communications security"
}

@book{Ravi2008,
    author = "Ravi, Nishkam and Scott, James and Han, Lu and Iftode, Liviu",
    publisher = "IEEE",
    doi = "10.1109/PERCOM.2008.108",
    isbn = "978-0-7695-3113-7",
    title = "{Context-aware Battery Management for Mobile Phones}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4517397 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4517397",
    abstract = "In this paper, we propose a system for context- aware battery management that warns the user when it detects that the phone battery can run out before the next charging opportunity is encountered. At the heart of this system, are algorithms that predict: (1) when the next charging opportunity will be available, (2) how much call-time will be required by the user in the interim, and (3) how long the battery will last if the current set of applications continue to execute. We propose algorithms that process user's location traces and call-logs for making some of these predictions. We also propose a technique to predict battery consumption of applications. We present the design of the system and demonstrate its feasibility by experimentally showing that each of the prediction algorithms can perform with fairly high accuracy.",
    mendeley-tags = "power",
    month = "3",
    pages = "224--233",
    file = "::",
    year = "2008",
    keywords = "power",
    booktitle = "2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications (PerCom)"
}

@phdthesis{Reams2012,
    author = "Reams, Charles",
    school = "University of Cambridge",
    title = "{Modelling energy efficiency for computation}",
    url = "http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-821.html",
    number = "821",
    year = "2012",
    pages = "135"
}

@inproceedings{Reardon2012,
    author = "Reardon, Joel and Capkun, Srdjan and David, A",
    title = "{Data node encrypted file system: Efficient secure deletion for flash memory}",
    url = "https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final74.pdf",
    abstract = "We propose the Data Node Encrypted File System (DNEFS), which uses on-the-fly encryption and decryption of file system data nodes to efficiently and securely delete data on flash memory systems. DNEFS is a generic modification of existing flash file systems or controllers that enables secure data deletion while preserving the underlying systems’ desirable properties: application-independence, fine-grained data access, wear-levelling, and efficiency. We describe DNEFS both abstractly and in the context of the flash file system UBIFS. We propose UBIFSec, which integrates DNEFS into UBIFS. We implement UBIFSec by extending UBIFS’s Linux implementation and we integrate UBIFSec in the Android operating system running on a Google Nexus One smartphone. We show that it is efficient and usable; Android OS and applications (including video and audio playback) run normally on top of UBIFSec. To the best of our knowledge, this work presents the first comprehensive and fully-implemented secure deletion solution that works within the specification of flash memory.",
    file = ":home/drt24/Downloads/sec12-final74.pdf:pdf",
    year = "2012",
    booktitle = "USENIX Security"
}

@article{Reich2010,
    author = "Reich, Joshua and Goraczko, Michel and Kansal, Aman and Padhye, Jitendra",
    publisher = "USENIX Association",
    doi = "10.2307/4016472",
    title = "{Sleepless in Seattle No Longer}",
    journal = "Proceedings of the 2010 USENIX conference on USENIX annual technical conference",
    abstract = "In enterprise networks, idle desktop machines rarely sleep, because users (and IT departments) want them to be always accessible. While a number of solutions have been proposed, few have been evaluated via real deployments. We have built and deployed a lightweight sleep proxy system at Microsoft Research. Our system has been operational for six months, and has over 50 active users. This paper focuses on providing a detailed description of our implementation and test deployment, the first we are aware of on an operational network. Overall, we find that our lightweight approach effected significant energy savings by allowing user machines to sleep (most sleeping over 50\% of the time) while maintaining their network accessibility to user satisfaction. However, much potential sleep was lost due to interference from IT management tasks. We identify fixing this issue as the main path to improving energy savings, and provide suggestions for doing so. We also address a number of issues overlooked by prior work, including complications caused by IPsec. Finally, we find that if certain cloud-based applications become more widely adopted in the enterprise, more specialized proxy reaction policies will need be adopted. We believe our experience and insights will prove useful in guiding the design and deployment of future sleep solutions for enterprise networks.",
    number = "1",
    volume = "168",
    url = "http://research.microsoft.com/pubs/131390/SleeplessNoLonger_USENIX_2010.pdf",
    year = "2010",
    pages = "17"
}

@article{Reis2009,
    author = "Reis, Charles and Barth, Adam and Pizano, Carlos",
    title = "{Browser security: lessons from google chrome}",
    url = "http://dl.acm.org/citation.cfm?id=1556050",
    journal = "ACM Queue",
    file = ":home/drt24/Downloads/p3-reis.pdf:pdf",
    year = "2009",
    pages = "1--8"
}

@article{Ren2010a,
    author = "Ren, Lei and Tian, Feng and {(Luke) Zhang}, Xiaolong and Zhang, Lin",
    publisher = "Elsevier",
    doi = "10.1016/j.jvlc.2010.05.003",
    title = "{DaisyViz: A model-based user interface toolkit for interactive information visualization systems}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X10000297",
    abstract = "While information visualization technologies have transformed our life and work, designing information visualization systems still faces challenges. Non-expert users or end-users need toolkits that allow for rapid design and prototyping, along with supporting uniﬁed data structures suitable for different data types (e.g., tree, network, temporal, and multi-dimensional data), various visualization, interaction tasks. To address these issues, we designed DaisyViz, a model-based user interface toolkit, which enables end-users to rapidly develop domain-speciﬁc information visualization applications without traditional programming. DaisyViz is based on a user interface model for information (UIMI), which includes three declarative models: data model, visualization model, and control model. In the development process, a user ﬁrst constructs a UIMI with interactive visual tools. The results of the UIMI are then parsed to generate a prototype system automatically. In this paper, we discuss the concept of UIMI, describe the architecture of DaisyViz, and show how to use DaisyViz to build an information visualization system. We also present a usability study of DaisyViz we conducted. Our ﬁndings indicate DaisyViz is an effective toolkit to help end-users build interactive information visualization systems",
    issn = "1045926X",
    mendeley-tags = "End-User Programming,Mobile,Visual Programming",
    number = "4",
    month = "8",
    volume = "21",
    pages = "209--229",
    file = "::",
    year = "2010",
    keywords = "End-User Programming,Information visualization,Mobile,Model-based interface development,Multiple coordinated views,User interface,Visual Programming",
    journal = "Journal of Visual Languages \& Computing"
}

@inproceedings{Rennhard2012,
    author = "Rennhard, Marc and Tschannen, Michael and Christen, Tobias",
    isbn = "9781450312233",
    title = "{SecureSafe: a highly secure online data safe industrial use case}",
    url = "http://dl.acm.org/citation.cfm?id=2181196.2181197",
    abstract = "In this paper, we present the core security architecture of SecureSafe, a cloud service that provides a highly secure online storage for sensitive data. The architecture combines best practices in cryptography and security protocols with novel approaches to offer high security while providing good usability and performance. More than two years of successful operation with many satisfied customers and no security incidents demonstrate the soundness of the architecture. In addition to granting insight into the security architecture of a field-proven service to provide inputs for other services that have similar requirements, there’s another motivation for this paper: We believe that to increase trust in cloud services, service providers should be more open about internal security details – although this is in contrast to what typical cloud service providers do today.",
    file = ":auto/homes/drt24/Downloads/a1-rennhard.pdf:pdf",
    year = "2012",
    keywords = "Cloud Security,DoubleSec,Security Architecture",
    booktitle = "Measurement, Privacy, and Mobility"
}

@techreport{Rescorla2003,
    author = "Rescorla, E and Korver, B",
    title = "{Guidelines for Writing RFC Text on Security Considerations}",
    url = "http://portal.acm.org/citation.cfm?id=RFC3552",
    abstract = "All RFCs are required to have a Security Considerations section. Historically, such sections have been relatively weak. This document provides guidelines to RFC authors on how to write a good Security Considerations section.",
    mendeley-tags = "BCP,RFC",
    pages = "1--45",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rescorla, Korver - 2003 - Guidelines for Writing RFC Text on Security Considerations.pdf:pdf",
    year = "2003",
    keywords = "BCP,RFC",
    institution = "Network Working Group"
}

@article{Reshef2011,
    author = "Reshef, D. N. and Reshef, Y. A. and Finucane, H. K. and Grossman, S. R. and McVean, G. and Turnbaugh, P. J. and Lander, E. S. and Mitzenmacher, M. and Sabeti, P. C.",
    doi = "10.1126/science.1205438",
    title = "{Detecting Novel Associations in Large Data Sets}",
    url = "http://www.sciencemag.org/content/334/6062/1518.abstract",
    abstract = "Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R2) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.",
    issn = "0036-8075",
    number = "6062",
    month = "12",
    volume = "334",
    pages = "1518--1524",
    file = "::",
    year = "2011",
    journal = "Science"
}

@inproceedings{Ribeiro2011,
    author = "Ribeiro, Jo\ {a}o and Barreto, Jo\ {a}o and Ferreira, Paulo",
    publisher = "ACM",
    isbn = "9781450310659",
    title = "{MultiRep: synchronous multi-device consistency}",
    url = "http://dl.acm.org/citation.cfm?id=2090323 http://www.gsd.inesc-id.pt/~jpbarreto/bib/MultiRepMMPAC2012.pdf",
    abstract = "Nowadays, people increasingly use multiple devices to manage and share information anywhere anytime. Users are increasingly spreading large sets of files and folders among sev- eral devices. Since users cannot know at one device which files/folders are stored by other devices, data management across multiple devices has become a very difficult task. For instance, when one user needs an object that is not stored on the device being used, he/she needs to manually explore the entire object collection, which is spread across multiple devices. Additionally, different versions of files are created on multiple devices raising a consistency problem. Most current solutions ensure data management and consistency across devices through central servers or Internet services. Since portable devices have intermittent network connection or no connection at all to access these services, it is essential to take advantage of proximity between devices to synchronize data among them. This paper introduces MultiRep, a single-user file synchronizer middleware that provides the user with information about the location of files and folders stored on multiple devices. MultiRep is a totally decentralized system based on optimistic replication. It ensures eventual consistency among multiple devices through pairwise interactions, reporting all relevant information about conflicts to the users.",
    pages = "1--6",
    file = ":home/drt24/Downloads/MultiRepMMPAC2012.pdf:pdf",
    year = "2011",
    keywords = "conflict resolution,eventual consistency,file synchronizer,metadata management",
    booktitle = "M-MPAC"
}

@article{Rice,
    author = "Rice, a.C.",
    publisher = "Ieee",
    doi = "10.1109/PERCOMW.2006.36",
    isbn = "0-7695-2520-2",
    title = "{Dependability and accountability for context-aware middleware systems}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1599009 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1599009",
    journal = "Pervasive Computing and",
    file = "::",
    year = "2006",
    pages = "378--382"
}

@techreport{Rice2007,
    author = "Rice, Andrew C.",
    title = "{Dependable systems for Sentient Computing}",
    abstract = "Computers and electronic devices are continuing to proliferate throughout our lives. Sentient Computing systems aim to reduce the time and effort required to interact with these devices by composing them into systems which fade into the background of the user’s perception. Failures are a significant problem in this scenario because their occurrence will pull the system into the foreground as the user attempts to discover and understand the fault. However, attempting to exist and interact with users in a real, unpredictable, physical environment rather than a well- constrained virtual environment makes failures inevitable. This dissertation describes a study of dependability. A dependable system permits applications to discover the extent of failures and to adapt accordingly such that their continued behaviour is intuitive to users of the system. Cantag, a reliable marker-based machine-vision system, has been developed to aid the investi- gation of dependability. The description of Cantag includes specific contributions for marker tracking such as rotationally invariant coding schemes and reliable back-projection for circu- lar tags. An analysis of Cantag’s theoretical performance is presented and compared to its real-world behaviour. This analysis is used to develop optimised tag designs and performance metrics. The use of validation is proposed to permit runtime calculation of observable metrics and verification of system components. Formal proof methods are combined with a logical validation framework to show the validity of performance optimisations.",
    number = "686",
    institution = "University of Cambridge Computer Laboratory",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rice - 2007 - Dependable systems for Sentient Computing.pdf:pdf",
    year = "2007",
    booktitle = "Computer"
}

@article{Rice2007a,
    author = "Rice, Andrew C",
    year = "2007",
    number = "686",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rice - 2007 - Dependable systems for Sentient Computing.pdf:pdf",
    title = "{for Sentient Computing}"
}

@techreport{Rice2008,
    author = "Rice, Andrew C. and Akoush, Sherif and Hopper, Andy",
    title = "{Failure is an option}",
    abstract = "Reducing the level of redundancy in a datacentre’s power and cool- ing infrastructure can have a big impact on reducing overall energy costs. One means to reduce this overhead is to expect failures and adapt to them rather than attempting to eliminate them at all costs. High-level specification of services within a datacentre combined with technologies such asmigrationmight provide us with the flex- ibility to run closer to the wire and adapt to infrastructure failures if they occur. We argue that Service Level Agreements (SLAs) currently act as a disincentive to exploiting this flexibility and we suggest amore customer-centric specification which gives service providers the freedom to provision adaptively and provides incentives for both parties to work towards an appropriate service level for the client’s business needs. Specifying these agreements in machine-readable form is an important challenge and would provide two benefits: reaching, and relying, on these agreements can be made easier by modelling of the expected emergent behaviour of both parties; and integrating the specification of these new agreements into service declarations will allow us to begin to develop tools for orchestrating optimal adaption when failures occur.",
    mendeley-tags = "Economics",
    number = "Tier 4",
    file = ":home/drt24/Library/papers/Unknown/Rice, Akoush, Hopper/Rice, Akoush, Hopper - 2008 - Failure is an option.pdf:pdf",
    year = "2008",
    keywords = "Data Centre,Economics,Efficiency,SLA,UPS",
    pages = "4--6"
}

@inproceedings{Rice2010,
    author = "Rice, Andrew C. and Hay, Simon and Ryder-cook, Dan",
    title = "{A Limited-Data Model Of Building Energy Consumption}",
    abstract = "We present a model targeted at practical, wide-scale de- ployment which produces an ongoing breakdown of building energy consumption. We argue that wide-scale deployment is practical due to its reliance only on commonly available sensor information and crowd-sourced inventory data. The results for our own building over the previous 10 months show many of the trends seen in the building’s true, me- tered energy consumption and we find our model predicts long term averages within 10\% of the true value in some scenarios. We further use our model to estimate the potential impact of some energy saving scenarios.",
    mendeley-tags = "Economics,Measurement",
    pages = "3--8",
    file = ":home/drt24/Library/papers/BuildSys/Rice, Hay, Ryder-cook/Rice, Hay, Ryder-cook - 2010 - A Limited-Data Model Of Building Energy Consumption.pdf:pdf",
    year = "2010",
    keywords = "Economics,Measurement,personal energy meter",
    booktitle = "BuildSys"
}

@inproceedings{Rice2010a,
    author = "Rice, Andrew C. and Hay, Simon",
    title = "{Decomposing power measurements for mobile devices}",
    abstract = "Modern mobile phones are an appealing platform for pervasive computing applications. However, the complexity of these devices makes it difficult for developers to understand the power consumption of their applications. Our measurement framework is the first we have seen which can produce fine- grained, annotated traces of a phone’s power consumption and is designed to develop an understanding of how particular aspects of an application drive energy use. We are using our framework to analyse the power consumption of Android-based G1 and Magic handsets and show that particular choices of message size and send buffer can alter the energy required to send data by an order of magnitude in certain cases.",
    file = ":home/drt24/Library/papers/PerCom/Rice, Hay/Rice, Hay - 2010 - Decomposing power measurements for mobile devices.pdf:pdf",
    year = "2010",
    keywords = "energy measurement,mobile communication,power measurement,wireless lan",
    booktitle = "PerCom"
}

@inproceedings{Rice2010b,
    author = "Rice, Andrew C. and Woodman, Oliver J.",
    publisher = "Ieee",
    doi = "10.1109/PERCOMW.2010.5470536",
    isbn = "978-1-4244-6605-4",
    title = "{Crowd-sourcing world models with OpenRoomMap}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5470536",
    abstract = "The construction of world models typically re- quires laborious survey and cataloguing of a building’s con- tents. OpenRoomMap attempts to crowd-source this informa- tion by allowing all building occupants to contribute to the model. Our initial deployment of OpenRoomMap has consid- ered our office building that has a floor area of approximately 10000 square meters over 3 floors. Building occupants have mapped approximately 70\% of the building and placed over 4000 objects.We show how the accuracy of placement depends on the physical restrictions that constrain the positions of objects and discuss the strategies we are using to encourage ongoing update and maintenance of the data.",
    month = "3",
    pages = "764--767",
    file = ":home/drt24/Library/papers/PerCom/Rice, Woodman/Rice, Woodman - 2010 - Crowd-sourcing world models with OpenRoomMap.pdf:pdf",
    year = "2010",
    keywords = "context-aware,crowd-sourcing,vgi,world-model",
    booktitle = "PerCom"
}

@article{Rice2010c,
    author = "Rice, Andrew C. and Hay, Simon",
    publisher = "Elsevier B.V.",
    doi = "10.1016/j.pmcj.2010.07.005",
    title = "{Measuring mobile phone energy consumption for 802.11 wireless networking}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1574119210000593",
    abstract = "The complexity of modern mobile phones makes it difficult for developers to understand the power consumption of their applications. Our measurement framework produces fine- grained, annotated traces of a phone’s power consumption which we are using to develop an understanding of how particular aspects of an application drive energy use. We ran a large number of automated tests using Google Android G1, Magic, Hero and Nexus handsets and present results for the average energy consumption of connection and data transmission over 802.11 wireless networks. Our results show that the optimal choice of data transmission strategy is different between handsets, operating systems, and device context.",
    issn = "15741192",
    number = "6",
    month = "12",
    volume = "6",
    pages = "593--606",
    file = ":home/drt24/Library/papers/Pervasive and Mobile Computing/Rice, Hay/Rice, Hay - 2010 - Measuring mobile phone energy consumption for 802.11 wireless networking.pdf:pdf",
    year = "2010",
    journal = "Pervasive and Mobile Computing"
}

@inproceedings{Rice2010d,
    author = "Rice, Andrew and Hay, Simon",
    publisher = "IEEE",
    doi = "10.1109/PERCOM.2010.5466991",
    isbn = "978-1-4244-5329-0",
    title = "{Decomposing power measurements for mobile devices}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5466991 http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?reload=true\&arnumber=5466991 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5466991",
    abstract = "Modern mobile phones are an appealing platform for pervasive computing applications. However, the complexity of these devices makes it difficult for developers to understand the power consumption of their applications. Our measurement framework is the first we have seen which can produce fine-grained, annotated traces of a phone's power consumption and is designed to develop an understanding of how particular aspects of an application drive energy use. We are using our framework to analyse the power consumption of Android-based G1 and Magic handsets and show that particular choices of message size and send buffer can alter the energy required to send data by an order of magnitude in certain cases.",
    mendeley-tags = "Mobile,Power",
    month = "3",
    pages = "70--78",
    file = "::",
    year = "2010",
    keywords = "Mobile,Power",
    booktitle = "2010 IEEE International Conference on Pervasive Computing and Communications (PerCom)"
}

@techreport{Richard2003,
    author = "Richard, B and Nioclais, Donal Mac and Chalon, D",
    publisher = "Citeseer",
    title = "{Clique: A transparent, Peer-to-Peer collaborative file sharing system}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.3830\&amp;rep=rep1\&amp;type=pdf",
    abstract = "Clique is a HP Labs Grenoble project. The goal is to develop a novel peer-to-peer, server-less distributed file system based on optimistic replication algorithms, which transparently integrates into users' native file systems. Some properties of the Clique system are epidemic replication, a no lost updates consistency model and conflict management, as well as disconnected operation and replica convergence. These properties ensure that updates done by any peer of the group will never be lost,...",
    file = ":auto/homes/drt24/Downloads/10.1.1.3.3830.pdf:pdf",
    year = "2003",
    keywords = "file system,groupware,optimistic reconciliation,peer-to-peer,replication",
    booktitle = "Proceedings of the 4th international conference on mobile data management MDM’03"
}

@book{RichardBubel,
    author = {{Richard Bubel}, Reiner H\"{a}hnle},
    isbn = "978-3-540-68977-5",
    language = "en",
    title = "{Pattern-Driven Formal Specification}",
    url = "http://publications.lib.chalmers.se/publication/24944-pattern-driven-formal-specification",
    volume = "4334",
    file = "::",
    keywords = "OCL,formal methods,object-oriented software,program verification,specification languages,systems modeling",
    pages = "295--315"
}

@article{Riedmiller,
    author = "Riedmiller, M. and Braun, H.",
    publisher = "Ieee",
    doi = "10.1109/ICNN.1993.298623",
    isbn = "0-7803-0999-5",
    title = "{A direct adaptive method for faster backpropagation learning: the RPROP algorithm}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=298623",
    journal = "IEEE International Conference on Neural Networks",
    file = ":home/drt24/Library/papers/IEEE International Conference on Neural Networks/Riedmiller, Braun/Riedmiller, Braun - Unknown - A direct adaptive method for faster backpropagation learning the RPROP algorithm.pdf:pdf",
    pages = "586--591"
}

@online{Riley2006,
    author = "Riley, Shannon",
    publisher = "Software Usability Research Laboratory, Wichita State University",
    title = "{Password security: What users know and what they actually do}",
    url = "http://usabilitynews.org/password-security-what-users-know-and-what-they-actually-do/",
    abstract = "This study investigated the common password generation practices of online users. Three hundred and fifteen undergraduate and graduate students completed a survey querying (1) the types and number of different password protected accounts maintained; (2) actual practices used in generating, storing and using passwords; (3) practices believed they should use in generating and storing passwords; and (4) general demographic information. Results indicate that, in general, users do not vary the complexity of passwords depending on the nature of the site (bank account vs. instant messenger) or change their passwords on any regular basis if it is not required by the site. Users report using lower case letters, numbers or digits, personally meaningful numbers and personally meaningful words when creating passwords, despite the fact that they realize that these methods may not be the most secure.",
    number = "1",
    volume = "8",
    file = ":home/drt24/Downloads/Usability News 81 - Riley.pdf:pdf",
    year = "2006",
    urldate = "2014-01-07",
    booktitle = "Usability News"
}

@article{Riva2012,
    author = "Riva, Oriana and Qin, Chuan and Strauss, Karin and Lymberopoulos, Dimitrios",
    publisher = "USENIX",
    title = "{Progressive authentication : deciding when to authenticate on mobile phones}",
    url = "http://research.microsoft.com/apps/pubs/default.aspx?id=168102 https://www.usenix.org/conference/usenixsecurity12/progressive-authentication-deciding-when-authenticate-mobile-phones",
    abstract = "Mobile users are often faced with a trade-off between security and convenience. Either users do not use any security lock and risk compromising their data, or they use security locks but then have to inconveniently authenticate every time they use the device. Rather than exploring a new authentication scheme, we address the problem of deciding when to surface authentication and for which applications. We believe reducing the number of times a user is requested to authenticate lowers the barrier of entry for users who currently do not use any security. Progressive authentication, the approach we propose, combines multiple signals (biometric, continuity, possession) to determine a level of confidence in a user’s authenticity. Based on this confidence level and the degree of protection the user has configured for his applications, the system determines whether access to them requires authentication. We built a prototype running on modern phones to demonstrate progressive authentication and used it in a lab study with nine users. Compared to the state-of-theart, the system is able to reduce the number of required authentications by 42\% and still provide acceptable security guarantees, thus representing an attractive solution for users who do not use any security mechanism on their devices.",
    file = ":home/drt24/Downloads/pa.pdf:pdf",
    year = "2012",
    journal = "USENIX Security"
}

@article{Rivest1978,
    author = "Rivest, Ron L. and Shamir, Adi and Adleman, Len",
    publisher = "ACM",
    doi = "10.1145/359340.359342",
    title = "{A method for obtaining digital signatures and public-key cryptosystems}",
    url = "http://portal.acm.org/citation.cfm?doid=359340.359342",
    abstract = "An encryption method is presented with the novel property that publicly revealing an encryption key does not thereby reveal the corresponding decryption key. This has two important consequences: (1) Couriers or other secure means are not needed to transmit keys, since a message can be enciphered using an encryption key publicly revealed by the intented recipient. Only he can decipher the message, since only he knows the corresponding decryption key. (2) A message can be “signed” using a privately held decryption key. Anyone can verify this signature using the corresponding publicly revealed encryption key. Signatures cannot be forged, and a signer cannot later deny the validity of his signature. This has obvious applications in “electronic mail” and “electronic funds transfer” systems. A message is encrypted by representing it as a number M, raising M to a publicly specified power e, and then taking the remainder when the result is divided by the publicly specified product, n, of two large secret primer numbers p and q. Decryption is similar; only a different, secret, power d is used, where e * d ≡ 1(mod (p - 1) * (q - 1)). The security of the system rests in part on the difficulty of factoring the published divisor, n.",
    issn = "00010782",
    number = "2",
    month = "2",
    volume = "21",
    pages = "120--126",
    file = ":home/drt24/Downloads/p120-rivest.pdf:pdf",
    year = "1978",
    keywords = "authentication,cryptography,digital signatures,electronic funds transfer,electronic mail,factorization,message-passing,prime number,privacy,public-key cryptosystems,security",
    journal = "Communications of the ACM"
}

@article{Roe1998,
    author = "Roe, Michael and Christianson, Bruce and Wheeler, David",
    publisher = "Springer Berlin Heidelberg",
    doi = "10.1007/11542322_24",
    isbn = "978-3-540-28389-8",
    title = "{Secure sessions from weak secrets}",
    url = "http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-445.pdf http://link.springer.com/chapter/10.1007/11542322_24",
    abstract = "Sometimes two parties who already share a weak secret k such as a password wish to share also a strong secret s such as a session key without revealing information about k to an active attacker. We assume that both parties can generate strong random numbers and forget secrets, and present new protocols for secure strong secret sharing, based on RSA, Diffie-Hellman, and El-Gamal. As well as being simpler and quicker than their predecessors, our protocols also have stronger security properties. In particular, our protocols make no cryptographic use of s and so do not impose subtle restrictions upon the use which is subsequently made of s by other protocols. Neither do we rely upon the existence of hash functions with serendipitous properties. In the course of presenting these protocols, we also consider how to frustrate some new types of cryptographic and system attack.",
    pages = "190--205",
    volume = "3364",
    file = ":home/drt24/Downloads/10.1007\_11542322\_24.pdf:pdf",
    year = "1998",
    journal = "Security Protocols"
}

@article{Roesner2012,
    author = "Roesner, Franziska and Kohno, Tadayoshi and Moshchuk, Alexander and Parno, Bryan and Wang, Helen J. and Cowan, Crispin",
    publisher = "Ieee",
    doi = "10.1109/SP.2012.24",
    isbn = "978-1-4673-1244-8",
    title = "{User-Driven Access Control: Rethinking Permission Granting in Modern Operating Systems}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6234415",
    abstract = "Modern client platforms, such as iOS, Android, Windows Phone, Windows 8, and web browsers, run each application in an isolated environment with limited privileges. A pressing open problem in such systems is how to allow users to grant applications access to user-owned resources, e.g., to privacy- and cost-sensitive devices like the camera or to user data residing in other applications. A key challenge is to enable such access in a way that is non-disruptive to users while still maintaining least-privilege restrictions on applications. In this paper, we take the approach of user-driven access control, whereby permission granting is built into existing user actions in the context of an application, rather than added as an afterthought via manifests or system prompts. To allow the system to precisely capture permission-granting intent in an application’s context, we introduce access control gadgets (ACGs). Each user-owned resource exposes ACGs for applications to embed. The user’s authentic UI interactions with an ACG grant the application permission to access the corresponding resource. Our prototyping and evaluation experience indicates that user- driven access control enables in-context, non-disruptive, and least-privilege permission granting on modern client platforms.",
    month = "5",
    pages = "224--238",
    file = ":home/drt24/Downloads/06234415.pdf:pdf",
    year = "2012",
    keywords = "ACGs,access control,access control gadgets,least-privilege,operating systems,permission granting,permissions,user intent,user-driven access control,user-owned resources",
    journal = "2012 IEEE Symposium on Security and Privacy"
}

@article{Rogowski2012,
    editor = "Saeed, Khalid and Nagashima, Tomomasa",
    author = "Rogowski, Marcin and Saeed, Khalid",
    publisher = "Springer New York",
    doi = "10.1007/978-1-4614-5608-7",
    isbn = "978-1-4614-5607-0",
    title = "{A Study on Touch Screen Devices: User Authentication Problems}",
    url = "http://www.springerlink.com/index/10.1007/978-1-4614-5608-7",
    abstract = "The focus of this chapter is on security of touch screen devices. The emphasis is placed on smartphones – such as Apple iPhone and Android phones – and tablets – such as Apple iPad. The chapter starts with the description how the touch screen devices are winning a significant share in the market. The current state of the security methods used on these devices is discussed. Deficiencies of prevailing approaches are pointed out, and the need for new authentication mechanisms is reasoned. The hardware available in modern touch screen devices is characterized, and the sensors providing biometric data are described. In the last part of this chapter, some of the new security means using biometric features and potential new directions are discussed.",
    year = "2012",
    file = ":home/drt24/Downloads/fulltext (11).pdf:pdf",
    address = "New York, NY",
    pages = "89--111"
}

@inproceedings{Romana,
    author = "Schlegel, Roman and Zhang, Kehuan and Zhou, Xiaoyong and Intwala, Mehool and Kapadia, Apu and Wang, Xiaofeng and Roman, Schlegel",
    title = "{Soundcomber: A Stealthy and Context-Aware Sound Trojan for Smartphones}",
    url = "http://www.cs.indiana.edu/~kapadia/papers/soundcomber-ndss11.pdf",
    abstract = "We explore the threat of smartphone malware with access to on-board sensors, which opens new avenues for illicit collection of private information. While existing work shows that such “sensory malware” can convey raw sensor data (e.g., video and audio) to a remote server, these approaches lack stealthiness, incur significant communication and computation overhead during data transmission and processing, and can easily be defeated by existing protections like denying installation of applications with access to both sensitive sensors and the network. We present Soundcomber, a Trojan with few and innocuous permissions, that can extract a small amount of targeted private information from the audio sensor of the phone. Using targeted profiles for context-aware analysis, Soundcomber intelligently “pulls out” sensitive data such as credit card and PIN numbers from both tone- and speech-based interaction with phone menu systems. Soundcomber performs efficient, stealthy local extraction, thereby greatly reducing the communication cost for delivering stolen data. Soundcomber automatically infers the destination phone number by analyzing audio, circumvents known security defenses, and conveys information remotely without direct network access. We also design and implement a defensive architecture that foils Soundcomber, identify new covert channels specific to smartphones, and provide a video demonstration of Soundcomber.",
    file = ":home/drt24/Downloads/soundcomber-ndss11.pdf:pdf;::",
    year = "2011",
    booktitle = "NDSS"
}

@article{Roselli2000,
    author = "Roselli, Drew and Lorch, Jacob R. and Anderson, Thomas E.",
    url = "http://dl.acm.org/citation.cfm?id=1267724.1267728",
    title = "{A comparison of file system workloads}",
    year = "2000",
    pages = "4",
    month = "6"
}

@inproceedings{Rosenblum2011,
    author = "Rosenblum, Nathan and Miller, B.P. and Zhu, Xiaojin",
    isbn = "9781450305624",
    title = "{Recovering the toolchain provenance of binary code}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Recovering+the+Toolchain+Provenance+of+Binary+Code\#0",
    booktitle = "Twentieth International Symposium on Sofware Testing and Analysis (ISSTA), Toronto, Ontario, Canada, July",
    file = "::",
    year = "2011",
    keywords = "all or part of,forensics,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,program provenance,provided that copies are,static binary analysis,this work for"
}

@article{Ross2005,
    author = "Ross, Blake and Jackson, Collin and Miyake, Nick and Boneh, Dan and Mitchell, John C.",
    title = "{Stronger password authentication using browser extensions}",
    url = "http://www.usenix.org/event/sec05/tech/full_papers/ross/ross_html/ https://www.usenix.org/legacy/publications/library/proceedings/sec05/tech/ross.html",
    abstract = "We describe a browser extension, PwdHash, that transparently produces a different password for each site, improving web password security and defending against password phishing and other attacks. Since the browser extension applies a cryptographic hash function to a combination of the plaintext password entered by the user, data associated with the web site, and (optionally) a private salt stored on the client machine, theft of the password received at one site will not yield a password that is useful at another site. While the scheme requires no changes on the server side, implementing this password method securely and transparently in a web browser extension turns out to be quite difficult. We describe the challenges we faced in implementing PwdHash and some techniques that may be useful to anyone facing similar security issues in a browser environment.",
    pages = "17--31",
    file = ":home/drt24/Downloads/ross.pdf:pdf",
    year = "2005",
    journal = "Proceedings of the 14th USENIX Security Symposium"
}

@inproceedings{Rosu,
    author = "Rosu, M.C. and Olsen, C.M. and Narayanaswami, C. and Luo, L.",
    publisher = "IEEE",
    doi = "10.1109/MCSA.2004.18",
    isbn = "0-7695-2258-0",
    title = "{PAWP: A Power Aware Web Proxy for Wireless LAN Clients}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1377329 http://www.mendeley.com/share/viewDocument/webLibrary/3177171_4374493845:/1329994853/23b7dd5cf6e9e3c36368bf31e2b632c23fa6ce14/",
    abstract = "The relative power consumed in the WLAN interface of a mobile device is rising due to significant improvements in the energy efficiency of the other device components. The unpredictability of the incoming WLAN traffic limit the effectiveness of existing power saving techniques. This paper introduces a power aware Web proxy (PAWP) architecture designed to schedule incoming Web traffic into intervals of high and no communication. This traffic pattern allows WLAN interfaces to switch to a low power state after very short idle intervals. PAWP uses a collection of HTTP-level techniques to compensate any negative impact that traffic scheduling may have. PAWP does not require any client or Web server modifications. In this paper, we describe our initial experiences with a PAWP implementation for 802.11b WLANs. Our experiments show savings of more than 50\% in the energy consumed by the WLAN interface. Finally, our experiences give us insights into possible browser improvements when power consumption is taken into account.",
    mendeley-tags = "energy,measure,mobile,power,wifi",
    pages = "206--215",
    file = "::",
    keywords = "energy,measure,mobile,power,wifi",
    booktitle = "Sixth IEEE Workshop on Mobile Computing Systems and Applications"
}

@article{Roudaut2009,
    author = "Roudaut, Anne",
    publisher = "ACM Press",
    doi = "10.1145/1520340.1520450",
    isbn = "9781605582474",
    title = "{Visualization and interaction techniques for mobile devices}",
    url = "http://portal.acm.org/citation.cfm?doid=1520340.1520450",
    journal = "Proceedings of the 27th international conference extended abstracts on Human factors in computing systems - CHI EA '09",
    year = "2009",
    file = "::",
    address = "New York, New York, USA",
    keywords = "acm classification keywords,interaction technique,mobile devices,one-handed interaction,thumb gestures,visualization",
    pages = "3153"
}

@inproceedings{Rowstron2001,
    author = "Rowstron, Antony and Druschel, Peter",
    publisher = "Springer",
    title = "{Pastry: Scalable, decentralized object location, and routing for large-scale peer-to-peer systems}",
    url = "http://www.springerlink.com/index/404522p56nm85503.pdf",
    abstract = "This paper presents the design and evaluation of Pastry, a scalable, distributed object location and routing scheme for wide-area peer-to-peer appli- cations. Pastry performs application-level routing and object location in a poten- tially very large overlay network of nodes connected via the Internet. It can be used to support a wide range of peer-to-peer applications like global data storage, global data sharing, and naming. An insert operation in Pastry stores an object at a user-defined number of diverse nodes within the Pastry network. A lookup operation reliably retrieves a copy of the requested object if one exists.Moreover, a lookup is usually routed to the node nearest the client issuing the lookup (by some measure of proximity), among the nodes storing the requested object. Pastry is completely decentralized, scalable, and self-configuring; it automatically adapts to the arrival, departure and failure of nodes. Experimental results obtained with a prototype implementation on a simulated network of up to 100,000 nodes confirm Pastry’s scalability, its ability to self- configure and adapt to node failures, and its good network locality properties.",
    pages = "329--350",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rowstron, Druschel - 2001 - Pastry Scalable, decentralized object location, and routing for large-scale peer-to-peer systems.pdf:pdf",
    year = "2001",
    booktitle = "Middleware 2001"
}

@article{Rowstron2001a,
    author = "Rowstron, Antony and Druschel, Peter",
    publisher = "ACM",
    doi = "10.1145/502059.502053",
    isbn = "1-58113-389-8",
    title = "{Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility}",
    url = "http://dl.acm.org/citation.cfm?id=502059.502053 http://portal.acm.org/citation.cfm?doid=502059.502053",
    abstract = "This paper presents and evaluates the storage management and caching in PAST, a large-scale peer-to-peer persistent storage utility. PAST is based on a self-organizing, Internet-based overlay network of storage nodes that cooperatively route file queries, store multiple replicas of files, and cache additional copies of popular files.In the PAST system, storage nodes and files are each assigned uniformly distributed identifiers, and replicas of a file are stored at nodes whose identifier matches most closely the file's identifier. This statistical assignment of files to storage nodes approximately balances the number of files stored on each node. However, non-uniform storage node capacities and file sizes require more explicit storage load balancing to permit graceful behavior under high global storage utilization; likewise, non-uniform popularity of files requires caching to minimize fetch distance and to balance the query load.We present and evaluate PAST, with an emphasis on its storage management and caching system. Extensive trace-driven experiments show that the system minimizes fetch distance, that it balances the query load for popular files, and that it displays graceful degradation of performance as the global storage utilization increases beyond 95\%.",
    issn = "01635980",
    number = "5",
    month = "12",
    volume = "35",
    pages = "188--201",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rowstron, Druschel - 2001 - Storage management and caching in PAST, a large-scale, persistent peer-to-peer storage utility.pdf:pdf",
    year = "2001",
    journal = "ACM SIGOPS Operating Systems Review"
}

@inproceedings{Rozner2010,
    author = "Rozner, Eric and Navda, Vishnu and Ramjee, Ramachandran and Rayanchu, Shravan",
    publisher = "ACM Press",
    doi = "10.1145/1814433.1814445",
    isbn = "9781605589855",
    title = "{NAPman}",
    url = "http://dl.acm.org/citation.cfm?id=1814433.1814445",
    booktitle = "Proceedings of the 8th international conference on Mobile systems, applications, and services - MobiSys '10",
    year = "2010",
    month = "6",
    address = "New York, New York, USA",
    keywords = "802.11,access points (APs),power save mode (PSM),scheduling,smart-phones,wireless local area networks (WLANSs)",
    pages = "91"
}

@inproceedings{Ryder2009,
    author = "Ryder, Jason and Longstaff, Brent and Reddy, Sasank and Estrin, Deborah",
    publisher = "IEEE",
    doi = "10.1109/CSE.2009.312",
    isbn = "978-1-4244-5334-4",
    language = "English",
    title = "{Ambulation: A Tool for Monitoring Mobility Patterns over Time Using Mobile Phones}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5283030' escapeXml='false'/>",
    booktitle = "2009 International Conference on Computational Science and Engineering",
    volume = "4",
    year = "2009",
    keywords = "Base stations,Batteries,Computerized monitoring,Data visualization,Global Positioning System,Legged locomotion,Mobile handsets,Patient monitoring,Sensor systems,Web server,ambulation,human factors,intuitive Web-based visualization,mobile computing,mobile phones,mobility monitoring system,mobility-affecting chronic diseases,muscular dystrophy,personal health monitoring systems",
    pages = "927--931"
}

@online{S,
    author = "S, Ackerman Mark",
    url = "http://scott.mainzone.com/pubs/05-privacy-issues-and-hci.pdf",
    urldate = "05/10/12",
    file = "::",
    title = "{Privacy Issues and Human-Computer Interaction}"
}

@inproceedings{Sailhan,
    author = "Sailhan, F. and Issarny, V.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/ICDCSW.2002.1030869",
    isbn = "0-7695-1588-6",
    title = "{Energy-aware Web caching for mobile terminals}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1030869",
    abstract = "A terminal's latency, connectivity, energy and memory are the main characteristics of today's mobile environments whose performance may be improved by caching. We present an adaptive scheme for mobile Web data caching, which accounts for congestion of the wireless network and energy limitation of mobile terminals. Our main design objective is to minimize the energy cost of peer-to-peer communication among mobile terminals so as to allow for inexpensive Web access when a fixed access point is not available in the communication range of the mobile terminal. We propose a collaborative cache management strategy among mobile terminals interacting via an ad-hoc network. We further provide evaluation of the proposed solution in terms of energy consumption on mobile devices.",
    mendeley-tags = "adhoc,energy,network,power,simulation,wifi",
    pages = "820--825",
    file = "::",
    keywords = "adhoc,energy,network,power,simulation,wifi",
    booktitle = "Proceedings 22nd International Conference on Distributed Computing Systems Workshops"
}

@techreport{Saito2002,
    author = "Saito, Yasushi and Shapiro, Marc",
    publisher = "Citeseer",
    title = "{Replication : Optimistic Approaches}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.8072\&amp;rep=rep1\&amp;type=pdf",
    abstract = "Replication is a key enabling technology in distributed data sharing systems for improving both availability and performance. This paper surveys optimistic replication algorithms, which allow replica contents to diverge in the short term, in order to support concurrent work and to tolerate failures in low-quality communication links. The importance of such techniques is increasing as collaboration through wide-area and mobile networks is becoming more popular. Optimistic replication algorithms employ techniques vastly different from those for traditional pessimistic algorithms. Whereas a pessimistic algorithm relies on synchronous replica coordination, an optimistic algorithm propagates its updates in the background, discovers conflicts after they happen, and reaches an agreement on the final object contents incrementally. This paper identifies the key challenges that optimistic replication systems face − achieving uniformity, guaranteeing quality of replica contents, and scaling − and presents a comprehensive survey of techniques developed for addressing these challenges.",
    file = ":auto/homes/drt24/Downloads/HPL-2002-33.pdf:pdf",
    year = "2002",
    keywords = "optimistic,replication,survey",
    booktitle = "HP Laboratories Palo Alto Tech Rep HPL200233"
}

@article{Saltzer1975,
    author = "Saltzer, Jerome H. and Schroeder, Michael D.",
    publisher = "IEEE",
    doi = "10.1109/PROC.1975.9939",
    title = "{The protection of information in computer systems}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1451869 http://www.cs.virginia.edu/~evans/cs551/saltzer/",
    abstract = "This tutorial paper explores the mechanics of protecting computer-stored information from unauthorized use or modification. It concentrates on those architectural structures-whether hardware or software-that are necessary to support information protection. The paper develops in three main sections. Section I describes desired functions, design principles, and examples of elementary protection and authentication mechanisms. Any reader familiar with computers should find the first section to be reasonably accessible. Section II requires some familiarity with descriptor-based computer architecture. It examines in depth the principles of modern protection architectures and the relation between capability systems and access control list systems, and ends with a brief analysts of protected subsystems and protected objects. The reader who is dismayed by either the prerequisites or the level of detail in the second section may wish to skip to Section III, which reviews the state of the art and current research projects and provides suggestions for further reading.",
    issn = "00189219",
    number = "9",
    pages = "1278--1308",
    volume = "63",
    file = ":auto/homes/drt24/Downloads/Saltzer and Schroeder, The Protection of Information in Computer Systems.html:html",
    year = "1975",
    journal = "Proceedings of the IEEE"
}

@inproceedings{Samuel2010,
    author = "Samuel, Justin and Mathewson, Nick and Cappos, Justin and Dingledine, Roger",
    publisher = "ACM",
    doi = "10.1145/1866307.1866315",
    isbn = "9781450302449",
    title = "{Survivable key compromise in software update systems}",
    url = "http://dl.acm.org/citation.cfm?id=1866315",
    abstract = "Today's software update systems have little or no defense against key compromise. As a result, key compromises have put millions of software update clients at risk. Here we identify three classes of information whose authenticity and integrity are critical for secure software updates. Analyzing existing software update systems with our framework, we find their ability to communicate this information securely in the event of a key compromise to be weak or nonexistent. We also find that the security problems in current software update systems are compounded by inadequate trust revocation mechanisms. We identify core security principles that allow software update systems to survive key compromise. Using these ideas, we design and implement TUF, a software update framework that increases resilience to key compromise.",
    pages = "61--72",
    file = ":home/drt24/Downloads/p61-samuel.pdf:pdf",
    year = "2010",
    keywords = "authentication,delegation,key compromise,key management,revocation,software updates,threshold signatures",
    booktitle = "Proceedings of the 17th ACM conference on Computer and communications security"
}

@article{Santos2008,
    author = "Santos, Jose Renato and Turner, Yoshio and Janakiraman, G. and Pratt, Ian",
    url = "http://dl.acm.org/citation.cfm?id=1404014.1404017",
    title = "{Bridging the gap between software and hardware techniques for I/O virtualization}",
    year = "2008",
    pages = "29--42",
    month = "6"
}

@inproceedings{Sarin1986,
    author = "Sarin, Sunil K. and Kaufman, Charles W. and Somers, Janet E.",
    title = "{Using history information to process delayed database updates}",
    url = "http://www.vldb.org/conf/1986/P071.PDF",
    abstract = "An algorithm is described which processes database updates arriving out of order in a way that maintains a consistent view of the data. This problem arises in the context of high availability replicated database architecture in which updates are totally ordered by timestamp but do not necessarily arrive at a site in timestamp order. The algorithm uses a history of object values written and objects read by updates. When a new update arrives and is executed, higher-timestamped updates athat read its results are scheduled for undoing and reexecution; such reexecution may in turn cause additional updates to be reexecuted, and so on. A major goal of the algorithm is to avoid this kind of cascading when reexecution fan updated would have the same effect as it had before. A prototype implementation of the algorithm for a relational database is descried. It is suggested that the algorithm may be of use outside its original context, in the maintenance of historical databases.",
    year = "1986",
    file = ":auto/homes/drt24/Downloads/P071.PDF:PDF",
    address = "Kyoto",
    booktitle = "Proc. 12th Int. Conf. on Very Large Data Bases, Kyoto, Japan",
    pages = "71--78"
}

@article{Sarin1987,
    author = "Sarin, Sunil K. and Lynch, Nancy A.",
    publisher = "IEEE",
    doi = "10.1109/TSE.1987.232564",
    title = "{Discarding Obsolete Information in a Replicated Database System}",
    url = "http://www.computer.org/portal/web/csdl/doi/10.1109/TSE.1987.232564",
    abstract = {A replicated database architecture is described in which updates processed at a site must be saved to allow reconcilliation of newly arriving updates in a way that preserves mutual consistency. The storage space occupied by the saved updates increases indefinitely, and periodic discarding of old updates is needed to avoid running out of storage. A protocol is described which allows sites in the system to agree that updates older than a given timestamp are no longer needed and can be discarded. This protocol uses a "distributed snapshot" algorithm of Chandy and Lamport and represents a practical application of that algorithm. A protocol for permanent removal of sites is also described, which will allow the discarding of updates to continue when one or more sites crash and are expected not to recover.},
    issn = "00985589",
    number = "1",
    pages = "39--47",
    volume = "SE-13",
    file = ":auto/homes/drt24/Downloads/01702131.pdf:pdf",
    year = "1987",
    keywords = "Distributed databases,distributed snapshots,mutual consistency,network partitions,replicated data,timestamps",
    journal = "Software Engineering IEEE Transactions on"
}

@article{Sarkar2009,
    author = "Sarkar, Prateek and Saund, Eric and Lin, Jing",
    publisher = "Ieee",
    doi = "10.1109/ICDAR.2009.252",
    isbn = "978-1-4244-4500-4",
    title = "{Classifying Foreground Pixels in Document Images}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277566",
    journal = "2009 10th International Conference on Document Analysis and Recognition",
    file = "::",
    year = "2009",
    pages = "641--645"
}

@article{Sathi1985,
    author = "Sathi, a and Fox, M S and Greenberg, M",
    title = "{Representation of activity knowledge for project management.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/21869291",
    abstract = "Representation of activity knowledge is important to any application which must reason about activities such as new product management, factory scheduling, robot control, vehicle control, software engineering, and air traffic control. This paper provides an integration of the underlying theories needed for modeling activities. Using the domain of large computer design projects as an example, the semantics of activity modeling is described. While the past research in knowledge representation has discovered most of the underlying concepts, our attempt is toward their integration. This includes the epistemological concepts for erecting the required knowledge structure; the concepts of activity, state, goal, and manifestation for the adequate description of the plan and the progress; and the concepts of time and causality to infer the progression among the activities. We also address the issues which arise due to the integration of aggregation, time, and causality among activities and states.",
    issn = "0162-8828",
    number = "5",
    month = "5",
    volume = "7",
    pages = "531--52",
    file = "::",
    year = "1985",
    pmid = "21869291",
    journal = "IEEE transactions on pattern analysis and machine intelligence"
}

@article{Satyanarayanan2001,
    author = "Satyanarayanan, M.",
    publisher = "IEEE",
    doi = "10.1109/98.943998",
    title = "{Pervasive Computing: Vision and Challenges}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=943998",
    abstract = "This article discusses the challenges in computer systems research posed by the emerging field of pervasive computing. It first examines the relationship of this new field to its predecessors: distributed systems and mobile computing. It then identifies four new research thrusts: effective use of smart spaces, invisibility, localized scalability, and masking uneven conditioning. Next, it sketches a couple of hypothetical pervasive computing scenarios, and uses them to identify key capabilities missing from today's systems. The article closes with a discussion of the research necessary to develop these capabilities",
    issn = "10709916",
    number = "August",
    pages = "10--17",
    volume = "8",
    file = ":home/drt24/Downloads/00943998.pdf:pdf",
    year = "2001",
    journal = "Ieee Personal Communications"
}

@inproceedings{Saund2003,
    author = "Saund, Eric and Fleed, David and Mahoney, James V. and Larner, Daniel",
    booktitle = "Symposium on Document Image Understanding Technology",
    year = "2003",
    file = "::",
    title = "{Rough Document Interpretation by Perceptual Organisation}"
}

@inproceedings{Saund2009a,
    author = "Saund, Eric and Lin, Jing and Sarkar, Prateek",
    publisher = "Ieee",
    doi = "10.1109/ICDAR.2009.250",
    isbn = "978-1-4244-4500-4",
    title = "{PixLabeler : User Interface for Pixel-Level Labeling of Elements in Document Images}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5277567",
    abstract = "We present a user interface design for labeling elements in document images at a pixel level. Labels are represented by overlay color, which might map to such terms as “hand- writing”, “machine print”, “graphics”, etc. The primary purpose is to streamline processes for manual production of groundtruth data, which is necessary for training algo- rithms and evaluating performance. Unlike general paint- type programs, the UI design is targeted specifically toward selection of collections of foreground pixels that are likely to be meaningful elements in a document image analysis con- text. Our implementation, called PixLabeler, is available for download and allows customized plug-ins for bootstrap- ping according to the labeling task.",
    pages = "646--650",
    file = "::;::",
    year = "2009",
    booktitle = "Proceedings of the International Conference on Document Analysis and Recognition"
}

@article{Saund2011a,
    author = "Saund, Eric",
    publisher = "Ieee",
    doi = "10.1109/ICDAR.2011.216",
    isbn = "978-1-4577-1350-7",
    title = "{A Graph Lattice Approach to Maintaining Dense Collections of Subgraphs as Image Features}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6065474",
    journal = "2011 International Conference on Document Analysis and Recognition",
    month = "9",
    file = "::;::",
    year = "2011",
    keywords = "-graph lattice,document classification",
    pages = "1069--1074"
}

@inproceedings{Schaeffer2012,
    author = "Schaeffer, Yuri and Overeinder, Benno and Mekking, Matthijs",
    title = "{Flexible and Robust Key Rollover in DNSSEC}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Schaeffer.pdf http://conferences.npl.co.uk/satin/presentations/satin2012slides-Schaeffer.pdf",
    abstract = "DNSSEC security extensions make use of a public- private key pair to sign and validate origin and integrity of DNS data. The ability to renew keys is a standard operational practice in the deployment of DNSSEC. This key renewal, or actually key rollover, is a complex and error prone process.We propose a new method for key rollover in which not the individual procedural steps of a rollover are specified, but the validity of a step in the rollover process is specified. The rollover process can now find an optimal and correct path from an old key to a new key. The proposed method is robust, is effective in emergency situations in which a compromised key must be rolled over in the shortest amount of time possible, and allows for efficient combined rollover of multiple keys. The new key rollover method presented in this paper is implemented and integrated within the OpenDNSSEC software framework.",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/presentations/satin2012slides-Schaeffer.pdf:pdf;:auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Schaeffer.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@techreport{Schlyter2006,
    author = "Schlyter, J (OpenSSH) and Griffin, W (SPARTA)",
    title = "{Using DNS to Securely Publish Secure Shell (SSH) Key Fingerprints (rfc4255)}",
    url = "http://tools.ietf.org/pdf/rfc4255",
    abstract = "This document describes a method of verifying Secure Shell (SSH) host keys using Domain Name System Security (DNSSEC). The document defines a new DNS resource record that contains a standard SSH key fingerprint.",
    pages = "1--10",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schlyter, Griffin - 2006 - Using DNS to Securely Publish Secure Shell (SSH) Key Fingerprints (rfc4255).pdf:pdf",
    year = "2006",
    keywords = "DNS,DNSSEC,SSH,authentication,fingerprint,keys",
    institution = "The Internet Society - Network Working Group"
}

@inproceedings{Schmid2010,
    author = "Schmid, Thomas and Culler, David and Dutta, Prabal",
    isbn = "9781450304580",
    title = "{Meter Any Wire , Anywhere by Virtualizing the Voltage Channel}",
    abstract = "AC power meters require both voltage and current to be sampled concurrently to obtain real, reactive, and apparent power. Typically, the two measurements are taken in close physical proximity and fed into a single power metering de- vice. In this paper, we explore the viability of decoupling the voltage and current channels, and placing them in phys- ically disparate locations. Such decoupling could ease the installation of metering infrastructure and enable new sens- ing scenarios. However, decoupling the voltage and current channels raises a new question: how should they be recom- bined? Of the various approaches, we propose the voltage channel be virtualized: a voltage sensor measures the volt- age magnitude, frequency, and phase, typically near the root of a circuit branch. The extracted phase is time-stamped rela- tive to a global clock and disseminated wirelessly, along with the magnitude and frequency measurements, to power meters throughout the network. The power meters synthesize a suit- ably scaled replica of the voltage waveform locally, based on the parameters reported by the voltage sensor, and combine it with locally-measured current readings. This paper demonstrates – through empirical characterization of the line voltages, a proof-of-concept power meter implementation, and house-scale evaluation – that the design holds promise and offers substantially lower measurement errors than other dis- tributed power metering approaches for non-resistive loads.",
    mendeley-tags = "Design,Measurement,Performance",
    file = ":home/drt24/Library/papers/BuildSys/Schmid, Culler, Dutta/Schmid, Culler, Dutta - 2010 - Meter Any Wire , Anywhere by Virtualizing the Voltage Channel.pdf:pdf",
    year = "2010",
    keywords = "Design,Energy metering,Measurement,Performance,power factor measurement,time synchronization,wireless sensing",
    booktitle = "BuildSys"
}

@article{Schmidt2006a,
    author = {Schmidt, Albrecht and H\"{a}kkil\"{a}, Jonna and Atterer, Richard and Rukzio, Enrico and Holleis, Paul},
    publisher = "ACM Press",
    doi = "10.1145/1125451.1125692",
    title = "{Utilizing mobile phones as ambient information displays}",
    url = "http://portal.acm.org/citation.cfm?doid=1125451.1125692",
    journal = "CHI '06 extended abstracts on Human factors in computing systems - CHI '06",
    year = "2006",
    file = "::",
    address = "New York, New York, USA",
    keywords = "Ambient displays,information art,mobile phones,user interfaces",
    pages = "1295"
}

@inproceedings{Schmidt2009,
    author = "Schmidt, A.-D. and Bye, R. and Schmidt, H.-G. and Clausen, J. and Kiraz, O. and Yuksel, K. A. and Camtepe, S. A. and Albayrak, S.",
    publisher = "IEEE",
    doi = "10.1109/ICC.2009.5199486",
    title = "{Static Analysis of Executables for Collaborative Malware Detection on Android}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5199486",
    abstract = "Smartphones are getting increasingly popular and several malwares appeared targeting these devices. General countermeasures to smartphone malwares are currently limited to signature-based antivirus scanners which efficiently detect known malwares, but they have serious shortcomings with new and unknown malwares creating a window of opportunity for attackers. As smartphones become host for sensitive data and applications, extended malware detection mechanisms are necessary complying with the corresponding resource constraints. The contribution of this paper is twofold. First, we perform static analysis on the executables to extract their function calls in Android environment using the command readelf. Function call lists are compared with malware executables for classifying them with PART, Prism and Nearest Neighbor Algorithms. Second, we present a collaborative malware detection approach to extend these results. Corresponding simulation results are presented.",
    month = "6",
    year = "2009",
    booktitle = "2009 IEEE International Conference on Communications",
    pages = "1--5"
}

@article{Schneider1990,
    author = "Schneider, Fred B",
    publisher = "ACM",
    doi = "10.1145/98163.98167",
    title = "{Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial}",
    url = "http://portal.acm.org/citation.cfm?id=98163.98167",
    abstract = "The state machine approach is a general method for implementing fault-tolerant services in distributed systems. This paper reviews the approach and describes protocols for two different failure modelsByzantine and fail stop. Systems reconfiguration techniques for removing faulty components and integrating repaired components are also discussed.",
    issn = "03600300",
    number = "4",
    pages = "299--319",
    volume = "22",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schneider - 1990 - Implementing Fault-Tolerant Approach A Tutorial Services Using the State Machine.pdf:pdf",
    year = "1990",
    keywords = "and phrases,client-server",
    journal = "ACM Computing Surveys"
}

@online{Schneier2000,
    author = "Schneier, Bruce",
    title = "{Full Disclosure and the Window of Exposure}",
    url = "http://web.archive.org/web/20011213013638/http://www.counterpane.com/crypto-gram-0009.html https://archive.today/cXyow",
    abstract = {Every season yields a bumper crop of computer security stories: break-ins, new vulnerabilities, new products. But this season has also given us a crop of stories about computer security philosophy. There has been a resurgence in opposition to the full disclosure movement: the theory that states that publishing vulnerabilities is the best way to fix them. In response, defenders of the movement have published their rebuttals. And even more experts have weighed in with opinions on the DeCSS case, where a New York judge ruled that distributing an attack tool is illegal. What's interesting is that everybody wants the same thing; they're just disagreeing about the best way to get there. When a security vulnerability exists in a product, it creates what I call a window of exposure. This window exists until the vulnerability is patched, and that patch is installed. The shape of this window depends on how many people can exploit this vulnerability, and how fast it is patched. What everyone wants is to make this window as small as possible. figure 1A window of exposure has five distinct phases. Phase 1 is before the vulnerability is discovered. The vulnerability exists, but no one can exploit it. Phase 2 is after the vulnerability is discovered, but before it is announced. At that point only a few people know about the vulnerability, but no one knows to defend against it. Depending on who knows what, this could either be an enormous risk or no risk at all. During this phase, news about the vulnerability spreads -- either slowly, quickly, or not at all -- depending on who discovered the vulnerability. Of course, multiple people can make the same discovery at different times, so this can get very complicated. Phase 3 is after the vulnerability is announced. Maybe the announcement is made by the person who discovered the vulnerability in Phase 2, or maybe it is made by someone else who independently discovered the vulnerability later. At that point more people learn about the vulnerability, and the risk increases. In Phase 4, an automatic attack tool to exploit the vulnerability is published. Now the number of people who can exploit the vulnerability grows exponentially. Finally, the vendor issues a patch that closes the vulnerability, starting Phase 5. As people install the patch and re-secure their systems, the risk of exploit shrinks. Some people never install the patch, so there is always some risk. But it decays over time as systems are naturally upgraded. In some instances the phases are long, and sometimes they're short. Sometimes Phase 5 happens so fast that Phases 3 and 4 never occur. Sometimes Phase 5 never occurs, either because the vendor doesn't care or no fix is possible. But this is basically the way things work. The goal of any responsible security professional is to reduce the window of exposure -- the area under the curve -- as much as possible. There are two basic approaches to this. figure 2The first is to reduce the window in the space dimension by limiting the amount of vulnerability information available to the public. The idea is that the less attackers know about attack methodologies, and the harder it is for them to get their hands on attack tools, the safer networks become. The extreme position in this camp holds that attack tools should be made illegal. This might work in theory, but unfortunately it is impossible to enforce in practice. There is a continuous stream of research in security vulnerabilities, and most of this research results in public announcements. Hackers write new attack exploits all the time, and the exploits quickly end up in the hands of malicious attackers. Any one country could make some of these actions illegal, but it would make little difference on the international Internet. There have been some isolated incidences of a researcher deliberately not publishing a vulnerability he discovered, but public dissemination of vulnerability information is the norm...because it is the best way to improve security. The second approach is to reduce the window of exposure in time. Since a window remains open until the vendor patches the vulnerability and the network administrator installs the patches, the faster the vendor can issue the patch the faster the window starts closing. To spur the vendors to patch faster, full-disclosure proponents publish vulnerabilities far and wide. Ideally, the vendor will distribute the patch before any automatic attack tools are written. But writing such tools can only hasten the patches. figure 2This also works a lot better in theory than in practice. There are many instances of security-conscious vendors publishing patches in a timely fashion. But there are just as many examples of security vendors ignoring problems, and of network administrators not bothering to install existing patches. A series of credit card thefts in early 2000 was facilitated by a vulnerability in Microsoft IIS that was discovered, and a patch released for, a year and a half earlier. The problem is that for the most part, the size and shape of the window of exposure is not under the control of any central authority. Not publishing a vulnerability is no guarantee that someone else won't publish it. Publishing a vulnerability is no guarantee that someone else won't write an exploit tool, and no guarantee that the vendor will fix it. Releasing a patch is no guarantee that a network administrator will actually install it. Trying to impose rules on such a chaotic system just doesn't work. And to make matters worse, it's never one single vulnerability. There are dozens and hundreds of vulnerabilities, all with overlapping windows. One vulnerability might be shrinking while another ten are growing. We're like the little Dutch boy, plugging leaks in the dike with our fingers while others spring up nearby. It doesn't matter if we believe that full disclosure is the best way to reduce the window's size or if quietly alerting the vendor does better...we're going to lose the war fighting it either way. Vulnerabilities are inevitable. As our networks get more complex and more pervasive, the vulnerabilities will become more frequent, not less. We're already seeing this; every year brings more security holes than the previous one. The only way to close the window of exposure is to make it not matter. And the only way to do that is to build security systems that are resilient to vulnerabilities. In Secrets and Lies, I talk about security processes that make systems resilient to vulnerabilities. The most relevant one to this debate is detection and response. Most computer-security products are sold as prophylactics: firewalls prevent network intrusions, PKI prevents impersonation, encryption prevents eavesdropping, etc. The problem with this model is that the product can either succeed or fail: either the window of exposure is closed or it is open. Good security includes not only protection, but also detection and response. An Internet alarm system that detects attacks in progress, regardless of the vulnerability that was exploited, has the ability to close the window of exposure completely. The key to Internet detection and response is vigilance. Attacks can happen at all times of the day and night, and any day of the year. New attack tools appear all the time; new vulnerabilities become public all the time. I built Counterpane Internet Security, Inc. as a managed security monitoring company because I saw this as the only way to bring security to computer networks. Without outsourced detection and monitoring, we're at the mercy of all the hackers and product vendors and security professionals. Those advocating secrecy are right that full disclosure causes damage, in some cases more damage than good. They are also right that those who build attack tools should be held liable for their actions; the defense of "I just built the bomb; I didn't place it or set the fuse" rings hollow. But they are wrong to think they can enforce secrecy. Information naturally disseminates, and strategies that go against that are doomed. Those advocating full disclosure are right that rapid dissemination of the information benefits everyone, even though some people make ill use of that information. We would be in a much worse position today if vulnerability information were only in the hands of a privileged few. Neither full disclosure nor secrecy "solve" computer security; the debate has no solution because there is no one solution. Both sides are missing the point. The real issue, how to close the window of exposure, is more subtle. We have to stop thinking of software security as an end state, that fixing the bugs will somehow make the software perfect. Security vulnerabilities are inevitable and there will always be a window of exposure; smart security solutions will work regardless.},
    file = ":home/drt24/Downloads/cryptogram-0009.pdf:pdf",
    year = "2000",
    urldate = "2014-06-09",
    booktitle = "Cryptogram"
}

@online{Schneier2012,
    author = "Schneier, Bruce",
    title = "{Feudal security}",
    url = "http://www.schneier.com/blog/archives/2012/12/feudal_sec.html",
    abstract = "It’s a feudal world out there. Some of us have pledged our allegiance to Google: We have Gmail accounts, we use Google Calendar and Google Docs, and we have Android phones. Others have pledged allegiance to Apple: We have Macintosh laptops, iPhones, and iPads; and we let iCloud automatically synchronize and back up everything. Still others of us let Microsoft do it all. Or we buy our music and e-books from Amazon, which keeps records of what we own and allows downloading to a Kindle, computer, or phone. Some of us have pretty much abandoned e-mail altogether \ldots for Facebook. These vendors are becoming our feudal lords, and we are becoming their vassals. We might refuse to pledge allegiance to all of them -- or to a particular one we don't like. Or we can spread our allegiance around. But either way, it's becoming increasingly difficult to not pledge allegiance to at least one of them. Feudalism provides security. Classical medieval feudalism depended on overlapping, complex, hierarchical relationships. There were oaths and obligations: a series of rights and privileges. A critical aspect of this system was protection: vassals would pledge their allegiance to a lord, and in return, that lord would protect them from harm. Of course, I'm romanticizing here; European history was never this simple, and the description is based on stories of that time, but that's the general model. And it's this model that's starting to permeate computer security today.",
    month = "12",
    year = "2012",
    booktitle = "Schneier on Security"
}

@article{Schnorr1990,
    author = "Schnorr, C. P.",
    doi = "10.1007/0-387-34805-0_22",
    title = "{Efficient identification and signatures for smart cards}",
    url = "http://www.springerlink.com/index/8l9c4bu4nn747wpn.pdf",
    journal = "Lecture Notes in Computer Science",
    volume = "435/1990",
    file = ":auto/homes/drt24/Downloads/fulltext (8).pdf:pdf",
    year = "1990",
    pages = "239--252"
}

@inproceedings{Schulman2010,
    author = "Schulman, Aaron and Navda, Vishnu and Ramjee, Ramachandran and Spring, Neil and Deshpande, Pralhad and Grunewald, Calvin and Jain, Kamal and Padmanabhan, Venkata N.",
    publisher = "ACM Press",
    doi = "10.1145/1859995.1860006",
    isbn = "9781450301817",
    title = "{Bartendr: a practical approach to energy-aware cellular data scheduling}",
    url = "http://dl.acm.org/citation.cfm?id=1859995.1860006",
    abstract = "Cellular radios consume more power and suffer reduced data rate when the signal is weak. According to our measurements, the communication energy per bit can be as much as 6x higher when the signal is weak than when it is strong. To realize energy savings, applications must preferentially communicate when the signal is strong, either by deferring non-urgent communication or by advancing anticipated communication to coincide with periods of strong signal. Allowing applications to perform such scheduling requires predicting signal strength, so that opportunities for energy-efficient communication can be anticipated. Furthermore, such prediction must be performed at little energy cost. In this paper, we make several contributions towards a practical system for energy-aware cellular data scheduling called Bartendr. First, we establish, via measurements, the relationship between signal strength and power consumption. Second, we show that location alone is not sufficient to predict signal strength and motivate the use of tracks to enable effective prediction. Finally, we develop energy-aware scheduling algorithms for different workloads - syncing and streaming - and evaluate these via simulation driven by traces obtained during actual drives, demonstrating energy savings of up to 60\%. Our experiments have been performed on four cellular networks across two large metropolitan areas, one in India and the other in the U.S.",
    year = "2010",
    month = "9",
    pages = "85",
    file = "::",
    address = "New York, New York, USA",
    keywords = "bartendr,cellular,energy,evdo,hsdpa,mobile",
    booktitle = "Proceedings of the sixteenth annual international conference on Mobile computing and networking - MobiCom '10"
}

@inproceedings{Schulman2010a,
    author = "Schulman, Aaron and Navda, Vishnu and Ramjee, Ramachandran and Spring, Neil and Deshpande, Pralhad and Grunewald, Calvin and Jain, Kamal and Padmanabhan, Venkata N.",
    publisher = "ACM Press",
    doi = "10.1145/1859995.1860006",
    isbn = "9781450301817",
    title = "{Bartendr: a practical approach to energy-aware cellular data scheduling}",
    url = "http://dl.acm.org/citation.cfm?id=1859995.1860006",
    abstract = "Cellular radios consume more power and suffer reduced data rate when the signal is weak. According to our measurements, the communication energy per bit can be as much as 6x higher when the signal is weak than when it is strong. To realize energy savings, applications must preferentially communicate when the signal is strong, either by deferring non-urgent communication or by advancing anticipated communication to coincide with periods of strong signal. Allowing applications to perform such scheduling requires predicting signal strength, so that opportunities for energy-efficient communication can be anticipated. Furthermore, such prediction must be performed at little energy cost. In this paper, we make several contributions towards a practical system for energy-aware cellular data scheduling called Bartendr. First, we establish, via measurements, the relationship between signal strength and power consumption. Second, we show that location alone is not sufficient to predict signal strength and motivate the use of tracks to enable effective prediction. Finally, we develop energy-aware scheduling algorithms for different workloads - syncing and streaming - and evaluate these via simulation driven by traces obtained during actual drives, demonstrating energy savings of up to 60\%. Our experiments have been performed on four cellular networks across two large metropolitan areas, one in India and the other in the U.S.",
    year = "2010",
    month = "9",
    pages = "85",
    address = "New York, New York, USA",
    keywords = "bartendr,cellular,energy,evdo,hsdpa,mobile",
    booktitle = "Proceedings of the sixteenth annual international conference on Mobile computing and networking - MobiCom '10"
}

@article{Schumann2011,
    author = "Schumann, Heidrun and Tominski, Christian",
    publisher = "Elsevier",
    doi = "10.1016/j.jvlc.2011.03.002",
    title = "{Analytical, visual and interactive concepts for geo-visual analytics}",
    url = "http://linkinghub.elsevier.com/retrieve/pii/S1045926X11000176",
    journal = "Journal of Visual Languages \& Computing",
    issn = "1045926X",
    number = "4",
    month = "8",
    volume = "22",
    file = "::",
    year = "2011",
    keywords = "Association analysis,Extended focus+context,Geo-spatial data,Hierarchical data,Visual analytics",
    pages = "257--267"
}

@article{Schuster-Bockler2007,
    author = {Schuster-B\"{o}ckler, Benjamin and Bateman, Alex},
    doi = "10.1002/0471250953.bia03as18",
    title = "{An introduction to hidden Markov models.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/18428778",
    abstract = "This unit introduces the concept of hidden Markov models in computational biology. It describes them using simple biological examples, requiring as little mathematical knowledge as possible. The unit also presents a brief history of hidden Markov models and an overview of their current applications before concluding with a discussion of their limitations.",
    issn = "1934-340X",
    number = "January",
    month = "6",
    volume = "Appendix 3",
    pages = "Appendix 3A",
    file = {:home/drt24/Library/papers/Current protocols in bioinformatics editoral board, Andreas D. Baxevanis ... et al/Schuster-B\"{o}ckler, Bateman/Schuster-B\"{o}ckler, Bateman - 2007 - An introduction to hidden Markov models.pdf:pdf},
    year = "2007",
    keywords = "Algorithms,Artificial Intelligence,Computer Simulation,Data Interpretation, Statistical,Markov Chains,Models, Biological,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Sequence Analysis,Sequence Analysis: methods",
    pmid = "18428778",
    journal = "Current protocols in bioinformatics / editoral board, Andreas D. Baxevanis ... [et al.]"
}

@inproceedings{Schwartz2010b,
    author = "Schwartz, Edward J. and Avgerinos, Thanassis and Brumley, David",
    publisher = "IEEE",
    doi = "10.1109/SP.2010.26",
    isbn = "978-1-4244-6894-2",
    title = "{All You Ever Wanted to Know about Dynamic Taint Analysis and Forward Symbolic Execution (but Might Have Been Afraid to Ask)}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5504796\&contentType=Conference+Publications\&queryText=all+you+ever+wanted+to+know+about+dynamic+taint+analysis",
    abstract = "Dynamic taint analysis and forward symbolic execution are quickly becoming staple techniques in security analyses. Example applications of dynamic taint analysis and forward symbolic execution include malware analysis, input filter generation, test case generation, and vulnerability discovery. Despite the widespread usage of these two techniques, there has been little effort to formally define the algorithms and summarize the critical issues that arise when these techniques are used in typical security contexts. The contributions of this paper are two-fold. First, we precisely describe the algorithms for dynamic taint analysis and forward symbolic execution as extensions to the run-time semantics of a general language. Second, we highlight important implementation choices, common pitfalls, and considerations when using these techniques in a security context. View full abstract»",
    pages = "317--331",
    file = ":home/drt24/Downloads/oakland10.pdf:pdf",
    year = "2010",
    booktitle = "2010 IEEE Symposium on Security and Privacy"
}

@inproceedings{Schwartz2010c,
    author = "Schwartz, Edward J. and Avgerinos, Thanassis and Brumley, David",
    publisher = "IEEE",
    title = "{All You Ever Wanted to Know about Dynamic Taint Analysis and Forward Symbolic Execution (but Might Have Been Afraid to Ask)}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5504796\&contentType=Conference+Publications\&queryText=all+you+ever+wanted+to+know+about+dynamic+taint+analysis",
    abstract = "Dynamic taint analysis and forward symbolic execution are quickly becoming staple techniques in security analyses. Example applications of dynamic taint analysis and forward symbolic execution include malware analysis, input filter generation, test case generation, and vulnerability discovery. Despite the widespread usage of these two techniques, there has been little effort to formally define the algorithms and summarize the critical issues that arise when these techniques are used in typical security contexts. The contributions of this paper are two-fold. First, we precisely describe the algorithms for dynamic taint analysis and forward symbolic execution as extensions to the run-time semantics of a general language. Second, we highlight important implementation choices, common pitfalls, and considerations when using these techniques in a security context. View full abstract»",
    pages = "317--331",
    file = ":home/drt24/Downloads/oakland10.pdf:pdf",
    year = "2010",
    booktitle = "2010 IEEE Symposium on Security and Privacy"
}

@article{Schwarz1999,
    author = "Schwarz, Whittaker and Whittaker, Steve and Ave, Mountain and Hill, Murray",
    title = "{Board meetings : the impact of scheduling medium on long term group coordination in software development 1 Program in Science Technology and Society}",
    abstract = {Despite a wealth of electronic group tools for coordinating the software development process, instead we find many groups preferring to use apparently outmoded "material" tools in critical projects. The current ethnographic study investigates this paradox. We begin by building up a detailed picture of the overall software development process and identify critical general problems in achieving coordination. Coordination problems arise in software development from the complex dependencies that hold among the work of different individuals. We identify the critical role of the schedule as a coordination device, but find that its value can be undermined because the schedule is often neither accurate nor current. As a result, the schedule is not used as a resource for individual or group planning, and we identify the reasons why this occurs. We then compare coordination in two development groups, one using electronic and the other material scheduling tools. We found that the medium of the schedule has a major impact on coordination problems. The size, public location and physical qualities of material tools engender certain crucial group processes that current electronic technologies fail to support. A large wallboard located in a public area encouraged greater responsibility, commitment and updating and its material properties served to encourage more reflective planning. Furthermore, the public nature of the wallboard promoted group interaction around the board, it enabled collaborative problem solving, as well as informing individuals about the local and global progress of theproject. Despite these benefits, however, the material tool fell short on several other dimensions such as distribution, complex dependency tracking, and versioning. We make design recommendations about how the benefits of material tools could be incorporated into electronic groupware systems and discuss the theoretical implications of this work.},
    pages = "1--46",
    file = "::",
    year = "1999",
    journal = "Computer Support Collaborative Work"
}

@phdthesis{Schwarzkopf2009,
    author = "Schwarzkopf, Malte",
    school = "University of Cambridge",
    year = "2009",
    file = ":home/drt24/Library/papers/Unknown/Schwarzkopf/Schwarzkopf - 2009 - Proteus - Interactive Annotation-Based 3D Structure-from-Motion.pdf:pdf",
    title = "{Proteus - Interactive Annotation-Based 3D Structure-from-Motion}"
}

@inproceedings{Schwarzkopf2012,
    author = "Schwarzkopf, Malte and Murray, Derek G and Hand, Steven",
    abstract = "Research into distributed parallelism on “the cloud” has surged lately. As the methodologies and foci in this area are being established, we observe a tendency towards certain common simplifications and shortcuts employed by researchers, which we provocatively term “sins”. We believe that these sins, in some cases, are threats to the scientific integrity and practical applicability of the re- search presented. In this paper, we discuss seven “deadly sins” we have identified (and many of which we have also committed!); present evidence illustrating that they pose real problems; and discuss ways for the community to avoid them in the future.",
    year = "2012",
    booktitle = "HotCloud",
    file = ":auto/homes/drt24/Downloads/2012-hotcloud.pdf:pdf",
    title = "{The seven deadly sins of cloud computing research}"
}

@online{Scott,
    author = "Scott, James and Hui, Pan and Crowcroft, Jon and Diot, Christophe",
    title = "{Haggle: a Networking Architecture Designed Around Mobile Users}",
    url = "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.126.8298",
    abstract = "Current mobile computing applications are infrastructure-centric, due to the IP-based API that these applications are written around. This causes many frustrations for end users, whose needs might be easily met with local connectivity resources but whose applications do not support this (e.g. emailing someone sitting next to you when there is no wireless access point). We identify the general scenario faced by the user of Pocket Switched Networking (PSN), and discuss why the IP-based status quo does not cope well in this environment. We present a set of architectural principles for PSN, and the high-level design of Haggle, our asynchronous, data-centric network architecture which addresses this environment by “raising ” the API so that applications can provide the network with application-layer data units (ADUs) with high-level metadata concerning ADU identification, security and delivery to user-named endpoints. I.",
    mendeley-tags = "power",
    file = "::",
    keywords = "power"
}

@techreport{Scott1998,
    author = "Scott, G (Defence Information Systems Agency)",
    title = "{Guide for Internet Standards Writers}",
    abstract = {This document is a guide for Internet standard writers. It defines those characteristics that make standards coherent, unambiguous, and easy to interpret. In addition, it singles out usage believed to have led to unclear specifications, resulting in non-interoperable interpretations in the past. These guidelines are to be used with RFC 2223, "Instructions to RFC Authors".},
    mendeley-tags = "BCP,RFC",
    pages = "1--21",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scott - 1998 - Guide for Internet Standards Writers.pdf:pdf",
    year = "1998",
    keywords = "BCP,RFC",
    institution = "Network Working Group"
}

@online{SecurityISlides,
    author = "Kuhn, Markus",
    url = "http://www.cl.cam.ac.uk/teaching/1213/SecurityI/slides.pdf",
    year = "2013",
    pages = "1--140",
    title = "{Security I slides}"
}

@book{Seeger2004,
    author = "Seeger, Matthias",
    isbn = "026218253X",
    title = "{Gaussian processes for machine learning.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/15112367",
    abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
    issn = "0129-0657",
    number = "2",
    month = "4",
    volume = "14",
    pages = "69--106",
    file = ":home/drt24/Library/papers/International journal of neural systems/Seeger/Seeger - 2004 - Gaussian processes for machine learning.pdf:pdf",
    year = "2004",
    keywords = "Algorithms,Artificial Intelligence,Bayes Theorem,Entropy,Linear Models,Models, Statistical,Normal Distribution,Regression Analysis,Statistics, Nonparametric",
    pmid = "15112367",
    booktitle = "International journal of neural systems"
}

@article{Segel2010,
    author = "Segel, Edward and Heer, Jeffrey",
    doi = "10.1109/TVCG.2010.179",
    title = "{Narrative visualization: telling stories with data.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/20975152",
    abstract = "Data visualization is regularly promoted for its ability to reveal stories within data, yet these \&\#8220;data stories\&\#8221; differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.",
    issn = "1077-2626",
    number = "6",
    pages = "1139--48",
    volume = "16",
    file = "::",
    year = "2010",
    pmid = "20975152",
    journal = "IEEE transactions on visualization and computer graphics"
}

@online{Seneviratne,
    author = "Seneviratne, Oshani",
    keywords = "Accountability,Usable Security and Privacy,Usage Restrictions,Web Protocols",
    url = "http://dig.csail.mit.edu/2012/Papers/WWW_PhD_Symposium/paper.pdf",
    abstract = "Given the ubiquity of data on the web, and the lack of usage restriction enforcement mechanisms, stories of personal, creative and other kinds of data misuses are on the rise. There should be both sociological and technological mechanisms that facilitate accountability on the web that would prevent such data misuses from occurring. Sociological mechanisms use coercion to appeal to the data consumer’s self-interest in adhering to the data provider’s desires. This involves a system of rewards such as recognition and financial incentives, and deterrents such as prohibitions by laws for any violations and social pressure. However, there is no well-defined technological mechanism for the discovery of accountability or the lack of it on the web. As part of my PhD thesis I propose to find a solution to this problem by designing a web protocol called HTTPA (Accountable HTTP). This protocol will enable data consumers and data producers to agree to specific usage restrictions, preserve the provenance of data transferred from a web server to a client and back to another web server and so on, and more importantly provide a mechanism to derive an ‘audit trail’ for the data reuse with the help of a trusted intermediary called a ‘Provenance Tracker Network’. This paper describes the problem, state of the art, a novel approach, the work in progress and the future work on realizing a sound and a timely solution to the problem of data misuse on the web.",
    title = "{Augmenting the Web with Accountability}"
}

@article{Seo2008,
    author = "Seo, Euiseong and Jeong, Jinkyu and Park, Seonyeong and Lee, Joonwon",
    doi = "10.1109/TPDS.2008.104",
    title = "{Energy Efficient Scheduling of Real-Time Tasks on Multicore Processors}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4553699",
    journal = "IEEE Transactions on Parallel and Distributed Systems",
    issn = "1045-9219",
    number = "11",
    month = "11",
    volume = "19",
    year = "2008",
    pages = "1540--1552"
}

@online{Shahriyar,
    author = "Shahriyar, Amini and Jialiu, Lin and Jason, Hong and Janne, Lindqvist and Joy, Zhang",
    url = "http://www.cylab.cmu.edu/files/pdfs/tech_reports/CMUCyLab12006.pdf",
    urldate = "29/02/2012",
    abstract = "With the widespread adoption of smartphones, mobile applications have gained mainstream popularity. However, the potential privacy and security risks associated with using mobile apps are quite high, as smartphones become increasingly integrated with our lives, being able to access our email, social networking accounts, financial information, personal photos, and even our cars and homes. To address this problem, we introduce AppScanner, an automated cloud-based service based on crowdsourcing and traditional security approaches to analyze mobile applications. Considering the large and growing number of mobile applications, our envisioned service builds on crowdsourcing, virtualization, and automation to enable large-scale analysis of apps. AppScanner provides end-users with more understandable information regarding what mobile apps are really doing on their devices. This paper offers an overview of our vision for building AppScanner, as well as work to date in specific components, including automated traversal and monitoring of mobile applications, and interactive visual presentation of app traversal results. Armed with transparent and descriptive information regarding app behavior, users can make better decisions when installing and running apps.",
    file = "::",
    title = "{Towards Scalable Evaluation of Mobile Applications through Crowdsourcing and Automation}"
}

@inproceedings{Shapiro1999,
    author = "Shapiro, Jonathan S. and Smith, Jonathan M. and Farber, David J.",
    publisher = "ACM",
    title = "{EROS: a fast capability system}",
    url = "http://dl.acm.org/citation.cfm?id=319163",
    abstract = "EROS is a capability-based operating system for commodity processors which uses a single level storage model. The single level store's persistence is transparent to applications. The performance consequences of support for transparent persistence and capability-bsed architectures are generally believed to be negative. Surprisingly, the basic operations of EROS (such as IPC) are generally comparable in cost to similar operations in conventional systems. This is demonstrated with a set of microbenchmark measurerments of semantically similar operations in Linux. The EROS system achieves its performance by coupling well-chosen abstract objects with caching techniques for those objects. The objects (processes, nodes, and pages) are well-supported by conventional hardware, reducing the overhead of capabilites. Software-manged cahing techniques for these objects reduce the cost of persistence. The resulting performance suggests that composing protected subsystems may be less costly than commonly believed.",
    number = "5",
    volume = "33",
    file = ":auto/homes/drt24/Downloads/sosp99-eros-preprint.ps:ps",
    year = "1999",
    booktitle = "SOSP"
}

@inproceedings{Shapiro2000,
    author = "Shapiro, Marc and Rowstron, Antony and Kermarrec, Anne-Marie",
    keywords = "loo,rep",
    organization = "\{ACM\} \{SIG\} on \{O\}perating \{S\}ystems (\{SIGOPS\})",
    booktitle = "SIGOPS European Workshop Beyond the PC New Challenges for the Operating System",
    year = "2000",
    title = "{Application-independent reconciliation for nomadic applications}"
}

@article{Shekhar2012,
    author = "Shekhar, Shashi and Dietz, Michael and Wallach, Dan S.",
    isbn = "978-931971-95-9",
    title = "{AdSplit: Separating smartphone advertising from applications}",
    journal = "Proceedings of the 21st USENIX conference on Security symposium",
    abstract = "A wide variety of smartphone applications today rely on third-party advertising services, which provide libraries that are linked into the hosting application. This situation is undesirable for both the application author and the advertiser. Advertising libraries require additional permissions, resulting in additional permission requests to users. Likewise, a malicious application could simulate the behavior of the advertising library, forging the user's interaction and effectively stealing money from the advertiser. This paper describes AdSplit, where we extended Android to allow an application and its advertising to run as separate processes, under separate user-ids, eliminating the need for applications to request permissions on behalf of their advertising libraries. We also leverage mechanisms from Quire to allow the remote server to validate the authenticity of client-side behavior. In this paper, we quantify the degree of permission bloat caused by advertising, with a study of thousands of downloaded apps. AdSplit automatically recompiles apps to extract their ad services, and we measure minimal runtime overhead. We also observe that most ad libraries just embed an HTML widget within and describe how AdSplit can be designed with this in mind to avoid any need for ads to have native code.",
    pages = "28",
    url = "https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final101.pdf$\backslash$nhttp://arxiv.org/abs/1202.4030",
    eprint = "1202.4030",
    file = ":home/drt24/Downloads/sec12-final101.pdf:pdf",
    year = "2012",
    archiveprefix = "arXiv",
    arxivid = "1202.4030"
}

@inproceedings{Sheng2006,
    author = "Sheng, Steve and Broderick, Levi and Hyland, Jeremy J and Koranda, Colleen Alison",
    title = "{Why Johnny still can't encrypt: evaluating the usability of email encryption software}",
    url = "http://chariotsfire.com/pub/sheng-poster_abstract.pdf",
    abstract = "Our research seeks to understand the current usability situation of email encryption software, particularly PGP 9 in comparison to previous studies of PGP 5. We designed a pilot study to find current problems in the following areas: create a key pair, get public keys, verify public keys, encrypt an email, sign an email, decrypt an email, verify a digital signature, and save a backup of public and private keys.",
    pages = "3--4",
    file = ":auto/homes/drt24/Downloads/sheng-poster\_abstract.pdf:pdf",
    year = "2006",
    booktitle = "Symposium On Usable Privacy and Security"
}

@article{Shepard1968,
    author = "Shepard, Donald",
    publisher = "ACM Press",
    doi = "10.1145/800186.810616",
    title = "{A two-dimensional interpolation function for irregularly-spaced data}",
    url = "http://portal.acm.org/citation.cfm?doid=800186.810616",
    journal = "Proceedings of the 1968 23rd ACM national conference on -",
    year = "1968",
    file = ":home/drt24/Library/papers/Proceedings of the 1968 23rd ACM national conference on -/Shepard/Shepard - 1968 - A two-dimensional interpolation function for irregularly-spaced data.pdf:pdf",
    address = "New York, New York, USA",
    pages = "517--524"
}

@article{Shepard2011,
    author = "Shepard, Clayton and Rahmati, Ahmad and Tossell, Chad and Zhong, Lin and Kortum, Phillip",
    doi = "10.1145/1925019.1925023",
    title = "{LiveLab}",
    url = "http://dl.acm.org/citation.cfm?id=1925019.1925023",
    journal = "ACM SIGMETRICS Performance Evaluation Review",
    issn = "01635999",
    number = "3",
    month = "1",
    volume = "38",
    year = "2011",
    pages = "15"
}

@inproceedings{Shih2002,
    author = "Shih, Eugene and Bahl, Paramvir and Sinclair, Michael J.",
    publisher = "ACM Press",
    doi = "10.1145/570645.570666",
    isbn = "158113486X",
    title = "{Wake on wireless:}",
    url = "http://dl.acm.org/citation.cfm?id=570645.570666",
    booktitle = "Proceedings of the 8th annual international conference on Mobile computing and networking - MobiCom '02",
    year = "2002",
    month = "9",
    file = "::",
    address = "New York, New York, USA",
    keywords = "low-power radio,power consumption of wireless LANs,wake-on-wireless",
    pages = "160"
}

@misc{Shneiderman1996,
    author = "Shneiderman, Ben",
    abstract = "A useful starting point for designing advanced graphical user interfaces is the visual Information-Seeking Mantra: Overview first, zoom and filter, then details-on-demand. But this is only the starting point in trying to understand the rich and varied set of information visualzations that have been proposed in recent years. This paper offers a task by data type taxonomy with seven data types (1-, 2-, 3- dimensional data, temporal and multi-dimensional data, and tree and network data) and seven tasks (overview, zoom, filter, details-on-demand, relate, history, and extract).",
    year = "1996",
    file = "::",
    title = "{The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations}"
}

@inproceedings{Shraer2010,
    author = "Shraer, Alexander and Shaket, Dani and Cachin, Christian and Cidon, Asaf and Keidar, Idit and Michalevsky, Yan",
    publisher = "ACM Press",
    doi = "10.1145/1866835.1866841",
    isbn = "9781450300896",
    title = "{Venus : Verification for Untrusted Cloud Storage}",
    url = "http://portal.acm.org/citation.cfm?id=1866841",
    series = "CCSW '10",
    abstract = "This paper presents Venus, a service for securing user interaction with untrusted cloud storage. Specifically, Venus guarantees integrity and consistency for applications accessing a key-based object store service, without requiring trusted components or changes to the storage provider. Venus completes all operations optimistically, guaranteeing data integrity. It then verifies operation consistency and notifies the application. Whenever either integrity or consistency is violated, Venus alerts the application. We implemented Venus and evaluated it with Amazon S3 commodity storage service. The evaluation shows that it adds no noticeable overhead to storage operations.",
    issn = "15437221",
    pages = "19--29",
    file = ":auto/homes/drt24/Downloads/p19-shraer.pdf:pdf",
    year = "2010",
    keywords = "cloud storage,forking semantics,hashing,integrity",
    booktitle = "Electrical Engineering"
}

@inproceedings{ShuaiHaoDingLiWilliamG.J.Halfond2013,
    author = "{Shuai Hao, Ding Li, William G. J. Halfond}, Ramesh Govindan",
    booktitle = "ICSE",
    year = "2013",
    pages = "90----99",
    title = "{Estimating mobile application energy consumption using program analysis}"
}

@article{Shvachko2010,
    author = "Shvachko, Konstantin and Kuang, Hairong and Radia, Sanjay and Chansler, Robert",
    publisher = "Ieee",
    doi = "10.1109/MSST.2010.5496972",
    isbn = "9781424471522",
    title = "{The Hadoop Distributed File System}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5496972",
    abstract = "The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of HDFS and report on experience using HDFS to manage 25 petabytes of enterprise data at Yahoo!.",
    pages = "1--10",
    file = ":auto/homes/drt24/Downloads/05496972.pdf:pdf",
    year = "2010",
    keywords = "HDFS,Hadoop,distributed file system",
    journal = "2010 IEEE 26th Symposium on Mass Storage Systems and Technologies MSST"
}

@inproceedings{Shye2009,
    author = "Shye, Alex and Scholbrock, Benjamin and Memik, Gokhan",
    publisher = "ACM Press",
    doi = "10.1145/1669112.1669135",
    isbn = "9781605587981",
    title = "{Into the wild: studying real user activity patterns to guide power optimizations for mobile architectures}",
    url = "http://dl.acm.org/citation.cfm?id=1669112.1669135",
    abstract = "As the market for mobile architectures continues its rapid growth, it has become increasingly important to understand and optimize the power consumption of these battery-driven devices. While energy consumption has been heavily explored, there is one critical factor that is often overlooked - the end user. Ultimately, the energy consumption of a mobile architecture is defined by user activity. In this paper, we study mobile architectures in their natural environment - in the hands of the end user. Specifically, we develop a logger application for Android G1 mobile phones and release the logger into the wild to collect traces of real user activity. We then show how the traces can be used to characterize power consumption, and guide the development of power optimizations. We present a regression-based power estimation model that only relies on easily-accessible measurements collected by our logger. The model accurately estimates power consumption and provides insights about the power breakdown among hardware components. We show that energy consumption widely varies depending upon the user. In addition, our results show that the screen and the CPU are the two largest power consuming components. We also study patterns in user behavior to derive power optimizations. We observe that majority of the active screen time is dominated by long screen intervals. To reduce the energy consumption during these long intervals, we implement a scheme that slowly reduces the screen brightness over time. Our results reveal that the users are happier with a system that slowly reduces the screen brightness rather than abruptly doing so, even though the two schemes settle at the same brightness. Similarly, we experiment with a scheme that slowly reduces the CPU frequency over time. We evaluate these optimizations with a user study and demonstrate 10.6\% total system energy savings with a minimal impact on user satisfaction.",
    year = "2009",
    month = "12",
    pages = "168",
    address = "New York, New York, USA",
    booktitle = "Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture - Micro-42"
}

@inproceedings{Shye2009b,
    author = "Shye, Alex and Scholbrock, Benjamin and Memik, Gokhan",
    publisher = "ACM Press",
    doi = "10.1145/1669112.1669135",
    isbn = "9781605587981",
    title = "{Into the wild}",
    url = "http://dl.acm.org/citation.cfm?id=1669112.1669135",
    booktitle = "Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture - Micro-42",
    year = "2009",
    month = "12",
    address = "New York, New York, USA",
    pages = "168"
}

@article{Shye2010,
    author = "Shye, Alex and Scholbrock, Benjamin and Memik, Gokhan and Dinda, Peter A.",
    doi = "10.1145/1811099.1811094",
    isbn = "978-1-4503-0038-4",
    title = "{Characterizing and modeling user activity on smartphones}",
    url = "http://dl.acm.org/citation.cfm?id=1811099.1811094",
    abstract = "In this paper, we present a comprehensive analysis of real smartphone usage during a 6-month study of real user activity on the Android G1 smartphone. Our goal is to study the high-level characteristics of smartphone usage, and to understand the implications on optimizing smartphones, and their networks. Overall, we present 11 findings that cover general usage behavior, interaction with the battery, power consumption, network activity, frequently-run applications, and modeling usage states.",
    issn = "01635999",
    number = "1",
    month = "6",
    volume = "38",
    pages = "375",
    file = "::",
    year = "2010",
    keywords = "embedded systems,human factors",
    journal = "ACM SIGMETRICS Performance Evaluation Review"
}

@article{Simmhan2005,
    author = "Simmhan, Y.L. and Plale, Beth and Gannon, Dennis",
    publisher = "ACM",
    title = "{A survey of data provenance in e-science}",
    url = "http://portal.acm.org/citation.cfm?id=1084812",
    journal = "ACM Sigmod Record",
    number = "3",
    volume = "34",
    file = "::",
    year = "2005",
    pages = "31--36"
}

@incollection{Simmons1996,
    author = "Simmons, Gustavus J",
    booktitle = "Information Hiding",
    year = "1996",
    file = ":auto/homes/drt24/Downloads/fulltext (5).pdf:pdf",
    title = "{The History of Subliminal Channels}"
}

@article{Simmons1998,
    author = "Simmons, G.J.",
    doi = "10.1109/49.668969",
    title = "{The history of subliminal channels}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=668969",
    abstract = "In 1978 the United States was considering adopting a national security protocol designed to enable the USSR to verify how many Minuteman missiles the United States had emplaced in a field of 1000 silos without revealing which silos actually contained missiles. For this protocol to have been acceptable to the USSR, the messages would have had to be digitally signed with signatures which the USSR could verify were authentic, but which the United States could not forge. Subliminal channels were the discovery that these digital signatures could host undetectable covert channels. In general, any time redundant information is introduced into a communication to provide an overt function such as digital signatures, error detection and/or correction, authentication, etc. it may be possible to subvert the purported function to create a covert (subliminal) communications channel. This paper recounts the development of subliminal channels from their origins when only a couple of bits could be communicated covertly to today when potentially a couple of hundred bits can be concealed in signatures generated using the most popular digital signature schemes",
    issn = "07338716",
    number = "4",
    month = "5",
    volume = "16",
    pages = "452--462",
    year = "1998",
    journal = "IEEE Journal on Selected Areas in Communications"
}

@article{Slo-LiChuShiue-RuChen2013,
    author = "{Slo-Li Chu, Shiue-Ru Chen}, Sheng-Fu Weng",
    journal = "Applied mathematics \& information sciences",
    year = "2013",
    pages = "793--800",
    title = "{CPPM: A comprehensive power-aware processor manager for a multicore system}"
}

@article{Smalley,
    author = "Smalley, Stephen and Craig, Robert",
    title = "{Security Enhanced (SE) Android: Bringing Flexible MAC to Android}",
    url = "http://selinuxproject.org/~seandroid/papers/NDSS2013-SEAndroid-Paper.pdf",
    abstract = "The Android software stack for mobile devices defines and enforces its own security model for apps through its application-layer permissions model. However, at its foundation, Android relies upon the Linux kernel to protect the system from malicious or flawed apps and to isolate apps from one another. At present, Android leverages Linux dis- cretionary access control (DAC) to enforce these guarantees, despite the known shortcomings of DAC. In this pa- per, we motivate and describe our work to bring flexible mandatory access control (MAC) to Android by enabling the effective use of Security Enhanced Linux (SELinux) for kernel-level MAC and by developing a set of middleware MAC extensions to the Android permissions model. We then demonstrate the benefits of our security enhancements for Android through a detailed analysis of how they mitigate a number of previously published exploits and vulnerabilities for Android. Finally, we evaluate the overheads imposed by our security enhancements.",
    file = ":home/drt24/Downloads/NDSS2013-SEAndroid-Paper.pdf:pdf",
    year = "2013",
    journal = "NDSS"
}

@article{Smalley2013,
    author = "Smalley, Stephen and Craig, Robert",
    title = "{Security Enhanced (SE) Android: Bringing Flexible MAC to Android}",
    url = "http://selinuxproject.org/~seandroid/papers/NDSS2013-SEAndroid-Paper.pdf",
    abstract = "The Android software stack for mobile devices defines and enforces its own security model for apps through its application-layer permissions model. However, at its foundation, Android relies upon the Linux kernel to protect the system from malicious or flawed apps and to isolate apps from one another. At present, Android leverages Linux discretionary access control (DAC) to enforce these guarantees, despite the known shortcomings of DAC. In this pa- per, we motivate and describe our work to bring flexible mandatory access control (MAC) to Android by enabling the effective use of Security Enhanced Linux (SELinux) for kernel-level MAC and by developing a set of middleware MAC extensions to the Android permissions model. We then demonstrate the benefits of our security enhancements for Android through a detailed analysis of how they mitigate a number of previously published exploits and vulnerabilities for Android. Finally, we evaluate the overheads imposed by our security enhancements.",
    file = ":home/drt24/Downloads/NDSS2013-SEAndroid-Paper.pdf:pdf",
    year = "2013",
    journal = "Network and Distributed System Security Symposium (NDSS)"
}

@online{Soghoian2013,
    author = "Soghoian, Christopher and Wizner, Ben",
    title = "{ACLU FTC Android updates}",
    url = "http://www.aclu.org/files/assets/aclu_-_android_ftc_complaint_-_final.pdf",
    abstract = "The major wireless carriers have sold millions of Android smartphones to consumers. The vast majority of these devices rarely receive software security updates. A significant number of consumers are using smartphones running a version of the Android operating system with known, exploitable security vulnerabilities for which fixes have been published by Google, but have not been distributed to consumers’ smartphones by the wireless carriers and their handset manufacturer partners. Android smartphones that do not receive regular, prompt security updates are defective and unreasonably dangerous. As the FTC has acknowledged, security vulnerabilities on consumers’ mobile devices may be used “to record and transmit information entered into or stored on the device \ldots to target spear-phishing campaigns, physically track or stalk individuals, and perpetrate fraud, resulting in costly bills to the consumer \ldots [and to misuse] sensitive device functionality such as the device’s audio recording feature \ldots to capture private details of an individual’s life.” Widely distributed Android malware has exploited known security vulnerabilities in the Android operating system for which fixes from Google existed, but which the vast majority of consumer devices had not received at the time of infection. The wireless carriers have failed to warn consumers that the smartphones sold to them are defective, that they are running vulnerable software, and that other smartphones are available that receive regular, prompt updates to which consumers could switch. President Obama, the Federal Trade Commission, the National Security Agency and several other government agencies have all stressed the importance of software updates and their critical impact on the cybersecurity of consumer, business and government computer systems. The practices of the major wireless carriers alleged herein as they relate to the poor security of the smartphones sold to consumers constitute deceptive and unfair business practices subject to review by the FTC under section 5 of The Federal Trade Commission Act.",
    file = ":home/drt24/Downloads/aclu\_-\_android\_ftc\_complaint\_-\_final (1).pdf:pdf",
    year = "2013",
    pages = "1--17"
}

@inproceedings{Sounthiraraj2014,
    author = "Sounthiraraj, David and Sahs, Justin and Greenwood, Garret and Lin, Zhiqiang and Khan, Latifur",
    isbn = "1891562355",
    title = "{SMV-HUNTER : Large Scale, Automated Detection of SSL/TLS Man-in-the-Middle Vulnerabilities in Android Apps}",
    abstract = "Many Android apps use SSL/TLS to transmit sensitive information securely. However, developers often provide their own implementation of the standard SSL/TLS certificate validation process. Unfortunately, many such custom implementations have subtle bugs, have built-in exceptions for self-signed certificates, or blindly assert all certificates are valid, leaving many Android apps vulnerable to SSL/TLS Man-in-the-Middle attacks. In this paper, we present SMV-HUNTER, a system for the automatic, large-scale identification of such vulnerabilities that combines both static and dynamic analysis. The static component detects when a custom validation procedure has been given, thereby identifying potentially vulnerable apps, and extracts information used to guide the dynamic analysis, which then uses user interface enumeration and automation techniques to trigger the potentially vulnerable code under an active Man-in-the-Middle attack. We have implemented SMV-HUNTER and evaluated it on 23,418 apps downloaded from the Google Play market, of which 1,453 apps were identified as being potentially vulnerable by static analysis, with an average overhead of approximately 4 seconds per app, running on 16 threads in parallel. Among these potentially vulnerable apps, 726 were confirmed vulnerable using our dynamic analysis, with an average overhead of about 44 seconds per app, running on 8 emulators in parallel.",
    number = "February",
    file = ":home/drt24/Downloads/NDSS14b.pdf:pdf",
    year = "2014",
    booktitle = "Network and Distributed System Security Symposium (NDSS)",
    pages = "23--26"
}

@inproceedings{Souza2010,
    author = "Souza, Mateus De and Dias, Diego and Carvalho, Bispo and Barth, Peter and Ramos, Jeferson Vieira",
    title = "{Using acceleration data from smartphones to interact with 3D medical data}",
    abstract = "Accelerometers integrated in modern smartphones pave the way to intuitively use gestures for collaboratively con- trolling interactive applications. Using and holding smartphones has become natural and ensures user acceptance as well as intuitive handling. We focus on using accelerators in several smartphones at the same time to interactively control a medical imaging solution. To this end, we introduce a framework to collect, modify, and distribute acceleration sensor data from multiple smartphones and integrate it with a medical imaging system which results in an environment suitable for e.g. doctors reviewing and explaining diagnostic findings.We performed some experiments to evaluate the usability of this approach and present an ongoing research in adapting the smartphone interface to physical simulation applications.",
    year = "2010",
    file = "::",
    address = "Gramado",
    keywords = "acceleration sensor,medical images,mobile,smartphone",
    booktitle = "Graphics, Patterns and Images (SIBGRAPI)"
}

@inproceedings{Spring2012,
    author = "Spring, Jonathan M and Huth, Carly L",
    title = "{The Impact of Passive DNS Collection on End-user Privacy}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-Spring.pdf",
    abstract = "There are two distinct problems in determining the impact of passive DNS (pDNS) on end-user privacy. One is whether or not pDNS would allow the observer to reconstruct an individual end-user’s DNS behavior. The other is if DNS behavior constitutes personally identifiable information (PII) or is otherwise legally protected. This paper develops a framework to discuss both aspects of the privacy issue. From the technical point of view, DNS sensor architecture is analyzed and a statistical model is developed to describe the sensor’s ability to violate end- user privacy. To the other end, a review of various jurisdictions’ privacy legislation is presented and analyzed in the context of DNS as a system and pDNS as a collection mechanism. In general, we find that pDNS, properly configured, does not violate end-user privacy.",
    pages = "1--11",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-Spring.pdf:pdf",
    year = "2012",
    keywords = "Measurement studies,Passive DNS,Privacy and the DNS",
    booktitle = "SATIN"
}

@article{Stajano1999,
    author = "Stajano, Frank and Anderson, Ross",
    doi = "10.1007/10720107",
    isbn = "3540673814",
    title = "{The Resurrecting Duckling : Security Issues for Ad-hoc Wireless Networks}",
    abstract = "In the near future, many personal electronic devices will be able to communicate with each other over a short range wireless channel. We investigate the principal security issues for such an environment. Our discussion is based on the concrete example of a thermometer that makes its readings available to other nodes over the air. Some lessons learned from this example appear to be quite general to ad-hoc networks, and rather different from what we have come to expect in more conventional systems: denial of service, the goals of authentication, and the problems of naming all need re-examination. We present the resurrecting duckling security policy model, which describes secure transient association of a device with multiple serialised owners.",
    pages = "1--11",
    volume = "1796",
    year = "1999",
    journal = "Time"
}

@article{Stajano2011,
    author = "Stajano, Frank",
    publisher = "Springer",
    doi = "10.1007/978-3-642-25867-1_6",
    isbn = "978-3-642-25866-4",
    title = "{Pico: No more passwords!}",
    url = "http://link.springer.com/chapter/10.1007/978-3-642-25867-1_6",
    abstract = "From a usability viewpoint, passwords and PINs have reached the end of their useful life. Even though they are convenient for imple- menters, for users they are increasingly unmanageable. The demands placed on users (passwords that are unguessable, all different, regularly changed and never written down) are no longer reasonable now that each person has to manage dozens of passwords. Yet we can’t abandon pass- words until we come up with an alternative method of user authentication that is both usable and secure. We present an alternative design based on a hardware token called Pico that relieves the user from having to remember passwords and PINs. Unlike most alternatives, Pico doesn’t merely address the case of web passwords: it also applies to all the other contexts in which users must at present remember passwords, passphrases and PINs. Besides relieving the user from memorization efforts, the Pico solution scales to thousands of credentials, provides “continuous authentication” and is resistant to brute force guessing, dictionary attacks, phishing and keylogging.",
    pages = "49--81",
    volume = "7114",
    file = ":home/drt24/Downloads/2011-Stajano-pico.pdf:pdf",
    year = "2011",
    journal = "Security Protocols XIX"
}

@inproceedings{Stark2009,
    author = "Stark, Emily and Hamburg, Michael and Boneh, Dan",
    publisher = "Ieee",
    doi = "10.1109/ACSAC.2009.42",
    isbn = "978-1-4244-5327-6",
    title = "{Symmetric Cryptography in Javascript}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5380691 http://bitwiseshiftleft.github.io/sjcl/acsac.pdf",
    abstract = "We take a systematic approach to developing a symmetric cryptography library in Javascript. We study various strategies for optimizing the code for the Javascript interpreter, and observe that traditional crypto optimization techniques do not apply when implemented in Javascript. We propose a number of optimizations that reduce both running time and code size. Our optimized library is about four times faster and 12\% smaller than the fastest and smallest existing symmetric Javascript encryption libraries. On Internet Explorer 8, our library is about 11 times faster than the fastest previously existing code. In addition, we show that certain symmetric systems that are faster than AES when implemented in native x86 code, are in fact much slower than AES when implemented in Javascript. As a result, the choice of ciphers for a Javascript crypto library may be substantially different from the choice of ciphers when implementing crypto natively. Finally, we study the problem of generating strong randomness in Javascript and give extensive measurements validating our techniques.",
    month = "12",
    pages = "373--381",
    file = ":home/drt24/Downloads/acsac.pdf:pdf",
    year = "2009",
    keywords = "cryptography,javascript,optimization",
    booktitle = "2009 Annual Computer Security Applications Conference"
}

@inproceedings{Stevens2012,
    author = "Stevens, Ryan and Gibler, Clint and Crussell, Jon and Erickson, Jeremy and Chen, Hao",
    title = "{Investigating User Privacy in Android Ad Libraries}",
    url = "http://www.mostconf.org/2012/papers/27.pdf http://www.cs.ucdavis.edu/~hchen/paper/most2012ad.pdf",
    abstract = "Recent years have witnessed incredible growth in the popularity and prevalence of smart phones. A ﬂourishing mobile application market has evolved to provide users with additional functionality such as interacting with social networks, games, and more. Mobile applications may have a direct purchasing cost or be free but ad-supported. Unlike in-browser ads, the privacy implications of ads in Android applications has not been thoroughly explored. We start by comparing the similarities and differences of in-browser ads and in-app ads. We examine the effect on user privacy of thirteen popular Android ad providers by reviewing their use of permissions. Worryingly, several ad libraries checked for permissions beyond the required and optional ones listed in their documentation, including dangerous permissions like CAMERA, WRITE CALENDAR and WRITE CONTACTS. Further, we discover the insecure use of Android’s JavaScript extension mechanism in several ad libraries. We identify ﬁelds in ad requests for private user information and conﬁrm their presence in network data obtained from a tier-1 network provider. We also show that users can be tracked by a network sniffer across ad providers and by an ad provider across applications. Finally, we discuss several possible solutions to the privacy issues identiﬁed above.",
    file = ":home/drt24/Downloads/most2012ad.pdf:pdf",
    year = "2012",
    booktitle = "IEEE Mobile Security Technologies (MoST)"
}

@article{Stoica2001,
    author = "Stoica, Ion and Morris, Robert and Karger, David R. and Kaashoek, M. Frans and Balakrishnan, H.",
    publisher = "ACM",
    isbn = "1581134118",
    title = "{Chord: A scalable peer-to-peer lookup service for internet applications}",
    journal = "ACM SIGCOMM Computer Communication Review",
    abstract = "A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and ex- periments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.",
    number = "4",
    volume = "31",
    url = "http://portal.acm.org/citation.cfm?id=964723.383071",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stoica et al. - 2001 - Chord A scalable peer-to-peer lookup service for internet applications.pdf:pdf",
    year = "2001",
    pages = "149--160"
}

@article{Stoica2003,
    author = "Stoica, Ion and Morris, Robert and Liben-Nowell, David and Karger, David R. and Kaashoek, M. Frans and Dabek, Frank and Balakrishnan, Hari",
    doi = "10.1109/TNET.2002.808407",
    title = "{Chord: a scalable peer-to-peer lookup protocol for internet applications}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1180543",
    abstract = "A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.",
    issn = "1063-6692",
    number = "1",
    month = "2",
    volume = "11",
    pages = "17--32",
    file = ":auto/homes/drt24/Downloads/01180543.pdf:pdf",
    year = "2003",
    journal = "IEEE/ACM Transactions on Networking"
}

@article{Su2007,
    editor = "Krumm, John and Abowd, Gregory D and Seneviratne, Aruna and Strang, Thomas",
    author = "Su, Jing and Scott, James and Hui, Pan and Crowcroft, Jon and {De Lara}, Eyal and Diot, Christophe and Goel, Ashvin and Lim, Meng How and Upton, Eben",
    publisher = "Springer",
    doi = "10.1109/WAINA.2009.201",
    isbn = "9781424439997",
    title = "{Haggle: Seamless networking for mobile applications}",
    url = "http://www.springerlink.com/index/d28x215q552267gl.pdf",
    series = "LNCS",
    abstract = "This paper presents Haggle, an architecture for mobile devices that enables seamless network connectivity and application functionality in dynamic mobile environments. Current applications must contain significant network binding and protocol logic, which makes them inflexible to the dynamic networking environments facing mobile devices. Haggle allows separating application logic from transport bindings so that applications can be communication agnostic. Internally, the Haggle framework provides a mechanism for late-binding interfaces, names, protocols, and resources for network communication. This separation allows applications to easily utilize multiple communication modes and methods across infrastructure and infrastructure-less environments. We provide a prototype implementation of the Haggle framework and evaluate it by demonstrating support for two existing legacy applications, email and web browsing. Haggle makes it possible for these applications to seamlessly utilize mobile networking opportunities both with and without infrastructure.",
    number = "2007",
    pages = "391--408",
    volume = "4717",
    file = ":auto/homes/drt24/Downloads/fulltext.pdf:pdf",
    year = "2007",
    journal = "Lecture Notes in Computer Science"
}

@article{Systems2009,
    author = "Systems, File",
    publisher = "ACM",
    doi = "10.1145/1594204.1594206",
    title = "{Case Study GFS : Evolution on Fast-forward}",
    url = "http://portal.acm.org/citation.cfm?id=1594204.1594206",
    abstract = "A discussion between Kirk McKusick and Sean Quinlan about the origin and evolution of the Google File System",
    issn = "15427730",
    number = "7",
    pages = "1--11",
    volume = "7",
    file = ":home/drt24/Downloads/p10-case\_study.pdf:pdf",
    year = "2009",
    journal = "Queue"
}

@inproceedings{Syverson1994,
    author = "Syverson, Paul F. and van Oorschot, Paul C.",
    doi = "10.1109/RISP.1994.296595",
    title = "{On unifying some cryptographic protocol logics}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=63854 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=296595",
    abstract = "We present a logic for analyzing cryptographic protocols. This logic encompasses a unification of four of its predecessors in the BAN family of logics, namely those given in [GNYSO], [AT91], [vO93], and BAN itself [BAN89]. We also present a model-theoretic semantics with respect to which the logic is sound. The logic herein captures all of the desirable features of its predecessors and more; nonetheless, it accomplishes this with no more axioms or rules than the simplest of its predecessors.",
    pages = "14--28",
    file = ":auto/homes/drt24/Downloads/00296595.pdf:pdf",
    year = "1994",
    booktitle = "IEEE Computer Society Symposium on Research in Security and Privacy"
}

@techreport{TamJennifera,
    author = "Tam, Jennifer and Reeder, Robert W and Schechter, Stuart",
    url = "http://research.microsoft.com/pubs/131517/appauth.pdf https://research.microsoft.com/apps/pubs/default.aspx?id=131517",
    abstract = "Computer operating systems, and now websites that serve as application platforms, are increasingly adopting stricter application security models; they restrict the resources ap- plications can access to those authorized by the user. Users are asked to authorize access to these resources either when the application is installed or when previously-unauthorized resources are required. For example, Facebook requires its 400+million users to make authorization decisions whenever an application first tries to run within a user’s account. The Android mobile phone OS requires its millions of users to make application authorization decisions when downloading new applications. While the security of these users’ systems and data increasingly rests on their ability to make these au- thorization decisions, there is little research to guide those designing these application authorization experiences. We performed a laboratory study to evaluate different de- signs for disclosing the actions and resources that an applica- tion will be authorized to perform once installed. We used a within-participants design to observe thirty-three Facebook users’ ability to absorb and search information in seventeen different disclosure designs, all of which were presented in the context of a fictional Facebook application. These de- signs were chosen to proxy for designs users rely upon to- day, from platforms including Facebook, Android, OAuth, and HealthVault. Four of these designs conveyed only a set of resources to be authorized, such as the user’s contact information or friends. The other thirteen designs paired resources with different actions that could be performed on them, such as seeing contact information, changing contact information, or adding new contact information. We find that participants overwhelmingly prefer disclo- sure designs that present resources visually, using icons or pictures, and can search those containing icons most quickly. Surprisingly, we find little variance in participants’ perfor- mance on our information-absorption tasks over widely vary- ing disclosure designs. We do, however, find that partici- pants perform better when disclosures are organized by ac- tions, and followed by the various resources on which the ac- tions would be authorized, than when information is grouped by the resources.",
    institution = "Microsoft Research",
    file = ":home/drt24/Downloads/appauth.pdf:pdf;::",
    title = "{I'm Allowing What? - Disclosing the authority applications demand of users as a condition of installation}"
}

@inproceedings{Tang2012,
    author = "Tang, Yang and Ames, Phillip and Bhamidipati, Sravan and Bijlani, Ashish",
    publisher = "USENIX",
    title = "{CleanOS: Limiting mobile data exposure with idle eviction}",
    url = "http://www.cs.columbia.edu/~roxana/research/projects/cleanos/osdi2012cleanos.pdf",
    abstract = "Mobile-device theft and loss have reached gigantic proportions. Despite these threats, today’s mobile devices are saturated with sensitive information due to operating systems that never securely erase data and applications that hoard it on the vulnerable device for performance or convenience. This paper presents CleanOS, a new Android-based operating system that manages sensitive data rigorously and maintains a clean environment at all times. To do so, CleanOS leverages a key property of today’s mobile applications – the use of trusted, cloud- based services. Specifically, CleanOS identifies and tracks sensitive data in RAM and on stable storage, encrypts it with a key, and evicts that key to the cloud when the data is not in active use on the device. We call this process idle eviction of sensitive data. To implement CleanOS, we used the TaintDroid mobile taint-tracking system to identify sensitive data locations and instrumented Android’s Dalvik interpreter to securely evict that data after a specified period of non-use. Our experimental results show that CleanOS limits sensitive-data exposure drasti- cally while incurring acceptable overheads on mobile networks.",
    file = ":home/drt24/Downloads/wpid-cleanos-osdi2012.pdf:pdf",
    year = "2012",
    booktitle = "Proceedings of the USENIX Conference on Operating Systems Design and Implementation"
}

@book{Taylor1997,
    author = "Taylor, John R.",
    year = "1997",
    edition = "2",
    title = "{An introduction to error analysis}",
    isbn = "093570275X",
    publisher = "University Science Books Sausalito, California"
}

@inproceedings{Terry1994,
    author = "Terry, Douglas B. and Demers, Alan J. and Petersen, Karin and Spreitzer, Mike J. and Theimer, Marvin M. and Welch, B B",
    publisher = "IEEE Comput. Soc. Press",
    doi = "10.1109/PDIS.1994.331722",
    isbn = "0818664002",
    title = "{Session guarantees for weakly consistent replicated data}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=331722",
    abstract = "Four per-session guarantees are proposed to aid users and applications of weakly consistent replicated data: read your writes, monotonic reads, writes follow reads, and monotonic writes. The intent is to present individual applications with a view of the database that is consistent with their own actions, even if they read and write from various, potentially inconsistent servers. The guarantees can be layered on existing systems that employ a read-any/write-any replication scheme while retaining the principal benefits of such a scheme, namely high availability, simplicity, scalability, and support for disconnected operation. These session guarantees were developed in the context of the Bayou project at Xerox PARC in which we are designing and building a replicated storage system to support the needs of mobile computing users who may be only intermittently connected",
    number = "CSL-94-9",
    pages = "140--149",
    file = ":home/drt24/Downloads/00331722.pdf:pdf",
    year = "1994",
    organization = "Xerox Parc",
    booktitle = "Proceedings of 3rd International Conference on Parallel and Distributed Information Systems"
}

@article{Terry1995,
    author = "Terry, Douglas B. and Theimer, Marvin M. and Petersen, Karin and Demers, Alan J. and Spreitzer, Mike J. and Hauser, Carl H.",
    publisher = "ACM",
    doi = "10.1145/224057.224070",
    title = "{Managing Update Conflicts in Bayou, a Weakly Connected Replicated Storage System}",
    url = "http://portal.acm.org/citation.cfm?id=224070",
    journal = "ACM SIGOPS Operating Systems Review",
    number = "5",
    volume = "29",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Terry et al. - 1995 - Managing Update Conflicts in Bayou, a Weakly Connected Replicated Storage System.pdf:pdf",
    year = "1995",
    pages = "172--182"
}

@inproceedings{Terry2013,
    author = "Terry, Douglas B and Prabhakaran, Vijayan and Kotla, Ramakrishna and Balakrishnan, Mahesh and Aguilera, Marcos K and Abu-Libdeh, Hussam",
    isbn = "9781450323888",
    title = "{Consistency-Based Service Level Agreements for Cloud Storage}",
    url = "http://research.microsoft.com/en-us/people/aguilera/pileus-sosp2013.pdf",
    abstract = "Choosing a cloud storage system and specific operations for reading and writing data requires developers to make decisions that trade off consistency for availability and performance. Applications may be locked into a choice that is not ideal for all clients and changing conditions. Pileus is a replicated key-value store that allows applications to declare their consistency and latency priorities via consistency-based service level agreements (SLAs). It dynamically selects which servers to access in order to deliver the best service given the current configuration and system conditions. In application-specific SLAs, developers can request both strong and eventual consistency as well as intermediate guarantees such as read-my-writes. Evaluations running on a worldwide test bed with geo-replicated data show that the system adapts to varying client-server latencies to provide service that matches or exceeds the best static consistency choice and server selection scheme.",
    file = ":home/drt24/Downloads/pileus-sosp2013.pdf:pdf",
    year = "2013",
    keywords = "cloud computing,consistency,replication,service level agreement,storage",
    booktitle = "SOSP"
}

@techreport{Thacker2010,
    author = "Thacker, N A",
    abstract = "This document derives estimators of frequency and probability for the elimination of numerical instability when processing small samples. The analysis uses the quantitative methodology motivated in previous documents [6, 7]. In particular we show that the expectation of the mean of a Poisson sample is n + 1/2, and for a Binomial sample is (n + 1/2)/(N + 1). We argue that this is a better estimator of the underlying generator than conventional Likelihood in these cases. Some of the consequences of these results are illustrated on the ‘reference class problem’",
    year = "2010",
    number = "2009",
    file = ":home/drt24/Library/papers/Unknown/Thacker/Thacker - 2010 - Avoiding Zero and Infinity in Sample Based Algorithms Avoiding Zero and Infinity in Sample Based Algorithms.pdf:pdf",
    title = "{Avoiding Zero and Infinity in Sample Based Algorithms}"
}

@online{TheMendeleySupportTeam2011,
    author = "{The Mendeley Support Team}",
    publisher = "Mendeley Ltd.",
    title = "{Getting Started with Mendeley}",
    url = "http://www.mendeley.com",
    abstract = "A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.",
    year = "2011",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf:pdf",
    address = "London",
    keywords = "Mendeley,how-to,user manual",
    booktitle = "Mendeley Desktop",
    pages = "1--16"
}

@online{Thomas2013,
    author = "Thomas, Daniel R. and Beresford, Alastair R.",
    url = "http://www.cl.cam.ac.uk/research/dtg/nigori/",
    urldate = "2013",
    booktitle = "Computer Laboratory - Digital Technology Group",
    year = "2013",
    title = "{Nigori: Secrets in the cloud}"
}

@article{Thomas2015,
    author = "Thomas, Daniel R. and Beresford, Alastair R. and Wagner, Daniel T. and Rice, Andrew",
    journal = "Under submission",
    year = "2015",
    file = ":home/drt24/git/papers/da/securityupdates/securityupdates.pdf:pdf",
    title = "{Timeliness of security updates for Android}"
}

@article{Thompson1984,
    author = "Thompson, Ken",
    doi = "10.1145/358198.358210",
    title = "{Reflections on trusting trust}",
    url = "http://portal.acm.org/citation.cfm?doid=358198.358210",
    abstract = {I thank the ACM for this award. I can't help but feel that I am receiving this honor for timing and serendipity as much as technical merit. UNIX1 swept into popularity with an industry-wide change from central mainframes to autonomous minis. I suspect that Daniel Bob- row [1] would be here instead of me if he could not afford a PDP-10 and had had to "settle" for a PDP-11. Moreover, the current state of UNIX is the result of the labors of a large number of people. There is an old adage, "Dance with the one that brought you," which means that I should talk about UNIX. I have not worked on mainstream UNIX in many years, yet I continue to get undeserved credit for the work of others. Therefore, I am not going to talk about UNIX, but I want to thank everyone who has contributed. That brings me to Dennis Ritchie. Our collaboration has been a thing of beauty. In the ten years that we have worked together, I can recall only one case of miscoordination of work. On that occasion, I discovered that we both had written the same 20-line assembly language program. I compared the sources and was astounded to find that they matched character-for-character. The result of our work together has been far greater than the work that we each contributed. I am a programmer. On my 1040 form, that is what I put down as my occupation. As a programmer, I writeprograms. I would like to present to you the cutest program I ever wrote. I will do this in three stages and try to bring it together at the end.},
    issn = "00010782",
    number = "8",
    month = "8",
    volume = "27",
    pages = "761--763",
    file = ":auto/homes/drt24/Downloads/reflections.pdf:pdf",
    year = "1984",
    journal = "Communications of the ACM"
}

@article{Thusoo2009,
    author = "Thusoo, Ashish and Sarma, Joydeep Sen and Jain, Namit and Shao, Zheng and Chakka, Prasad and Anthony, Suresh and Liu, Hao and Wyckoff, Pete and Murthy, Raghotham",
    publisher = "VLDB Endowment",
    isbn = "0000000000000",
    title = "{Hive - A Warehousing Solution Over a Map-Reduce Framework}",
    url = "http://portal.acm.org/citation.cfm?id=1687609",
    abstract = "The size of data sets being collected and analyzed in the industry for business intelligence is growing rapidly, making traditional warehousing solutions prohibitively expensive. Hadoop 3 is a popular open-source map-reduce implementation which is being used as an alternative to store and process extremely large data sets on commodity hardware. However, the map-reduce programming model is very low level and requires developers to write custom programs which are hard to maintain and reuse.",
    issn = "21508097",
    number = "2",
    pages = "1626--1629",
    volume = "2",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thusoo et al. - 2009 - Hive - A Warehousing Solution Over a Map-Reduce Framework.pdf:pdf",
    year = "2009",
    pmid = "1687609",
    journal = "Sort"
}

@inproceedings{Tiwari,
    author = "Tiwari, V. and Malik, S. and Wolfe, A.",
    publisher = "IEEE",
    doi = "10.1109/LPE.1994.573195",
    isbn = "0-7803-1953-2",
    title = "{Compilation techniques for low energy: an overview}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=573195",
    abstract = "Recent years have witnessed a rapid growth in research activity targeted at reducing energy consumption in microprocessor based systems. However, this research has by and large not recognised the potential energy savings achievable through optimization of software running on the microprocessor. This paper presents an overview of techniques used in our work and in other recent research in this area. Several possible techniques for energy reduction through code compilation are presented. Examples with energy reduction of up to 40\% on an Intel 486DX2 based system, obtained by rewriting code, demonstrate the potential of these ideas. Several additional avenues for reducing CPU and memory system energy through code compilation are identified. The effect of traditional compilation techniques on energy reduction is discussed and some of these techniques that can be beneficial in this regard are reviewed",
    pages = "38--39",
    booktitle = "Proceedings of 1994 IEEE Symposium on Low Power Electronics"
}

@article{Tiwari1994,
    author = "Tiwari, Vivek and Malik, Sharad and Wolfe, Andrew",
    publisher = "IEEE",
    doi = "10.1109/92.335012",
    title = "{Power analysis of embedded software: a first step towards software power minimization}",
    url = "http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=335012 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=335012",
    abstract = "Embedded computer systems are characterized by the presence of a dedicated processor and the software that runs on it. Power constraints are increasingly becoming the critical component of the design specification of these systems. At present, however, power analysis tools can only be applied at the lower levels of the design-the circuit or gate level. It is either impractical or impossible to use the lower level tools to estimate the power cost of the software component of the system. This paper describes the first systematic attempt to model this power cost. A power analysis technique is developed that has been applied to two commercial microprocessors-Intel 486DX2 and Fujitsu SPARClite 934. This technique can be employed to evaluate the power cost of embedded software. This can help in verifying if a design meets its specified power constraints. Further, it can also be used to search the design space in software power optimization. Examples with power reduction of up to 40\%, obtained by rewriting code using the information provided by the instruction level power model, illustrate the potential of this idea.",
    issn = "1063-8210",
    number = "4",
    month = "12",
    volume = "2",
    pages = "437--445",
    file = "::",
    year = "1994",
    journal = "Very Large Scale Integration (VLSI) Systems, IEEE Transactions on"
}

@inproceedings{Tolvanen2006,
    author = "Tolvanen, Jarkko and Suihko, Tapio and Lipasti, Jaakko and Asokan, N",
    publisher = "IEEE",
    isbn = "0780395751",
    title = "{Remote storage for mobile devices}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1665195",
    abstract = "The ability to access remote file storage from mobile devices enables a number of new use cases for storing and sharing data. We describe the design and implementation of a Remote Storage Client framework on Symbian OS, the leading smart phone OS on the market. Our work is inspired and informed by previous work like Coda. We describe why Coda cannot be used directly in our target scenarios and environments. We then describe how we adapted the Coda concepts to suit our needs. The advanced features supported by the framework include disconnected operation with whole-file caching and immediate file access (adapting whole-file caching principle to multimedia- centric smart phones). Using this framework, we have implemented Symbian OS remote filesystems based on WebDAV and FTP.",
    pages = "1--9",
    file = ":auto/homes/drt24/Downloads/01665195.pdf:pdf",
    year = "2006",
    keywords = "Symbian OS,WebDAV,disconnected operation,remote file systems",
    booktitle = "Communication System Software and Middleware, 2006. Comsware 2006. First International Conference on"
}

@article{Tominski2009,
    author = "Tominski, Christian",
    doi = "10.1057/ivs.2009.32",
    title = "{Event-based concepts for user-driven visualization}",
    url = "http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.32",
    journal = "Information Visualization",
    issn = "1473-8716",
    number = "1",
    month = "12",
    file = "::",
    year = "2009",
    keywords = "event,user,visualization"
}

@article{Tonder2008a,
    author = "Tonder, Bradley Van and Wesson, Janet",
    title = "{Visualisation of Personal Communication Patterns Using Mobile Phones}",
    abstract = "Ambient displays are attractive, subtle visualisations of information. They are typically situated on the periphery of human perception, requiring minimal effort to be understood. The vast volume of communication facilitated by modern means of communication has led to research into methods of visualising this information to facilitate rapid understanding. These two research areas have, however, seldom been combined to include the use of ambient displays as visualisations of personal communication patterns. The research outlined in this paper addresses this issue by combining ambient displays and visualisation of personal communication patterns in a mobile context. This paper details the development of the AmbiMate system, analyses its usefulness and investigates the lessons which can be learned from its implementation in order to guide the future development of such systems.",
    pages = "260--274",
    file = "::",
    year = "2008",
    keywords = "ambient displays,personal communication patterns,visualisation",
    journal = "Ifip International Federation For Information Processing"
}

@article{Toyama:2009:CGD:1629607.1629616,
    author = "Toyama, Kentaro and Ali, Muneeb",
    publisher = "ACM",
    doi = "10.1145/1629607.1629616",
    title = "{Computing for global development}",
    url = "http://doi.acm.org/10.1145/1629607.1629616",
    year = "2009",
    abstract = "CatePoverty and the associated su erings remain a global challenge, with over a billion people surviving on less than a dollar a day. Technology, applied appropriately, can help improve their lives. Despite some clear examples of technical research playing a key role in global development, there is a question that repeatedly arises in this area: can technologies for developing regions be considered a core area of computer science research? In this note, we examine some of the arguments on both sides of this question, deliberately avoid answering the question itself (for the lack of community consensus), and provide some suggestions for the case where the answer is in the affirmative.",
    issn = "01464833",
    mendeley-tags = "ict4d",
    number = "5",
    month = "10",
    volume = "39",
    pages = "40",
    file = "::",
    address = "New York",
    keywords = "developing regions,global development,ict4d",
    journal = "ACM SIGCOMM Computer Communication Review"
}

@article{Truong2004,
    author = "Truong, Nghi and Roe, Paul and Bancroft, Peter",
    title = "{Static analysis of students' Java programs}",
    url = "http://dl.acm.org/citation.cfm?id=979968.980011",
    month = "1",
    year = "2004",
    keywords = "Java,Web,XML,online learning,static analysis,tutoring system",
    pages = "317--325"
}

@inproceedings{Truong2010,
    author = "Truong, Khai N. and Kientz, Julie A. and Sohn, Timothy and Rosenzweig, Alyssa and Fonville, Amanda and Smith, Tim",
    publisher = "ACM Press",
    doi = "10.1145/1864349.1864400",
    isbn = "9781605588438",
    title = "{The design and evaluation of a task-centered battery interface}",
    url = "http://dl.acm.org/citation.cfm?id=1864349.1864400",
    abstract = "Battery interfaces provide important feedback about how much time users can continue using their mobile devices. Based on this information, they may develop mental models of the types of activities, tasks, and applications they can use before needing to recharge. Many of today's battery interfaces tend to report energy in coarse granularities or are highly inaccurate. As a result, users may find it difficult to depend on the estimates given. We conducted a survey with 104 participants to understand how users interact with various mobile battery interfaces. Based on the survey results, we designed and prototyped a task-centered battery interface on a mobile device that shows more accurate information about how long individual and combinations of tasks with several applications can be performed. Our pilot study of eight users demonstrated that fine-grained information separated by tasks can help users be more effective with and increase their understanding of their device's battery usage.",
    year = "2010",
    month = "9",
    pages = "341",
    file = "::",
    address = "New York, New York, USA",
    keywords = "battery interface,mobile computing,ubiquitous computing",
    booktitle = "Proceedings of the 12th ACM international conference on Ubiquitous computing - Ubicomp '10"
}

@article{Truong2013,
    author = "Truong, Hien Thi Thu and Lagerspetz, Eemil and Nurmi, Petteri and Oliner, Adam J and Tarkoma, Sasu and Asokan, N and Bhattacharya, Sourav",
    title = "{The Company You Keep: Mobile Malware Infection Rates and Inexpensive Risk Indicators}",
    url = "http://arxiv.org/abs/1312.3245",
    journal = "arXiv preprint arXiv",
    eprint = "arXiv:1312.3245v1",
    file = ":home/drt24/Downloads/1312.3245.pdf:pdf",
    year = "2013",
    arxivid = "arXiv:1312.3245v1",
    archiveprefix = "arXiv",
    abstract = "There is little information from independent sources in the public domain about mobile malware infection rates. The only previous independent estimate (0.0009\%) [5], was based on indirect measurements obtained from domain name resolution traces. In this paper, we present the first independent study of malware infection rates and associated risk factors using data collected directly from over 55,000 Android devices. We find that the malware infection rates in Android devices estimated using two malware datasets (0.28\% and 0.26\%), though small, are significantly higher than the previous independent estimate. Using our datasets, we investigate how indicators extracted inexpensively from the devices correlate with malware infection. Based on the hypothesis that some application stores have a greater density of malicious applications and that advertising within applications and cross-promotional deals may act as infection vectors, we investigate whether the set of applications used on a device can serve as an indicator for infection of that device. Our analysis indicates that this alone is not an accurate indicator for pinpointing infection. However, it is a very inexpensive but surprisingly useful way for significantly narrowing down the pool of devices on which expensive monitoring and analysis mechanisms must be deployed. Using our two malware datasets we show that this indicator performs 4.8 and 4.6 times (respectively) better at identifying infected devices than the baseline of random checks. Such indicators can be used, for example, in the search for new or previously undetected malware. It is therefore a technique that can complement standard malware scanning by anti-malware tools. Our analysis also demonstrates a marginally significant difference in battery use between infected and clean devices."
}

@book{Tufte2001,
    author = "Tufte, Edward",
    publisher = "Graphics Press USA",
    isbn = "978-0961392147",
    title = "{The Visual Display of Quantitative Information}",
    edition = "2nd",
    year = "2001",
    pages = "1--190"
}

@techreport{UCAM-CL-TR-437,
    author = "Harbison, William S",
    title = "{Trusting in computer systems}",
    address = "15 JJ Thomson Avenue, Cambridge CB3 0FD, United Kingdom, phone +44 1223 763500",
    number = "UCAM-CL-TR-437",
    file = ":home/drt24/Downloads/201309201334.pdf:pdf",
    year = "1997",
    institution = "University of Cambridge, Computer Laboratory"
}

@inproceedings{Uppoor2010,
    author = "Uppoor, Sandesh and Flouris, Michail D. and Bilas, Angelos",
    isbn = "9781424483969",
    title = "{Cloud-based synchronization of distributed file system hierarchies}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613087",
    abstract = "As the number of user-managed devices continues to increase, the need for synchronizing multiple file hierarchies distributed over devices with ad hoc connectivity, is becoming a significant problem. In this paper, we propose a new approach for efficient cloud-based synchronization of an arbitrary number of distributed file system hierarchies. Our approach maintains both the advantages of peer-to-peer synchronization with the cloud-based approach that stores a master replica online. In contrast, we do not assume storage of any user’s data in the cloud, so we address the related capacity, cost, security, and privacy limitations. Finally, the proposed system performs data synchronization in a peer-to-peer manner, eliminating cost and bandwidth concerns that arise in the ”cloud master-replica” approach.",
    file = ":auto/homes/drt24/Downloads/05613087.pdf:pdf",
    year = "2010",
    keywords = "File synchronization,cloud service.,data management,distributed storage",
    booktitle = "Computing Workshops and"
}

@article{Vache2009,
    author = "Vache, Geraldine",
    doi = "10.1109/ESEM.2009.5315969",
    isbn = "978-1-4244-4842-5",
    title = "{Vulnerability analysis for a quantitative security evaluation}",
    url = "http://dl.acm.org/citation.cfm?id=1671248.1671291",
    abstract = "This paper presents the quantitative characterization of vulnerability life cycle and of exploit creation by probability distributions. This work aims at helping the production of quantitative measures of information system security considering system environment. In this paper, we focus on two environmental factors: the vulnerability life cycle; and the attacker behaviour. We look for the probability distributions and their parameters that could model quantatively these environmental factor events. Thus, to obtain precise measures, it is needed to characterize these events using real data. For that purpose, we first selected an appropriate vulnerability database by comparing the existing and available ones. We choose the open source vulnerability database. After having brought back the data we need, we evaluate quantitatively the model parameters related to the vulnerability life cycle and the attacker behaviour. In doing so, we look for specificities of vulnerability categories to define the parameterization of our quantitative security evaluation modelling more precisely.",
    issn = "1938-6451",
    pages = "526--534",
    file = ":home/drt24/Downloads/05315969.pdf:pdf",
    year = "2009",
    journal = "2009 3rd International Symposium on Empirical Software Engineering and Measurement"
}

@techreport{Vahdat2000,
    author = "Vahdat, Amin and Becker, David",
    url = "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6151\&amp;rep=rep1\&amp;type=pdf",
    abstract = "Mobile ad hoc routing protocols allow nodes with wireless adaptors to communicate with one an- other without any pre-existing network infrastructure. Existing ad hoc routing protocols, while robust to rapidly changing network topology, assume the presence of a connected path from source to destination. Given power limitations, the advent of short-range wireless networks, and the wide physical conditions over which ad hoc networks must be deployed, in some scenarios it is likely that this assumption is invalid. In this work, we develop techniques to deliver messages in the case where there is never a connected path from source to destination or when a network partition exists at the time a message is originated. To this end, we introduce Epidemic Routing, where random pair-wise exchanges of mes- sages among mobile hosts ensure eventual message delivery. The goals of Epidemic Routing are to: i) maximize message delivery rate, ii) minimize message latency, and iii) minimize the total resources consumed in message delivery. Through an implementation in the Monarch simulator, we show that Epidemic Routing achieves eventual delivery of 100\% of messages with reasonable aggregate resource consumption in a number of interesting scenarios.",
    year = "2000",
    file = ":home/drt24/Downloads/10.1.1.34.6151.pdf:pdf",
    title = "{Epidemic routing for partially connected ad hoc networks}"
}

@inproceedings{Vallina-rodriguez2010,
    author = "Vallina-rodriguez, Narseo and Hui, Pan and Crowcroft, Jon and Rice, Andrew C.",
    isbn = "9781450301978",
    title = "{Exhausting Battery Statistics}",
    abstract = "Despite the advances in battery technologies, mobile phones still suffer from severe energy limitations. Modern handsets are rich devices that can support multitasking thanks to their high processing power and provide a wide range of resources such as sensors and network interfaces with different energy demands. There have been multiple attempts to characterise those energy demands; both to save or to allocate energy to the applications on the handset. However, there is still little understanding on how the interdependencies between resources (interdependencies caused by the appli- cations and users’ behaviour) affect the battery life. In this pa- per, we demonstrate the necessity of considering all those dynam- ics in order to characterise the energy demands of the system ac- curately. These results indicate that simple algorithmic and rule- based scheduling techniques [7] are not the most appropriate way of managing the resources since their usage can be affected by con- textual factors, making necessary to find customised solutions that consider each user’s behaviour and handset features.",
    mendeley-tags = "Measurement,human factors",
    number = "February",
    pages = "9--14",
    file = ":home/drt24/Library/papers/MobiHeld/Vallina-rodriguez et al/Vallina-rodriguez et al. - 2010 - Exhausting Battery Statistics.pdf:pdf",
    year = "2010",
    keywords = "Measurement,Mobile Usage,Usage patterns,human factors,resources demand,smartphone usage,user behaviour",
    booktitle = "MobiHeld"
}

@inproceedings{Vallina-rodriguez2011,
    author = "Vallina-rodriguez, Narseo and Crowcroft, Jon",
    publisher = "ACM Press",
    doi = "10.1145/1999916.1999926",
    isbn = "9781450307406",
    title = "{ErdOS : Achieving Energy Savings in Mobile OS}",
    url = "http://www.uniroma2.it/didattica/infomob/deposito/ErdOS.pdf",
    series = "MobiArch '11",
    abstract = "The integration of multiple hardware components available in current smartphones improves their functionality but reduces their battery life to few hours of operation. Despite the positive improvements achieved by hardware and operating system vendors to make mobile platforms more energy efficient at various levels, we believe that an efficient power management in mobile devices is compromised by strict layering of the system caused by complex mobile business models that mitigates against cross-layering optimisations. However, there is a lot of room for improvement in the operating system. This paper presents ErdOS, a user-centered energy-aware operating system that extends the battery life of mobile handsets by managing resources proactively and by exploiting opportunistic access to resources in nearby devices using social connections between users.",
    pages = "37--42",
    year = "2011",
    keywords = "energy awareness,mobile computing,mobile social os,operating systems,opportunistic computing,re,resources sharing,sources management",
    booktitle = "MobiArch '11 Proceedings of the sixth international workshop on MobiArch"
}

@article{Vasudevan2011,
    author = "Vasudevan, Vijay and Andersen, David G. and Kaminsky, Michael and Franklin, Jason and Kozuch, Michael A. and Moraru, Iulian and Pillai, Padmanabhan and Tan, Lawrence",
    doi = "10.1145/1945023.1945029",
    title = "{Challenges and opportunities for efficient computing with FAWN}",
    url = "http://dl.acm.org/citation.cfm?id=1945023.1945029",
    abstract = "This paper presents the architecture and motivation for a clusterbased, many-core computing architecture for energy-efficient, dataintensive computing. FAWN, a Fast Array of Wimpy Nodes, consists of a large number of slower but efficient nodes coupled with low-power storage. We present the computing trends that motivate a FAWN-like approach, for CPU, memory, and storage. We follow with a set of microbenchmarks to explore under what workloads these FAWN nodes perform well (or perform poorly), and briefly examine scenarios in which both code and algorithms may need to be re-designed or optimized to perform well on an efficient platform. We conclude with an outline of the longer-term implications of FAWN that lead us to select a tightly integrated stacked chip and-memory architecture for future FAWN development.",
    issn = "01635980",
    number = "1",
    month = "2",
    volume = "45",
    pages = "34",
    file = "::",
    year = "2011",
    keywords = "cluster computing,design,energy efficiency,flash,measurement,performance",
    journal = "ACM SIGOPS Operating Systems Review"
}

@article{Verkasalo2008,
    author = "Verkasalo, Hannu",
    publisher = "Springer London",
    doi = "10.1007/s00779-008-0197-0",
    title = "{Contextual patterns in mobile service usage}",
    url = "http://www.springerlink.com/content/a10478874476771t/",
    abstract = "Mobile services differ from other services because of their temporal and spatial attributes. Mobile services additionally differ from each other in their value-added to the end-user. Some services—such as emailing and voice—are more business oriented. On the other hand, various free-time oriented services are provided in new smartphones, such as imaging and music playback. The present paper studies how mobile services are used in different contexts. For this, the paper develops a specialized algorithm that can be used with handset-based usage data acquired straight from end-users in an established panel study process. Educated guesses can be drawn on the user context based on the developed algorithm. In the present exercise usage contexts were divided into home, office and “on the move”. The algorithm is used with exemplary data from Finland and the UK covering 324 consumers in 2006. More than 70\% of contextual use cases are correctly classified based on raw data. According to exemplary results particularly multimedia services are used “on the move”, whereas legacy mobile services experience more evenly distributed usage across all contexts. The algorithm that identifies context based on raw data provides a new angle to mobile end-user research. In the future, the accuracy of the algorithm will be improved with the integration of seamless cell-id logging and GPS data.",
    issn = "1617-4909",
    number = "5",
    month = "3",
    volume = "13",
    pages = "331--342",
    file = "::",
    year = "2008",
    keywords = "Computer Science",
    journal = "Personal and Ubiquitous Computing"
}

@article{Vermeesch2005,
    author = "Vermeesch, Pieter",
    doi = "10.1029/2004JB003479",
    title = "{Statistical uncertainty associated with histograms in the Earth sciences}",
    url = "http://www.agu.org/pubs/crossref/2005/2004JB003479.shtml",
    journal = "Journal of Geophysical Research",
    issn = "0148-0227",
    number = "B2",
    volume = "110",
    file = ":home/drt24/Library/papers/Journal of Geophysical Research/Vermeesch/Vermeesch - 2005 - Statistical uncertainty associated with histograms in the Earth sciences.pdf:pdf",
    year = "2005",
    pages = "1--15"
}

@article{Vidas2011,
    author = "Vidas, Timothy and Cylab, E C E and Votipka, Daniel and Cylab, I N I and Christin, Nicolas",
    publisher = "USENIX Association",
    title = "{All Your Droid Are Belong To Us : A Survey of Current Android Attacks}",
    url = "http://www.usenix.org/event/woot/tech/final_files/Vidas.pdf",
    series = "WOOT",
    journal = "Proceedings of the 5th USENIX conference on Offensive technologies",
    number = "1",
    abstract = "In the past few years, mobile devices (smartphones, PDAs) have seen both their computational power and their data connectivity rise to a level nearly equivalent to that available on small desktop computers, while becoming ubiquitous. On the downside, these mobile devices are now an extremely attractive target for large-scale security attacks. Mobile device middleware is thus experiencing an increased focus on attempts to mitigate potential security compromises. In particular, Android incorporates by design many well-known security features such as privilege separation. The Android security model also creates several new security sensitive concepts such as Android's application permission system and the unmoderated Android market. In this paper we look to Android as a specific instance of mobile computing. We first discuss the Android security model and some potential weaknesses of the model. We then provide a taxonomy of attacks to the platform demonstrated by real attacks that in the end guarantee privileged access to the device. Where possible, we also propose mitigations for the identified vulnerabilities.",
    institution = "USENIX Association",
    volume = "256",
    file = ":home/drt24/Downloads/Vidas.pdf:pdf",
    year = "2011",
    pages = "10"
}

@article{Viega2012,
    author = "Viega, John",
    doi = "10.1109/MSP.2012.157",
    title = "{Ten Years On, How Are We Doing? (Spoiler Alert: We Have No Clue)}",
    url = "http://ieeexplore.ieee.org/ielx5/8013/6375711/06375718.pdf?tp=\&arnumber=6375718\&isnumber=6375711$\backslash$nhttp://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6375718",
    abstract = "As this magazine closes out its 10th anniversary year, its editor in chief gives the industry a report card for the past decade, both to see how well it did and to set some goals for the next 10 years.",
    issn = "1540-7993",
    number = "December",
    pages = "13 --16",
    volume = "10",
    file = ":home/drt24/Downloads/06375718.pdf:pdf",
    year = "2012",
    journal = "IEEE Security Privacy"
}

@article{Viegas2008,
    author = "Viegas, Fernanda B. and Wattenberg, Martin and McKeon, Matt and Ham, Frank Van and Kriss, Jesse",
    publisher = "Ieee",
    doi = "10.1109/HICSS.2008.188",
    isbn = "0-7695-3075-8",
    title = "{Harry Potter and the Meat-Filled Freezer: A Case Study of Spontaneous Usage  of Visualization Tools}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4438862",
    journal = "Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)",
    issn = "1530-1605",
    month = "1",
    file = "::",
    year = "2008",
    pages = "159--159"
}

@article{Viennot2014,
    author = "Viennot, Nicolas and Garcia, Edward and Nieh, Jason",
    doi = "10.1145/2591971.2592003",
    isbn = "9781450327893",
    title = "{A measurement study of google play}",
    url = "http://dl.acm.org/citation.cfm?id=2592003",
    abstract = "Although millions of users download and use third-party Android applications from the Google Play store, little in- formation is known on an aggregated level about these ap- plications. We have built PlayDrone, the first scalable Google Play store crawler, and used it to index and analyze over 1,100,000 applications in the Google Play store on a daily basis, the largest such index of Android applications. PlayDrone leverages various hacking techniques to circum- vent Google’s roadblocks for indexing Google Play store con- tent, and makes proprietary application sources available, including source code for over 880,000 free applications. We demonstrate the usefulness of PlayDrone in decompiling and analyzing application content by exploring four pre- viously unaddressed issues: the characterization of Google Play application content at large scale and its evolution over time, library usage in applications and its impact on appli- cation portability, duplicative application content in Google Play, and the ineffectiveness of OAuth and related service authentication mechanisms resulting in malicious users be- ing able to easily gain unauthorized access to user data and resources on Amazon Web Services and Facebook.",
    file = ":home/drt24/Downloads/p221-viennot.pdf:pdf",
    year = "2014",
    keywords = "android,authentication,clone detection,decompilation,google play,mobile computing,oauth,security",
    journal = "SIGMETRICS"
}

@article{Vogt2008,
    author = "Vogt, Henrik and Aasbrenn, Martin",
    title = "{The Writing on the wall}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/21430295",
    journal = "Tidsskrift for den Norske l\ae geforening : tidsskrift for praktisk medicin, ny r\ae kke",
    issn = "0807-7096",
    number = "21",
    month = "11",
    volume = "128",
    file = "::",
    year = "2008",
    keywords = "Education,Educational Technology,Humans,Learning,Medical,Medical: methods,Medical: standards,Questionnaires,Students,Teaching,Teaching: methods,Teaching: standards",
    pmid = "19096474",
    pages = "2473--4"
}

@article{VonBidder2003,
    author = "von Bidder, a. and Weiler, N.",
    publisher = "IEEE Comput. Soc",
    doi = "10.1109/ENABL.2003.1231416",
    isbn = "0-7695-1963-6",
    title = "{Key Exchange (KX) - a next generation protocol to synchronise PGP Keyservers}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1231416",
    abstract = "In the Internet, securing email has always been an important issue. Various standards and products have been created. One of the most successful standards is OpenPGP [4], which uses public key cryptography (RSA [13] and others) and is implemented in systems like Pretty Good Privacy [15], GNU Privacy Guard [8], Hushmail [1] and others. A well-known difficulty with the use of public key crypto- graphic systems is the verification and distribution of the public keys. OpenPGP solves the problem of verifying the authenticity of a public key by having users certify each others keys, building a “Web of Trust” [5] by bundling these key certificates with each users public key. Therefore, adding a new public key and updating an existing public key (or replacing it by a new version) are the two most important operations of any PGP public key repository. To allow easy distribution of PGP public keys, the OpenPGP community established a network of open access public keyservers [7], allowing users of OpenPGP software to freely exchange public keys. The nodes of this keyserver network synchronise their database by exchanging new public keys and key updates amongst each other, virtually building one global key database. At the mo- ment, this synchronisation is done with an inefficient and ineffec- tive email based protocol. This paper describes the implementation of an alternative protocol – KX – on the popular pksd keyserver [6], based on direct TCP connections between the keyservers and unambiguous identifiers for every key update or newkey.With the dropping of the dependency on a working mail system and the improved fault mechanisms, KX is a lightweight alternative in terms of used network, disk and CPU resources.",
    pages = "249--254",
    file = ":home/drt24/Downloads/01231416.pdf:pdf",
    year = "2003",
    keywords = "E-Mail Security,Keyserver,OpenPGP,Secure Synchronisation Protocol",
    journal = "WET ICE"
}

@techreport{Wagner2002,
    author = "Wagner, David and Tribble, Dean",
    url = "http://combexin.temp.veriohosting.com/papers/darpa-review/security-review.pdf",
    booktitle = "Online at: http://www. combex. com/papers/darpa-review",
    year = "2002",
    file = ":auto/homes/drt24/Downloads/security-review.ps:ps",
    title = "{A Security Analysis of the Combex DarpaBrowser Architecture}"
}

@inproceedings{Wagner2009,
    author = "Wagner, Daniel T and Rice, Andrew and Beresford, Alastair R",
    title = "{Device Analyzer}",
    booktitle = "HOTMOBILE 2011 12th Workshop on Mobile Computing Systems and Applications",
    number = "4",
    volume = "10",
    file = ":home/drt24/Downloads/wagner-daabstract (1).pdf:pdf",
    year = "2009",
    pages = "505445"
}

@inproceedings{Wagner2013,
    author = "Wagner, Daniel T. and Rice, Andrew and Beresford, Alastair R.",
    publisher = "ACM",
    title = "{Device Analyzer: Large-scale mobile data collection}",
    url = "http://www.sigmetrics.org/sigmetrics2013/bigdataanalytics/abstracts2013/bdaw2013_submission_5.pdf",
    abstract = "We collected usage information from 12,500 Android devices in the wild over the course of nearly 2 years. Our dataset contains 53 billion data points from 894 models of devices running 687 ver- sions of Android. Processing the collected data presents a number of challenges ranging from scalability to consistency and privacy considerations. We present our system architecture for collection and analysis of this highly-distributed dataset, discuss how our sys- tem can reliably collect time-series data in the presence of unreli- able timing information, and discuss issues and lessons learned that we believe apply to many other big data collection projects.",
    year = "2013",
    month = "6",
    file = ":home/drt24/Downloads/bdaw2013\_submission\_5 (1).pdf:pdf",
    address = "Pittsburgh, PA",
    booktitle = "Sigmetrics, Big Data Workshop"
}

@article{Wagner2013a,
    author = "Wagner, Daniel T. and Rice, Andrew and Beresford, Alastair R.",
    title = "{Device Analyzer: Understanding smartphone usage}",
    abstract = "We describe Device Analyzer, a robust data collection tool which is able to reliably collect information on Android smartphone usage from an open community of contributors.We collected the largest,most detailed dataset of An- droid phone use publicly available to date. In this paper we systematically eval- uate smartphones as a platform for mobile ubiquitous computing by quantifying access to critical resources in the wild. Our analysis of the dataset demonstrates considerable diversity in behaviour between users but also over time.We further demonstrate the value of handset-centric data collection by presenting case-study analyses of human mobility, interaction patterns, and energy management and identify notable differences between our results and those found by other studies.",
    pages = "1--12",
    file = ":home/drt24/Downloads/wagner-understanding (7).pdf:pdf",
    year = "2013",
    journal = "10th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services"
}

@incollection{Wainer2009,
    author = "Wainer, Howard",
    chapter = "1",
    publisher = "Princeton University Press",
    title = "{The most dangerous equation}",
    booktitle = "Picturing the uncertain world",
    file = "::",
    year = "2009",
    pages = "5--20"
}

@misc{Wallach2005,
    author = "Wallach, Hanna M",
    year = "2005",
    file = ":home/drt24/Library/papers/Unknown/Wallach/Wallach - 2005 - Introduction to Gaussian Process Regression.pdf:pdf",
    title = "{Introduction to Gaussian Process Regression}"
}

@article{Wallach2011,
    author = "Wallach, Dan",
    journal = "Rice University",
    year = "2011",
    pages = "1--11",
    file = ":home/drt24/Downloads/smartphone-security.pdf:pdf",
    title = "{Smartphone Security: Trends and Predictions}"
}

@article{Walny2011,
    author = "Walny, Jagoda and Carpendale, Sheelagh and Riche, Nathalie Henry and Venolia, Gina and Fawcett, Philip",
    doi = "10.1109/TVCG.2011.251",
    title = "{Visual thinking in action: visualizations as used on whiteboards.}",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/22034372",
    abstract = "While it is still most common for information visualization researchers to develop new visualizations from a data- or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.",
    issn = "1077-2626",
    number = "12",
    month = "12",
    volume = "17",
    pages = "2508--17",
    file = "::",
    year = "2011",
    pmid = "22034372",
    journal = "IEEE transactions on visualization and computer graphics"
}

@inproceedings{Wang2009,
    author = "Wang, Le and Manner, Jukka",
    publisher = "IEEE",
    doi = "10.1109/CYBERC.2009.5342172",
    isbn = "978-1-4244-5218-7",
    title = "{Evaluation of data compression for energy-aware communication in mobile networks}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5342172 http://www.mendeley.com/share/viewDocument/webLibrary/3177171_4374515665:/1329994836/d732d0f0c0bfe35eff243583430e7ecf4d785ef9/",
    abstract = "The development of ICT following Moore's Law has resulted in a situation where mobile users are able to make use of a wealth of versatile services. Yet, battery and electronics technology has not followed this development as well, which has resulted in a situation where a mobile user's battery can only enable a few hours of active use. Therefore, we need to focus increasingly on energy efficient wireless and mobile communication to reduce energy consumption, but also to cut down greenhouse emissions and improve business competitiveness. Due to significant energy consumption of transmitting data over wireless networks, data compression techniques are one simple way to trade the overhead of compression for less communication energy. This paper investigates the usages of data compression to reduce the energy consumption in a modern hand-held device. By conducting various experiments, we analyze content-aware compression schemes that can reduce energy consumption significantly. Yet, blind or careless use of compression results in a huge energy loss. We also discuss the deployment issues of data compression.",
    mendeley-tags = "compression,energy,measure,mobile,network,power",
    month = "10",
    pages = "69--76",
    file = "::",
    year = "2009",
    keywords = "compression,energy,measure,mobile,network,power",
    booktitle = "2009 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery"
}

@inproceedings{Wang2009b,
    author = "Wang, Le and Manner, Jukka",
    publisher = "IEEE",
    doi = "10.1109/CYBERC.2009.5342172",
    isbn = "978-1-4244-5218-7",
    title = "{Evaluation of data compression for energy-aware communication in mobile networks}",
    url = "http://www.mendeley.com/share/viewDocument/webLibrary/3177171_4374515665:/1329994836/d732d0f0c0bfe35eff243583430e7ecf4d785ef9/",
    booktitle = "2009 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery",
    month = "10",
    year = "2009",
    pages = "69--76"
}

@article{Wang2013,
    author = "Wang, Rui and Xing, Luyi and Wang, XiaoFeng and Chen, Shuo",
    isbn = "9781450324779",
    title = "{Unauthorized Origin Crossing on Mobile Platforms: Threats and Mitigation}",
    url = "http://www.charlesneedham.com/pubs/200406/ccs127-wang.pdf",
    abstract = "With the progress in mobile computing, web services are increasingly delivered to their users through mobile apps, instead of web browsers. However, unlike the browser, which enforces origin-based security policies to mediate the interactions between the web content from different sources, today’s mobile OSes do not have a comparable security mechanism to control the cross-origin communications between apps, as well as those between an app and the web. As a result, a mobile user’s sensitive web resources could be exposed to the harms from a malicious origin. In this paper, we report the first systematic study on this mobile cross-origin risk. Our study inspects the main cross-origin channels on Android and iOS, including intent, scheme and web-accessing utility classes, and further analyzes the ways popular web services (e.g., Facebook, Dropbox, etc.) and their apps utilize those channels to serve other apps. The research shows that lack of origin-based protection opens the door to a wide spectrum of cross-origin attacks. These attacks are unique to mobile platforms, and their consequences are serious: for example, using carefully designed techniques for mobile cross-site scripting and request forgery, an unauthorized party can obtain a mobile user’s Facebook/Dropbox authentication credentials and record her text input. We report our findings to related software vendors, who all acknowledged their importance. To address this threat, we designed an origin-based protection mechanism, called Morbs, for mobile OSes. Morbs labels every message with its origin information, lets developers easily specify security policies, and enforce the policies on the mobile channels based on origins. Our evaluation demonstrates the effectiveness of our new technique in defeating unauthorized origin crossing, its efficiency and the convenience for the developers to use such protection. Categories",
    file = ":home/drt24/Downloads/ccs127-wang.pdf:pdf",
    year = "2013",
    journal = "CCS"
}

@article{Wang2013a,
    author = "Wang, Tielei and Lu, K and Lu, Long and Chung, Simon and Lee, Wenke",
    isbn = "9781931971034",
    title = "{Jekyll on iOS: when benign apps become evil}",
    url = "https://www.usenix.org/system/files/conference/usenixsecurity13/sec13-paper_wang-updated-8-23-13.pdf",
    abstract = "Apple adopts the mandatory app review and code sign- ing mechanisms to ensure that only approved apps can run on iOS devices. In this paper, we present a novel attack method that fundamentally defeats both mechanisms. Our method allows attackers to reliably hide ma- licious behavior that would otherwise get their app rejected by the Apple review process. Once the app passes the review and is installed on an end user’s device, it can be instructed to carry out the intended attacks. The key idea is to make the apps remotely exploitable and subsequently introduce malicious control flows by rearranging signed code. Since the new control flows do not exist during the app review process, such apps, namely Jekyll apps, can stay undetected when reviewed and easily obtain Apple’s approval. We implemented a proof-of-concept Jekyll app and successfully published it in App Store. We remotely launched the attacks on a controlled group of devices that installed the app. The result shows that, despite run- ning inside the iOS sandbox, Jekyll app can successfully perform many malicious tasks, such as stealthily posting tweets, taking photos, stealing device identity information, sending email and SMS, attacking other apps, and even exploiting kernel. vulnerabilities",
    pages = "559--572",
    file = ":home/drt24/Downloads/sec13-paper\_wang-updated-8-23-13.pdf:pdf",
    year = "2013",
    journal = "Proceedings of the 22nd USENIX Security Symposium"
}

@article{Wash2010,
    author = "Wash, Rick",
    publisher = "ACM Press",
    doi = "10.1145/1837110.1837125",
    isbn = "9781450302647",
    title = "{Folk models of home computer security}",
    url = "http://portal.acm.org/citation.cfm?doid=1837110.1837125",
    abstract = "Home computer systems are insecure because they are administered by untrained users. The rise of botnets has amplified this problem; attackers compromise these computers, aggregate them, and use the resulting network to attack third parties. Despite a large security industry that provides software and advice, home computer users remain vulnerable. I identify eight ‘folk models’ of security threats that are used by home computer users to decide what security software to use, and which expert security advice to follow: four conceptualizations of ‘viruses’ and other malware, and four conceptualizations of ‘hackers’ that break into computers. I illustrate how these models are used to justify ignoring expert security advice. Finally, I describe one reason why botnets are so difficult to eliminate: they cleverly take advantage of gaps in these models so thatmany home computer users do not take steps to protect against them.",
    year = "2010",
    pages = "1----16",
    file = ":home/drt24/Downloads/rwash-homesec-soups10-final.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "folk models,home security,mental models",
    journal = "Proceedings of the Sixth Symposium on Usable Privacy and Security - SOUPS '10"
}

@inproceedings{Watson2007,
    author = "Watson, RNM",
    title = "{Exploiting concurrency vulnerabilities in system call wrappers}",
    url = "http://static.usenix.org/events/woot07/tech/full_papers/watson/watson.pdf",
    abstract = "System call interposition allows the kernel security model to be extended. However, when combined with current operating systems, it is open to concurrency vulnerabilities leading to privilege escalation and audit bypass. We discuss the theory and practice of system call wrapper concurrency vulnerabilities, and demonstrate exploit tech- niques against GSWTK, Systrace, and CerbNG.",
    file = ":home/drt24/Downloads/2007usenixwoot-exploitingconcurrency.pdf:pdf",
    year = "2007",
    booktitle = "USENIX Workshop on Offensive Technologies"
}

@inproceedings{Watson2010,
    author = "Watson, Robert N. M. and Anderson, Jonathan and Kennaway, Kris and Laurie, Ben",
    publisher = "USENIX Association",
    title = "{Capsicum: practical capabilities for UNIX}",
    url = "http://www.usenix.org/events/sec10/tech/full_papers/Watson.pdf",
    series = "USENIX Security'10",
    abstract = "Capsicum is a lightweight operating system capabil- ity and sandbox framework planned for inclusion in FreeBSD 9. Capsicum extends, rather than replaces, UNIX APIs, providing newkernel primitives (sandboxed capability mode and capabilities) and a userspace sand- box API. These tools support compartmentalisation of monolithic UNIX applications into logical applications, an increasingly common goal supported poorly by dis- cretionary and mandatory access control. We demon- strate our approach by adapting core FreeBSD utilities and Googles Chromium web browser to use Capsicum primitives, and compare the complexity and robustness of Capsicum with other sandboxing techniques.",
    issn = "03601315",
    number = "2",
    month = "8",
    volume = "46",
    pages = "29--46",
    file = ":home/drt24/Downloads/Watson.pdf:pdf",
    year = "2010",
    booktitle = "USENIX Security Symposium"
}

@article{Weaver,
    author = "Weaver, C.",
    publisher = "Ieee",
    doi = "10.1109/INFVIS.2004.12",
    isbn = "0-7803-8779-3",
    title = "{Building Highly-Coordinated Visualizations in Improvise}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1382904",
    journal = "IEEE Symposium on Information Visualization",
    file = "::",
    keywords = "coordinated queries,coordination,exploratory visual-,ization,multiple views,visual abstraction language",
    pages = "159--166"
}

@article{Weitzner2008,
    author = "Weitzner, Daniel J. and Abelson, Harold and Berners-Lee, Tim and Feigenbaum, Joan and Hendler, James and Sussman, Gerald Jay",
    doi = "10.1145/1349026.1349043",
    title = "{Information accountability}",
    url = "http://dl.acm.org/ft_gateway.cfm?id=1349043\&type=html",
    abstract = "With access control and encryption no longer capable of protecting privacy, laws and systems are needed that hold people accountable for the misuse of personal information, whether public or secret.",
    issn = "00010782",
    number = "6",
    month = "6",
    volume = "51",
    pages = "82--87",
    file = ":home/drt24/Downloads/p82-weitzner.pdf:pdf",
    year = "2008",
    journal = "Communications of the ACM"
}

@inproceedings{Wernke2012,
    author = "Wernke, Marius and Durr, Frank and Rothermel, Kurt",
    publisher = "IEEE",
    title = "{PShare: Position sharing for location privacy based on multi-secret sharing}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6199862",
    abstract = "Location-based applications such as Facebook Places, Foursquare, or Loopt attract millions of users by implementing point of interest finders, friend finders, geosocial networking, etc. Typically, these applications act as clients to a location service such as Google Latitude or Yahoo Fire Eagle, which manage mobile object positions and ensure the scalability to provide various clients with mobile object positions. However, exposing precise user positions raises user privacy concerns, especially if location service providers are not fully trusted, and private position information could be “lost”, leaked, stolen, etc. To enable the secure management of private user positions on non-trusted location servers (LSs), we present novel position sharing approaches based on the concept of multi-secret sharing. Our approaches split up a precise user position into position shares, which are distributed to different LSs of different providers such that a compromised provider only reveals user positions with degraded precision. On the other hand, clients can combine several shares queried from different LSs to increase their provided precision without the need to store precise information at a single LS. We propose two position sharing approaches: PShare-SLM is the first position sharing approach presented so far for symbolic location models. For geometric location models, we present PShare-GLM, which improves existing geometric position sharing approaches [1] by considering continuous position updates and by increasing the robustness against various attacks.",
    month = "3",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wernke, Durr, Rothermel - 2012 - PShare Position sharing for location privacy based on multi-secret sharing.pdf:pdf",
    year = "2012",
    booktitle = "2012 IEEE International Conference on Pervasive Computing and Communications",
    pages = "153--161"
}

@phdthesis{Whitehouse2011,
    author = "Whitehouse, Richard and Scott, Malcolm",
    school = "University of Cambridge",
    year = "2011",
    file = ":home/drt24/Library/papers/Unknown/Whitehouse, Scott/Whitehouse, Scott - 2011 - Implementation of Data Link Layer Protocols for a Network Simulator Project Title.pdf:pdf",
    title = "{Implementation of Data Link Layer Protocols for a Network Simulator Project Title :}"
}

@inproceedings{Whitten1999,
    editor = "Cranor, L and Simson, G",
    author = "Whitten, A and Tygar, JD",
    publisher = "O'Reilly",
    title = "{Why Johnny Can't Encrypt}",
    url = "http://www.doug-tygar.com/papers/Why_Johnny_Cant_Encrypt/OReilly.pdf",
    abstract = "User errors cause or contribute to most computer security failures, yet user interfaces for security still tend to be clumsy, confusing, or near nonexistent. Is this simply because of a failure to apply standard user interface design techniques to security? We argue that, on the contrary, effective security requires a different usability standard, and that it will not be achieved through the user interface design techniques appropriate to other types of consumer software.1 To test this hypothesis, we performed a case study of a security program that does have a good user interface by general standards: PGP 5.0. Our case study used a cognitive walkthrough analysis together with a laboratory user test to evaluate whether PGP 5.0 can be used successfully by cryptography novices to achieve effective electronic mail security. The analysis found a number of user interface design flaws that may contribute to security failures, and the user test demonstrated that when our test participants were given 90 minutes in which to sign and encrypt a message using PGP 5.0, the majority of them were unable to do so successfully. We conclude that PGP 5.0 is not usable enough to provide effective security for most computer users, despite its attractive graphical user interface, supporting our hypothesis that user interface design for effective security remains an open problem. We close with a brief description of our continuing work on the development and application of user interface design principles and techniques for security.",
    year = "1999",
    number = "October",
    volume = "1999",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whitten, Tygar - 2005 - Why Johnny Can ’ t Encrypt.pdf:pdf",
    address = "Washington, D.C.",
    booktitle = "USENIX Security Symposium",
    pages = "679--702"
}

@article{Whitten2005,
    editor = "Cranor, L and Simson, G",
    author = "Whitten, A and Tygar, JD",
    publisher = "O'Reilly",
    title = "{Why Johnny Can’t Encrypt}",
    journal = "USENIX Security Symposium",
    abstract = "U ER ERRORS CAUSE OR CONTRIBUTE TO MOST COMPUTER SECURITY FAILURES, yet user interfaces for security still tend to be clumsy, confusing, or near nonexistent. Is this simply because of a failure to apply standard user interface design techniques to security? We argue that, on the contrary, effective security requires a different usability standard, and that it will not be achieved through the user interface design techniques appropriate to other types of consumer software.1 To test this hypothesis, we performed a case study of a security program that does have a good user interface by general standards: PGP 5.0. Our case study used a cognitive walkthrough analysis together with a laboratory user test to evaluate whether PGP 5.0 can be used successfully by cryptography novices to achieve effective electronic mail security. The analysis found a number of user interface design flaws that may contribute to security failures, and the user test demonstrated that when our test participants were given 90 minutes in which to sign and encrypt a message using PGP 5.0, the majority of them were unable to do so successfully. We conclude that PGP 5.0 is not usable enough to provide effective security for most computer users, despite its attractive graphical user interface, supporting our hypothesis that user interface design for effective security remains an open problem. We close with a brief description of our continuing work on the development and application of user interface design principles and techniques for security.",
    number = "October",
    volume = "1999",
    url = "http://www.doug-tygar.com/papers/Why_Johnny_Cant_Encrypt/OReilly.pdf",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whitten, Tygar - 2005 - Why Johnny Can ’ t Encrypt.pdf:pdf",
    year = "2005",
    pages = "679--702"
}

@inproceedings{Wiese2011,
    author = "Wiese, Jason and Kelley, Patrick Gage and Cranor, Lorrie Faith and Dabbish, Laura and Hong, Jason I. and Zimmerman, John",
    publisher = "ACM Press",
    doi = "10.1145/2030112.2030140",
    isbn = "9781450306300",
    title = "{Are you close with me? are you nearby?: investigating social groups, closeness, and willingness to share}",
    url = "http://dl.acm.org/citation.cfm?id=2030112.2030140",
    abstract = "As ubiquitous computing becomes increasingly mobile and social, personal information sharing will likely increase in frequency, the variety of friends to share with, and range of information that can be shared. Past work has identified that whom you share with is important for choosing whether or not to share, but little work has explored which features of interpersonal relationships influence sharing. We present the results of a study of 42 participants, who self-report aspects of their relationships with 70 of their friends, including frequency of collocation and communication, closeness, and social group. Participants rated their willingness to share in 21 different scenarios based on information a UbiComp system could provide. Our findings show that (a) self-reported closeness is the strongest indicator of willingness to share, (b) individuals are more likely to share in scenarios with common information (e.g. we are within one mile of each other) than other kinds of scenarios (e.g. my location wherever I am), and (c) frequency of communication predicts both closeness and willingness to share better than frequency of collocation.",
    year = "2011",
    month = "9",
    pages = "197",
    file = "::",
    address = "New York, New York, USA",
    keywords = "privacy,relationships,social networking,tie strength",
    booktitle = "Proceedings of the 13th international conference on Ubiquitous computing - UbiComp '11"
}

@inproceedings{Wilcox-O'Hearn2008,
    author = "Wilcox-O'Hearn, Zooko and Warner, Brian",
    publisher = "ACM",
    isbn = "9781605582993",
    title = "{Tahoe: the least-authority filesystem}",
    url = "http://dl.acm.org/citation.cfm?id=1456474",
    abstract = "Tahoe is a system for secure, distributed storage. It uses capabilities for access control, cryptography for confidentiality and integrity, and erasure coding for fault-tolerance. It has been deployed in a commercial backup service and is currently operational. The implementation is Open Source.",
    file = ":home/drt24/Downloads/524.pdf:pdf",
    year = "2008",
    keywords = "capabilities,fault-tolerance,open source,peer-to-peer",
    booktitle = "StorageSS"
}

@inproceedings{Wilensky2003,
    author = "Kang, Brent ByungHoon and Wilensky, Robert and Kubiatowicz, John",
    publisher = "IEEE",
    doi = "10.1109/ICDCS.2003.1203518",
    isbn = "0769519202",
    title = "{The hash history approach for reconciling mutual inconsistency}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1203518",
    abstract = "We introduce the hash history mechanism for capturing dependencies among distributed replicas. Hash histories, consisting of a directed graph of version hashes, are in- dependent of the number of active nodes but dependent on the rate and number of modifications. We present the basic hash history scheme and discuss mechanisms for trimming the history over time. We simulate the efficacy of hash his- tories on several large CVS traces. Our results highlight a useful property of the hash history: the ability to recognize when two different non-commutative operations produce the same output, thereby reducing false conflicts and increasing the rate of convergence. We call these events co- incidental equalities and demonstrate that their recognition can greatly reduce the time to global convergence.",
    pages = "670--677",
    file = ":auto/homes/drt24/Downloads/01203518.pdf:pdf",
    year = "2003",
    booktitle = "23rd International Conference on Distributed Computing Systems"
}

@inproceedings{Winstein2012,
    author = "Winstein, Keith and Balakrishnan, Hari",
    booktitle = "Usenix",
    year = "2012",
    file = "::",
    title = "{Mosh: An Interactive Remote Shell for Mobile Clients}"
}

@inproceedings{Winstein2012a,
    author = "Winstein, Keith and Balakrishnan, Hari",
    abstract = "This paper describes Mosh, a mobile shell application that supports intermittent connectivity, allows roaming, and provides speculative local echo of user keystrokes. Mosh is built on the State Synchronization Protocol, a new UDP-based protocol that securely synchronizes client and server state, even across client IP address changes. Mosh uses SSP to synchronize a character-cell terminal emulator. By maintaining the terminal state at both client and server, the Mosh client predicts the effect of user keystrokes and speculatively displays many of its predictions without waiting for the server to echo. For mobile clients, Mosh is considerably more usable than the Secure Shell (SSH) protocol for two reasons. First, unlike SSH, it maintains sessions across periods of disconnection and changes in network address. Second, by speculatively echoing keystrokes locally, Mosh im- proves interactivity over high- or variable-delay network paths. Our evaluation analyzed keystroke traces from six different users covering a period of 40 hours of real- world usage and including 9,986 keystrokes. Mosh was able to display immediately the effects of 70\% of the user keystrokes. Over a commercial EV-DO (3G) network, median keystroke response latency with Moshwas 4.8 ms, compared with 503 ms for SSH. Mosh erred in predicting the keystroke response 0.9\% of the time, but removed the error from the screen after at most one round-trip time.",
    year = "2012",
    booktitle = "USENIX ATC",
    file = ":auto/homes/drt24/Downloads/mosh-paper-draft.pdf:pdf",
    title = "{Mosh : An Interactive Remote Shell for Mobile Clients State Synchronization Protocol}"
}

@inproceedings{Wobbrock2007,
    author = "Wobbrock, Jacob O and Hall, Mary Gates and Wilson, Andrew D",
    title = "{Gestures without Libraries , Toolkits or Training : A \$ 1 Recognizer for User Interface Prototypes}",
    abstract = "Although mobile, tablet, large display, and tabletop computers increasingly present opportunities for using pen, finger, and wand gestures in user interfaces, implementing gesture recognition largely has been the privilege of pattern matching experts, not user interface prototypers. Although some user interface libraries and toolkits offer gesture recognizers, such infrastructure is often unavailable in design-oriented environments like Flash, scripting environments like JavaScript, or brand new off-desktop prototyping environments. To enable novice programmers to incorporate gestures into their UI prototypes, we present a “\$1 recognizer” that is easy, cheap, and usable almost anywhere in about 100 lines of code. In a study comparing our \$1 recognizer, Dynamic Time Warping, and the Rubine classifier on user-supplied gestures, we found that \$1 obtains over 97\% accuracy with only 1 loaded template and 99\% accuracy with 3+ loaded templates. These results were nearly identical to DTW and superior to Rubine. In addition, we found that medium-speed gestures, in which users balanced speed and accuracy, were recognized better than slow or fast gestures for all three recognizers. We also discuss the effect that the number of templates or training examples has on recognition, the score falloff along recognizers’ N-best lists, and results for individual gestures. We include detailed pseudocode of the \$1 recognizer to aid development, inspection, extension, and testing.",
    year = "2007",
    file = "::",
    address = "New York, New York, USA",
    keywords = "all or part of,dynamic time warping,gesture recognition,marks,or hard copies of,permission to make digital,rapid prototyping,recognition rates,rubine,statistical classifiers,strokes,symbols,this work for,unistrokes,user interfaces",
    booktitle = "Proceedings of the 20th annual ACM symposium on User interface software and technology",
    pages = "159--168"
}

@article{Wognsen2012,
    author = "Wognsen, Erik Ramsgaard and Karlsen, Henrik S\o ndberg",
    abstract = "Malicious apps pose an important problem on Android, the world’s most popular smart- phone operating system. Android apps are typically written in Java and compiled to run on the register based Dalvik virtual ma- chine. Static analysis can approximate pro- gram behaviour and this approximation can be used to find malicious behaviour, for ex- ample covert sending of expensive text mes- sages. We expand our original operational seman- tics for the Dalvik instruction set to more accurately model the Android implementa- tion, and we update our control flow analy- sis with these changes and improve its pre- cision to achieve useful results when analyz- ing real apps. The analysis is further ex- panded to include support for reflection and Javascript interfaces, two dynamic features that are used extensively in popular Android apps. Finally, we implement a prototype of the analysis which is able to create call graphs and run on real-world apps.",
    year = "2012",
    file = ":home/drt24/Downloads/rapport.pdf:pdf",
    title = "{Static Analysis of Dalvik Bytecode and Reflection in Android}"
}

@book{Woodwark1992,
    author = "Woodwark, John",
    publisher = "Information Geometers",
    isbn = "1 874728 00 3",
    title = "{How to run a paper mill: Writing technical papers and getting them published}",
    url = "http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:How+to+run+a+paper+mill\#0",
    file = ":auto/homes/drt24/Downloads/pmill.pdf:pdf",
    year = "1992"
}

@phdthesis{Wright2014,
    author = "Wright, Jason L.",
    school = "University of Idaho",
    title = "{Software vulnerabilities: lifespans, metrics, and case study}",
    url = "http://www.thought.net/thesis/thesis.pdf",
    abstract = "It is difficult for end-users to judge the risk posed by software security vulnerabilities. This thesis examines three aspects of the software security vulnerability ecosystem to determine if commonly used metrics are based on sound engineering principals. First, the decision by several security research firms to decrease the grace period before publicly releasing vulnerability details was examined. No evidence was found suggest that periods less than 6 months are effective. Second, two new metrics are presented which are more easily computed, repeatable, and verifiable than previous metrics. Both metrics provide the ability to compare software packages based on number of vulnerabilities and vendor response time. Third, metrics based strictly on known vulnerabilities are brought into question. The number of bugs which represent vulnerabilities is estimated for a particular package and the estimated number of resulting vulnerabilities is found to be far greater than the currently known vulnerabilities.",
    number = "May",
    file = ":home/drt24/Downloads/thesis (1).pdf:pdf",
    year = "2014"
}

@article{Wulf1974,
    author = "Wulf, W. and Cohen, E. and Corwin, W. and Jones, A. and Levin, Roy and Pierson, C. and Pollack, F.",
    doi = "10.1145/355616.364017",
    title = "{HYDRA: the kernel of a multiprocessor operating system}",
    url = "http://portal.acm.org/citation.cfm?doid=355616.364017",
    journal = "Communications of the ACM",
    issn = "00010782",
    number = "6",
    month = "6",
    volume = "17",
    file = ":auto/homes/drt24/Downloads/10.1.1.62.8610.pdf:pdf",
    year = "1974",
    keywords = "2,3,4,6,and phrases,cr categories,kernel,nucleus,operating system,protection,security",
    pages = "337--345"
}

@inproceedings{Wustrow2011,
    author = "Wustrow, Eric and Wolchok, Scott and Goldberg, Ian and Halderman, J. Alex",
    title = "{Telex: Anticensorship in the network infrastructure}",
    url = "http://www.usenix.org/events/sec/tech/full_papers/Wustrow.pdf",
    abstract = "In this paper, we present Telex, a new approach to resisting state-level Internet censorship. Rather than at- tempting to win the cat-and-mouse game of finding open proxies, we leverage censors’ unwillingness to completely block day-to-day Internet access. In effect, Telex converts innocuous, unblocked websites into proxies, without their explicit collaboration. We envision that friendly ISPs would deploy Telex stations on paths between censors’ networks and popular, uncensored Internet destinations. Telex stations would monitor seemingly innocuous flows for a special “tag” and transparently divert them to a for- bidden website or service instead. We propose a new cryptographic scheme based on elliptic curves for tagging TLS handshakes such that the tag is visible to a Telex station but not to a censor. In addition, we use our tagging scheme to build a protocol that allows clients to connect to Telex stations while resisting both passive and active at- tacks. We also present a proof-of-concept implementation that demonstrates the feasibility of our system.",
    file = ":auto/homes/drt24/Downloads/Wustrow.pdf:pdf",
    year = "2011",
    booktitle = "proceedings of the 20th USENIX Security Symposium"
}

@article{Xing2014,
    author = "Xing, Luyi and Pan, Xiaorui and Wang, R and Yuan, Kan and Wang, XF",
    title = "{Upgrading Your Android, Elevating My Malware: Privilege Escalation Through Mobile OS Updating}",
    url = "http://www.informatics.indiana.edu/xw7/papers/privilegescalationthroughandroidupdating.pdf",
    abstract = "Android is a fast evolving system, with new updates coming out one after another. These updates often completely overhaul a running system, replacing and adding tens of thou- sands of files across Android’s complex architecture, in the presence of critical user data and applications (apps for short). To avoid accidental damages to such data and existing apps, the upgrade process involves complicated program logic, whose security implications, however, are less known. In this paper, we report the first systematic study on the Android updating mechanism, focusing on its Package Management Service (PMS). Our research brought to light a new type of security-critical vulnerabilities, called Pileup flaws, through which a malicious app can strategically declare a set of privileges and attributes on a low-version operating system (OS) and wait until it is upgraded to escalate its privileges on the new system. Specifically, we found that by exploiting the Pileup vulnerabilities, the app can not only acquire a set of newly added system and signature permissions but also determine their settings (e.g., protection levels), and it can further substitute for new system apps, contaminate their data (e.g., cache, cookies of Android default browser) to steal sensitive user information or change security configurations, and prevent installation of critical system services. We systematically analyzed the source code of PMS using a program verification tool and confirmed the presence of those security flaws on all Android official versions and over 3,000 customized versions. Our research also identified hundreds of exploit opportunities the adversary can leverage over thousands of devices across different device manufacturers, carriers and countries. To mitigate this threat without endangering user data and apps during an upgrade, we also developed a new detection service, called SecUP, which deploys a scanner on the user’s device to capture the malicious apps designed to exploit Pileup vulnerabilities, based upon the vulnerability-related information automatically collected from newly released Android OS images.",
    file = ":home/drt24/Downloads/privilegescalationthroughandroidupdating.pdf:pdf",
    year = "2014",
    journal = "IEEE Security and Privacy"
}

@article{Xu2012,
    author = "Xu, Rubin and Saıdi, Hassen and Anderson, Ross",
    publisher = "USENIX",
    title = "{Aurasium: Practical Policy Enforcement for Android Applications}",
    url = "https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final60.pdf",
    abstract = "The increasing popularity of Google’s mobile platform Android makes it the prime target of the latest surge in mobile malware. Most research on enhancing the platform’s security and privacy controls requires extensive modification to the operating system, which has significant usability issues and hinders efforts for widespread adoption. We develop a novel solution called Aurasium that bypasses the need to modify the Android OS while providing much of the security and privacy that users desire. We automatically repackage arbitrary applications to attach user-level sandboxing and policy enforcement code, which closely watches the application’s behavior for security and privacy violations such as attempts to retrieve a user’s sensitive information, send SMS covertly to premium numbers, or access malicious IP addresses. Aurasium can also detect and prevent cases of privilege escalation attacks. Experiments show that we can apply this solution to a large sample of benign and malicious applications with a near 100 percent success rate, with- out significant performance and space overhead. Aura- sium has been tested on three versions of the Android OS, and is freely available.",
    file = ":home/drt24/Downloads/sec12-final60.pdf:pdf",
    year = "2012",
    journal = "Proceedings of the 21st USENIX conference on Security symposium"
}

@article{Xu2013,
    author = "Xu, Tianyin and Zhang, Jiaqi and Huang, Peng and Zheng, Jing and Sheng, Tianwei and Yuan, Ding and Zhou, Yuanyuan and Pasupathy, Shankar",
    publisher = "ACM Press",
    doi = "10.1145/2517349.2522727",
    isbn = "9781450323888",
    title = "{Do not blame users for misconfigurations}",
    url = "http://dl.acm.org/citation.cfm?doid=2517349.2522727",
    journal = "Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles - SOSP '13",
    year = "2013",
    file = ":home/drt24/Downloads/sosp13.pdf:pdf",
    address = "New York, New York, USA",
    keywords = "constraint,inference,misconfiguration,testing,vulnerability",
    pages = "244--259"
}

@inproceedings{Ye2012,
    author = "Ye, Haibo and Gu, Tao and Zhu, Xiaorui and Xu, Jinwei and Tao, Xianping and Lu, Jian and Jin, Ning",
    publisher = "IEEE",
    doi = "10.1109/PerCom.2012.6199843",
    isbn = "978-1-4673-0258-6",
    language = "English",
    title = "{FTrack: Infrastructure-free floor localization via mobile phone sensing}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6199843",
    abstract = "Mobile phone localization plays a key role in the fast-growing Location Based Applications domain. Most of the existing localization schemes rely on infrastructure support such as GSM, WiFi or GPS. In this paper, we present FTrack, a novel floor localization system to identify the floor level in a multi-floor building on which a mobile user is located. FTrack uses the mobile phone's accelerometer only without any infrastructure support. It does not require any prior knowledge of the building such as floor height. By capturing user encounters and analyzing user trails, FTrack finds the mapping from the traveling time (when taking the elevator) or the step counts (when walking on the stairs) between any two floors to the number of floor levels. The mapping can then be used for mobile users to pinpoint their current floor levels. We conduct both simulation and field studies to demonstrate the effectiveness of FTrack. Our field trial in a 10-floor building shows that FTrack achieves an accuracy of over 90\% after two hours in our experiment.",
    month = "3",
    pages = "2--10",
    file = "::",
    year = "2012",
    keywords = "Acceleration,Accelerometer,Elevators,FTrack,Floor Localization,Legged locomotion,Merging,Mobile Phone Localization,Mobile communication,Servers,accelerometers,floor level identification,infrastructure-free floor localization,location based applications,mobile phone sensing,mobility management (mobile radio),multifloor building,step counts,traveling time,user encounters,user trail analysis",
    booktitle = "2012 IEEE International Conference on Pervasive Computing and Communications"
}

@article{Ye2012a,
    author = "Ye, Juan and Dobson, Simon and McKeever, Susan",
    doi = "10.1016/j.pmcj.2011.01.004",
    title = "{Situation identification techniques in pervasive computing: A review}",
    url = "http://dx.doi.org/10.1016/j.pmcj.2011.01.004",
    abstract = "Pervasivesystems must offer an open, extensible, and evolving portfolio of services which integrate sensor data from a diverse range of sources. The core challenge is to provide appropriate and consistent adaptive behaviours for these services in the face of huge volumes of sensor data exhibiting varying degrees of precision, accuracy and dynamism. Situation identification is an enabling technology that resolves noisy sensor data and abstracts it into higher-level concepts that are interesting to applications. We provide a comprehensive analysis of the nature and characteristics of situations, discuss the complexities of situation identification, and review the techniques that are most popularly used in modelling and inferring situations from sensor data. We compare and contrast these techniques, and conclude by identifying some of the open research opportunities in the area.",
    issn = "15741192",
    number = "1",
    month = "2",
    volume = "8",
    pages = "36--66",
    file = "::",
    year = "2012",
    keywords = "context modelling,data mining,machine learning,ontologies,pervasive computing,situation identification,temporal reasoning,uncertain reasoning",
    journal = "Pervasive and Mobile Computing"
}

@article{Ye2012b,
    author = "Ye, Haibo and Gu, Tao and Zhu, Xiaorui and Xu, Jinwei and Tao, Xianping and Lu, Jian and Jin, Ning",
    isbn = "9781467302586",
    title = "{FTrack : Infrastructure-free Floor Localization via Mobile Phone Sensing}",
    journal = "Encounter",
    abstract = "Mobile phone localization plays a key role in the fast-growing Location Based Applications domain. Most of the existing localization schemes rely on infrastructure support such as GSM, WiFi or GPS. In this paper, we present FTrack, a novel floor localization system to identify the floor level in a multi- floor building on which a mobile user is located. FTrack uses the mobile phones accelerometer only without any infrastructure support. It does not require any prior knowledge of the building such as floor height. By capturing user encounters and analyzing user trails, FTrack finds the mapping from the traveling time (when taking the elevator) or the step counts (when walking on the stairs) between any two floors to the number of floor levels. The mapping can then be used for mobile users to pinpoint their current floor levels.We conduct both simulation and field studies to demonstrate the effectiveness of FTrack. Our field trial in a 10-floor building shows that FTrack achieves an accuracy of over 90\% after two hours in our experiment.",
    number = "March",
    year = "2012",
    keywords = "ac,floor localization,mobile phone localization",
    pages = "2--10"
}

@article{Yee2009,
    author = "Yee, Bennet and Sehr, David and Dardyk, Gregory and Chen, J Bradley and Muth, Robert and Ormandy, Tavis and Okasaka, Shiki and Narula, Neha and Fullagar, Nicholas",
    publisher = "Ieee",
    doi = "10.1109/SP.2009.25",
    isbn = "9780769536330",
    title = "{Native Client: A Sandbox for Portable, Untrusted x86 Native Code}",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5207638",
    series = "Proceedings of the IEEE Symposium on Security and Privacy",
    abstract = "This paper describes the design, implementation and eval- uation of Native Client, a sandbox for untrusted x86 native code. Native Client aims to give browser-based applications the computational performance of native applications with- out compromising safety. Native Client uses software fault isolation and a secure runtime to direct system interaction and side effects through interfaces managed by Native Client. Native Client provides operating system portability for binary code while supporting performance-oriented fea- tures generally absent from web application programming environments, such as thread support, instruction set ex- tensions such as SSE, and use of compiler intrinsics and hand-coded assembler. We combine these properties in an open architecture that encourages community review and 3rd-party tools.",
    issn = "10816011",
    number = "1",
    pages = "79--93",
    volume = "53",
    file = ":home/drt24/Downloads/05207638.pdf:pdf",
    year = "2009",
    journal = "2009 30th IEEE Symposium on Security and Privacy"
}

@inproceedings{Yin2011,
    author = "Yin, Zuoning and Ma, Xiao and Zheng, Jing and Zhou, Yuanyuan and Bairavasundaram, Lakshmi N. and Pasupathy, Shankar",
    publisher = "ACM Press",
    doi = "10.1145/2043556.2043572",
    isbn = "9781450309776",
    title = "{An empirical study on configuration errors in commercial and open source systems}",
    url = "http://dl.acm.org/citation.cfm?doid=2043556.2043572",
    abstract = "Configuration errors (i.e., misconfigurations) are among the dominant causes of system failures. Their importance has inspired many research efforts on detecting, diagnosing, and fixing misconfigurations; such research would benefit greatly from a real-world charac- teristic study on misconfigurations. Unfortunately, few such studies have been conducted in the past, primarily because historical misconfigurations usually have not been recorded rigorously in databases. In this work, we undertake one of the first attempts to conduct a real-world misconfigura- tion characteristic study. We study a total of 546 real world misconfigurations, including 309 misconfigurations from a commercial storage system deployed at thousands of cus- tomers, and 237 from four widely used open source systems (CentOS, MySQL, Apache HTTP Server, and OpenLDAP). Some of our major findings include: (1) A majority of misconfigurations (70.0\%∼85.5\%) are due to mistakes in setting configuration parame- ters; however, a significant number of misconfigurations are due to compatibility issues or component configurations (i.e., not parameter-related). (2) 38.1\%∼53.7\% of parameter mistakes are caused by illegal parameters that clearly violate some format or rules, mo- tivating the use of an automatic configuration checker to detect these misconfigurations. (3) A significant percentage (12.2\%∼29.7\%) of parameter-based mistakes are due to incon- sistencies between different parameter values. (4) 21.7\%∼57.3\% of the misconfigurations involve configurations external to the examined system, some even on entirely different hosts. (5) A significant portion of misconfigurations can cause hard-to-diagnose failures, such as crashes, hangs, or severe performance degradation, indicating that systems should be better-equipped to handle misconfigurations.",
    year = "2011",
    pages = "159",
    file = ":auto/homes/drt24/Downloads/12-yin-online.pdf:pdf",
    address = "Cascais, Portugal",
    keywords = "Misconfigurations,characteristic study",
    booktitle = "SOSP"
}

@inproceedings{York2012,
    author = "York, Dan",
    title = "{Challenges and Opportunities In Deploying DNSSEC A progress report on an investigation into DNSSEC deployment}",
    url = "http://conferences.npl.co.uk/satin/papers/satin2012-York.pdf",
    abstract = "In the process of building a web portal[1] focused on providing real-world deployment information about DNS Security Extensions (DNSSEC), Internet Society staff identified a number of areas where DNSSEC deployment can be simplified for domain name holders, domain name infrastructure operators and domain name consumers (i.e. users of DNSSEC-signed domains). Some areas were predictably around the need for more education of consumers, businesses, developers and network operators about DNSSEC. Other areas, though, were more involved with the process involved in signing domains and also in bootstrapping the overall process of using DNSSEC. This paper outlines the challenges identified so far and offers suggestions on how to overcome those challenges.",
    file = ":auto/homes/drt24/Ubuntu One/Documents/satin2012/papers/satin2012-York.pdf:pdf",
    year = "2012",
    booktitle = "SATIN"
}

@inproceedings{Yu2010,
    author = "Yu, Bin and Wang, Le and Manner, Jukka",
    publisher = "IEEE",
    doi = "10.1109/GreenCom-CPSCom.2010.128",
    isbn = "978-1-4244-9779-9",
    title = "{Energy-Efficient Web Access on Mobile Devices}",
    url = "http://portal.acm.org/citation.cfm?id=1953383.1953443",
    booktitle = "2010 IEEE/ACM Int'l Conference on Green Computing and Communications \& Int'l Conference on Cyber, Physical and Social Computing",
    mendeley-tags = "energy,measure,mobile,network,power,wifi",
    month = "12",
    file = "::",
    year = "2010",
    keywords = "Mobile services,energy,lossless data compression,measure,mobile,network,power,wifi,wireless communications",
    pages = "442--447"
}

@article{Yuan2010,
    author = "Yuan, Ding and Mai, Haohui and Xiong, Weiwei and Tan, Lin and Zhou, Yuanyuan and Pasupathy, Shankar",
    doi = "10.1145/1735971.1736038",
    isbn = "978-1-60558-839-1",
    title = "{SherLog}",
    url = "http://dl.acm.org/citation.cfm?id=1735971.1736038",
    journal = "ACM SIGPLAN Notices",
    issn = "03621340",
    number = "3",
    month = "3",
    volume = "45",
    year = "2010",
    keywords = "failure diagnostics,log,static analysis",
    pages = "143"
}

@inproceedings{Zaharia2010,
    author = "Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J. and Shenker, Scott and Stoica, Ion",
    title = "{Spark: cluster computing with working sets}",
    url = "http://dl.acm.org/citation.cfm?id=1863103.1863113",
    abstract = "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
    month = "6",
    file = "::",
    year = "2010",
    booktitle = "HotCloud'10 Proceedings of the 2nd USENIX conference on Hot topics in cloud computing",
    pages = "10"
}

@article{Zeqian,
    author = "Zeqian, Shen; Kwan-Liu Ma;",
    isbn = "9781424419661",
    title = "{MobiVis : A Visualization System for Exploring Mobile Data}",
    abstract = {The widespread use of mobile devices brings opportunities to capture large-scale, continuous information about human behavior. Mobile data has tremendous value, leading to business opportunities, market strategies, security concerns, etc. Visual analytics systems that support interactive exploration and discovery are needed to extracting insight from the data. However, visual analysis of complex social-spatial-temporal mobile data presents several challenges. We have created MobiVis, a visual analytics tool, which incorporates the idea of presenting social and spatial information in one heterogeneous network. The system supports temporal and semantic filtering through an interactive time chart and ontology graph, respectively, such that data subsets of interest can be isolated for close-up investigation. "Behavior rings," a compact radial representation of individual and group behaviors, is introduced to allow easy comparison of behavior patterns. We demonstrate the capability of MobiVis with the results obtained from analyzing the MIT Reality Mining dataset.},
    number = "VIDi",
    pages = "175--182",
    file = "::",
    keywords = "3,5,6,computer graphics,h,i,index terms,information systems,information visualization,interaction techniques,methodology and,mobile data,social-spatial-temporal data visualiza-,techniques,tion,visual analytics",
    journal = "Visualization Symposium, 2008. PacificVIS '08. IEEE Pacific"
}

@article{Zhang2010,
    author = "Zhang, Lide and Tiwana, B and Qian, Z and Wang, Zhaoguang and Dick, RP and Mao, Z.M. and Yang, L.",
    title = "{Accurate Online Power Estimation and Automatic Battery Behavior Based Power Model Generation for Smartphones}",
    url = "http://ziyang.eecs.umich.edu/projects/powertutor/camera-ready.pdf",
    journal = "International Conference on Hardware/Software Codesign and System Synthesis",
    file = "::",
    year = "2010",
    keywords = "battery,mobile phones,power modeling"
}

@inproceedings{Zhang2010a,
    author = "Zhang, Lide and Tiwana, Birjodh and Qian, Zhiyun and Wang, Zhaoguang and Dick, Robert P. and Mao, Zhuoqing Morley and Yang, Lei",
    publisher = "ACM Press",
    doi = "10.1145/1878961.1878982",
    isbn = "9781605589053",
    title = "{Accurate online power estimation and automatic battery behavior based power model generation for smartphones}",
    url = "http://ziyang.eecs.umich.edu/projects/powertutor/camera-ready.pdf http://portal.acm.org/citation.cfm?doid=1878961.1878982 http://dl.acm.org/citation.cfm?id=1878961.1878982",
    abstract = "This paper describes PowerBooter, an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor, a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants, which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined, PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.",
    year = "2010",
    mendeley-tags = "energy,fuelgauge,measure,mobile,power",
    month = "10",
    pages = "105",
    file = "::;::",
    address = "New York, New York, USA",
    keywords = "battery,energy,fuelgauge,measure,mobile,mobile phones,power,power modeling",
    booktitle = "Proceedings of the eighth IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis - CODES/ISSS '10"
}

@inproceedings{Zhang2011,
    author = "Zhang, Olive Qing and Kirchberg, Markus and Ko, Ryan K.L. and Lee, Bu Sung",
    publisher = "IEEE",
    doi = "10.1109/CloudCom.2011.66",
    isbn = "978-1-4673-0090-2",
    title = "{How to Track Your Data: The Case for Cloud Computing Provenance}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6133175\&contentType=Conference+Publications\&searchField=Search_All\&queryText=how+to+track+your+data",
    abstract = "Provenance, a meta-data describing the derivation history of data, is crucial for the uptake of cloud computing to enhance reliability, credibility, accountability, transparency, and confidentiality of digital objects in a cloud. In this paper, we survey current mechanisms that support provenance for cloud computing, we classify provenance according to its granularities encapsulating the various sets of provenance data for different use cases, and we summarize the challenges and requirements for collecting provenance in a cloud, based on which we show the gap between current approaches to requirements. Additionally, we propose our approach, Data PROVE, that aims to effectively and efficiently satisfy those challenges and requirements in cloud provenance, and to provide a provenance supplemented cloud for better integrity and safety of customers' data.",
    month = "11",
    year = "2011",
    booktitle = "2011 IEEE Third International Conference on Cloud Computing Technology and Science",
    pages = "446--453"
}

@inproceedings{Zhang2012,
    author = "Zhang, Olive Qing and Ko, Ryan K.L. and Kirchberg, Markus and Suen, Chun Hui and Jagadpramana, Peter and Lee, Bu Sung",
    publisher = "IEEE",
    doi = "10.1109/TrustCom.2012.175",
    isbn = "978-1-4673-2172-3",
    title = "{How to Track Your Data: Rule-Based Data Provenance Tracing Algorithms}",
    url = "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=6296150\&contentType=Conference+Publications\&searchField=Search_All\&queryText=how+to+track+your+data",
    abstract = "As cloud computing and virtualization technologies become mainstream, the need to be able to track data has grown in importance. Having the ability to track data from its creation to its current state or its end state will enable the full transparency and accountability in cloud computing environments. In this paper, we showcase a novel technique for tracking end-to-end data provenance, a meta-data describing the derivation history of data. This breakthrough is crucial as it enhances trust and security for complex computer systems and communication networks. By analyzing and utilizing provenance, it is possible to detect various data leakage threats and alert data administrators and owners; thereby addressing the increasing needs of trust and security for customers' data. We also present our rule-based data provenance tracing algorithms, which trace data provenance to detect actual operations that have been performed on files, especially those under the threat of leaking customers' data. We implemented the cloud data provenance algorithms into an existing software with a rule correlation engine, show the performance of the algorithms in detecting various data leakage threats, and discuss technically its capabilities and limitations.",
    month = "6",
    year = "2012",
    booktitle = "2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications",
    pages = "1429--1437"
}

@article{Zhang2012b,
    author = "Zhang, Yinqian and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas",
    publisher = "ACM Press",
    doi = "10.1145/2382196.2382230",
    isbn = "9781450316514",
    title = "{Cross-VM side channels and their use to extract private keys}",
    url = "http://dl.acm.org/citation.cfm?doid=2382196.2382230 https://mexico.rsa.com/rsalabs/presentations/cross-vm-side-channels.pdf",
    abstract = "This paper details the construction of an access-driven side- channel attack by which a malicious virtual machine (VM) extracts fine-grained information from a victim VM running on the same physical computer. This attack is the first such attack demonstrated on a symmetric multiprocessing system virtualized using a modern VMM (Xen). Such systems are very common today, ranging from desktops that use virtualization to sandbox application or OS compromises, to clouds that co-locate the workloads of mutually distrustful customers. Constructing such a side-channel requires overcoming challenges including core migration, numerous sources of channel noise, and the difficulty of preempting the victim with sufficient frequency to extract fine-grained information from it. This paper addresses these challenges and demonstrates the attack in a lab setting by extracting an ElGamal decryption key from a victim using the most recent version of the libgcrypt cryptographic library.",
    year = "2012",
    pages = "305",
    file = ":home/drt24/Downloads/p305-zhang.pdf:pdf;::",
    address = "New York, New York, USA",
    keywords = "cache-based side,cache-based side channel,cross-vm side channel,side-channel attack",
    journal = "Proceedings of the 2012 ACM conference on Computer and communications security - CCS '12"
}

@article{Zhang2013,
    author = "Zhang, Yang and Power, Russell and Zhou, Siyuan and Sovran, Yair and Aguilera, Marcos K and Li, Jinyang",
    isbn = "9781450323888",
    title = "{Transaction chains: achieving serializability with low latency in geo-distributed storage systems}",
    url = "http://www.news.cs.nyu.edu/~jinyang/pub/sosp13-lynx.pdf",
    abstract = "Currently, users of geo-distributed storage systems face a hard choice between having serializable transactions with high latency, or limited or no transactions with low latency. We show that it is possible to obtain both serializable transactions and low latency, under two conditions. First, transactions are known ahead of time, permitting an a priori static analysis of conflicts. Second, transactions are structured as transaction chains consisting of a sequence of hops, each hop modifying data at one server. To demonstrate this idea, we built Lynx, a geo-distributed storage system that offers transaction chains, secondary indexes, materialized join views, and geo-replication. Lynx uses static analysis to determine if each hop can execute separately while preserving serializability—if so, a client needs wait only for the first hop to complete, which occurs quickly. To evaluate Lynx, we built three applications: an auction service, a Twitter-like microblogging site and a social networking site. These applications successfully use chains to achieve low latency operation and good throughput.",
    file = ":home/drt24/Downloads/sosp13\_lynx.pdf:pdf",
    year = "2013",
    journal = "SOSP"
}

@inproceedings{Zhou2006,
    author = "Zhou, Chao and Lejeune, Christophe and B\'{e}nel, Aur\'{e}lien",
    publisher = "IOS Press",
    title = "{Towards a standard protocol for community-driven organizations of knowledge}",
    url = "http://portal.acm.org/citation.cfm?id=1566717",
    abstract = "This paper deals with the “Web 2.0”, where every user can contribute to the content, “harnessing collective intelligence”. After studying what makes the success of services like Google Base, Del.icio.us and the Open Directory Project, we propose a unifying “REST” protocol for this kind of community-driven organizations of knowledge. The aim is to make the collaboration possible beyond the boundaries of the software and of the resulting communities.",
    pages = "438--449",
    file = ":auto/homes/drt24/Downloads/10.1.1.93.6152.pdf:pdf",
    year = "2006",
    keywords = "0,communities,knowledge management,rest web,web 2",
    booktitle = "Proceeding of the 2006 conference on Leading the Web in Concurrent Engineering: Next Generation Concurrent Engineering"
}

@inproceedings{Zhou2012a,
    author = "Zhou, Yajin and Wang, Zhi and Zhou, Wu and Jiang, Xuxian",
    title = "{Hey, you, get off of my market: Detecting malicious apps in official and alternative Android markets}",
    url = "http://www.csd.uoc.gr/~hy558/papers/mal_apps.pdf",
    abstract = "In this paper, we present a systematic study for the detection of malicious applications (or apps) on popular Android Markets. To this end, we first propose a permission- based behavioral footprinting scheme to detect new samples of known Android malware families. Then we apply a heuristics-based filtering scheme to identify certain inherent behaviors of unknown malicious families. We imple- mented both schemes in a system called DroidRanger. The experiments with 204, 040 apps collected from five different Android Markets in May-June 2011 reveal 211 malicious ones: 32 from the official Android Market (0.02\% infection rate) and 179 from alternative marketplaces (infection rates ranging from 0.20\% to 0.47\%). Among those mali- cious apps, our system also uncovered two zero-day malware (in 40 apps): one from the official Android Market and the other from alternative marketplaces. The results show that current marketplaces are functional and rela- tively healthy. However, there is also a clear need for a rigorous policing process, especially for non-regulated alternative marketplaces.",
    number = "2",
    file = ":home/drt24/Downloads/mal\_apps.pdf:pdf",
    year = "2012",
    booktitle = "Network and Distributed System Security Symposium (NDSS)"
}

@article{Zhou2012b,
    author = "Zhou, Yajin and Jiang, Xuxian",
    publisher = "Ieee",
    doi = "10.1109/SP.2012.16",
    isbn = "978-1-4673-1244-8",
    title = "{Dissecting Android Malware: Characterization and Evolution}",
    journal = "2012 IEEE Symposium on Security and Privacy",
    abstract = "The popularity and adoption of smartphones has greatly stimulated the spread of mobile malware, especially on the popular platforms such as Android. In light of their rapid growth, there is a pressing need to develop effective solutions. However, our defense capability is largely constrained by the limited understanding of these emerging mobile malware and the lack of timely access to related samples. In this paper, we focus on the Android platform and aim to systematize or characterize existing Android malware. Particularly, with more than one year effort, we have managed to collect more than 1,200 malware samples that cover the majority of existing Android malware families, ranging from their debut in August 2010 to recent ones in October 2011. In addition, we systematically characterize them from various aspects, including their installation methods, activation mech- anisms as well as the nature of carried malicious payloads. The characterization and a subsequent evolution-based study of representative families reveal that they are evolving rapidly to circumvent the detection from existing mobile anti-virus software. Based on the evaluation with four representative mobile security software, our experiments show that the best case detects 79.6\% of them while the worst case detects only 20.2\% in our dataset. These results clearly call for the need to better develop next-generation anti-mobile-malware solutions.",
    issn = "10816011",
    number = "4",
    month = "5",
    volume = "0",
    url = "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6234407",
    pages = "95--109",
    file = ":home/drt24/Downloads/OAKLAND12.pdf:pdf;:home/drt24/Downloads/06234407.pdf:pdf",
    year = "2012",
    keywords = "android malware,smartphone security",
    institution = "IEEE"
}

@article{Zhu2011,
    author = "Zhu, David (Yu) and Jung, Jaeyeon and Song, Dawn and Kohno, Tadayoshi and Wetherall, David",
    doi = "10.1145/1945023.1945039",
    title = "{TaintEraser: protecting sensitive data leaks using application-level taint tracking}",
    url = "http://dl.acm.org/citation.cfm?id=1945023.1945039",
    journal = "ACM SIGOPS Operating Systems Review",
    issn = "01635980",
    number = "1",
    month = "2",
    volume = "45",
    file = "::",
    year = "2011",
    keywords = "dynamic information flow tracking,privacy,sensitive data protection",
    pages = "142"
}

@article{Zitzewitz2011,
    author = "Zitzewitz, Eric",
    title = "{Forensic Economics}",
    url = "http://www.dartmouth.edu/~ericz/forensic.pdf",
    abstract = {A new meta-field of "forensic economics" has begun to emerge, uncovering evidence of hidden behavior in a variety of domains. Examples include teachers cheating on exams, road builders skimping on materials, violations of U.N. sanctions, unnecessary heart surgeries, and racial biases in employment decisions, traffic stops, auto retailing, and even sports judging. In each case, part of the contribution of economic analysis is in uncovering evidence of wrongdoing. Although research questions differ, forensic economic work shares commonalities in approaches and limitations. This article seeks to draw out the common threads, with the hope of stimulating further research across fields.},
    number = "February",
    file = ":home/drt24/Downloads/forensic.pdf:pdf",
    year = "2011",
    journal = "Journal of Economic Literature"
}

@article{Ziv1977,
    author = "Ziv, J. and Lempel, A.",
    doi = "10.1109/TIT.1977.1055714",
    title = "{A universal algorithm for sequential data compression}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1055714",
    abstract = "A universal algorithm for sequential data compression is presented. Its performance is investigated with respect to a nonprobabilistic model of constrained sources. The compression ratio achieved by the proposed universal code uniformly approaches the lower bounds on the compression ratios attainable by block-to-variable codes and variable-to-block codes designed to match a completely specified source.",
    issn = "0018-9448",
    number = "3",
    month = "5",
    volume = "23",
    pages = "337--343",
    year = "1977",
    journal = "IEEE Transactions on Information Theory"
}

@article{Zovi2011,
    author = "Zovi, DA Dai",
    url = "http://media.blackhat.com/bh-us-11/DaiZovi/BH_US_11_DaiZovi_iOS_Security_WP.pdf",
    journal = "Black Hat USA, July",
    year = "2011",
    file = ":home/drt24/Downloads/BH\_US\_11\_DaiZovi\_iOS\_Security\_WP.pdf:pdf",
    title = "{Apple iOS 4 security evaluation}"
}

@inproceedings{abadi1994prudent,
    author = "Abadi, H. and Needham, R.",
    publisher = "IEEE",
    title = "{Prudent engineering practice for cryptographic protocols}",
    url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=296587",
    booktitle = "Research in Security and Privacy, 1994. Proceedings., 1994 IEEE Computer Society Symposium on",
    file = "::",
    year = "1994",
    pages = "122--136"
}

@article{anderson2009information,
    author = "Anderson, R. and Moore, T.",
    publisher = "The Royal Society",
    title = "{Information security: where computer science, economics and psychology meet}",
    url = "http://rsta.royalsocietypublishing.org/content/367/1898/2717.short",
    journal = "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences",
    number = "1898",
    volume = "367",
    year = "2009",
    pages = "2717--2727"
}

@online{androidvulnerabilities.org,
    author = "Thomas, Daniel R. and Beresford, Alastair R.",
    url = "http://androidvulnerabilities.org/",
    urldate = "http://androidvulnerabilities.org/",
    title = "{AndroidVulnerabilities.org}"
}

@inproceedings{bellovin1995using,
    author = "Bellovin, S.M.",
    url = "http://www.usenix.org/publications/library/proceedings/security95/full_papers/bellovin.pdf",
    booktitle = "Proceedings of the Fifth Usenix UNIX Security Syposium, Salt Lake City, UT",
    year = "1995",
    title = "{Using the domain name system for system break-ins}"
}

@inproceedings{bonneau2010password,
    author = "Bonneau, J. and Preibusch, S.",
    url = "http://www.preibusch.de/publications/Bonneau_Preibusch__password_thicket.pdf",
    booktitle = "The Ninth Workshop on the Economics of Information Security, WEIS",
    year = "2010",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonneau, Preibusch - 2010 - The password thicket technical and market failures in human authentication on the web.pdf:pdf",
    title = "{The password thicket: technical and market failures in human authentication on the web}"
}

@article{burrows1989logic,
    author = "Burrows, M. and Abadi, M. and Needham, R.M.",
    publisher = "The Royal Society",
    title = "{A logic of authentication}",
    url = "http://rspa.royalsocietypublishing.org/content/426/1871/233.short",
    journal = "Proceedings of the Royal Society of London. A. Mathematical and Physical Sciences",
    number = "1871",
    volume = "426",
    file = "::",
    year = "1989",
    pages = "233--271"
}

@online{codeaurora-security-advisories,
    url = "https://www.codeaurora.org/projects/security-advisories",
    title = "{Code Aurora security advisories}"
}

@online{cve-details,
    url = "http://www.cvedetails.com/",
    title = "{CVE details}"
}

@inproceedings{florêncio2010security,
    author = "Flor\^{e}ncio, D. and Herley, C.",
    publisher = "ACM",
    title = "{Where do security policies come from?}",
    url = "http://dl.acm.org/citation.cfm?id=1837110.1837124",
    booktitle = "Proceedings of the Sixth Symposium on Usable Privacy and Security",
    file = ":home/drt24/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Florencio, Herley - 2010 - Where do security policies come from.pdf:pdf",
    year = "2010",
    pages = "10"
}

@article{hall2011resilience,
    author = "Hall, C. and Anderson, R. and Clayton, R. and Ouzounis, E. and Trimintzios, P.",
    url = "http://weis2011.econinfosec.org/papers/Resilience of the Internet Interconnection Ecosystem.pdf",
    journal = "European Network and Information Security Agency",
    year = "2011",
    file = "::",
    title = "{Resilience of the Internet Interconnection Ecosystem}"
}

@online{jelly-bean-release,
    author = "Inc., Google",
    url = "https://developer.android.com/about/versions/jelly-bean.html",
    title = "{Jelly Bean version information}"
}

@inproceedings{margo2009case,
    author = "Margo, D.W. W and Seltzer, Margo",
    publisher = "USENIX Association",
    title = "{The case for browser provenance}",
    url = "http://dl.acm.org/citation.cfm?id=1525941",
    booktitle = "First workshop on on Theory and practice of provenance",
    file = "::",
    year = "2009",
    organization = "USENIX Association",
    pages = "9"
}

@article{nature-editorial-2012,
    publisher = "Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.",
    doi = "10.1038/486293a",
    shorttitle = "Nature",
    title = "{Time to open up (Editorial)}",
    url = "http://dx.doi.org/10.1038/486293a",
    abstract = "If scientists want the public to continue to volunteer for research projects, they must learn to be a lot more forthcoming about the ways in which the information they garner will be used.",
    issn = "1476-4687",
    number = "7403",
    month = "6",
    volume = "486",
    pages = "293",
    file = "::",
    year = "2012",
    keywords = "Consent Forms,Consent Forms: ethics,Humans,Informed Consent,Informed Consent: ethics,Informed Consent: standards",
    pmid = "22722149",
    journal = "Nature"
}

